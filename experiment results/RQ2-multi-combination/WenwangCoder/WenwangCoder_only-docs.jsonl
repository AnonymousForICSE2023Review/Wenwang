{"file_path": "neo4j/_codec/hydration/v1/temporal.py", "project": "neo4j/neo4j-python-driver", "name": "hydrate_time", "docstring": "Hydrator for `Time` and `LocalTime` values.\n\n:param nanoseconds:\n:param tz:\n:return: Time", "ques_id": "62e60f43d76274f8a4026e28", "code": ["def hydrate_time(nanoseconds, tz=None):\n    if nanoseconds < 0:\n        return LocalTime(nanoseconds)\n    else:\n        return Time(nanoseconds, tz)\n", "def hydrate_time(nanoseconds, tz=None):\n    if not isinstance(nanoseconds, int):\n        raise ValueError('Nanoseconds must be an integer')\n    if nanoseconds < 0:\n        raise ValueError('Nanoseconds must be greater than 0')\n    if tz is not None and not isinstance(tz, tzinfo):\n        raise ValueError('tz must be a subclass of datetime.tzinfo')\n\n    return Time(nanoseconds / 1000000000, tz=tz)\n", "def hydrate_time(nanoseconds, tz=None):\n    if tz is None:\n        tz = get_current_timezone()\n\n    return Time(nanoseconds, tz=tz)\n", "def hydrate_time(nanoseconds, tz=None):\n    if tz is None:\n        return Time(nanoseconds // 1000000000, tz=UTC)\n\n    if isinstance(tz, tuple):\n        return Time(nanoseconds // 1000000000, tz=tz[0], tzinfo=tz[1])\n    else:\n        return Time(nanoseconds // 1000000000, tz=tz)\n", "def hydrate_time(nanoseconds, tz=None):\n    if not isinstance(nanoseconds, int):\n        raise ValueError(\"Nanos must be an int\")\n    if nanoseconds < 0:\n        raise ValueError(\"Nanos must be greater than 0\")\n\n    if tz is None:\n        tz = pytz.utc\n\n    offset = tz.utcoffset(datetime.datetime.utcnow())\n    nanos = int(nanoseconds + offset.total_seconds())\n    return tz.localize(datetime.datetime.utcfromtimestamp(nanos))\n", "def hydrate_time(nanoseconds, tz=None):\n    if tz is not None:\n        return LocalTime(nanoseconds, tz)\n    else:\n        return Time(nanoseconds)\n", "def hydrate_time(nanoseconds, tz=None):\n    if tz is not None:\n        return LocalTime(nanoseconds, tz)\n    else:\n        return Time(nanoseconds)\n", "def hydrate_time(nanoseconds, tz=None):\n    if tz is None:\n        tz = timezone.utc\n\n    return Time(nanoseconds / 1000000000, tz=tz)\n", "def hydrate_time(nanoseconds, tz=None):\n    if nanoseconds == 0:\n        return LocalTime(0, tz)\n    else:\n        return Time(nanoseconds, tz)\n", "def hydrate_time(nanoseconds, tz=None):\n    if tz is None:\n        tz = timezone.utc\n    else:\n        if not isinstance(tz, timezone.tzinfo):\n            raise TypeError('tz must be a timezone.tzinfo instance')\n\n    return time(nanoseconds=nanoseconds, tzinfo=tz)\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if nanoseconds < 0:\n        return LocalTime(nanoseconds)\n    else:\n        return Time(nanoseconds, tz)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if not isinstance(nanoseconds, int):\n        raise ValueError('Nanoseconds must be an integer')\n    if nanoseconds < 0:\n        raise ValueError('Nanoseconds must be greater than 0')\n    if tz is not None and not isinstance(tz, tzinfo):\n        raise ValueError('tz must be a subclass of datetime.tzinfo')\n\n    return Time(nanoseconds / 1000000000, tz=tz)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if tz is None:\n        tz = get_current_timezone()\n\n    return Time(nanoseconds, tz=tz)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if tz is None:\n        return Time(nanoseconds // 1000000000, tz=UTC)\n\n    if isinstance(tz, tuple):\n        return Time(nanoseconds // 1000000000, tz=tz[0], tzinfo=tz[1])\n    else:\n        return Time(nanoseconds // 1000000000, tz=tz)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if not isinstance(nanoseconds, int):\n        raise ValueError(\"Nanos must be an int\")\n    if nanoseconds < 0:\n        raise ValueError(\"Nanos must be greater than 0\")\n\n    if tz is None:\n        tz = pytz.utc\n\n    offset = tz.utcoffset(datetime.datetime.utcnow())\n    nanos = int(nanoseconds + offset.total_seconds())\n    return tz.localize(datetime.datetime.utcfromtimestamp(nanos))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if tz is not None:\n        return LocalTime(nanoseconds, tz)\n    else:\n        return Time(nanoseconds)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if tz is not None:\n        return LocalTime(nanoseconds, tz)\n    else:\n        return Time(nanoseconds)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if tz is None:\n        tz = timezone.utc\n\n    return Time(nanoseconds / 1000000000, tz=tz)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if nanoseconds == 0:\n        return LocalTime(0, tz)\n    else:\n        return Time(nanoseconds, tz)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hydrate_time(nanoseconds, tz=None):\n    if tz is None:\n        tz = timezone.utc\n    else:\n        if not isinstance(tz, timezone.tzinfo):\n            raise TypeError('tz must be a timezone.tzinfo instance')\n\n    return time(nanoseconds=nanoseconds, tzinfo=tz)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_codec/hydration/v1/temporal.py", "project": "neo4j/neo4j-python-driver", "name": "dehydrate_timedelta", "docstring": "Dehydrator for `timedelta` values.\n\n:param value:\n:type value: timedelta\n:return:", "ques_id": "62e60f3bd76274f8a4026e10", "code": ["def dehydrate_timedelta(value):\n    return datetime.timedelta(seconds=value.total_seconds())\n", "def dehydrate_timedelta(value):\n    return timedelta(seconds=value.days * 86400 + value.seconds)\n", "def dehydrate_timedelta(value):\n    if value.days == 0:\n        return datetime.timedelta(0)\n\n    return datetime.timedelta(days=value.days)\n", "def dehydrate_timedelta(value):\n    return datetime.timedelta(days=value.days, seconds=value.seconds,\n                              microseconds=value.microseconds)\n", "def dehydrate_timedelta(value):\n    if value is None:\n        return None\n\n    return timedelta(seconds=value.total_seconds())\n", "def dehydrate_timedelta(value):\n    if isinstance(value, datetime.timedelta):\n        return value\n\n    return datetime.timedelta(seconds=value)\n", "def dehydrate_timedelta(value):\n    if value.days == 0:\n        return datetime.timedelta(0)\n\n    return datetime.timedelta(value.seconds + value.days * 24 * 3600)\n", "def dehydrate_timedelta(value):\n    if value.days < 0:\n        raise ValueError(\"Can't represent negative delta timedelta: %r\" % value)\n\n    return timedelta(seconds=value.seconds + value.days * 24 * 3600)\n", "def dehydrate_timedelta(value):\n    if isinstance(value, datetime.timedelta):\n        return value\n\n    return datetime.timedelta(seconds=value)\n", "def dehydrate_timedelta(value):\n    return datetime.timedelta(microseconds=value.microseconds)\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def dehydrate_timedelta(value):\n    return datetime.timedelta(seconds=value.total_seconds())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    return timedelta(seconds=value.days * 86400 + value.seconds)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    if value.days == 0:\n        return datetime.timedelta(0)\n\n    return datetime.timedelta(days=value.days)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    return datetime.timedelta(days=value.days, seconds=value.seconds,\n                              microseconds=value.microseconds)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    if value is None:\n        return None\n\n    return timedelta(seconds=value.total_seconds())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    if isinstance(value, datetime.timedelta):\n        return value\n\n    return datetime.timedelta(seconds=value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    if value.days == 0:\n        return datetime.timedelta(0)\n\n    return datetime.timedelta(value.seconds + value.days * 24 * 3600)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    if value.days < 0:\n        raise ValueError(\"Can't represent negative delta timedelta: %r\" % value)\n\n    return timedelta(seconds=value.seconds + value.days * 24 * 3600)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    if isinstance(value, datetime.timedelta):\n        return value\n\n    return datetime.timedelta(seconds=value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_timedelta(value):\n    return datetime.timedelta(microseconds=value.microseconds)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_codec/hydration/v1/temporal.py", "project": "neo4j/neo4j-python-driver", "name": "dehydrate_time", "docstring": "Dehydrator for `time` values.\n\n:param value:\n:type value: Time\n:return:", "ques_id": "62e60f37d76274f8a4026dfd", "code": ["def dehydrate_time(value):\n    return value.date()\n", "def dehydrate_time(value):\n    return value.date()\n", "def dehydrate_time(value):\n    return value.date()\n", "def dehydrate_time(value):\n    return value.strftime('%H:%M:%S')\n", "def dehydrate_time(value):\n    return value.strftime('%H:%M')\n", "def dehydrate_time(value):\n    return value.strftime('%H:%M:%S')\n", "def dehydrate_time(value):\n    return value.date()\n", "def dehydrate_time(value):\n    return value.date()\n", "def dehydrate_time(value):\n    return value.strftime('%H:%M')\n", "def dehydrate_time(value):\n    return value.strftime('%H:%M:%S')\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def dehydrate_time(value):\n    return value.date()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    return value.date()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    return value.date()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    return value.strftime('%H:%M:%S')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    return value.strftime('%H:%M')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    return value.strftime('%H:%M:%S')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    return value.date()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    return value.date()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    return value.strftime('%H:%M')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_time(value):\n    return value.strftime('%H:%M:%S')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_codec/hydration/v1/spatial.py", "project": "neo4j/neo4j-python-driver", "name": "dehydrate_point", "docstring": "Dehydrator for Point data.\n\n:param value:\n:type value: Point\n:return:", "ques_id": "62e60f33d76274f8a4026de9", "code": ["def dehydrate_point(value):\n    return Point(value.lon, value.lat)\n", "def dehydrate_point(value):\n    return {\n        'lat': value.latitude,\n        'lon': value.longitude\n    }\n", "def dehydrate_point(value):\n    return {\n        'x': value.x,\n        'y': value.y\n    }\n", "def dehydrate_point(value):\n    if not isinstance(value, Point):\n        raise BadPointData('Only Point objects are allowed.')\n    return value\n", "def dehydrate_point(value):\n    return {\n        'type': 'Point',\n        'coordinates': value.coordinates\n    }\n", "def dehydrate_point(value):\n    return Point(value.latitude, value.longitude)\n", "def dehydrate_point(value):\n    return {\n        'latitude': value.latitude,\n        'longitude': value.longitude\n    }\n", "def dehydrate_point(value):\n    return {\n        'lat': value.latitude,\n        'lng': value.longitude\n    }\n", "def dehydrate_point(value):\n    return {\n        'lat': value.latitude,\n        'lon': value.longitude\n    }\n", "def dehydrate_point(value):\n    return {\n        'latitude': value.latitude,\n        'longitude': value.longitude\n    }\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def dehydrate_point(value):\n    return Point(value.lon, value.lat)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    return {\n        'lat': value.latitude,\n        'lon': value.longitude\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    return {\n        'x': value.x,\n        'y': value.y\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    if not isinstance(value, Point):\n        raise BadPointData('Only Point objects are allowed.')\n    return value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    return {\n        'type': 'Point',\n        'coordinates': value.coordinates\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    return Point(value.latitude, value.longitude)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    return {\n        'latitude': value.latitude,\n        'longitude': value.longitude\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    return {\n        'lat': value.latitude,\n        'lng': value.longitude\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    return {\n        'lat': value.latitude,\n        'lon': value.longitude\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dehydrate_point(value):\n    return {\n        'latitude': value.latitude,\n        'longitude': value.longitude\n    }\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_data.py", "project": "neo4j/neo4j-python-driver", "name": "keys", "docstring": "Return the keys of the record.\n\n:return: list of key names", "ques_id": "62e60ed4d76274f8a4026da0", "code": ["def keys(self):\n    return [k for k, v in self]\n", "def keys(self):\n    return [key for key in self]\n", "def keys(self):\n    return [k for k in self]\n", "def keys(self):\n    return [key for key, value in self]\n", "def keys(self):\n    return [k for k in self]\n", "def keys(self):\n    return [key for key in self]\n", "def keys(self):\n    return [k for k in self]\n", "def keys(self):\n    return [k for k in self]\n", "def keys(self):\n    return [k.decode('utf-8') for k in self._redis.keys(pattern=self._key_pattern)]\n", "def keys(self):\n    return [key for key in self]\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def keys(self):\n    return [k for k, v in self]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return [key for key in self]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return [k for k in self]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return [key for key, value in self]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return [k for k in self]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return [key for key in self]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return [k for k in self]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return [k for k in self]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return [k.decode('utf-8') for k in self._redis.keys(pattern=self._key_pattern)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def keys(self):\n    return [key for key in self]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_sync/io/_bolt.py", "project": "neo4j/neo4j-python-driver", "name": "protocol_handlers", "docstring": "Return a dictionary of available Bolt protocol handlers,\nkeyed by version tuple. If an explicit protocol version is\nprovided, the dictionary will contain either zero or one items,\ndepending on whether that version is supported. If no protocol\nversion is provided, all available versions will be returned.\n\n:param protocol_version: tuple identifying a specific protocol\n    version (e.g. (3, 5)) or None\n:return: dictionary of version tuple to handler class for all\n    relevant and supported protocol versions\n:raise TypeError: if protocol version is not passed in a tuple", "ques_id": "62e60ecfd76274f8a4026d6a", "code": ["def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is not None:\n        return cls._protocol_handlers_cache[protocol_version]\n\n    return cls._protocol_handlers_cache\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n    elif isinstance(protocol_version, tuple):\n        return cls._protocol_handlers.get(protocol_version, {})\n    else:\n        raise TypeError('protocol_version must be a tuple')\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n\n    if isinstance(protocol_version, tuple):\n        return cls._protocol_handlers[protocol_version]\n\n    raise TypeError(\"protocol_version must be a tuple or None\")\n", "def protocol_handlers(cls, protocol_version=None):\n    versions = {\n        1: Bolt1Handler,\n        2: Bolt2Handler,\n        3: Bolt3Handler,\n        4: Bolt4Handler,\n        5: Bolt5Handler,\n        6: Bolt6Handler,\n        7: Bolt7Handler,\n        8: Bolt8Handler,\n        9: Bolt9Handler,\n    }\n\n    if protocol_version is None:\n        return versions\n\n    if protocol_version in versions:\n        return versions[protocol_version]\n\n    # Not supported\n    raise TypeError(\n        'Unsupported protocol version %s. Supported versions are %s' % (\n            protocol_version,\n            ', '.join(versions.keys())\n        )\n    )\n", "def protocol_handlers(cls, protocol_version=None):\n    version_tuples = {\n        (1, 0, 0): ProtocolHandler1,\n        (1, 1, 0): ProtocolHandler1,\n        (1, 1, 1): ProtocolHandler1,\n        (2, 0, 0): ProtocolHandler2,\n        (2, 1, 0): ProtocolHandler2,\n        (2, 1, 1): ProtocolHandler2,\n        (2, 2, 0): ProtocolHandler2,\n        (2, 2, 1): ProtocolHandler2,\n        (3, 0, 0): ProtocolHandler3,\n        (3, 1, 0): ProtocolHandler3,\n        (3, 1, 1): ProtocolHandler3,\n        (3, 2, 0): ProtocolHandler3,\n        (3, 2, 1): ProtocolHandler3,\n        (4, 0, 0): ProtocolHandler4,\n        (4, 1, 0): ProtocolHandler4,\n        (4, 2, 0): ProtocolHandler4,\n        (4, 3, 0): ProtocolHandler4,\n        (4, 3, 1): ProtocolHandler4,\n        (5, 0, 0): ProtocolHandler5,\n        (5,", "def protocol_handlers(cls, protocol_version=None):\n    version_tuple = _protocol_version_tuple(protocol_version)\n\n    if version_tuple is None:\n        return {}\n\n    return _BoltProtocolHandlerDict[version_tuple]\n", "def protocol_handlers(cls, protocol_version=None):\n    versions = cls._protocol_versions\n\n    if protocol_version is None:\n        return versions\n\n    if isinstance(protocol_version, tuple):\n        return {version: klass for version, klass in versions.items()\n                if version in protocol_version}\n\n    raise TypeError('protocol_version must be a tuple')\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n    elif not isinstance(protocol_version, tuple):\n        raise TypeError('protocol_version must be a tuple')\n    return {\n        version: cls._protocol_handlers.get(version, False)\n        for version in protocol_version\n    }\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n\n    return {\n        v: k for k, v in cls._protocol_handlers.items()\n        if (k >= protocol_version[0] and k <= protocol_version[1])\n    }\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is not None:\n        return cls._protocol_handlers.get(protocol_version, {})\n    else:\n        return cls._protocol_handlers\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is not None:\n        return cls._protocol_handlers_cache[protocol_version]\n\n    return cls._protocol_handlers_cache\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n    elif isinstance(protocol_version, tuple):\n        return cls._protocol_handlers.get(protocol_version, {})\n    else:\n        raise TypeError('protocol_version must be a tuple')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n\n    if isinstance(protocol_version, tuple):\n        return cls._protocol_handlers[protocol_version]\n\n    raise TypeError(\"protocol_version must be a tuple or None\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    versions = {\n        1: Bolt1Handler,\n        2: Bolt2Handler,\n        3: Bolt3Handler,\n        4: Bolt4Handler,\n        5: Bolt5Handler,\n        6: Bolt6Handler,\n        7: Bolt7Handler,\n        8: Bolt8Handler,\n        9: Bolt9Handler,\n    }\n\n    if protocol_version is None:\n        return versions\n\n    if protocol_version in versions:\n        return versions[protocol_version]\n\n    # Not supported\n    raise TypeError(\n        'Unsupported protocol version %s. Supported versions are %s' % (\n            protocol_version,\n            ', '.join(versions.keys())\n        )\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    version_tuples = {\n        (1, 0, 0): ProtocolHandler1,\n        (1, 1, 0): ProtocolHandler1,\n        (1, 1, 1): ProtocolHandler1,\n        (2, 0, 0): ProtocolHandler2,\n        (2, 1, 0): ProtocolHandler2,\n        (2, 1, 1): ProtocolHandler2,\n        (2, 2, 0): ProtocolHandler2,\n        (2, 2, 1): ProtocolHandler2,\n        (3, 0, 0): ProtocolHandler3,\n        (3, 1, 0): ProtocolHandler3,\n        (3, 1, 1): ProtocolHandler3,\n        (3, 2, 0): ProtocolHandler3,\n        (3, 2, 1): ProtocolHandler3,\n        (4, 0, 0): ProtocolHandler4,\n        (4, 1, 0): ProtocolHandler4,\n        (4, 2, 0): ProtocolHandler4,\n        (4, 3, 0): ProtocolHandler4,\n        (4, 3, 1): ProtocolHandler4,\n        (5, 0, 0): ProtocolHandler5,\n        (5,", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    version_tuple = _protocol_version_tuple(protocol_version)\n\n    if version_tuple is None:\n        return {}\n\n    return _BoltProtocolHandlerDict[version_tuple]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    versions = cls._protocol_versions\n\n    if protocol_version is None:\n        return versions\n\n    if isinstance(protocol_version, tuple):\n        return {version: klass for version, klass in versions.items()\n                if version in protocol_version}\n\n    raise TypeError('protocol_version must be a tuple')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n    elif not isinstance(protocol_version, tuple):\n        raise TypeError('protocol_version must be a tuple')\n    return {\n        version: cls._protocol_handlers.get(version, False)\n        for version in protocol_version\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n\n    return {\n        v: k for k, v in cls._protocol_handlers.items()\n        if (k >= protocol_version[0] and k <= protocol_version[1])\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is not None:\n        return cls._protocol_handlers.get(protocol_version, {})\n    else:\n        return cls._protocol_handlers\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/work/query.py", "project": "neo4j/neo4j-python-driver", "name": "unit_of_work", "docstring": "This function is a decorator for transaction functions that allows extra control over how the transaction is carried out.\n\nFor example, a timeout may be applied::\n\n    from neo4j import unit_of_work\n\n    @unit_of_work(timeout=100)\n    def count_people_tx(tx):\n        result = tx.run(\"MATCH (a:Person) RETURN count(a) AS persons\")\n        record = result.single()\n        return record[\"persons\"]\n\n:param metadata:\n    a dictionary with metadata.\n    Specified metadata will be attached to the executing transaction and visible in the output of ``dbms.listQueries`` and ``dbms.listTransactions`` procedures.\n    It will also get logged to the ``query.log``.\n    This functionality makes it easier to tag transactions and is equivalent to ``dbms.setTXMetaData`` procedure, see https://neo4j.com/docs/operations-manual/current/reference/procedures/ for procedure reference.\n:type metadata: dict\n\n:param timeout:\n    the transaction timeout in seconds.\n    Transactions that execute longer than the configured timeout will be terminated by the database.\n    This functionality allows to limit query/transaction execution time.\n    Specified timeout overrides the default timeout configured in the database using ``dbms.transaction.timeout`` setting.\n    Value should not represent a negative duration.\n    A zero duration will make the transaction execute indefinitely.\n    None will use the default timeout configured in the database.\n:type timeout: float or :const:`None`", "ques_id": "62e60e49d76274f8a4026d25", "code": ["def unit_of_work(metadata=None, timeout=None):\n    def _wrapper(f):\n        def _wrapped(*args, **kwargs):\n            return f(*args, **kwargs)\n        _wrapped.timeout = timeout\n        _wrapped.metadata = metadata\n        return _wrapped\n    return _wrapper\n", "def unit_of_work(metadata=None, timeout=None):\n\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            tx = _UnitOfWorkTransaction(func, metadata, timeout, *args, **kwargs)\n            return tx.run()\n\n        return wrapper\n\n    return decorator\n", "def unit_of_work(metadata=None, timeout=None):\n    def decorator(f):\n        @wraps(f)\n        def wrapper(*args, **kw):\n            self = args[0]\n            metadata = metadata or getattr(self, '_metadata', None)\n            timeout = timeout or self._metadata.get('timeout', None)\n            tx = dbms.Transaction(metadata=metadata, timeout=timeout)\n            return f(tx, *args[1:], **kw)\n        return wrapper\n    return decorator\n", "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kw):\n            tx = Transaction()\n            result = tx.run(func, *args, **kw)\n            return result\n\n        # Set the metadata if specified.\n        if metadata is not None:\n            wrapper.metadata = metadata\n\n        # Add the timeout if specified.\n        if timeout is not None:\n            wrapper.timeout = timeout\n\n        # Return the wrapper function.\n        return wrapper\n\n    # Instantiate the decorator.\n    return decorator\n", "def unit_of_work(metadata=None, timeout=None):\n    def wrapper(f):\n        if metadata is None:\n            metadata = {}\n        if timeout is None:\n            timeout = dbms.get_transaction_default_timeout()\n        @wraps(f)\n        def wrapped(*args, **kwargs):\n            tx = dbms.Transaction(dbms.get_current_transaction())\n            result = f(*args, **kwargs)\n            tx.set_timeout(timeout)\n            query = dbms.get_transaction_query(tx)\n            record = tx.get_record(query)\n            record[\"query\"] = query\n            record[\"metadata\"] = metadata\n            return result\n        return wrapped\n    return wrapper\n", "def unit_of_work(metadata=None, timeout=None):\n\n    def inner(f):\n        f.__unit_of_work__ = metadata or {}\n        f.__unit_of_work__timeout__ = timeout or None\n\n        @wraps(f)\n        def wrapped(*args, **kwargs):\n            return f(*args, **kwargs)\n\n        return wrapped\n\n    return inner\n", "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kw):\n            with transaction.manager:\n                result = func(*args, **kw)\n            return result\n\n        if metadata is not None:\n            wrapper.__neo4j_metadata__ = metadata\n        if timeout is not None:\n            with transaction.manager:\n                transaction.manager.setTimeout(timeout)\n        return wrapper\n\n    return decorator\n", "def unit_of_work(metadata=None, timeout=None):\n\n    def wrapper(func):\n        @functools.wraps(func)\n        def wrapped(*args, **kw):\n            with Transaction(metadata, timeout):\n                return func(*args, **kw)\n\n        return wrapped\n\n    return wrapper\n", "def unit_of_work(metadata=None, timeout=None):\n    def wrapper(f):\n        @functools.wraps(f)\n        def wrapped(*args, **kwargs):\n            with Transaction(timeout):\n                return f(*args, **kwargs)\n        return wrapped\n    if metadata:\n        metadata.update({'timeout': timeout})\n        return wrapper\n    else:\n        return wrapper\n", "def unit_of_work(metadata=None, timeout=None):\n    def wrapper(f):\n        @wraps(f)\n        def wrapped(*args, **kwargs):\n            metadata = metadata or {}\n            timeout = timeout or metadata.get('timeout', None)\n            transaction = dbms.startTransaction(timeout=timeout)\n            result = f(*args, **kwargs)\n            dbms.endTransaction(transaction)\n            return result\n        return wrapped\n    return wrapper\n"], "level": "self_contained", "generate_results": [{"generate_code": "def unit_of_work(metadata=None, timeout=None):\n    def _wrapper(f):\n        def _wrapped(*args, **kwargs):\n            return f(*args, **kwargs)\n        _wrapped.timeout = timeout\n        _wrapped.metadata = metadata\n        return _wrapped\n    return _wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n\n    def decorator(func):\n        def wrapper(*args, **kwargs):\n            tx = _UnitOfWorkTransaction(func, metadata, timeout, *args, **kwargs)\n            return tx.run()\n\n        return wrapper\n\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n    def decorator(f):\n        @wraps(f)\n        def wrapper(*args, **kw):\n            self = args[0]\n            metadata = metadata or getattr(self, '_metadata', None)\n            timeout = timeout or self._metadata.get('timeout', None)\n            tx = dbms.Transaction(metadata=metadata, timeout=timeout)\n            return f(tx, *args[1:], **kw)\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kw):\n            tx = Transaction()\n            result = tx.run(func, *args, **kw)\n            return result\n\n        # Set the metadata if specified.\n        if metadata is not None:\n            wrapper.metadata = metadata\n\n        # Add the timeout if specified.\n        if timeout is not None:\n            wrapper.timeout = timeout\n\n        # Return the wrapper function.\n        return wrapper\n\n    # Instantiate the decorator.\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n    def wrapper(f):\n        if metadata is None:\n            metadata = {}\n        if timeout is None:\n            timeout = dbms.get_transaction_default_timeout()\n        @wraps(f)\n        def wrapped(*args, **kwargs):\n            tx = dbms.Transaction(dbms.get_current_transaction())\n            result = f(*args, **kwargs)\n            tx.set_timeout(timeout)\n            query = dbms.get_transaction_query(tx)\n            record = tx.get_record(query)\n            record[\"query\"] = query\n            record[\"metadata\"] = metadata\n            return result\n        return wrapped\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n\n    def inner(f):\n        f.__unit_of_work__ = metadata or {}\n        f.__unit_of_work__timeout__ = timeout or None\n\n        @wraps(f)\n        def wrapped(*args, **kwargs):\n            return f(*args, **kwargs)\n\n        return wrapped\n\n    return inner\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n    def decorator(func):\n        @functools.wraps(func)\n        def wrapper(*args, **kw):\n            with transaction.manager:\n                result = func(*args, **kw)\n            return result\n\n        if metadata is not None:\n            wrapper.__neo4j_metadata__ = metadata\n        if timeout is not None:\n            with transaction.manager:\n                transaction.manager.setTimeout(timeout)\n        return wrapper\n\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n\n    def wrapper(func):\n        @functools.wraps(func)\n        def wrapped(*args, **kw):\n            with Transaction(metadata, timeout):\n                return func(*args, **kw)\n\n        return wrapped\n\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n    def wrapper(f):\n        @functools.wraps(f)\n        def wrapped(*args, **kwargs):\n            with Transaction(timeout):\n                return f(*args, **kwargs)\n        return wrapped\n    if metadata:\n        metadata.update({'timeout': timeout})\n        return wrapper\n    else:\n        return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unit_of_work(metadata=None, timeout=None):\n    def wrapper(f):\n        @wraps(f)\n        def wrapped(*args, **kwargs):\n            metadata = metadata or {}\n            timeout = timeout or metadata.get('timeout', None)\n            transaction = dbms.startTransaction(timeout=timeout)\n            result = f(*args, **kwargs)\n            dbms.endTransaction(transaction)\n            return result\n        return wrapped\n    return wrapper\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_data.py", "project": "neo4j/neo4j-python-driver", "name": "index", "docstring": "Return the index of the given item.\n\n:param key: a key\n:return: index\n:rtype: int", "ques_id": "62e60e05d76274f8a4026cfd", "code": ["def index(self, key):\n    k = self._key(key)\n    i = bisect_left(self._keys, k)\n    j = bisect_right(self._keys, k)\n    return self._items[i:j].index(key) + i\n", "def index(self, key):\n    bucket = self._buckets[self._bucket_index(key)]\n    for i, kv in enumerate(bucket):\n        k, v = kv\n        if v == key:\n            return i\n    raise KeyError('Key not in bucket.')\n", "def index(self, key):\n    bucket = self._bucket(key)\n    for i, kv in enumerate(bucket):\n        if kv[0] == key:\n            return i\n    return -1\n", "def index(self, key):\n    return self._keys.index(key)\n", "def index(self, key):\n    return self._keys.index(key)\n", "def index(self, key):\n    return self._map.index(key)\n", "def index(self, key):\n    return self._map.index(key)\n", "def index(self, key):\n    return self._table[key][0]\n", "def index(self, key):\n    return self._keys.index(key)\n", "def index(self, key):\n    index = self._hash(key) % self._size\n    for i, kv in enumerate(self._buckets[index]):\n        if kv[0] == key:\n            return i\n    return -1\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def index(self, key):\n    k = self._key(key)\n    i = bisect_left(self._keys, k)\n    j = bisect_right(self._keys, k)\n    return self._items[i:j].index(key) + i\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    bucket = self._buckets[self._bucket_index(key)]\n    for i, kv in enumerate(bucket):\n        k, v = kv\n        if v == key:\n            return i\n    raise KeyError('Key not in bucket.')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    bucket = self._bucket(key)\n    for i, kv in enumerate(bucket):\n        if kv[0] == key:\n            return i\n    return -1\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    return self._keys.index(key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    return self._keys.index(key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    return self._map.index(key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    return self._map.index(key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    return self._table[key][0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    return self._keys.index(key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def index(self, key):\n    index = self._hash(key) % self._size\n    for i, kv in enumerate(self._buckets[index]):\n        if kv[0] == key:\n            return i\n    return -1\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_data.py", "project": "neo4j/neo4j-python-driver", "name": "values", "docstring": "Return the values of the record, optionally filtering to\ninclude only certain values by index or key.\n\n:param keys: indexes or keys of the items to include; if none\n             are provided, all values will be included\n:return: list of values\n:rtype: list", "ques_id": "62e60da4d76274f8a4026cf1", "code": ["def values(self, *keys):\n\n    return [record.value for record in self._iter(keys)]\n", "def values(self, *keys):\n    return [item[1] for item in self._items(keys)]\n", "def values(self, *keys):\n    return [record[1] for record in self._records if (keys is None or record[0] in keys)]\n", "def values(self, *keys):\n\n    return [record.value for record in self._records if (\n        keys is None or (len(keys) > 0 and (keys[0] is None or keys[0] in record.keys())))]\n", "def values(self, *keys):\n    return [record.value for record in self.itervalues(*keys)]\n", "def values(self, *keys):\n    return [item[1] for item in self._items(keys)]\n", "def values(self, *keys):\n\n    return [record.value for record in self.records if (\n        not keys or (len(keys) == 0 and record.index is None))]\n", "def values(self, *keys):\n    return [record.value for record in self.itervalues(*keys)]\n", "def values(self, *keys):\n    return [item[1] for item in self._items(keys)]\n", "def values(self, *keys):\n\n    return [item[1] for item in self._items(keys)]\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def values(self, *keys):\n\n    return [record.value for record in self._iter(keys)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def values(self, *keys):\n    return [item[1] for item in self._items(keys)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def values(self, *keys):\n    return [record[1] for record in self._records if (keys is None or record[0] in keys)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def values(self, *keys):\n\n    return [record.value for record in self._records if (\n        keys is None or (len(keys) > 0 and (keys[0] is None or keys[0] in record.keys())))]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def values(self, *keys):\n    return [record.value for record in self.itervalues(*keys)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def values(self, *keys):\n    return [item[1] for item in self._items(keys)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def values(self, *keys):\n\n    return [record.value for record in self.records if (\n        not keys or (len(keys) == 0 and record.index is None))]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def values(self, *keys):\n    return [record.value for record in self.itervalues(*keys)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def values(self, *keys):\n    return [item[1] for item in self._items(keys)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def values(self, *keys):\n\n    return [item[1] for item in self._items(keys)]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_data.py", "project": "neo4j/neo4j-python-driver", "name": "data", "docstring": "Return the keys and values of this record as a dictionary,\noptionally including only certain values by index or key. Keys\nprovided in the items that are not in the record will be\ninserted with a value of :const:`None`; indexes provided\nthat are out of bounds will trigger an :exc:`IndexError`.\n\n:param keys: indexes or keys of the items to include; if none\n              are provided, all values will be included\n:return: dictionary of values, keyed by field name\n:raises: :exc:`IndexError` if an out-of-bounds index is specified", "ques_id": "62e60b10d76274f8a4026ccd", "code": ["def data(self, *keys):\n    return {k: v for k, v in super(Record, self).data(*keys)}\n", "def data(self, *keys):\n    return {k: v for k, v in super(Record, self).data(*keys)}\n", "def data(self, *keys):\n    return dict(zip(keys, self))\n", "def data(self, *keys):\n    d = {}\n    for key in keys:\n        if key >= len(self) or key < 0:\n            raise IndexError(\"Index out of bounds\")\n        d[key] = getattr(self, key)\n    return d\n", "def data(self, *keys):\n    if len(keys) == 0:\n        return {k: v for k, v in self if v is not None}\n    elif len(keys) == 1:\n        return {keys[0]: self[keys[0]]}\n    else:\n        keys = tuple(keys)\n        if len(keys) < len(self):\n            raise IndexError(\"Indexes out of bounds\")\n        return {k: self[k] for k in keys}\n", "def data(self, *keys):\n    return dict(zip(keys, self))\n", "def data(self, *keys):\n    return dict(zip(keys, self))\n", "def data(self, *keys):\n    r = {}\n    for k in keys:\n        if k >= len(self):\n            raise IndexError(\"Index out of bounds\")\n        r[k] = getattr(self, k)\n    return r\n", "def data(self, *keys):\n    return {k: v for k, v in super(Record, self).data(*keys)}\n", "def data(self, *keys):\n    r = {}\n    for k in keys:\n        if k is None:\n            r[k] = None\n        else:\n            r[k] = self[k]\n    return r\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def data(self, *keys):\n    return {k: v for k, v in super(Record, self).data(*keys)}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    return {k: v for k, v in super(Record, self).data(*keys)}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    return dict(zip(keys, self))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    d = {}\n    for key in keys:\n        if key >= len(self) or key < 0:\n            raise IndexError(\"Index out of bounds\")\n        d[key] = getattr(self, key)\n    return d\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    if len(keys) == 0:\n        return {k: v for k, v in self if v is not None}\n    elif len(keys) == 1:\n        return {keys[0]: self[keys[0]]}\n    else:\n        keys = tuple(keys)\n        if len(keys) < len(self):\n            raise IndexError(\"Indexes out of bounds\")\n        return {k: self[k] for k in keys}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    return dict(zip(keys, self))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    return dict(zip(keys, self))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    r = {}\n    for k in keys:\n        if k >= len(self):\n            raise IndexError(\"Index out of bounds\")\n        r[k] = getattr(self, k)\n    return r\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    return {k: v for k, v in super(Record, self).data(*keys)}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def data(self, *keys):\n    r = {}\n    for k in keys:\n        if k is None:\n            r[k] = None\n        else:\n            r[k] = self[k]\n    return r\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_codec/packstream/v1/__init__.py", "project": "neo4j/neo4j-python-driver", "name": "pop_u16", "docstring": "Remove the last two bytes of data, returning them as a big-endian\n16-bit unsigned integer.", "ques_id": "62e6087bd76274f8a4026bfa", "code": ["def pop_u16(self):\n    return struct.unpack('>H', self.pop(2))[0]\n", "def pop_u16(self):\n    return self.pop_u8() << 8 | self.pop_u8()\n", "def pop_u16(self):\n    return self.pop_u8() << 8 | self.pop_u8()\n", "def pop_u16(self):\n    return self.pop_u8() << 16\n", "def pop_u16(self):\n    return struct.unpack(\">H\", self.pop(2))[0]\n", "def pop_u16(self):\n    return self.pop_u8() << 8 | self.pop_u8()\n", "def pop_u16(self):\n    return struct.unpack('>H', self.pop(2))[0]\n", "def pop_u16(self):\n    return struct.unpack('>H', self.pop(2))[0]\n", "def pop_u16(self):\n    return struct.unpack(\">H\", self.pop(2))[0]\n", "def pop_u16(self):\n    return struct.unpack('>H', self.pop(2))[0]\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def pop_u16(self):\n    return struct.unpack('>H', self.pop(2))[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    return self.pop_u8() << 8 | self.pop_u8()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    return self.pop_u8() << 8 | self.pop_u8()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    return self.pop_u8() << 16\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    return struct.unpack(\">H\", self.pop(2))[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    return self.pop_u8() << 8 | self.pop_u8()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    return struct.unpack('>H', self.pop(2))[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    return struct.unpack('>H', self.pop(2))[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    return struct.unpack(\">H\", self.pop(2))[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop_u16(self):\n    return struct.unpack('>H', self.pop(2))[0]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_async/io/_bolt3.py", "project": "neo4j/neo4j-python-driver", "name": "discard", "docstring": "Appends a DISCARD message to the output queue.\n\n:param n: number of records to discard, default = -1 (ALL)\n:param qid: query ID to discard for, default = -1 (last query)\n:param dehydration_hooks:\n    Hooks to dehydrate types (dict from type (class) to dehydration\n    function). Dehydration functions receive the value and returns an\n    object of type understood by packstream.\n:param hydration_hooks:\n    Hooks to hydrate types (mapping from type (class) to\n    dehydration function). Dehydration functions receive the value of\n    type understood by packstream and are free to return anything.\n:param handlers: handler functions passed into the returned Response object", "ques_id": "62e6087ad76274f8a4026bf2", "code": ["def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type\n                                                                                                                                                                                                                                                                                                                                                              ", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function). Dehydration function receives\n        the value and returns an object of type desired by packstream.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from type (class) to dehydration function). Dehydration function\n        receives the value of type desired by packstream and are free to return anything.\n    :param handlers: handlers passed in in the returned Response object\n    \"\"\"\n    if n < 0:\n        n = -1\n    self.append(DiscardResponse(n, qid, dehydration_hooks, hydration_hooks, **handlers))\n", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function). Dehydration function\n    receives the value and returns an object of type desired by packstream.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from type (class) to dehydration function). Dehydration function\n    receives the value of type desired by packstream and are free to return anything.\n    :param handlers: handlers passed in in the returned Response object\n    \"\"\"\n    handlers = handlers or {}\n    return self.append(Response('discard', n=n, qid=qid, dehydration_hooks=dehydration_hooks,\n                                                                                    ", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type\n                                                                                                                                                                                                                                                                                                                                                              ", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n        to dehydration function). Dehydration function receives the value\n        and returns an object of type desired by packstream.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from type\n        (class) to dehydration function). Dehydration function receives the\n        value of type desired by packstream and are free to return anything.\n    :param handlers: handlers passed in in the returned Response object\n    \"\"\"\n    return Discard(n=n, qid=qid, dehydration_hooks=dehydration_hooks,\n                                                                 handlers=handlers,\n                   ", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type\n                                                                                                                                                                                                                                                                                                                                                              ", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n        to dehydration function). Dehydration functions receive the value\n        and returns an object of type desired by packstream.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from type\n        (class) to dehydration function). Dehydration functions receive the\n        value of type desired by packstream and are free to return anything.\n    :param handlers: handler functions passed in the returned Response object\n    \"\"\"\n    if not n:\n        n = -1\n\n    if not qid:\n        qid = -1\n\n    if not dehydration_hooks:\n        dehydration_hooks = {}\n\n    if not hydration_hooks:\n        hydration_hooks = {}\n\n  ", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function). Dehydration function receives the value and returns an object of type desired by packstream.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from type (class) to dehydration function). Dehydration function receives the value of type desired by packstream and are free to return anything.\n    :param handlers: handlers passed in in the returned Response object\n    \"\"\"\n    if not handlers:\n        handlers = {}\n    handlers.setdefault('discard', discard)\n    return self.append(ReliableMessage(n, qid, dehydration_hooks, **handlers))\n", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n        Dehydration functions receive the value and returns an object of type desired by packstream.\n    :param handlers: handlers passed in in the returned Response object\n    \"\"\"\n    return Discard(n, qid, dehydration_hooks, hydration_hooks, handlers)\n", "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n        to dehydration function). Dehydration function receives the value and\n        returns an object of type desired by packstream and are free to return\n        anything.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from type (class)\n        to dehydration function). Dehydration function receives the value of\n        type desired by packstream and are free to return anything.\n    :param handlers: handlers passed in in the returned Response object\n    \"\"\"\n    if n == -1:\n        n = 0\n    if qid == -1:\n        qid = 0\n    self.append(DiscardRecordsResponse(n, qid, dehydration_hooks,\n               "], "level": "project_runnable", "generate_results": [{"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type\n                                                                                                                                                                                                                                                                                                                                                              ", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function). Dehydration function receives\n        the value and returns an object of type desired by packstream.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from type (class) to dehydration function). Dehydration function\n        receives the value of type desired by packstream and are free to return anything.\n    :param handlers: handlers passed in in the returned Response object\n    \"\"\"\n    if n < 0:\n        n = -1\n    self.append(DiscardResponse(n, qid, dehydration_hooks, hydration_hooks, **handlers))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function). Dehydration function\n    receives the value and returns an object of type desired by packstream.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from type (class) to dehydration function). Dehydration function\n    receives the value of type desired by packstream and are free to return anything.\n    :param handlers: handlers passed in in the returned Response object\n    \"\"\"\n    handlers = handlers or {}\n    return self.append(Response('discard', n=n, qid=qid, dehydration_hooks=dehydration_hooks,\n                                                                                    ", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type\n                                                                                                                                                                                                                                                                                                                                                              ", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n        to dehydration function). Dehydration function receives the value\n        and returns an object of type desired by packstream.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from type\n        (class) to dehydration function). Dehydration function receives the\n        value of type desired by packstream and are free to return anything.\n    :param handlers: handlers passed in in the returned Response object\n    \"\"\"\n    return Discard(n=n, qid=qid, dehydration_hooks=dehydration_hooks,\n                                                                 handlers=handlers,\n                   ", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type\n                                                                                                                                                                                                                                                                                                                                                              ", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n        to dehydration function). Dehydration functions receive the value\n        and returns an object of type desired by packstream.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from type\n        (class) to dehydration function). Dehydration functions receive the\n        value of type desired by packstream and are free to return anything.\n    :param handlers: handler functions passed in the returned Response object\n    \"\"\"\n    if not n:\n        n = -1\n\n    if not qid:\n        qid = -1\n\n    if not dehydration_hooks:\n        dehydration_hooks = {}\n\n    if not hydration_hooks:\n        hydration_hooks = {}\n\n  ", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function). Dehydration function receives the value and returns an object of type desired by packstream.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from type (class) to dehydration function). Dehydration function receives the value of type desired by packstream and are free to return anything.\n    :param handlers: handlers passed in in the returned Response object\n    \"\"\"\n    if not handlers:\n        handlers = {}\n    handlers.setdefault('discard', discard)\n    return self.append(ReliableMessage(n, qid, dehydration_hooks, **handlers))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n        Dehydration functions receive the value and returns an object of type desired by packstream.\n    :param handlers: handlers passed in in the returned Response object\n    \"\"\"\n    return Discard(n, qid, dehydration_hooks, hydration_hooks, handlers)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def discard(self, n=-1, qid=-1, dehydration_hooks=None,\n                hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a DISCARD message to the output queue.\n\n    :param n: number of records to discard, default = -1 (ALL)\n    :param qid: query ID to discard for, default = -1 (last query)\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n        to dehydration function). Dehydration function receives the value and\n        returns an object of type desired by packstream and are free to return\n        anything.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from type (class)\n        to dehydration function). Dehydration function receives the value of\n        type desired by packstream and are free to return anything.\n    :param handlers: handlers passed in in the returned Response object\n    \"\"\"\n    if n == -1:\n        n = 0\n    if qid == -1:\n        qid = 0\n    self.append(DiscardRecordsResponse(n, qid, dehydration_hooks,\n               ", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_async/io/_bolt3.py", "project": "neo4j/neo4j-python-driver", "name": "begin", "docstring": "Appends a BEGIN message to the output queue.\n\n:param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n:param bookmarks: iterable of bookmark values after which this transaction should begin\n:param metadata: custom metadata dictionary to attach to the transaction\n:param timeout: timeout for transaction execution (seconds)\n:param db: name of the database against which to begin the transaction\n    Requires Bolt 4.0+.\n:param imp_user: the user to impersonate\n    Requires Bolt 4.4+\n:param dehydration_hooks:\n    Hooks to dehydrate types (dict from type (class) to dehydration\n    function). Dehydration functions receive the value and returns an\n    object of type understood by packstream.\n:param hydration_hooks:\n    Hooks to hydrate types (mapping from type (class) to\n    dehydration function). Dehydration functions receive the value of\n    type understood by packstream and are free to return anything.\n:param handlers: handler functions passed into the returned Response object\n:return: Response object", "ques_id": "62e60879d76274f8a4026bec", "code": ["def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n        - \"READ\" or \"WRITE\"\n        - \"READ_AND_WRITE\"\n\n    :param bookmarks: iterable of bookmark values after which this transaction\n        should be begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dictfrom type (class)\n        to dehydration function). Dehydration functions receive the value\n        and returns an object of type desired by packstream.\n\n    :param handlers: handlers passed in the returned Response object\n\n    :return: Response object\n\n    \"\"\"\n    return self.append(Command('BEGIN', {'mode': mode, 'bookmarks': bookmarks,\n               ", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n        - \"READ\" or \"WRITE\"\n        - \"READ_WRITE\"\n        - \"READ_EXTERNAL\"\n        - \"WRITE_EXTERNAL\"\n        - \"EXTERNAL\"\n    :param bookmarks: iterable of bookmark values after which this transaction should\n        begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n        to dehydration function). Dehydration function receives the value and\n        returns an object of type desired by packstream.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from\n        type (class) to dehydration function). Dehydration function receives\n", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n    :param bookmarks: iterable of bookmark values after which this transaction\n        should be begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dictfrom type (class)\n        to dehydration function). Dehydration function receives the value\n        and returns an object of type desired by packstream.\n    :param hyperlinks: handlers to dehydrate types (mapping from type\n        (class) to dehydration function). Dehydration function receives\n        the value of type desired by packstream and are free to return anything.\n    :param handlers: handlers passed in the returned Response object\n\n    :return: Response object\n    \"\"", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n        - \"READ\" or \"WRITE\"\n        - \"WRITE\" and \"READ\" are the same\n    :param bookmarks: iterable of bookmark values after which this transaction\n        should be begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n        (default)\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n        Dehydration functions receive the value and return an object of type desired\n        by packstream.\n    :param hyphenation_hooks: Hooks to dehydrate types (mapping from type (class) to dehydration function).\n        Dehydration functions receive the value of type desired by packstream and are\n        free to", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n        - \"READ\" or \"WRITE\"\n        - \"READ_WRITE\"\n    :param bookmarks: iterable of bookmark values after which this transaction should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n        Dehydration functions receives the value and returns an object of type desired by packstream.\n    :param handlers: handlers passed in to the returned Response object\n    :return: Response object\n    \"\"\"\n    return self.append(Command('BEGIN', handlers, timeout=timeout, db=db, imp_user=imp_user,\n                            ", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n        - \"READ\" or \"WRITE\"\n        - \"READ_ONLY\" (default)\n        - \"WRITE_ONLY\" (non-read)\n    :param bookmarks: iterable of bookmark values after which this transaction\n        should be begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type\n        (class) to dehydration function). Dehydration functions receive the\n        value and returns an object of type desired by packstream.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from\n        type (class) to dehydration function). Dehydration functions\n        receive the value of type desired by packstream and ar", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n    :param bookmarks: iterable of bookmark values after which this transaction\n        should be begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n        (default)\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n        to dehydration function). Dehydration functions receive the value\n        and returns an object of type desired by packstream.\n    :param handlers: handlers passed in the returned Response object\n    :return: Response object\n    \"\"\"\n\n    return self._append(TransactionType.BEGIN, mode=mode, bookmarks=bookmarks,\n                       metadata=metadata, timeout=timeout,\n                ", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n        - \"READ\" or \"WRITE\"\n        - \"READ_WRITE\"\n    :param bookmarks: iterable of bookmark values after which this transaction\n        should be begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n        (default)\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type\n                                                                                                                                                                                    ", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n        - \"READ\" or \"WRITE\"\n        - \"READ_WRITE\"\n        - \"EXECUTE\"\n        - \"EXECUTE_CALL\"\n        - \"BATCH\"\n        - \"BATCH_EXECUTE\"\n    :param bookmarks: iterable of bookmark values after which this transaction should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n        Dehydration functions receive the value and returns an object of type understood by packstream.\n    :param handlers: handlers passed in the returned Response object\n    :return: Response object\n    \"\"\"\n    return self", "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this transaction\n        should be begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dictfrom type (class)\n        to dehydration function). Dehydration functions receives the value\n        and returns an object of type desired by packstream.\n    :param handlers: handlers passed in the returned Response object\n    :return: Response object\n    \"\"\"\n\n    return self.append(Transaction('BEGIN', mode, bookmarks, metadata,\n                                 timeout, db, imp_user, dehydration_hoo"], "level": "project_runnable", "generate_results": [{"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n        - \"READ\" or \"WRITE\"\n        - \"READ_AND_WRITE\"\n\n    :param bookmarks: iterable of bookmark values after which this transaction\n        should be begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dictfrom type (class)\n        to dehydration function). Dehydration functions receive the value\n        and returns an object of type desired by packstream.\n\n    :param handlers: handlers passed in the returned Response object\n\n    :return: Response object\n\n    \"\"\"\n    return self.append(Command('BEGIN', {'mode': mode, 'bookmarks': bookmarks,\n               ", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n        - \"READ\" or \"WRITE\"\n        - \"READ_WRITE\"\n        - \"READ_EXTERNAL\"\n        - \"WRITE_EXTERNAL\"\n        - \"EXTERNAL\"\n    :param bookmarks: iterable of bookmark values after which this transaction should\n        begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n        to dehydration function). Dehydration function receives the value and\n        returns an object of type desired by packstream.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from\n        type (class) to dehydration function). Dehydration function receives\n", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n    :param bookmarks: iterable of bookmark values after which this transaction\n        should be begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dictfrom type (class)\n        to dehydration function). Dehydration function receives the value\n        and returns an object of type desired by packstream.\n    :param hyperlinks: handlers to dehydrate types (mapping from type\n        (class) to dehydration function). Dehydration function receives\n        the value of type desired by packstream and are free to return anything.\n    :param handlers: handlers passed in the returned Response object\n\n    :return: Response object\n    \"\"", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n        - \"READ\" or \"WRITE\"\n        - \"WRITE\" and \"READ\" are the same\n    :param bookmarks: iterable of bookmark values after which this transaction\n        should be begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n        (default)\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n        Dehydration functions receive the value and return an object of type desired\n        by packstream.\n    :param hyphenation_hooks: Hooks to dehydrate types (mapping from type (class) to dehydration function).\n        Dehydration functions receive the value of type desired by packstream and are\n        free to", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n        - \"READ\" or \"WRITE\"\n        - \"READ_WRITE\"\n    :param bookmarks: iterable of bookmark values after which this transaction should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n        Dehydration functions receives the value and returns an object of type desired by packstream.\n    :param handlers: handlers passed in to the returned Response object\n    :return: Response object\n    \"\"\"\n    return self.append(Command('BEGIN', handlers, timeout=timeout, db=db, imp_user=imp_user,\n                            ", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n        - \"READ\" or \"WRITE\"\n        - \"READ_ONLY\" (default)\n        - \"WRITE_ONLY\" (non-read)\n    :param bookmarks: iterable of bookmark values after which this transaction\n        should be begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type\n        (class) to dehydration function). Dehydration functions receive the\n        value and returns an object of type desired by packstream.\n    :param hydration_hooks: Hooks to dehydrate types (mapping from\n        type (class) to dehydration function). Dehydration functions\n        receive the value of type desired by packstream and ar", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n    :param bookmarks: iterable of bookmark values after which this transaction\n        should be begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n        (default)\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class)\n        to dehydration function). Dehydration functions receive the value\n        and returns an object of type desired by packstream.\n    :param handlers: handlers passed in the returned Response object\n    :return: Response object\n    \"\"\"\n\n    return self._append(TransactionType.BEGIN, mode=mode, bookmarks=bookmarks,\n                       metadata=metadata, timeout=timeout,\n                ", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n        - \"READ\" or \"WRITE\"\n        - \"READ_WRITE\"\n    :param bookmarks: iterable of bookmark values after which this transaction\n        should be begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n        (default)\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type\n                                                                                                                                                                                    ", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing\n        - \"READ\" or \"WRITE\"\n        - \"READ_WRITE\"\n        - \"EXECUTE\"\n        - \"EXECUTE_CALL\"\n        - \"BATCH\"\n        - \"BATCH_EXECUTE\"\n    :param bookmarks: iterable of bookmark values after which this transaction should begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dict from type (class) to dehydration function).\n        Dehydration functions receive the value and returns an object of type understood by packstream.\n    :param handlers: handlers passed in the returned Response object\n    :return: Response object\n    \"\"\"\n    return self", "is_pass": false, "return_code": 1}, {"generate_code": "def begin(self, mode=None, bookmarks=None, metadata=None, timeout=None,\n              db=None, imp_user=None, dehydration_hooks=None,\n              hydration_hooks=None, **handlers):\n    \"\"\"\n    Appends a BEGIN message to the output queue.\n\n    :param mode: access mode for routing - \"READ\" or \"WRITE\" (default)\n    :param bookmarks: iterable of bookmark values after which this transaction\n        should be begin\n    :param metadata: custom metadata dictionary to attach to the transaction\n    :param timeout: timeout for transaction execution (seconds)\n    :param db: name of the database against which to begin the transaction\n    :param imp_user: the user to impersonate\n    :param dehydration_hooks: Hooks to dehydrate types (dictfrom type (class)\n        to dehydration function). Dehydration functions receives the value\n        and returns an object of type desired by packstream.\n    :param handlers: handlers passed in the returned Response object\n    :return: Response object\n    \"\"\"\n\n    return self.append(Transaction('BEGIN', mode, bookmarks, metadata,\n                                 timeout, db, imp_user, dehydration_hoo", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/time/_arithmetic.py", "project": "neo4j/neo4j-python-driver", "name": "round_half_to_even", "docstring": ">>> round_half_to_even(3)\n    3\n    >>> round_half_to_even(3.2)\n    3\n    >>> round_half_to_even(3.5)\n    4\n    >>> round_half_to_even(3.7)\n    4\n    >>> round_half_to_even(4)\n    4\n    >>> round_half_to_even(4.2)\n    4\n    >>> round_half_to_even(4.5)\n    4\n    >>> round_half_to_even(4.7)\n    5\n\n:param n:\n:return:", "ques_id": "62e60723d76274f8a4026b75", "code": ["def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n) and ten_n % 10 == 5:\n        hundred_n = int(round(ten_n / 10)) * 10\n        if hundred_n == int(hundred_n) and hundred_n % 10 == 5:\n            return int(round(hundred_n / 10)) * 10\n        else:\n            return int(hundred_n)\n    else:\n        return int(round(n))\n", "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n):\n        ten_n = int(round(ten_n))\n    if ten_n == 10 * n:\n        return int(round_half_to_even(n))\n    if ten_n % 10 == 5:\n        return int(round_half_to_even(5))\n    return int(round_half_to_even(n // 10))\n", "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n) and ten_n % 10 == 5:\n        hundred_n = int(round(ten_n / 10)) * 10\n        if hundred_n == int(hundred_n) and hundred_n % 10 == 5:\n            return int(round(hundred_n / 10)) * 10\n\n        elif hundred_n == int(hundred_n) and hundred_n % 10 == 4:\n            return int(round(hundred_n / 10)) * 10\n\n        else:\n            return int(hundred_n)\n\n    else:\n        return int(round(n))\n", "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n) and ten_n % 10 == 5:\n        h = int(math.floor(math.log(abs(ten_n), 2)))\n        return 10 ** (h + 1) * h\n    else:\n        return int(round(n))\n", "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n):\n        ten_n = int(round(ten_n))\n        if ten_n % 10 == 5:\n            hundred = int(round(ten_n / 10)) * 10\n            if hundred % 10 == 5:\n                return hundred + 1\n            else:\n                return hundred\n        else:\n            return int(round(ten_n))\n    else:\n        return int(round(n))\n", "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n) and ten_n % 10 == 5:\n        hundred = int(ten_n / 10)\n        return hundred * hundred\n\n    hundred = int(round(ten_n / 10))\n    return hundred * 10\n", "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n) and ten_n % 10 == 5:\n        hundred = int(n / 100)\n        ten_hundred = 10 * hundred\n        return int(ten_hundred)\n    else:\n        return int(n)\n", "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n):\n        ten_n = int(round(ten_n))\n    elif ten_n % 10 == 5:\n        ten_n = int(round(10 * n + 1))\n    elif ten_n % 10 == 4:\n        ten_n = int(round(10 * n + 2))\n    elif ten_n % 10 == 3:\n        ten_n = int(round(10 * n + 3))\n    else:\n        ten_n = int(round(10 * n))\n    return ten_n\n", "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n) and ten_n % 10 == 5:\n        return int(round(n))\n    else:\n        return int(round(n) + 0.5)\n", "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n) and ten_n % 10 == 5:\n        h = int(math.floor(math.log(int(ten_n), 2)))\n        return 10 ** (h + 1) * n\n    else:\n        return int(round(n))\n"], "level": "self_contained", "generate_results": [{"generate_code": "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n) and ten_n % 10 == 5:\n        hundred_n = int(round(ten_n / 10)) * 10\n        if hundred_n == int(hundred_n) and hundred_n % 10 == 5:\n            return int(round(hundred_n / 10)) * 10\n        else:\n            return int(hundred_n)\n    else:\n        return int(round(n))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n):\n        ten_n = int(round(ten_n))\n    if ten_n == 10 * n:\n        return int(round_half_to_even(n))\n    if ten_n % 10 == 5:\n        return int(round_half_to_even(5))\n    return int(round_half_to_even(n // 10))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n) and ten_n % 10 == 5:\n        hundred_n = int(round(ten_n / 10)) * 10\n        if hundred_n == int(hundred_n) and hundred_n % 10 == 5:\n            return int(round(hundred_n / 10)) * 10\n\n        elif hundred_n == int(hundred_n) and hundred_n % 10 == 4:\n            return int(round(hundred_n / 10)) * 10\n\n        else:\n            return int(hundred_n)\n\n    else:\n        return int(round(n))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n) and ten_n % 10 == 5:\n        h = int(math.floor(math.log(abs(ten_n), 2)))\n        return 10 ** (h + 1) * h\n    else:\n        return int(round(n))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n):\n        ten_n = int(round(ten_n))\n        if ten_n % 10 == 5:\n            hundred = int(round(ten_n / 10)) * 10\n            if hundred % 10 == 5:\n                return hundred + 1\n            else:\n                return hundred\n        else:\n            return int(round(ten_n))\n    else:\n        return int(round(n))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n) and ten_n % 10 == 5:\n        hundred = int(ten_n / 10)\n        return hundred * hundred\n\n    hundred = int(round(ten_n / 10))\n    return hundred * 10\n", "is_pass": false, "return_code": 1}, {"generate_code": "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n) and ten_n % 10 == 5:\n        hundred = int(n / 100)\n        ten_hundred = 10 * hundred\n        return int(ten_hundred)\n    else:\n        return int(n)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n):\n        ten_n = int(round(ten_n))\n    elif ten_n % 10 == 5:\n        ten_n = int(round(10 * n + 1))\n    elif ten_n % 10 == 4:\n        ten_n = int(round(10 * n + 2))\n    elif ten_n % 10 == 3:\n        ten_n = int(round(10 * n + 3))\n    else:\n        ten_n = int(round(10 * n))\n    return ten_n\n", "is_pass": false, "return_code": 1}, {"generate_code": "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n) and ten_n % 10 == 5:\n        return int(round(n))\n    else:\n        return int(round(n) + 0.5)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def round_half_to_even(n):\n    ten_n = 10 * n\n    if ten_n == int(ten_n) and ten_n % 10 == 5:\n        h = int(math.floor(math.log(int(ten_n), 2)))\n        return 10 ** (h + 1) * n\n    else:\n        return int(round(n))\n", "is_pass": true, "return_code": 0}]}
{"file_path": "neo4j/_spatial/__init__.py", "project": "neo4j/neo4j-python-driver", "name": "point_type", "docstring": "Dynamically create a Point subclass.", "ques_id": "62e60707d76274f8a4026b69", "code": ["def point_type(name, fields, srid_map):\n    # type: (unicode, Dict[unicode, int], Dict[unicode, int]) -> Type[Point]\n    \"\"\"\n    Dynamically create a Point subclass.\n    \"\"\"\n    return type(name, (Point,), {\"_fields\": fields, \"_srid\": srid_map[name]})\n", "def point_type(name, fields, srid_map):\n    return type(\n        name,\n        (Point,),\n        {\n            '__module__': 'pyseaweed.geometry',\n            'coord_sys': 'Geometry',\n           'srid': 0,\n            'fields': tuple(fields),\n            '__doc__': 'A point representation of a bounding box '\n            'with a defined spatial reference.\\n\\n'\n            '* A bounding box is a shapely polygon that represents '\n            'the bounding box of the spatial reference specified by the '\n            '`srid` attribute.',\n            '__srid__': srid_map['srid'],\n        }\n    )\n", "def point_type(name, fields, srid_map):\n    class Point(BaseGeometry):\n        \"\"\"Point class.\"\"\"\n        def __init__(self, x, y):\n            super().__init__(srid=srid_map[fields[0]])\n            self.x = x\n            self.y = y\n\n        def convert(self, **kwargs):\n            return '{},{}'.format(self.x, self.y)\n\n        def length(self):\n            return math.sqrt(self.x ** 2 + self.y ** 2)\n\n    return Point\n", "def point_type(name, fields, srid_map):\n    class Point(BaseGeometry):\n        \"\"\"A simple point object.\"\"\"\n        def __init__(self, x, y):\n            super().__init__(srid=srid_map[fields[0]])\n            self.x = x\n            self.y = y\n\n        def transform(self, transformation_matrix):\n            return transformation_matrix.dot([x, y, 1])\n\n        def length(self):\n            return math.sqrt((self.x - self.y)**2 + 1)\n\n        def area(self):\n            return self.length() * self.length()\n\n    return Point\n", "def point_type(name, fields, srid_map):\n\n    class Point(PointBase, metaclass=PointMeta):\n        __schema__ = {\n            '__name__': name,\n            '__fields__': fields,\n            '__srid__': srid_map[name],\n        }\n\n    return Point\n", "def point_type(name, fields, srid_map):\n    return type(name, fields, {'_srid': srid_map['srid']})\n", "def point_type(name, fields, srid_map):\n    class Point(BaseGeometry):\n        \"\"\"Point class.\"\"\"\n        def __init__(self, x, y):\n            super().__init__(x, y)\n            self.name = name\n            self.fields = fields\n            self.srid = srid_map[name]\n\n        def __repr__(self):\n            return '<{}: {}>'.format(self.__class__.__name__, self.name)\n\n    return Point\n", "def point_type(name, fields, srid_map):\n\n    class Point(PointBase):\n        \"\"\"Point class.\"\"\"\n        srid = srid_map[name]\n\n    # Map field names to their corresponding srid-relative names.\n    field_mapping = {}\n    for field in fields:\n        try:\n            field_mapping[srid_map[field]].append(field)\n        except KeyError:\n            field_mapping[srid_map[field]] = [field]\n\n    # Convert the field names to their corresponding srid-relative names.\n    field_mapping = {\n        srid_map[f]: f\n        for f in fields\n        if f in srid_map\n    }\n\n    # Convert the field mapping to a Point instance.\n    Point = type(name, (PointBase,), field_mapping)\n    Point.__name__ = name\n    Point.__srid__ = srid_map[name]\n\n    return Point\n", "def point_type(name, fields, srid_map):\n    # Get the point class name\n    class_name = name.lower()\n    # Create the point class\n    point_class_name = class_name + POINT_SUFFIX\n    point_class = getattr(sys.modules[__name__], point_class_name)\n    return point_class(fields, srid_map)\n", "def point_type(name, fields, srid_map):\n    class Point(BaseGeometry):\n        \"\"\"Dynamically create a Point subclass.\"\"\"\n        def __init__(self, x, y):\n            super().__init__(srid=srid_map[fields[1]])\n            self.xy = tuple(map(int, (x, y)))\n\n        name = property(fget=lambda self: self.name)\n        x = property(fget=lambda self: self.xy[0])\n        y = property(fget=lambda self: self.xy[1])\n\n    return Point\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def point_type(name, fields, srid_map):\n    # type: (unicode, Dict[unicode, int], Dict[unicode, int]) -> Type[Point]\n    \"\"\"\n    Dynamically create a Point subclass.\n    \"\"\"\n    return type(name, (Point,), {\"_fields\": fields, \"_srid\": srid_map[name]})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n    return type(\n        name,\n        (Point,),\n        {\n            '__module__': 'pyseaweed.geometry',\n            'coord_sys': 'Geometry',\n           'srid': 0,\n            'fields': tuple(fields),\n            '__doc__': 'A point representation of a bounding box '\n            'with a defined spatial reference.\\n\\n'\n            '* A bounding box is a shapely polygon that represents '\n            'the bounding box of the spatial reference specified by the '\n            '`srid` attribute.',\n            '__srid__': srid_map['srid'],\n        }\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n    class Point(BaseGeometry):\n        \"\"\"Point class.\"\"\"\n        def __init__(self, x, y):\n            super().__init__(srid=srid_map[fields[0]])\n            self.x = x\n            self.y = y\n\n        def convert(self, **kwargs):\n            return '{},{}'.format(self.x, self.y)\n\n        def length(self):\n            return math.sqrt(self.x ** 2 + self.y ** 2)\n\n    return Point\n", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n    class Point(BaseGeometry):\n        \"\"\"A simple point object.\"\"\"\n        def __init__(self, x, y):\n            super().__init__(srid=srid_map[fields[0]])\n            self.x = x\n            self.y = y\n\n        def transform(self, transformation_matrix):\n            return transformation_matrix.dot([x, y, 1])\n\n        def length(self):\n            return math.sqrt((self.x - self.y)**2 + 1)\n\n        def area(self):\n            return self.length() * self.length()\n\n    return Point\n", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n\n    class Point(PointBase, metaclass=PointMeta):\n        __schema__ = {\n            '__name__': name,\n            '__fields__': fields,\n            '__srid__': srid_map[name],\n        }\n\n    return Point\n", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n    return type(name, fields, {'_srid': srid_map['srid']})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n    class Point(BaseGeometry):\n        \"\"\"Point class.\"\"\"\n        def __init__(self, x, y):\n            super().__init__(x, y)\n            self.name = name\n            self.fields = fields\n            self.srid = srid_map[name]\n\n        def __repr__(self):\n            return '<{}: {}>'.format(self.__class__.__name__, self.name)\n\n    return Point\n", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n\n    class Point(PointBase):\n        \"\"\"Point class.\"\"\"\n        srid = srid_map[name]\n\n    # Map field names to their corresponding srid-relative names.\n    field_mapping = {}\n    for field in fields:\n        try:\n            field_mapping[srid_map[field]].append(field)\n        except KeyError:\n            field_mapping[srid_map[field]] = [field]\n\n    # Convert the field names to their corresponding srid-relative names.\n    field_mapping = {\n        srid_map[f]: f\n        for f in fields\n        if f in srid_map\n    }\n\n    # Convert the field mapping to a Point instance.\n    Point = type(name, (PointBase,), field_mapping)\n    Point.__name__ = name\n    Point.__srid__ = srid_map[name]\n\n    return Point\n", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n    # Get the point class name\n    class_name = name.lower()\n    # Create the point class\n    point_class_name = class_name + POINT_SUFFIX\n    point_class = getattr(sys.modules[__name__], point_class_name)\n    return point_class(fields, srid_map)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def point_type(name, fields, srid_map):\n    class Point(BaseGeometry):\n        \"\"\"Dynamically create a Point subclass.\"\"\"\n        def __init__(self, x, y):\n            super().__init__(srid=srid_map[fields[1]])\n            self.xy = tuple(map(int, (x, y)))\n\n        name = property(fget=lambda self: self.name)\n        x = property(fget=lambda self: self.xy[0])\n        y = property(fget=lambda self: self.xy[1])\n\n    return Point\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/_meta.py", "project": "neo4j/neo4j-python-driver", "name": "deprecated", "docstring": "Decorator for deprecating functions and methods.\n\n::\n\n    @deprecated(\"'foo' has been deprecated in favour of 'bar'\")\n    def foo(x):\n        pass", "ques_id": "62e5dc9ed76274f8a4026b5b", "code": ["def deprecated(message):\n    def f__(f):\n        @wraps(f)\n        def f_(*args, **kwargs):\n            from. import DeprecationWarning\n            warnings.warn(message, DeprecationWarning, stacklevel=2)\n            return f(*args, **kwargs)\n        return f_\n    return f__\n", "def deprecated(message):\n    def _decorator(func):\n        @functools.wraps(func)\n        def newfunc(*args, **kwargs):\n            from. import deprecation\n            deprecation.ensure_installed(message)\n            return func(*args, **kwargs)\n        return newfunc\n    return _decorator\n", "def deprecated(message):\n    def _decorator(func):\n        if message is None:\n            message = '%s is deprecated' % func.__name__\n\n        def newfunc(*args, **kwds):\n            warnings.warn(message, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwds)\n        return newfunc\n    return _decorator\n", "def deprecated(message):\n    def _decorator(func):\n        @wraps(func)\n        def newfunc(*args, **kwargs):\n            deprecation_warning = \"Call to deprecated function {!r}. {}\".format(\n                func.__name__, message)\n            warnings.warn(deprecation_warning, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwargs)\n        return newfunc\n    return _decorator\n", "def deprecated(message):\n\n    def _decorator(func):\n        def newfunc(*args, **kwargs):\n            from warnings import warn\n            warn(message, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwargs)\n        return newfunc\n    return _decorator\n", "def deprecated(message):\n    def _decorator(func):\n        @functools.wraps(func)\n        def newfunc(*args, **kwargs):\n            deprecation_warning = \"Call to deprecated function {name}.\".format(name=func.__name__)\n            if message is None:\n                message = deprecation_warning\n            elif message!= deprecation_warning:\n                message = \"{message}\\nThis call will be deprecated. {deprecation_warning}\".format(message=message, deprecation_warning=deprecation_warning)\n            return func(*args, **kwargs)\n        return newfunc\n    return _decorator\n", "def deprecated(message):\n    def f__(f):\n        @wraps(f)\n        def f_(*args, **kwargs):\n            from. import __version__ as v\n            if v < '3.0.0':\n                warnings.warn(message, DeprecationWarning, stacklevel=2)\n            return f(*args, **kwargs)\n        return f_\n    return f__\n", "def deprecated(message):\n    def f__(f):\n        @wraps(f)\n        def f_(*args, **kwargs):\n            from. import __version__ as v\n            if message is None:\n                message = \"%s is deprecated\" % f.__name__\n\n            if v!= __version__:\n                from. import __doc__ as d\n                raise DeprecationWarning(message + \"\\n%s\" % d)\n            return f(*args, **kwargs)\n        return f_\n    return f__\n", "def deprecated(message):\n    def f__(f):\n        @wraps(f)\n        def f_(*args, **kwargs):\n            from. import __version__ as v\n            if v!= \"unknown\":\n                message = \"{0} is deprecated. {1}\".format(f.__name__, message)\n            return f(*args, **kwargs)\n        return f_\n    return f__\n", "def deprecated(message):\n\n    def _decorator(func):\n        @wraps(func)\n        def newfunc(*args, **kwargs):\n            from warnings import warn\n            warn(message, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwargs)\n        return newfunc\n    return _decorator\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def deprecated(message):\n    def f__(f):\n        @wraps(f)\n        def f_(*args, **kwargs):\n            from. import DeprecationWarning\n            warnings.warn(message, DeprecationWarning, stacklevel=2)\n            return f(*args, **kwargs)\n        return f_\n    return f__\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n    def _decorator(func):\n        @functools.wraps(func)\n        def newfunc(*args, **kwargs):\n            from. import deprecation\n            deprecation.ensure_installed(message)\n            return func(*args, **kwargs)\n        return newfunc\n    return _decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n    def _decorator(func):\n        if message is None:\n            message = '%s is deprecated' % func.__name__\n\n        def newfunc(*args, **kwds):\n            warnings.warn(message, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwds)\n        return newfunc\n    return _decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n    def _decorator(func):\n        @wraps(func)\n        def newfunc(*args, **kwargs):\n            deprecation_warning = \"Call to deprecated function {!r}. {}\".format(\n                func.__name__, message)\n            warnings.warn(deprecation_warning, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwargs)\n        return newfunc\n    return _decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n\n    def _decorator(func):\n        def newfunc(*args, **kwargs):\n            from warnings import warn\n            warn(message, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwargs)\n        return newfunc\n    return _decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n    def _decorator(func):\n        @functools.wraps(func)\n        def newfunc(*args, **kwargs):\n            deprecation_warning = \"Call to deprecated function {name}.\".format(name=func.__name__)\n            if message is None:\n                message = deprecation_warning\n            elif message!= deprecation_warning:\n                message = \"{message}\\nThis call will be deprecated. {deprecation_warning}\".format(message=message, deprecation_warning=deprecation_warning)\n            return func(*args, **kwargs)\n        return newfunc\n    return _decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n    def f__(f):\n        @wraps(f)\n        def f_(*args, **kwargs):\n            from. import __version__ as v\n            if v < '3.0.0':\n                warnings.warn(message, DeprecationWarning, stacklevel=2)\n            return f(*args, **kwargs)\n        return f_\n    return f__\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n    def f__(f):\n        @wraps(f)\n        def f_(*args, **kwargs):\n            from. import __version__ as v\n            if message is None:\n                message = \"%s is deprecated\" % f.__name__\n\n            if v!= __version__:\n                from. import __doc__ as d\n                raise DeprecationWarning(message + \"\\n%s\" % d)\n            return f(*args, **kwargs)\n        return f_\n    return f__\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n    def f__(f):\n        @wraps(f)\n        def f_(*args, **kwargs):\n            from. import __version__ as v\n            if v!= \"unknown\":\n                message = \"{0} is deprecated. {1}\".format(f.__name__, message)\n            return f(*args, **kwargs)\n        return f_\n    return f__\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deprecated(message):\n\n    def _decorator(func):\n        @wraps(func)\n        def newfunc(*args, **kwargs):\n            from warnings import warn\n            warn(message, DeprecationWarning, stacklevel=2)\n            return func(*args, **kwargs)\n        return newfunc\n    return _decorator\n", "is_pass": false, "return_code": 1}]}
{"file_path": "pre_commit/languages/r.py", "project": "pre-commit/pre-commit", "name": "_inline_r_setup", "docstring": "Some behaviour of R cannot be configured via env variables, but can\nonly be configured via R options once R has started. These are set here.", "ques_id": "62e4fc3c85ea98643089041e", "code": ["def _inline_r_setup(code: str) -> str:\n    if code in ('yes', 'true', 'on'):\n        return 'yes'\n    elif code in ('no', 'false', 'off'):\n        return 'no'\n    else:\n        raise Exception('Unknown value for option \"{}\"'.format(code))\n", "def _inline_r_setup(code: str):\n    if 'R' in code:\n        raise Exception('Cannot be configured via env variables, but R has started. It cannot be configured via env variables.')\n", "def _inline_r_setup(code: str):\n    global R_INLINE_SETUP, R_INLINE_TIMEOUT\n    R_INLINE_SETUP = code\n    R_INLINE_TIMEOUT = 5\n", "def _inline_r_setup(code: str) -> str:\n    code = f'export R=\"{code}\"'\n    return code\n", "def _inline_r_setup(code: str) -> str:\n    inline_r_command = (\n        \"export R={r_version}; \"\n        \"source /usr/local/R/bin/activate; \"\n        \"source /usr/local/R/third_party/r/bin/activate; \"\n        \"cd /usr/local/R; \"\n        \"R install_requires; \"\n        \"R setup_environment; \"\n        \"R build_ext.py setup.cfg build; \"\n        \"R install_lib.py install_source; \"\n        \"R setup.sh setup_environment; \"\n        \"R clean; \"\n        \"R env -u $(R -v) && R env --cwd $(R -v) && \"\n        \"R env --failure-only; \"\n        \"R env --root $(R -v) && R env --cwd $(R -v) && \"\n        \"R env --system $(R -v) && R env --system-site-packages \"\n        \"&& R env --site-packages $(R -v) && \"\n        \"R env --shallow ", "def _inline_r_setup(code: str) -> str:\n    inline = \"\"\"\n    int main(int n, char **args) {\n        return 0;\n    }\n    \"\"\"\n    return inline\n", "def _inline_r_setup(code: str) -> str:\n    if code == \"YOUR_ENV_VARIABLE\":\n        return \"export R={r}\".format(r=env.get(\"R\"))\n    return \"\"\n", "def _inline_r_setup(code: str) -> str:\n    env = os.environ.copy()\n    env.update({\n        'R': '1',\n        'RULES': '1',\n        'R_USERNAME': 'r-user',\n        'R_PASSWORD': 'r-pass',\n    })\n    return env.get('R', '') +'' + code\n", "def _inline_r_setup(code: str) -> str:\n    if code!= \"ok\":\n        return code\n\n    # If we have a list of R options, then we need to ensure that the R\n    # options are configured as well. Otherwise, we need to ensure that\n    # the R options are configured as needed.\n    r_options = os.environ.get(\"R_OPTIONS\", \"\").split(\",\")\n\n    for r_option in r_options:\n        if r_option not in R_OPTIONS:\n            return \"ok\"\n\n    return \"\"\n", "def _inline_r_setup(code: str) -> str:\n    if code in (\"\", \"--no-color\"):\n        return \"export R=r\"\n    return \"\"\n"], "level": "self_contained", "generate_results": [{"generate_code": "def _inline_r_setup(code: str) -> str:\n    if code in ('yes', 'true', 'on'):\n        return 'yes'\n    elif code in ('no', 'false', 'off'):\n        return 'no'\n    else:\n        raise Exception('Unknown value for option \"{}\"'.format(code))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str):\n    if 'R' in code:\n        raise Exception('Cannot be configured via env variables, but R has started. It cannot be configured via env variables.')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str):\n    global R_INLINE_SETUP, R_INLINE_TIMEOUT\n    R_INLINE_SETUP = code\n    R_INLINE_TIMEOUT = 5\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str) -> str:\n    code = f'export R=\"{code}\"'\n    return code\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str) -> str:\n    inline_r_command = (\n        \"export R={r_version}; \"\n        \"source /usr/local/R/bin/activate; \"\n        \"source /usr/local/R/third_party/r/bin/activate; \"\n        \"cd /usr/local/R; \"\n        \"R install_requires; \"\n        \"R setup_environment; \"\n        \"R build_ext.py setup.cfg build; \"\n        \"R install_lib.py install_source; \"\n        \"R setup.sh setup_environment; \"\n        \"R clean; \"\n        \"R env -u $(R -v) && R env --cwd $(R -v) && \"\n        \"R env --failure-only; \"\n        \"R env --root $(R -v) && R env --cwd $(R -v) && \"\n        \"R env --system $(R -v) && R env --system-site-packages \"\n        \"&& R env --site-packages $(R -v) && \"\n        \"R env --shallow ", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str) -> str:\n    inline = \"\"\"\n    int main(int n, char **args) {\n        return 0;\n    }\n    \"\"\"\n    return inline\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str) -> str:\n    if code == \"YOUR_ENV_VARIABLE\":\n        return \"export R={r}\".format(r=env.get(\"R\"))\n    return \"\"\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str) -> str:\n    env = os.environ.copy()\n    env.update({\n        'R': '1',\n        'RULES': '1',\n        'R_USERNAME': 'r-user',\n        'R_PASSWORD': 'r-pass',\n    })\n    return env.get('R', '') +'' + code\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str) -> str:\n    if code!= \"ok\":\n        return code\n\n    # If we have a list of R options, then we need to ensure that the R\n    # options are configured as well. Otherwise, we need to ensure that\n    # the R options are configured as needed.\n    r_options = os.environ.get(\"R_OPTIONS\", \"\").split(\",\")\n\n    for r_option in r_options:\n        if r_option not in R_OPTIONS:\n            return \"ok\"\n\n    return \"\"\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _inline_r_setup(code: str) -> str:\n    if code in (\"\", \"--no-color\"):\n        return \"export R=r\"\n    return \"\"\n", "is_pass": false, "return_code": 1}]}
{"file_path": "pre_commit/xargs.py", "project": "pre-commit/pre-commit", "name": "xargs", "docstring": "A simplified implementation of xargs.\n\ncolor: Make a pty if on a platform that supports it\ntarget_concurrency: Target number of partitions to run concurrently", "ques_id": "62e4fbda85ea986430890405", "code": ["def xargs(\n        cmd: Sequence[str],\n        target_concurrency: int = 1,\n        capture: bool = False,\n        shell: bool = False,\n) -> Iterator[str]:\n    \"\"\"\n    A simpler implementation of xargs.\n    color:\n    Make a pty if on a platform that supports it target_concurrency:\n\n        target_concurrency: Target number of partitions to run concurrently\n\n    \"\"\"\n    with Popen(cmd, stdin=PIPE, stdout=PIPE, stderr=PIPE, shell=shell) as p:\n        yield p.stdin.read()\n        if capture:\n            for line in p.stdout:\n                yield line\n        if shell:\n            for line in p.stderr:\n                yield line\n", "def xargs(\n        cmd: Command,\n        args: Iterable[str],\n        cwd: Optional[str] = None,\n        env: Optional[Mapping[str, str]] = None,\n        verbose: bool = False,\n        target_concurrency: int = 1,\n        **extra_args) -> Iterator[subprocess.CompletedProcess]:\n    \"\"\"\n    A simplified implementation of xargs.\n\n    color:\n    Make a pty if on a platform that supports it target_concurrency:\n    Target number of partitions to run concurrently at once\n    \"\"\"\n    return subprocess.run(\n        cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n        cwd=cwd, env=env, check=True,\n        args=args, check_returncode=False,\n        verbose=verbose, **extra_args)\n", "def xargs(\n        cmd: Iterable[str],\n        target_concurrency: int = None,\n        color: bool = False,\n        target_concurrency: int = None,\n) -> List[str]:\n    \"\"\"\n    A simplified implementation of xargs.\n\n    color:\n    Make a pty if on a platform that supports it target_concurrency:\n\n        target_concurrency: Target number of partitions to run concurrently\n\n    \"\"\"\n    if not isinstance(cmd, list):\n        cmd = list(cmd)\n\n    pty = Popen(cmd, stdout=PIPE, stderr=PIPE)\n    stdout, stderr = pty.communicate()\n    stdout = stdout.decode('utf-8')\n    stderr = stderr.decode('utf-8')\n    if color:\n        stdout = colorize(stdout, target_concurrency)\n        stderr = colorize(stderr, target_concurrency)\n    return stdout.split('\\n') + stderr.split('\\n')\n", "def xargs(\n        cmd: Iterable[str],\n        args: Iterable[str],\n        env: Dict[str, str] = None,\n        cwd: str = None,\n        verbose: bool = False,\n        target_concurrency: int = None,\n) -> Tuple[int, int, int, List[str]]:\n    \"\"\"\n    A simpler implementation of xargs.\n\n    color:\n    Make a pty if on a platform that supports it target_concurrency:\n\n        target_concurrency: Target number of partitions to run concurrently\n\n    \"\"\"\n    return _xargs(\n        cmd,\n        args,\n        env=env,\n        cwd=cwd,\n        verbose=verbose,\n        target_concurrency=target_concurrency,\n    )\n", "def xargs(\n        cmd: List[str],\n        target_concurrency: int = None,\n        color: bool = True,\n) -> List[str]:\n    \"\"\"\n    A simplified implementation of xargs.\n\n    color:\n    Make a pty if on a platform that supports it target_concurrency:\n\n        target_concurrency: Target number of partitions to run concurrently\n\n    \"\"\"\n    if sys.platform not in ['win32', 'darwin']:\n        return []\n\n    pty = False\n    if not color:\n        pty = True\n        color = os.environ.get('TERM') == 'dumb'\n\n    def colorize(cmd):\n        if color:\n            return '{}{}{}'.format(\n                '\\033[1;' if pty else '',\n               ''.join(cmd),\n                '\\033[0m' if pty else ''\n            )\n        else:\n            return cmd", "def xargs(\n        cmd: Iterable[str],\n        args: Iterable[str],\n        env: Optional[Mapping[str, str]] = None,\n        target_concurrency: int = None,\n        **kwargs) -> subprocess.CompletedProcess:\n    \"\"\"\n    A simplified implementation of xargs.\n\n    color: Make a pty if on a platform that supports it target_concurrency:\n    Target number of partitions to run concurrently\n    \"\"\"\n    p = subprocess.Popen(\n        cmd,\n        stdin=subprocess.PIPE,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        env=env,\n        cwd=os.getcwd(),\n        **kwargs\n    )\n    p.stdin.close()\n    p.stdout.close()\n    p.stderr.close()\n    return p.wait()\n", "def xargs(\n        cmd: Sequence[str],\n        target_concurrency: int = 1,\n        capture: bool = True,\n        env: Mapping[str, str] = None,\n        shell: bool = False,\n        stderr: bool = True,\n        stdin: bool = False,\n        stdout: bool = False,\n        stderr_pipe: bool = False,\n        bufsize: int = -1,\n        preexec_fn=None,\n) -> Tuple[int, str]:\n    \"\"\"\n    A simplified implementation of xargs.\n    color: Make a pty if on a platform that supports it\n    target_concurrency: Target number of partitions to run concurrently\n    \"\"\"\n    if stderr_pipe:\n        return _xargs_pipe_stderr, None\n    else:\n        return _xargs_stdout, _xargs_stderr_pipe\n", "def xargs(\n        cmd: Iterable[str],\n        args: Iterable[str],\n        cwd: str = None,\n        env: Iterable[str] = None,\n        encoding: str = 'utf-8',\n        stdin: str = None,\n        stdout: str = None,\n        stderr: str = None,\n        target_concurrency: int = None,\n        target_count: int = None,\n        **kwargs) -> Tuple[List[str], List[str]]:\n    \"\"\"\n    A simplified implementation of xargs.\n\n    color:\n    Make a pty if on a platform that supports it target_concurrency\n    :param cmd: Command line arguments\n    :param args: Command line arguments\n    :param cwd: Working directory\n    :param env: Environment variables\n    :param encoding: Encoding to use\n    :param stdin: Standard input\n    :param stdout: Standard output\n    :param stderr: Standard error\n    :param target_concurrency: Target concurrency\n ", "def xargs(\n        cmd: Iterable[str],\n        target_concurrency: int = None,\n        color: bool = False,\n        target_concurrency_sleep: float = 0.5,\n        **kwargs) -> Tuple[int, str]:\n    \"\"\"\n    A simplified implementation of xargs.\n    color:\n    Make a pty if on a platform that supports it target_concurrency:\n    Target number of partitions to run concurrently (if not specified)\n    color:\n    Make a pty if on a platform that supports it target_concurrency_sleep:\n    Target number of partitions to run concurrently (if not specified)\n    \"\"\"\n    if color:\n        target_concurrency = None\n\n    if target_concurrency is None:\n        if platform.system() == 'Windows':\n            target_concurrency = 3\n        else:\n            target_concurrency = int(os.environ.get('NOSE_COLORS', '').strip())\n\n    if target_concurrency < 0:\n        raise ValueError(\"`NOSE_CO", "def xargs(\n        cmd: str,\n        args: Iterable[str],\n        stdin: Iterable[str],\n        stdout: Iterable[str],\n        stderr: Iterable[str],\n        target_concurrency: int = None,\n) -> Tuple[int, List[str], List[str], List[str]]:\n    \"\"\"\n    A simplified implementation of xargs.\n\n    color:\n    Make a pty if on a platform that supports it target_concurrency:\n\n        target_concurrency: Target number of partitions to run concurrently\n    \"\"\"\n    if target_concurrency is None:\n        target_concurrency = os.environ.get('OS_TARGET_CONCURRENCY', 1)\n\n    if target_concurrency == 1:\n        pty = subprocess.Popen(\n            ['sudo', '-u', '-p', str(os.getuid()), '-c', 'pty,console'] + args,\n            stdin=stdin,\n            stdout=stdout,\n            stderr=stderr,\n        )"], "level": "project_runnable", "generate_results": [{"generate_code": "def xargs(\n        cmd: Sequence[str],\n        target_concurrency: int = 1,\n        capture: bool = False,\n        shell: bool = False,\n) -> Iterator[str]:\n    \"\"\"\n    A simpler implementation of xargs.\n    color:\n    Make a pty if on a platform that supports it target_concurrency:\n\n        target_concurrency: Target number of partitions to run concurrently\n\n    \"\"\"\n    with Popen(cmd, stdin=PIPE, stdout=PIPE, stderr=PIPE, shell=shell) as p:\n        yield p.stdin.read()\n        if capture:\n            for line in p.stdout:\n                yield line\n        if shell:\n            for line in p.stderr:\n                yield line\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: Command,\n        args: Iterable[str],\n        cwd: Optional[str] = None,\n        env: Optional[Mapping[str, str]] = None,\n        verbose: bool = False,\n        target_concurrency: int = 1,\n        **extra_args) -> Iterator[subprocess.CompletedProcess]:\n    \"\"\"\n    A simplified implementation of xargs.\n\n    color:\n    Make a pty if on a platform that supports it target_concurrency:\n    Target number of partitions to run concurrently at once\n    \"\"\"\n    return subprocess.run(\n        cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n        cwd=cwd, env=env, check=True,\n        args=args, check_returncode=False,\n        verbose=verbose, **extra_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: Iterable[str],\n        target_concurrency: int = None,\n        color: bool = False,\n        target_concurrency: int = None,\n) -> List[str]:\n    \"\"\"\n    A simplified implementation of xargs.\n\n    color:\n    Make a pty if on a platform that supports it target_concurrency:\n\n        target_concurrency: Target number of partitions to run concurrently\n\n    \"\"\"\n    if not isinstance(cmd, list):\n        cmd = list(cmd)\n\n    pty = Popen(cmd, stdout=PIPE, stderr=PIPE)\n    stdout, stderr = pty.communicate()\n    stdout = stdout.decode('utf-8')\n    stderr = stderr.decode('utf-8')\n    if color:\n        stdout = colorize(stdout, target_concurrency)\n        stderr = colorize(stderr, target_concurrency)\n    return stdout.split('\\n') + stderr.split('\\n')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: Iterable[str],\n        args: Iterable[str],\n        env: Dict[str, str] = None,\n        cwd: str = None,\n        verbose: bool = False,\n        target_concurrency: int = None,\n) -> Tuple[int, int, int, List[str]]:\n    \"\"\"\n    A simpler implementation of xargs.\n\n    color:\n    Make a pty if on a platform that supports it target_concurrency:\n\n        target_concurrency: Target number of partitions to run concurrently\n\n    \"\"\"\n    return _xargs(\n        cmd,\n        args,\n        env=env,\n        cwd=cwd,\n        verbose=verbose,\n        target_concurrency=target_concurrency,\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: List[str],\n        target_concurrency: int = None,\n        color: bool = True,\n) -> List[str]:\n    \"\"\"\n    A simplified implementation of xargs.\n\n    color:\n    Make a pty if on a platform that supports it target_concurrency:\n\n        target_concurrency: Target number of partitions to run concurrently\n\n    \"\"\"\n    if sys.platform not in ['win32', 'darwin']:\n        return []\n\n    pty = False\n    if not color:\n        pty = True\n        color = os.environ.get('TERM') == 'dumb'\n\n    def colorize(cmd):\n        if color:\n            return '{}{}{}'.format(\n                '\\033[1;' if pty else '',\n               ''.join(cmd),\n                '\\033[0m' if pty else ''\n            )\n        else:\n            return cmd", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: Iterable[str],\n        args: Iterable[str],\n        env: Optional[Mapping[str, str]] = None,\n        target_concurrency: int = None,\n        **kwargs) -> subprocess.CompletedProcess:\n    \"\"\"\n    A simplified implementation of xargs.\n\n    color: Make a pty if on a platform that supports it target_concurrency:\n    Target number of partitions to run concurrently\n    \"\"\"\n    p = subprocess.Popen(\n        cmd,\n        stdin=subprocess.PIPE,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        env=env,\n        cwd=os.getcwd(),\n        **kwargs\n    )\n    p.stdin.close()\n    p.stdout.close()\n    p.stderr.close()\n    return p.wait()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: Sequence[str],\n        target_concurrency: int = 1,\n        capture: bool = True,\n        env: Mapping[str, str] = None,\n        shell: bool = False,\n        stderr: bool = True,\n        stdin: bool = False,\n        stdout: bool = False,\n        stderr_pipe: bool = False,\n        bufsize: int = -1,\n        preexec_fn=None,\n) -> Tuple[int, str]:\n    \"\"\"\n    A simplified implementation of xargs.\n    color: Make a pty if on a platform that supports it\n    target_concurrency: Target number of partitions to run concurrently\n    \"\"\"\n    if stderr_pipe:\n        return _xargs_pipe_stderr, None\n    else:\n        return _xargs_stdout, _xargs_stderr_pipe\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: Iterable[str],\n        args: Iterable[str],\n        cwd: str = None,\n        env: Iterable[str] = None,\n        encoding: str = 'utf-8',\n        stdin: str = None,\n        stdout: str = None,\n        stderr: str = None,\n        target_concurrency: int = None,\n        target_count: int = None,\n        **kwargs) -> Tuple[List[str], List[str]]:\n    \"\"\"\n    A simplified implementation of xargs.\n\n    color:\n    Make a pty if on a platform that supports it target_concurrency\n    :param cmd: Command line arguments\n    :param args: Command line arguments\n    :param cwd: Working directory\n    :param env: Environment variables\n    :param encoding: Encoding to use\n    :param stdin: Standard input\n    :param stdout: Standard output\n    :param stderr: Standard error\n    :param target_concurrency: Target concurrency\n ", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: Iterable[str],\n        target_concurrency: int = None,\n        color: bool = False,\n        target_concurrency_sleep: float = 0.5,\n        **kwargs) -> Tuple[int, str]:\n    \"\"\"\n    A simplified implementation of xargs.\n    color:\n    Make a pty if on a platform that supports it target_concurrency:\n    Target number of partitions to run concurrently (if not specified)\n    color:\n    Make a pty if on a platform that supports it target_concurrency_sleep:\n    Target number of partitions to run concurrently (if not specified)\n    \"\"\"\n    if color:\n        target_concurrency = None\n\n    if target_concurrency is None:\n        if platform.system() == 'Windows':\n            target_concurrency = 3\n        else:\n            target_concurrency = int(os.environ.get('NOSE_COLORS', '').strip())\n\n    if target_concurrency < 0:\n        raise ValueError(\"`NOSE_CO", "is_pass": false, "return_code": 1}, {"generate_code": "def xargs(\n        cmd: str,\n        args: Iterable[str],\n        stdin: Iterable[str],\n        stdout: Iterable[str],\n        stderr: Iterable[str],\n        target_concurrency: int = None,\n) -> Tuple[int, List[str], List[str], List[str]]:\n    \"\"\"\n    A simplified implementation of xargs.\n\n    color:\n    Make a pty if on a platform that supports it target_concurrency:\n\n        target_concurrency: Target number of partitions to run concurrently\n    \"\"\"\n    if target_concurrency is None:\n        target_concurrency = os.environ.get('OS_TARGET_CONCURRENCY', 1)\n\n    if target_concurrency == 1:\n        pty = subprocess.Popen(\n            ['sudo', '-u', '-p', str(os.getuid()), '-c', 'pty,console'] + args,\n            stdin=stdin,\n            stdout=stdout,\n            stderr=stderr,\n        )", "is_pass": false, "return_code": 1}]}
{"file_path": "pre_commit/languages/helpers.py", "project": "pre-commit/pre-commit", "name": "_shuffled", "docstring": "Deterministically shuffle", "ques_id": "62e4fbda85ea986430890403", "code": ["def _shuffled(seq: Sequence[Any]) -> List[Any]:\n    \"Deterministically shuffle\"\n    rng = random.Random()\n    rng.shuffle(seq)\n    return seq\n", "def _shuffled(seq: Sequence[Any]) -> List[Any]:\n    \"Deterministically shuffle\"\n    lst = list(seq)\n    random.shuffle(lst)\n    return lst\n", "def _shuffled(seq: Sequence) -> List[Any]:\n    \"Deterministically shuffle\"\n    return sorted(seq)\n", "def _shuffled(seq: Sequence[T]) -> Iterator[T]:\n    \"Deterministically shuffle\"\n    seen = set()\n    for item in seq:\n        # Don't shuffle the same item\n        if item not in seen:\n            seen.add(item)\n            yield item\n", "def _shuffled(seq: Sequence[Any]) -> List[Any]:\n    return random.sample(seq, len(seq))\n", "def _shuffled(seq: Iterable[Any]) -> Iterable[Any]:\n    \"Deterministically shuffle\"\n    from random import shuffle\n\n    return shuffle(seq)\n", "def _shuffled(seq: Sequence[Any]) -> Sequence[Any]:\n    import random\n    return random.sample(seq, len(seq))\n", "def _shuffled(seq: Iterable[T]) -> List[T]:\n    \"Deterministically shuffle\"\n    seen = set()\n    for item in seq:\n        key = item if item not in seen else random.randint(0, 1000000)\n        seen.add(key)\n        yield item\n", "def _shuffled(seq: Sequence[Any]) -> Sequence[Any]:\n    \"Deterministically shuffle\"\n    lst = list(seq)\n    random.shuffle(lst)\n    return lst\n", "def _shuffled(seq: Iterable[Any]) -> Iterable[Any]:\n    \"Deterministically shuffle\"\n    lst = list(seq)\n    random.shuffle(lst)\n    return lst\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _shuffled(seq: Sequence[Any]) -> List[Any]:\n    \"Deterministically shuffle\"\n    rng = random.Random()\n    rng.shuffle(seq)\n    return seq\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Sequence[Any]) -> List[Any]:\n    \"Deterministically shuffle\"\n    lst = list(seq)\n    random.shuffle(lst)\n    return lst\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Sequence) -> List[Any]:\n    \"Deterministically shuffle\"\n    return sorted(seq)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Sequence[T]) -> Iterator[T]:\n    \"Deterministically shuffle\"\n    seen = set()\n    for item in seq:\n        # Don't shuffle the same item\n        if item not in seen:\n            seen.add(item)\n            yield item\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Sequence[Any]) -> List[Any]:\n    return random.sample(seq, len(seq))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Iterable[Any]) -> Iterable[Any]:\n    \"Deterministically shuffle\"\n    from random import shuffle\n\n    return shuffle(seq)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Sequence[Any]) -> Sequence[Any]:\n    import random\n    return random.sample(seq, len(seq))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Iterable[T]) -> List[T]:\n    \"Deterministically shuffle\"\n    seen = set()\n    for item in seq:\n        key = item if item not in seen else random.randint(0, 1000000)\n        seen.add(key)\n        yield item\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Sequence[Any]) -> Sequence[Any]:\n    \"Deterministically shuffle\"\n    lst = list(seq)\n    random.shuffle(lst)\n    return lst\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _shuffled(seq: Iterable[Any]) -> Iterable[Any]:\n    \"Deterministically shuffle\"\n    lst = list(seq)\n    random.shuffle(lst)\n    return lst\n", "is_pass": false, "return_code": 1}]}
{"file_path": "pre_commit/util.py", "project": "pre-commit/pre-commit", "name": "parse_version", "docstring": "poor man's version comparison", "ques_id": "62e4fb6585ea98643089032b", "code": ["def parse_version(s: str) -> Optional[Version]:\n    if not s:\n        return None\n    if \"-\" in s:\n        return Version(s.split(\"-\")[0], s.split(\"-\")[1])\n    return Version(s)\n", "def parse_version(s: str) -> Optional[Version]:\n\n    if not s:\n        return None\n\n    try:\n        return Version(s)\n    except InvalidVersion:\n        return None\n", "def parse_version(s: str) -> Optional[Version]:\n    if s is None:\n        return None\n    else:\n        m = re.match(r\"^(\\d+\\.\\d+)(\\.\\d+)?$\", s)\n        if m:\n            return Version(*m.groups())\n        else:\n            raise Exception(\"bad version string: %r\" % s)\n", "def parse_version(s: str) -> Optional[Version]:\n    if not s:\n        return None\n    try:\n        return Version(s)\n    except Exception:\n        return None\n", "def parse_version(s: str) -> Optional[Version]:\n    if s is not None:\n        return parse(s)\n    return None\n", "def parse_version(s: str) -> Optional[Version]:\n    if s is None:\n        return None\n    try:\n        return Version(s)\n    except InvalidVersion:\n        return None\n", "def parse_version(s: str) -> Optional[Version]:\n    if s is None or s == '':\n        return None\n    try:\n        return Version(s)\n    except Exception:\n        return None\n", "def parse_version(s: str) -> Optional[Version]:\n    if s is None or s == '':\n        return None\n    try:\n        return Version(s)\n    except InvalidVersion:\n        return None\n", "def parse_version(s: str) -> Optional[Version]:\n    if not s:\n        return None\n    try:\n        return Version(s)\n    except InvalidVersion:\n        return None\n", "def parse_version(s: str) -> Optional[Version]:\n\n    if not s:\n        return None\n\n    try:\n        return Version(s)\n    except Exception:\n        return None\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def parse_version(s: str) -> Optional[Version]:\n    if not s:\n        return None\n    if \"-\" in s:\n        return Version(s.split(\"-\")[0], s.split(\"-\")[1])\n    return Version(s)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_version(s: str) -> Optional[Version]:\n\n    if not s:\n        return None\n\n    try:\n        return Version(s)\n    except InvalidVersion:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_version(s: str) -> Optional[Version]:\n    if s is None:\n        return None\n    else:\n        m = re.match(r\"^(\\d+\\.\\d+)(\\.\\d+)?$\", s)\n        if m:\n            return Version(*m.groups())\n        else:\n            raise Exception(\"bad version string: %r\" % s)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_version(s: str) -> Optional[Version]:\n    if not s:\n        return None\n    try:\n        return Version(s)\n    except Exception:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_version(s: str) -> Optional[Version]:\n    if s is not None:\n        return parse(s)\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_version(s: str) -> Optional[Version]:\n    if s is None:\n        return None\n    try:\n        return Version(s)\n    except InvalidVersion:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_version(s: str) -> Optional[Version]:\n    if s is None or s == '':\n        return None\n    try:\n        return Version(s)\n    except Exception:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_version(s: str) -> Optional[Version]:\n    if s is None or s == '':\n        return None\n    try:\n        return Version(s)\n    except InvalidVersion:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_version(s: str) -> Optional[Version]:\n    if not s:\n        return None\n    try:\n        return Version(s)\n    except InvalidVersion:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_version(s: str) -> Optional[Version]:\n\n    if not s:\n        return None\n\n    try:\n        return Version(s)\n    except Exception:\n        return None\n", "is_pass": false, "return_code": 1}]}
{"file_path": "pre_commit/parse_shebang.py", "project": "pre-commit/pre-commit", "name": "normalize_cmd", "docstring": "Fixes for the following issues on windows\n- https://bugs.python.org/issue8557\n- windows does not parse shebangs\n\nThis function also makes deep-path shebangs work just fine", "ques_id": "62e4fb4d85ea9864308902e7", "code": ["def normalize_cmd(cmd: str) -> str:\n    cmd = substitute_paths(cmd)\n    return cmd\n", "def normalize_cmd(cmd: str) -> str:\n    if not cmd or cmd.startswith('\"') or cmd.endswith('\"'):\n        return cmd\n\n    if sys.platform == 'win32':\n        # Python 2.6 on Windows is buggy and doesn't parse shebangs\n        return cmd\n\n    return _substitute_paths(cmd, {'SHLIB': '\"{0}\"'.format(SHLIB_DEFAULT)})\n", "def normalize_cmd(cmd: str) -> str:\n    if sys.platform.startswith(\"win\"):\n        return cmd.replace(\"/usr/bin/\", \"/usr/bin/\")\n    return cmd\n", "def normalize_cmd(cmd: str) -> str:\n    # https://github.com/Microsoft/Cygwin/issues/23\n    if \"__CYGWIN_SHEBANG__\" in cmd:\n        cmd = cmd.replace(\"__CYGWIN_SHEBANG__\", \"/usr/bin/cygwin\")\n    if \"__NOSE_SHEBANG__\" in cmd:\n        cmd = cmd.replace(\"__NOSE_SHEBANG__\", \"/usr/bin/nose\")\n    return cmd\n", "def normalize_cmd(cmd: str) -> str:\n    if sys.platform.startswith(\"win\"):\n        return cmd.replace(\"/usr/bin/\", \"/usr/bin/\")\n    return cmd\n", "def normalize_cmd(cmd: str) -> str:\n    if \";\" in cmd:\n        return cmd.replace(\";\", \":\", 1)\n    return cmd\n", "def normalize_cmd(cmd: List[str]) -> List[str]:\n    if sys.platform.startswith(\"win\"):\n        new_cmd = []\n        for element in cmd:\n            if \";\" in element:\n                new_cmd.append(\"/usr/bin/\" + element)\n            else:\n                new_cmd.append(element)\n        return new_cmd\n    return cmd\n", "def normalize_cmd(cmd: str) -> str:\n    # windows doesn't parse shebangs correctly on Windows\n    if os.name == 'nt':\n        return cmd\n\n    # fix for #3899 - we don't parse shebangs on other systems\n    if '/usr/bin/python' in cmd:\n        return cmd.replace('/usr/bin/python', '/usr/bin/python3')\n\n    return cmd\n", "def normalize_cmd(cmd: str) -> str:\n    if sys.platform == 'win32':\n        return cmd.replace('/usr/bin/', '/usr/bin/')\n\n    return cmd\n", "def normalize_cmd(cmd: str) -> str:\n    # FIXME: this is a hack and a couple of things need to be improved\n    if os.name == 'nt':\n        return cmd.replace('/usr/bin/', '/usr/bin/')\n    return cmd\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def normalize_cmd(cmd: str) -> str:\n    cmd = substitute_paths(cmd)\n    return cmd\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: str) -> str:\n    if not cmd or cmd.startswith('\"') or cmd.endswith('\"'):\n        return cmd\n\n    if sys.platform == 'win32':\n        # Python 2.6 on Windows is buggy and doesn't parse shebangs\n        return cmd\n\n    return _substitute_paths(cmd, {'SHLIB': '\"{0}\"'.format(SHLIB_DEFAULT)})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: str) -> str:\n    if sys.platform.startswith(\"win\"):\n        return cmd.replace(\"/usr/bin/\", \"/usr/bin/\")\n    return cmd\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: str) -> str:\n    # https://github.com/Microsoft/Cygwin/issues/23\n    if \"__CYGWIN_SHEBANG__\" in cmd:\n        cmd = cmd.replace(\"__CYGWIN_SHEBANG__\", \"/usr/bin/cygwin\")\n    if \"__NOSE_SHEBANG__\" in cmd:\n        cmd = cmd.replace(\"__NOSE_SHEBANG__\", \"/usr/bin/nose\")\n    return cmd\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: str) -> str:\n    if sys.platform.startswith(\"win\"):\n        return cmd.replace(\"/usr/bin/\", \"/usr/bin/\")\n    return cmd\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: str) -> str:\n    if \";\" in cmd:\n        return cmd.replace(\";\", \":\", 1)\n    return cmd\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: List[str]) -> List[str]:\n    if sys.platform.startswith(\"win\"):\n        new_cmd = []\n        for element in cmd:\n            if \";\" in element:\n                new_cmd.append(\"/usr/bin/\" + element)\n            else:\n                new_cmd.append(element)\n        return new_cmd\n    return cmd\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: str) -> str:\n    # windows doesn't parse shebangs correctly on Windows\n    if os.name == 'nt':\n        return cmd\n\n    # fix for #3899 - we don't parse shebangs on other systems\n    if '/usr/bin/python' in cmd:\n        return cmd.replace('/usr/bin/python', '/usr/bin/python3')\n\n    return cmd\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: str) -> str:\n    if sys.platform == 'win32':\n        return cmd.replace('/usr/bin/', '/usr/bin/')\n\n    return cmd\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalize_cmd(cmd: str) -> str:\n    # FIXME: this is a hack and a couple of things need to be improved\n    if os.name == 'nt':\n        return cmd.replace('/usr/bin/', '/usr/bin/')\n    return cmd\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/decorators.py", "project": "pexip/os-python-cachetools", "name": "cached", "docstring": "Decorator to wrap a function with a memoizing callable that saves\nresults in a cache.", "ques_id": "62b8d27a48ba5a41d1c3f4c6", "code": ["def cached(cache, key=hashkey, lock=None):\n    def _wrapper(fn):\n        def __wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            result = cache.get(key)\n            if result is None:\n                result = fn(*args, **kwargs)\n                cache.set(key, result, cache.get_expiry_age(key))\n            return result\n        return __wrapper\n    return _wrapper\n", "def cached(cache, key=hashkey, lock=None):\n    def _wrapper(func):\n        @functools.wraps(func)\n        def __wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(*args, **kwargs)\n                return ret\n        __wrapper.cache = cache\n        __wrapper.key = key\n        return __wrapper\n    return _wrapper\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(fn):\n        @functools.wraps(fn)\n        def wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            result = cache.get(key)\n            if result is None:\n                result = fn(*args, **kwargs)\n                cache.set(key, result, timeout=cache_timeout)\n            return result\n        return wrapper\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cached_func = _Cached(func, cache, key, lock)\n        return lambda *a, **kw: cached_func(*a, **kw)\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        return Cached(func, cache, key, lock)\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        if lock is None:\n            lock = Lock()\n\n        def wrapper(*args, **kw):\n            key = key(*args, **kw)\n            result = cache.get(key)\n            if result is None:\n                result = func(*args, **kw)\n                cache.set(key, result, cache.timeout)\n            return result\n        return wrapper\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        if lock is None:\n            lock = threading.Lock()\n\n        def wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(*args, **kwargs)\n                return ret\n\n        def wrapped(*args, **kwargs):\n            ret = cache.get(key)\n            if ret is None:\n                ret = func(*args, **kwargs)\n                cache[key] = ret\n            return ret\n\n        return update_wrapper(wrapper, func)\n\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(fn):\n        if lock is None:\n            lock = threading.Lock()\n\n        def wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            with lock:\n                return cache[key]\n        return wrapper\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        if lock is None:\n            lock = threading.Lock()\n\n        def wrapper(*args, **kw):\n            key = key(*args, **kw)\n            entry = cache.get(key)\n            if entry is None:\n                entry = func(*args, **kw)\n                cache[key] = entry\n            return entry\n\n        return wrapper\n\n    return decorator\n", "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        return Cached(func, cache, key, lock)\n    return decorator\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def cached(cache, key=hashkey, lock=None):\n    def _wrapper(fn):\n        def __wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            result = cache.get(key)\n            if result is None:\n                result = fn(*args, **kwargs)\n                cache.set(key, result, cache.get_expiry_age(key))\n            return result\n        return __wrapper\n    return _wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n    def _wrapper(func):\n        @functools.wraps(func)\n        def __wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(*args, **kwargs)\n                return ret\n        __wrapper.cache = cache\n        __wrapper.key = key\n        return __wrapper\n    return _wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n    def decorator(fn):\n        @functools.wraps(fn)\n        def wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            result = cache.get(key)\n            if result is None:\n                result = fn(*args, **kwargs)\n                cache.set(key, result, timeout=cache_timeout)\n            return result\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        cached_func = _Cached(func, cache, key, lock)\n        return lambda *a, **kw: cached_func(*a, **kw)\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        return Cached(func, cache, key, lock)\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        if lock is None:\n            lock = Lock()\n\n        def wrapper(*args, **kw):\n            key = key(*args, **kw)\n            result = cache.get(key)\n            if result is None:\n                result = func(*args, **kw)\n                cache.set(key, result, cache.timeout)\n            return result\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        if lock is None:\n            lock = threading.Lock()\n\n        def wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(*args, **kwargs)\n                return ret\n\n        def wrapped(*args, **kwargs):\n            ret = cache.get(key)\n            if ret is None:\n                ret = func(*args, **kwargs)\n                cache[key] = ret\n            return ret\n\n        return update_wrapper(wrapper, func)\n\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n    def decorator(fn):\n        if lock is None:\n            lock = threading.Lock()\n\n        def wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            with lock:\n                return cache[key]\n        return wrapper\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        if lock is None:\n            lock = threading.Lock()\n\n        def wrapper(*args, **kw):\n            key = key(*args, **kw)\n            entry = cache.get(key)\n            if entry is None:\n                entry = func(*args, **kw)\n                cache[key] = entry\n            return entry\n\n        return wrapper\n\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cached(cache, key=hashkey, lock=None):\n    def decorator(func):\n        return Cached(func, cache, key, lock)\n    return decorator\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/func.py", "project": "pexip/os-python-cachetools", "name": "ttl_cache", "docstring": "Decorator to wrap a function with a memoizing callable that saves\nup to `maxsize` results based on a Least Recently Used (LRU)\nalgorithm with a per-item time-to-live (TTL) value.", "ques_id": "62b8d24048ba5a41d1c3f49f", "code": ["def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    # XXX: cache is a dictionary of keys to values that we store\n    #      when we need them to avoid having to create a new cache\n    #      object for that key.\n    cache = {}\n\n    def wrapper(f):\n        def wrapped(*args, **kw):\n            key = (args, frozenset(sorted(kw.items())))\n            try:\n                if key in cache:\n                    return cache[key]\n            except KeyError:\n                # This is the most likely case that the function doesn't\n                # have a cached value. We'll do the work ourselves.\n                ret = f(*args, **kw)\n                cache[key] = ret\n                return ret\n            else:\n                # Check if the function has expired. I", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    # You can make this decorator successor the actual decorator.\n    if not callable(maxsize):\n        raise TypeError('maxsize must be callable')\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than zero')\n    if maxsize == 1:\n        return identity\n    if maxsize < 1 or maxsize > 128:\n        raise ValueError('maxsize must be in range (1, 128)')\n    if ttl is not None and ttl < 0:\n        raise ValueError('ttl must be greater than zero')\n    if ttl is not None and ttl > timer():\n        return cached\n    # Store the result so that the caller can use it as a decorator.\n    cache = _Cache(maxsize, ttl, typed)\n    def wrapper(f):\n        # Wrap the function with a custom cache so that it will be\n        # per-item time-to-live.\n        return Cached(f, cache)\n    return", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    # If maxsize is a single number, then make it a tuple.\n    if isinstance(maxsize, int):\n        maxsize = (maxsize, maxsize)\n    if not isinstance(maxsize, tuple):\n        raise ValueError('maxsize must be a tuple')\n    if len(maxsize) < 1:\n        raise ValueError('maxsize must be a single number')\n\n    def wrapper(f):\n        cached = LruCached(f, maxsize, ttl, timer, typed)\n        return lambda *a, **kw: cached._call_done(a, kw)\n    return wrapper\n", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    # XXX: cache is a dictionary of callables (func, timeout) -> value\n    cache = {}\n    def wrapper(func):\n        def wrapped(*args, **kwargs):\n            key = (func, args, frozenset(sorted(kwargs.items())))\n            try:\n                cache_value = cache[key]\n            except KeyError:\n                cache[key] = cache_value = func(*args, **kwargs)\n            if timer() - cache_value < ttl:\n                return cache[key]\n            else:\n                cache[key] = \"<new value>\"\n                return func(*args, **kwargs)\n        return wrapped\n    if typed:\n        wrapper.__name__ = func.__name__\n        wrapper.__doc__ = func.__doc__\n        return wrapper\n    else:\n        return wrapper", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if maxsize == 1:\n        # No cache when there are no items.\n        return functools.partial(_ttl_cache_singleton, ttl, timer, typed)\n\n    def _wrapper(fn):\n        # Memoize is a special case that does not clear the cache.\n        cached_fn = _MemoizeCachedFunction(fn)\n        @functools.wraps(fn)\n        def wrapper(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cached_fn._cache[key]\n            except KeyError:\n                value = cached_fn._cache[key] = fn(*args, **kwargs)\n                return value\n\n        cached_fn._ttl = ttl\n        cached_fn._timer =", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    # XXX: cache is a dictionary of callables that return the time it took to run\n    #     the function with each iteration of the loop.  Time complexity is\n    #     O(n).\n    #\n    #     We need to make a copy of the dictionary because the function calls\n    #     the *callable* to the decorator, and this copy will have its own\n    #     mutable dictionary.\n    cache = dict()\n\n    def wrapper(fn):\n        def wrapped(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            if key not in cache:\n                # If the function doesn't have a cached value, we need to\n                # recalculate its time to run its decorator.\n                if typed:\n                    cache[key] = fn(*args, **kwargs)\n                else:\n        ", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    # XXX: cache is a MutableMapping subclass that emulates the ttl attribute.\n    #      This might be a better place to wrap it in a custom cache class.\n    return _Cache(TTLCache(maxsize, ttl, timer), typed)\n", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    # XXX: cache is a dictionary of callables (func, timeout) that return\n    #      the value of the last accessed key, if any, to the callable passed\n    #      to it.  This is a very simple cache, we just remember the value\n    #      of the last accessed key for later use in the other methods.\n    cache = {}\n    def wrapper(func):\n        @functools.wraps(func)\n        def wrapped(*args, **kwargs):\n            key = args[0]\n            if key not in cache:\n                cache[key] = func(*args, **kwargs)\n            if cache[key] is not None:\n                if cache[key] > ttl:\n                    cache[key] = None\n                    if typed:\n                        return type(cache[key])(cache[key])\n                  ", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if maxsize <= 0:\n        raise ValueError('maxsize must be greater than 0')\n    if maxsize == 1:\n        return identity\n    if ttl <= 0:\n        raise ValueError('ttl must be greater than 0')\n    if timer is None:\n        return partial(ttl_cache, maxsize=maxsize, ttl=ttl)\n    return TimedCache(timer, ttl=ttl, typed=typed)\n", "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    # XXX: cache is a dictionary of callables that return the values to be\n    #      cached, or None if the key never expires.\n    def wrapper(fn):\n        cached_func = _Cached(fn, maxsize, ttl, timer, typed)\n        return lambda *a, **kw: cached_func(*a, **kw)\n    return wrapper\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    # XXX: cache is a dictionary of keys to values that we store\n    #      when we need them to avoid having to create a new cache\n    #      object for that key.\n    cache = {}\n\n    def wrapper(f):\n        def wrapped(*args, **kw):\n            key = (args, frozenset(sorted(kw.items())))\n            try:\n                if key in cache:\n                    return cache[key]\n            except KeyError:\n                # This is the most likely case that the function doesn't\n                # have a cached value. We'll do the work ourselves.\n                ret = f(*args, **kw)\n                cache[key] = ret\n                return ret\n            else:\n                # Check if the function has expired. I", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    # You can make this decorator successor the actual decorator.\n    if not callable(maxsize):\n        raise TypeError('maxsize must be callable')\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than zero')\n    if maxsize == 1:\n        return identity\n    if maxsize < 1 or maxsize > 128:\n        raise ValueError('maxsize must be in range (1, 128)')\n    if ttl is not None and ttl < 0:\n        raise ValueError('ttl must be greater than zero')\n    if ttl is not None and ttl > timer():\n        return cached\n    # Store the result so that the caller can use it as a decorator.\n    cache = _Cache(maxsize, ttl, typed)\n    def wrapper(f):\n        # Wrap the function with a custom cache so that it will be\n        # per-item time-to-live.\n        return Cached(f, cache)\n    return", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    # If maxsize is a single number, then make it a tuple.\n    if isinstance(maxsize, int):\n        maxsize = (maxsize, maxsize)\n    if not isinstance(maxsize, tuple):\n        raise ValueError('maxsize must be a tuple')\n    if len(maxsize) < 1:\n        raise ValueError('maxsize must be a single number')\n\n    def wrapper(f):\n        cached = LruCached(f, maxsize, ttl, timer, typed)\n        return lambda *a, **kw: cached._call_done(a, kw)\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    # XXX: cache is a dictionary of callables (func, timeout) -> value\n    cache = {}\n    def wrapper(func):\n        def wrapped(*args, **kwargs):\n            key = (func, args, frozenset(sorted(kwargs.items())))\n            try:\n                cache_value = cache[key]\n            except KeyError:\n                cache[key] = cache_value = func(*args, **kwargs)\n            if timer() - cache_value < ttl:\n                return cache[key]\n            else:\n                cache[key] = \"<new value>\"\n                return func(*args, **kwargs)\n        return wrapped\n    if typed:\n        wrapper.__name__ = func.__name__\n        wrapper.__doc__ = func.__doc__\n        return wrapper\n    else:\n        return wrapper", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if maxsize == 1:\n        # No cache when there are no items.\n        return functools.partial(_ttl_cache_singleton, ttl, timer, typed)\n\n    def _wrapper(fn):\n        # Memoize is a special case that does not clear the cache.\n        cached_fn = _MemoizeCachedFunction(fn)\n        @functools.wraps(fn)\n        def wrapper(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cached_fn._cache[key]\n            except KeyError:\n                value = cached_fn._cache[key] = fn(*args, **kwargs)\n                return value\n\n        cached_fn._ttl = ttl\n        cached_fn._timer =", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    # XXX: cache is a dictionary of callables that return the time it took to run\n    #     the function with each iteration of the loop.  Time complexity is\n    #     O(n).\n    #\n    #     We need to make a copy of the dictionary because the function calls\n    #     the *callable* to the decorator, and this copy will have its own\n    #     mutable dictionary.\n    cache = dict()\n\n    def wrapper(fn):\n        def wrapped(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            if key not in cache:\n                # If the function doesn't have a cached value, we need to\n                # recalculate its time to run its decorator.\n                if typed:\n                    cache[key] = fn(*args, **kwargs)\n                else:\n        ", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    # XXX: cache is a MutableMapping subclass that emulates the ttl attribute.\n    #      This might be a better place to wrap it in a custom cache class.\n    return _Cache(TTLCache(maxsize, ttl, timer), typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    # XXX: cache is a dictionary of callables (func, timeout) that return\n    #      the value of the last accessed key, if any, to the callable passed\n    #      to it.  This is a very simple cache, we just remember the value\n    #      of the last accessed key for later use in the other methods.\n    cache = {}\n    def wrapper(func):\n        @functools.wraps(func)\n        def wrapped(*args, **kwargs):\n            key = args[0]\n            if key not in cache:\n                cache[key] = func(*args, **kwargs)\n            if cache[key] is not None:\n                if cache[key] > ttl:\n                    cache[key] = None\n                    if typed:\n                        return type(cache[key])(cache[key])\n                  ", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if maxsize <= 0:\n        raise ValueError('maxsize must be greater than 0')\n    if maxsize == 1:\n        return identity\n    if ttl <= 0:\n        raise ValueError('ttl must be greater than 0')\n    if timer is None:\n        return partial(ttl_cache, maxsize=maxsize, ttl=ttl)\n    return TimedCache(timer, ttl=ttl, typed=typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ttl_cache(maxsize=128, ttl=600, timer=time.monotonic, typed=False):\n    # XXX: cache is a dictionary of callables that return the values to be\n    #      cached, or None if the key never expires.\n    def wrapper(fn):\n        cached_func = _Cached(fn, maxsize, ttl, timer, typed)\n        return lambda *a, **kw: cached_func(*a, **kw)\n    return wrapper\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/func.py", "project": "pexip/os-python-cachetools", "name": "mru_cache", "docstring": "Decorator to wrap a function with a memoizing callable that saves\nup to `maxsize` results based on a Most Recently Used (MRU)\nalgorithm.", "ques_id": "62b8d23b48ba5a41d1c3f49a", "code": ["def mru_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if maxsize == 1:\n        # Must return a function that does nothing (i.e. no cache storage)\n        return lambda f: f\n\n    def wrapper(f):\n        # Must return a function that does nothing (i.e. no cache storage)\n        cached = Memoize(f, maxsize, typed)\n        return lambda *a, **kw: cached(*a, **kw)\n    return wrapper\n", "def mru_cache(maxsize=128, typed=False):\n    # Must be a function or method\n    if not isinstance(maxsize, int):\n        raise TypeError('maxsize must be an integer')\n    if maxsize < 0:\n        raise ValueError('maxsize must be greater than 0')\n\n    def decorator(func):\n        # Wrap the function with a MRU cache if required\n        if maxsize <= 0:\n            from functools import wraps\n            return wraps(func)\n\n        # Cache is already constructed, no need to build a new one\n        if typed:\n            return func\n\n        # Create a new cache of the same type\n        cache = MemoizeCache()\n        # Start the cache with an empty list of results\n        cache.clear()\n\n        @wraps(func)\n        def wrapper(*args):\n            key = (args, frozenset(sorted(args)))\n            try:\n   ", "def mru_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n\n    def decorator(fn):\n        cached = MruCache(fn, maxsize, typed)\n        return lambda *a, **kw: cached.invalidate(*a, **kw)\n    return decorator\n", "def mru_cache(maxsize=128, typed=False):\n    # You can make this decorator so that it works on functions that take\n    # only one argument.  The decorator takes *args (**kwargs) and **kwargs\n    # (**kwargs).  The memoize decorator works on functions that return\n    # both the value of the argument and the key of the dictionary.\n    def decorator(fn):\n        # We build a cache of the result of the decorated function, so\n        # that it is up to date on each call to fn.  The meaning of\n        # the cache variables is the same as for the decorator call:\n        #   fn(key, value) returns the value of the argument that was passed.\n        # As a result, we can access the cache directly using the attribute\n        # names:\n        cache = {}\n        def wrapper(key, *args, **kwargs):\n            if key not in cache:\n                cache[key] = fn(key, *args, *", "def mru_cache(maxsize=128, typed=False):\n    # flip the function argument so that the wrapper can be used on callables\n    func = lambda x: x\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        key = (args, frozenset(sorted(kwargs.items())))\n        try:\n            return cache[key]\n        except KeyError:\n            ret = cache[key] = wrapper(*args, **kwargs)\n            return ret\n\n    def clear_cache():\n        cache.clear()\n\n    cache = {}\n    wrapper.clear_cache = clear_cache\n    return wrapper\n", "def mru_cache(maxsize=128, typed=False):\n    # Must be a function and not a method\n    if not isinstance(maxsize, int):\n        raise TypeError('maxsize must be an integer')\n    if maxsize < 0:\n        raise ValueError('maxsize must be greater than 0')\n\n    def decorator(func):\n        cached = MruCache(maxsize, typed)\n        cached.func = func\n        return cached\n    return decorator\n", "def mru_cache(maxsize=128, typed=False):\n    # You can use a function that returns a MRU value e.g. `len(cache)`\n    # to get the length of the list of keys in the cache.\n\n    def wrapper(fn):\n        cache = MruCache(maxsize, typed)\n        return lambda *a, **kw: cache.setdefault(fn(*a, **kw), fn(*a, **kw))\n    return wrapper\n", "def mru_cache(maxsize=128, typed=False):\n    # You can make this decorator successor the old-fashioned coroutine.\n    def decorator(f):\n        cached = MruCache(f, maxsize, typed)\n        cached.name = f.__name__\n        return cached\n    return decorator\n", "def mru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return partial(mru_cache, maxsize=128)\n    else:\n        return _MruCache(maxsize, typed)\n", "def mru_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if typed:\n        return _MruCacheTyped(maxsize)\n    else:\n        return _MruCacheWrapper(maxsize)\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def mru_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if maxsize == 1:\n        # Must return a function that does nothing (i.e. no cache storage)\n        return lambda f: f\n\n    def wrapper(f):\n        # Must return a function that does nothing (i.e. no cache storage)\n        cached = Memoize(f, maxsize, typed)\n        return lambda *a, **kw: cached(*a, **kw)\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    # Must be a function or method\n    if not isinstance(maxsize, int):\n        raise TypeError('maxsize must be an integer')\n    if maxsize < 0:\n        raise ValueError('maxsize must be greater than 0')\n\n    def decorator(func):\n        # Wrap the function with a MRU cache if required\n        if maxsize <= 0:\n            from functools import wraps\n            return wraps(func)\n\n        # Cache is already constructed, no need to build a new one\n        if typed:\n            return func\n\n        # Create a new cache of the same type\n        cache = MemoizeCache()\n        # Start the cache with an empty list of results\n        cache.clear()\n\n        @wraps(func)\n        def wrapper(*args):\n            key = (args, frozenset(sorted(args)))\n            try:\n   ", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n\n    def decorator(fn):\n        cached = MruCache(fn, maxsize, typed)\n        return lambda *a, **kw: cached.invalidate(*a, **kw)\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    # You can make this decorator so that it works on functions that take\n    # only one argument.  The decorator takes *args (**kwargs) and **kwargs\n    # (**kwargs).  The memoize decorator works on functions that return\n    # both the value of the argument and the key of the dictionary.\n    def decorator(fn):\n        # We build a cache of the result of the decorated function, so\n        # that it is up to date on each call to fn.  The meaning of\n        # the cache variables is the same as for the decorator call:\n        #   fn(key, value) returns the value of the argument that was passed.\n        # As a result, we can access the cache directly using the attribute\n        # names:\n        cache = {}\n        def wrapper(key, *args, **kwargs):\n            if key not in cache:\n                cache[key] = fn(key, *args, *", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    # flip the function argument so that the wrapper can be used on callables\n    func = lambda x: x\n\n    @functools.wraps(func)\n    def wrapper(*args, **kwargs):\n        key = (args, frozenset(sorted(kwargs.items())))\n        try:\n            return cache[key]\n        except KeyError:\n            ret = cache[key] = wrapper(*args, **kwargs)\n            return ret\n\n    def clear_cache():\n        cache.clear()\n\n    cache = {}\n    wrapper.clear_cache = clear_cache\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    # Must be a function and not a method\n    if not isinstance(maxsize, int):\n        raise TypeError('maxsize must be an integer')\n    if maxsize < 0:\n        raise ValueError('maxsize must be greater than 0')\n\n    def decorator(func):\n        cached = MruCache(maxsize, typed)\n        cached.func = func\n        return cached\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    # You can use a function that returns a MRU value e.g. `len(cache)`\n    # to get the length of the list of keys in the cache.\n\n    def wrapper(fn):\n        cache = MruCache(maxsize, typed)\n        return lambda *a, **kw: cache.setdefault(fn(*a, **kw), fn(*a, **kw))\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    # You can make this decorator successor the old-fashioned coroutine.\n    def decorator(f):\n        cached = MruCache(f, maxsize, typed)\n        cached.name = f.__name__\n        return cached\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return partial(mru_cache, maxsize=128)\n    else:\n        return _MruCache(maxsize, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def mru_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if typed:\n        return _MruCacheTyped(maxsize)\n    else:\n        return _MruCacheWrapper(maxsize)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/func.py", "project": "pexip/os-python-cachetools", "name": "lru_cache", "docstring": "Decorator to wrap a function with a memoizing callable that saves\nup to `maxsize` results based on a Least Recently Used (LRU)\nalgorithm.", "ques_id": "62b8d23948ba5a41d1c3f498", "code": ["def lru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return _wrapper\n    else:\n        # XXX optimization: only save the function if its arguments are\n        #       the same object (e.g. Cache objects)\n        if maxsize < 1:\n            return _wrapper\n        else:\n            return _LRUCache(maxsize, typed)\n", "def lru_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than zero')\n\n    def wrapper(fn):\n        cached = LruCached(fn, maxsize)\n        return lambda *a, **kw: cached.call(*a, **kw)\n    if typed:\n        wrapper.__name__ = fn.__name__\n        wrapper.__doc__ = fn.__doc__\n        return wrapper\n    else:\n        return wrapper\n", "def lru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return partial(lru_cache, maxsize, typed)\n    else:\n        # This function is called on a single argument only, and we\n        # can simply return the result of cache_wrapper().\n        def wrapper(fn):\n            return cache_wrapper(fn, maxsize, typed)\n        return wrapper\n", "def lru_cache(maxsize=128, typed=False):\n    # This function must be wrapped with @memoize and not a decorator\n    if maxsize is None:\n        return None\n    else:\n        # wrap it with @memoize so the cache doesn't go over the limit\n        def wrapper(f):\n            return MemoizeCache(f, maxsize, typed)\n        return wrapper\n", "def lru_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than zero')\n    if typed:\n        return _TypedCache(maxsize)\n    else:\n        return _LRUCache(maxsize)\n", "def lru_cache(maxsize=128, typed=False):\n    # fetch the function from the namespace\n    cached = _lru_cache.cache.get(maxsize)\n    if cached is not None:\n        return cached\n\n    def decorator(fn):\n        # store the result of the decorated function in the LRU cache\n        _lru_cache.cache[maxsize] = (fn, fn(None))\n        return fn\n\n    if typed:\n        return decorator\n    else:\n        return decorator(fn)\n", "def lru_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n\n    def wrapper(fn):\n        cached = LruCached(fn, maxsize)\n        return lambda *a, **kw: cached.get(*a, **kw)\n\n    if typed:\n        wrapper.__doc__ = fn.__doc__\n        wrapper.__name__ = fn.__name__\n        return wrapper\n\n    return wrapper\n", "def lru_cache(maxsize=128, typed=False):\n    # If maxsize is an integer, wrap it in a function that caches its results\n    if type(maxsize) is not int:\n        def wrapper(f):\n            return LruCache(maxsize, typed, f)\n        return wrapper\n\n    # Decorator\n    def decorate(f):\n        # Wrap the function with a memoize cache if required\n        if maxsize is not None and maxsize < 0:\n            from functools import lru_cache\n            return lru_cache(maxsize)(f)\n        else:\n            return f\n\n    return decorate\n", "def lru_cache(maxsize=128, typed=False):\n    # You can use a docstring or something else to make this simple.\n\n    def wrapper(fn):\n        return LRUCache(maxsize, typed, fn)\n    return wrapper\n", "def lru_cache(maxsize=128, typed=False):\n    # Memoize is disabled in this implementation, and will be disabled in the\n    # next release of Python.\n    return _CacheDecorator(_LruCache(maxsize))\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def lru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return _wrapper\n    else:\n        # XXX optimization: only save the function if its arguments are\n        #       the same object (e.g. Cache objects)\n        if maxsize < 1:\n            return _wrapper\n        else:\n            return _LRUCache(maxsize, typed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than zero')\n\n    def wrapper(fn):\n        cached = LruCached(fn, maxsize)\n        return lambda *a, **kw: cached.call(*a, **kw)\n    if typed:\n        wrapper.__name__ = fn.__name__\n        wrapper.__doc__ = fn.__doc__\n        return wrapper\n    else:\n        return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    if maxsize is None:\n        return partial(lru_cache, maxsize, typed)\n    else:\n        # This function is called on a single argument only, and we\n        # can simply return the result of cache_wrapper().\n        def wrapper(fn):\n            return cache_wrapper(fn, maxsize, typed)\n        return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    # This function must be wrapped with @memoize and not a decorator\n    if maxsize is None:\n        return None\n    else:\n        # wrap it with @memoize so the cache doesn't go over the limit\n        def wrapper(f):\n            return MemoizeCache(f, maxsize, typed)\n        return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than zero')\n    if typed:\n        return _TypedCache(maxsize)\n    else:\n        return _LRUCache(maxsize)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    # fetch the function from the namespace\n    cached = _lru_cache.cache.get(maxsize)\n    if cached is not None:\n        return cached\n\n    def decorator(fn):\n        # store the result of the decorated function in the LRU cache\n        _lru_cache.cache[maxsize] = (fn, fn(None))\n        return fn\n\n    if typed:\n        return decorator\n    else:\n        return decorator(fn)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n\n    def wrapper(fn):\n        cached = LruCached(fn, maxsize)\n        return lambda *a, **kw: cached.get(*a, **kw)\n\n    if typed:\n        wrapper.__doc__ = fn.__doc__\n        wrapper.__name__ = fn.__name__\n        return wrapper\n\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    # If maxsize is an integer, wrap it in a function that caches its results\n    if type(maxsize) is not int:\n        def wrapper(f):\n            return LruCache(maxsize, typed, f)\n        return wrapper\n\n    # Decorator\n    def decorate(f):\n        # Wrap the function with a memoize cache if required\n        if maxsize is not None and maxsize < 0:\n            from functools import lru_cache\n            return lru_cache(maxsize)(f)\n        else:\n            return f\n\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    # You can use a docstring or something else to make this simple.\n\n    def wrapper(fn):\n        return LRUCache(maxsize, typed, fn)\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lru_cache(maxsize=128, typed=False):\n    # Memoize is disabled in this implementation, and will be disabled in the\n    # next release of Python.\n    return _CacheDecorator(_LruCache(maxsize))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/func.py", "project": "pexip/os-python-cachetools", "name": "lfu_cache", "docstring": "Decorator to wrap a function with a memoizing callable that saves\nup to `maxsize` results based on a Least Frequently Used (LFU)\nalgorithm.", "ques_id": "62b8d23748ba5a41d1c3f496", "code": ["def lfu_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if typed:\n        return _LFUTypedCache(maxsize)\n    else:\n        return _LFUWrapper(maxsize)\n", "def lfu_cache(maxsize=128, typed=False):\n    # You can use a function that returns a value than None (e.g., as opposed to a\n    # value from a coroutine or function). To access the returned value, you\n    # must use get().\n\n    # The lfu cache is a datastructure that stores values that correspond to\n    # keys of a LFU map. It is created by @lfu_cache and is updated by\n    # @lfu_cache.set.\n    cache = {}\n\n    def wrapper(fn):\n        @functools.wraps(fn)\n        def wrapped(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = fn(*args, **kwargs)\n                return ret\n\n        wrapped.__cache__ = {}\n        return wrapped\n\n    def wrapped_lfu_cache(*args", "def lfu_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if typed:\n        return _LFUTypedCache(maxsize)\n    else:\n        return _LFUWrapper(maxsize)\n", "def lfu_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if typed:\n        return _LFUTypedCache(maxsize)\n    else:\n        return _LFUWrapper(maxsize)\n", "def lfu_cache(maxsize=128, typed=False):\n    # You can access the function directly using the `cached` attribute.\n    # In this case, the cached result is returned immediately upon\n    # cache access.\n    def _wrapper(fn):\n        cached = _LFU.lfu_cache(maxsize, typed)\n        def _callable(*args, **kwargs):\n            key = _md5_key(fn, args, kwargs)\n            try:\n                return cached[key]\n            except KeyError:\n                result = cached[key] = fn(*args, **kwargs)\n                return result\n        return _callable\n    return _wrapper\n", "def lfu_cache(maxsize=128, typed=False):\n    # f = lfu_cache(maxsize)(function)\n    def _wrapper(function):\n        return Cache(function, maxsize, typed)\n    return _wrapper\n", "def lfu_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if maxsize == 1:\n        # No cache when the maxsize is one\n        return lambda f: f\n\n    def wrapper(f):\n        return LFUCache(f, maxsize, typed)\n    return wrapper\n", "def lfu_cache(maxsize=128, typed=False):\n    # You can use a function that returns a value than None and you don't want\n    # to cache it because that returns something already written into the\n    # cache.\n\n    def _wrapper(func):\n        cached_func = _LFUCodec(maxsize, typed)(func)\n        cached_func.cached = True\n        return cached_func\n\n    return _wrapper\n", "def lfu_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if typed:\n        return _LFUTypeCache(maxsize)\n    else:\n        return _LFUWrapper(maxsize)\n", "def lfu_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than zero')\n    if typed:\n        return _LFUCache(maxsize)\n    else:\n        def wrapper(fn):\n            return _LFUCache(maxsize, fn)\n        return wrapper\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if typed:\n        return _LFUTypedCache(maxsize)\n    else:\n        return _LFUWrapper(maxsize)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    # You can use a function that returns a value than None (e.g., as opposed to a\n    # value from a coroutine or function). To access the returned value, you\n    # must use get().\n\n    # The lfu cache is a datastructure that stores values that correspond to\n    # keys of a LFU map. It is created by @lfu_cache and is updated by\n    # @lfu_cache.set.\n    cache = {}\n\n    def wrapper(fn):\n        @functools.wraps(fn)\n        def wrapped(*args, **kwargs):\n            key = (args, frozenset(sorted(kwargs.items())))\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = fn(*args, **kwargs)\n                return ret\n\n        wrapped.__cache__ = {}\n        return wrapped\n\n    def wrapped_lfu_cache(*args", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if typed:\n        return _LFUTypedCache(maxsize)\n    else:\n        return _LFUWrapper(maxsize)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if typed:\n        return _LFUTypedCache(maxsize)\n    else:\n        return _LFUWrapper(maxsize)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    # You can access the function directly using the `cached` attribute.\n    # In this case, the cached result is returned immediately upon\n    # cache access.\n    def _wrapper(fn):\n        cached = _LFU.lfu_cache(maxsize, typed)\n        def _callable(*args, **kwargs):\n            key = _md5_key(fn, args, kwargs)\n            try:\n                return cached[key]\n            except KeyError:\n                result = cached[key] = fn(*args, **kwargs)\n                return result\n        return _callable\n    return _wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    # f = lfu_cache(maxsize)(function)\n    def _wrapper(function):\n        return Cache(function, maxsize, typed)\n    return _wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if maxsize == 1:\n        # No cache when the maxsize is one\n        return lambda f: f\n\n    def wrapper(f):\n        return LFUCache(f, maxsize, typed)\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    # You can use a function that returns a value than None and you don't want\n    # to cache it because that returns something already written into the\n    # cache.\n\n    def _wrapper(func):\n        cached_func = _LFUCodec(maxsize, typed)(func)\n        cached_func.cached = True\n        return cached_func\n\n    return _wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than 0')\n    if typed:\n        return _LFUTypeCache(maxsize)\n    else:\n        return _LFUWrapper(maxsize)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def lfu_cache(maxsize=128, typed=False):\n    if maxsize < 1:\n        raise ValueError('maxsize must be greater than zero')\n    if typed:\n        return _LFUCache(maxsize)\n    else:\n        def wrapper(fn):\n            return _LFUCache(maxsize, fn)\n        return wrapper\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/fifo.py", "project": "pexip/os-python-cachetools", "name": "popitem", "docstring": "Remove and return the `(key, value)` pair first inserted.", "ques_id": "62b8d22f48ba5a41d1c3f488", "code": ["def popitem(self):\n    try:\n        return dict.popitem(self)\n    except KeyError as err:\n        raise exceptions.BadArgumentError(\n            \"popitem() argument '{}' is not a valid argument for \"\n            \"this object\".format(err)\n        )\n", "def popitem(self):\n    raise NotImplementedError\n", "def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    try:\n        key = next(iter(self))\n        value = self[key]\n        del self[key]\n        return key, value\n    except StopIteration:\n        raise KeyError\n", "def popitem(self):\n    try:\n        return dict.popitem(self)[0]\n    except KeyError as e:\n        raise exceptions.BadRequestKeyError(str(e))\n", "def popitem(self):\n    value = dict.popitem(self)\n    self.__setitem__(keys(self), value)\n    return value\n", "def popitem(self):\n    try:\n        return dict.popitem(self)\n    except KeyError as e:\n        raise exceptions.BadRequestKeyError(str(e))\n", "def popitem(self):\n    if not self:\n        raise KeyError('popitem(): dictionary is already empty')\n    key = list(self._saved_values)[0]\n    return (key, self.pop(key))\n", "def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    value = dict.popitem(self)\n    key = value[0]\n    self.__delitem__(key)\n    return (key, value[1])\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def popitem(self):\n    try:\n        return dict.popitem(self)\n    except KeyError as err:\n        raise exceptions.BadArgumentError(\n            \"popitem() argument '{}' is not a valid argument for \"\n            \"this object\".format(err)\n        )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    raise NotImplementedError\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = next(iter(self))\n        value = self[key]\n        del self[key]\n        return key, value\n    except StopIteration:\n        raise KeyError\n", "is_pass": true, "return_code": 0}, {"generate_code": "def popitem(self):\n    try:\n        return dict.popitem(self)[0]\n    except KeyError as e:\n        raise exceptions.BadRequestKeyError(str(e))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    value = dict.popitem(self)\n    self.__setitem__(keys(self), value)\n    return value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        return dict.popitem(self)\n    except KeyError as e:\n        raise exceptions.BadRequestKeyError(str(e))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    if not self:\n        raise KeyError('popitem(): dictionary is already empty')\n    key = list(self._saved_values)[0]\n    return (key, self.pop(key))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    value = dict.popitem(self)\n    key = value[0]\n    self.__delitem__(key)\n    return (key, value[1])\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/cache.py", "project": "pexip/os-python-cachetools", "name": "setdefault", "docstring": "D.setdefault(k[,d]) -> D.get(k,d), also set D[k]=d if k not in D", "ques_id": "62b8d22a48ba5a41d1c3f47e", "code": ["def setdefault(self, key, default=None):\n    if key not in self:\n        self[key] = default\n    return self[key]\n", "def setdefault(self, key, default=None):\n    return super().setdefault(self._get_key(key), default)\n", "def setdefault(self, key, default=None):\n    return super().setdefault(key.lower(), default)\n", "def setdefault(self, key, default=None):\n    if not isinstance(key, string_types):\n        raise TypeError('keys must be strings')\n    return super(OrderedDict, self).setdefault(key, default)\n", "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "def setdefault(self, key, default=None):\n    return super().setdefault(self._keytransform(key), default)\n", "def setdefault(self, key, default=None):\n    return super().setdefault(key.lower(), default)\n", "def setdefault(self, key, default=None):\n    return super(OrderedDict, self).setdefault(key, default)\n", "def setdefault(self, key, default=None):\n    if key not in self:\n        super(OrderedDict, self).setdefault(key, default)\n    return super(OrderedDict, self).setdefault(key, default)\n", "def setdefault(self, key, default=None):\n    return super().setdefault(key.lower(), default)\n"], "level": "self_contained", "generate_results": [{"generate_code": "def setdefault(self, key, default=None):\n    if key not in self:\n        self[key] = default\n    return self[key]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def setdefault(self, key, default=None):\n    return super().setdefault(self._get_key(key), default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def setdefault(self, key, default=None):\n    return super().setdefault(key.lower(), default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def setdefault(self, key, default=None):\n    if not isinstance(key, string_types):\n        raise TypeError('keys must be strings')\n    return super(OrderedDict, self).setdefault(key, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def setdefault(self, key, default=None):\n    try:\n        return self[key]\n    except KeyError:\n        self[key] = default\n        return default\n", "is_pass": true, "return_code": 0}, {"generate_code": "def setdefault(self, key, default=None):\n    return super().setdefault(self._keytransform(key), default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def setdefault(self, key, default=None):\n    return super().setdefault(key.lower(), default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def setdefault(self, key, default=None):\n    return super(OrderedDict, self).setdefault(key, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def setdefault(self, key, default=None):\n    if key not in self:\n        super(OrderedDict, self).setdefault(key, default)\n    return super(OrderedDict, self).setdefault(key, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def setdefault(self, key, default=None):\n    return super().setdefault(key.lower(), default)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/cache.py", "project": "pexip/os-python-cachetools", "name": "get", "docstring": "D.get(k[,d]) -> D[k] if k in D, else d.  d defaults to None.", "ques_id": "62b8d22948ba5a41d1c3f47c", "code": ["def get(self, key, default=None):\n    return super().get(key.upper(), default)\n", "def get(self, key, default=None):\n    return self._dict.get(key, default)\n", "def get(self, key, default=None):\n    return super().get(key.upper(), default)\n", "def get(self, key, default=None):\n    return super().get(key.lower(), default)\n", "def get(self, key, default=None):\n    return self._dict.get(key, default)\n", "def get(self, key, default=None):\n    return self[key] if key in self else default\n", "def get(self, key, default=None):\n    return self[key] if key in self else default\n", "def get(self, key, default=None):\n    return self[key] if key in self else default\n", "def get(self, key, default=None):\n    return self[key] if key in self else default\n", "def get(self, key, default=None):\n    return self[key] if key in self else default\n"], "level": "self_contained", "generate_results": [{"generate_code": "def get(self, key, default=None):\n    return super().get(key.upper(), default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get(self, key, default=None):\n    return self._dict.get(key, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get(self, key, default=None):\n    return super().get(key.upper(), default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get(self, key, default=None):\n    return super().get(key.lower(), default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get(self, key, default=None):\n    return self._dict.get(key, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get(self, key, default=None):\n    return self[key] if key in self else default\n", "is_pass": true, "return_code": 0}, {"generate_code": "def get(self, key, default=None):\n    return self[key] if key in self else default\n", "is_pass": true, "return_code": 0}, {"generate_code": "def get(self, key, default=None):\n    return self[key] if key in self else default\n", "is_pass": true, "return_code": 0}, {"generate_code": "def get(self, key, default=None):\n    return self[key] if key in self else default\n", "is_pass": true, "return_code": 0}, {"generate_code": "def get(self, key, default=None):\n    return self[key] if key in self else default\n", "is_pass": true, "return_code": 0}]}
{"file_path": "cachetools/decorators.py", "project": "pexip/os-python-cachetools", "name": "cachedmethod", "docstring": "Decorator to wrap a class or instance method with a memoizing\ncallable that saves results in a cache.", "ques_id": "62b8d22548ba5a41d1c3f472", "code": ["def cachedmethod(cache, key=hashkey, lock=None):\n    def _wrapper(func):\n        if lock is None:\n            lock = threading.Lock()\n\n        def __wrapper(self, *args, **kwargs):\n            with lock:\n                return func(self, *args, **kwargs)\n        return __wrapper\n    return _wrapper(cache)\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        return CachedMethodWrapper(func, cache, key, lock)\n    return decorator\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        if lock is None:\n            lock = threading.Lock()\n\n        def wrapper(self, *args, **kw):\n            with lock:\n                return func(self, *args, **kw)\n        return wrapper\n    if isinstance(cache, type):\n        # We can cache on a class\n        return decorator(cache)\n    else:\n        # We can cache on an instance\n        return decorator(cache.__call__)\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def _wrapper(func):\n        if lock is None:\n            lock = cache.lock\n\n        @functools.wraps(func)\n        def __wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(*args, **kwargs)\n                return ret\n\n        __wrapper.cache = cache\n        __wrapper.key = key\n        return __wrapper\n    return _wrapper\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def _wrapper(func):\n        if lock is None:\n            lock = cache.lock\n        @functools.wraps(func)\n        def __wrapper(self, *args, **kwargs):\n            key = key(self, *args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(self, *args, **kwargs)\n                return ret\n        return __wrapper\n    return _wrapper\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        if lock is None:\n            lock = threading.Lock()\n\n        @functools.wraps(func)\n        def wrapper(self, *args, **kw):\n            key = key(self, *args, **kw)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(self, *args, **kw)\n                return ret\n\n        return wrapper\n\n    if isinstance(cache, Memoize):\n        return cache.get(key)\n    else:\n        decorator = decorator(cache)\n        return update_wrapper(decorator, func)\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def _wrapper(func):\n        if lock is None:\n            lock = cache.lock\n        def _inner(self, *args, **kwargs):\n            key = key(self, *args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(self, *args, **kwargs)\n                return ret\n        def _wrapped(self, *args, **kwargs):\n            key = key(self, *args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(self, *args, **kwargs)\n                return ret\n        return _inner\n    return _wrapper\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def _wrapper(func):\n        @functools.wraps(func)\n        def __wrapper(self, *args, **kwargs):\n            key = key(self, *args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(self, *args, **kwargs)\n                return ret\n        return __wrapper\n    return _wrapper\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def _wrapper(func):\n        return CachedMethod(func, cache, key, lock)\n    return _wrapper\n", "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        if lock is None:\n            lock = threading.Lock()\n\n        def wrapper(self, *args, **kw):\n            key = key(self, *args, **kw)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(self, *args, **kw)\n                return ret\n\n        wrapper.__doc__ = func.__doc__\n        wrapper.__name__ = func.__name__\n        wrapper.cache = cache\n        wrapper.key = key\n        return wrapper\n\n    if isinstance(cache, Memoize):\n        return cache\n    else:\n        decorator.cache = cache = Memoize()\n        return decorator\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def _wrapper(func):\n        if lock is None:\n            lock = threading.Lock()\n\n        def __wrapper(self, *args, **kwargs):\n            with lock:\n                return func(self, *args, **kwargs)\n        return __wrapper\n    return _wrapper(cache)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        return CachedMethodWrapper(func, cache, key, lock)\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        if lock is None:\n            lock = threading.Lock()\n\n        def wrapper(self, *args, **kw):\n            with lock:\n                return func(self, *args, **kw)\n        return wrapper\n    if isinstance(cache, type):\n        # We can cache on a class\n        return decorator(cache)\n    else:\n        # We can cache on an instance\n        return decorator(cache.__call__)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def _wrapper(func):\n        if lock is None:\n            lock = cache.lock\n\n        @functools.wraps(func)\n        def __wrapper(*args, **kwargs):\n            key = key(*args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(*args, **kwargs)\n                return ret\n\n        __wrapper.cache = cache\n        __wrapper.key = key\n        return __wrapper\n    return _wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def _wrapper(func):\n        if lock is None:\n            lock = cache.lock\n        @functools.wraps(func)\n        def __wrapper(self, *args, **kwargs):\n            key = key(self, *args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(self, *args, **kwargs)\n                return ret\n        return __wrapper\n    return _wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        if lock is None:\n            lock = threading.Lock()\n\n        @functools.wraps(func)\n        def wrapper(self, *args, **kw):\n            key = key(self, *args, **kw)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(self, *args, **kw)\n                return ret\n\n        return wrapper\n\n    if isinstance(cache, Memoize):\n        return cache.get(key)\n    else:\n        decorator = decorator(cache)\n        return update_wrapper(decorator, func)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def _wrapper(func):\n        if lock is None:\n            lock = cache.lock\n        def _inner(self, *args, **kwargs):\n            key = key(self, *args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(self, *args, **kwargs)\n                return ret\n        def _wrapped(self, *args, **kwargs):\n            key = key(self, *args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(self, *args, **kwargs)\n                return ret\n        return _inner\n    return _wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def _wrapper(func):\n        @functools.wraps(func)\n        def __wrapper(self, *args, **kwargs):\n            key = key(self, *args, **kwargs)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(self, *args, **kwargs)\n                return ret\n        return __wrapper\n    return _wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def _wrapper(func):\n        return CachedMethod(func, cache, key, lock)\n    return _wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def cachedmethod(cache, key=hashkey, lock=None):\n    def decorator(func):\n        if lock is None:\n            lock = threading.Lock()\n\n        def wrapper(self, *args, **kw):\n            key = key(self, *args, **kw)\n            try:\n                return cache[key]\n            except KeyError:\n                ret = cache[key] = func(self, *args, **kw)\n                return ret\n\n        wrapper.__doc__ = func.__doc__\n        wrapper.__name__ = func.__name__\n        wrapper.cache = cache\n        wrapper.key = key\n        return wrapper\n\n    if isinstance(cache, Memoize):\n        return cache\n    else:\n        decorator.cache = cache = Memoize()\n        return decorator\n", "is_pass": false, "return_code": 1}]}
{"file_path": "pysolbase/SolBase.py", "project": "champax/pysolbase", "name": "extostr", "docstring": "Format an exception.\n:param e: Any exception instance.\n:type e: Exception\n:param max_level: Maximum call stack level (default 30)\n:type max_level: int\n:param max_path_level: Maximum path level (default 5)\n:type max_path_level: int\n:return The exception readable string\n:rtype str", "ques_id": "62b8c517e0d34b282c18122e", "code": ["def extostr(cls, e, max_level=30, max_path_level=5):\n    out = ''\n    if issubclass(e.__class__, HTTPException):\n        out = e.get_response().get_data()\n    elif isinstance(e, HTTPError):\n        out = e.get_message()\n    elif isinstance(e, ConnectionError):\n        out = '%s (%s)' % (e.code, e.message)\n    elif isinstance(e, Timeout):\n        out = '%s (%s)' % (e.args[0], e.args[1])\n    else:\n        out = str(e)\n    if len(out) > max_path_level:\n        out = out[:max_path_level - 3] + '...'\n    return out\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    return ''.join(traceback.format_exception(\n        type(e),\n        e,\n        traceback.extract_tb(sys.exc_info()[2])\n    )[0]).rstrip()\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    return \"{0}\\n{1}\\n{2}\".format(e.__class__.__name__, str(e), \" \".join(traceback.format_stack(limit=max_path_level)))\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    if isinstance(e, Exception):\n        e_str = e.__str__()\n    elif isinstance(e, requests.Response):\n        e_str = e.text\n    else:\n        e_str = str(e)\n\n    return '{}: {} / {}'.format(cls.__name__, e_str, max_level)\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    if isinstance(e, HttpException):\n        return str(e)\n\n    if isinstance(e, Exception):\n        return str(e)\n\n    return ''\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    if isinstance(e, Exception):\n        return cls.__extostr__(e, max_level=max_level, max_path_level=max_path_level)\n    else:\n        return str(e)\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    if isinstance(e, str):\n        return e\n\n    if not isinstance(e, Exception):\n        return str(e)\n\n    lines = []\n    for attr, value in sorted(e.__dict__.items()):\n        if attr in ('__dict__', '__weakref__'):\n            continue\n\n        if isinstance(value, Exception):\n            lines.append('{}: {}'.format(attr, value))\n        else:\n            lines.append('{}: {}'.format(attr, value))\n\n    return '{}: {}'.format(cls.__name__, '\\n  '.join(lines))\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    return ''.join(traceback.format_exception(cls, e, max_path_level))\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    if isinstance(e, Exception):\n        return \"%s: %s\" % (cls.__name__, e)\n    else:\n        return str(e)\n", "def extostr(cls, e, max_level=30, max_path_level=5):\n    return ''.join(traceback.format_exception(cls, e, max_level))\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    out = ''\n    if issubclass(e.__class__, HTTPException):\n        out = e.get_response().get_data()\n    elif isinstance(e, HTTPError):\n        out = e.get_message()\n    elif isinstance(e, ConnectionError):\n        out = '%s (%s)' % (e.code, e.message)\n    elif isinstance(e, Timeout):\n        out = '%s (%s)' % (e.args[0], e.args[1])\n    else:\n        out = str(e)\n    if len(out) > max_path_level:\n        out = out[:max_path_level - 3] + '...'\n    return out\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    return ''.join(traceback.format_exception(\n        type(e),\n        e,\n        traceback.extract_tb(sys.exc_info()[2])\n    )[0]).rstrip()\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    return \"{0}\\n{1}\\n{2}\".format(e.__class__.__name__, str(e), \" \".join(traceback.format_stack(limit=max_path_level)))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    if isinstance(e, Exception):\n        e_str = e.__str__()\n    elif isinstance(e, requests.Response):\n        e_str = e.text\n    else:\n        e_str = str(e)\n\n    return '{}: {} / {}'.format(cls.__name__, e_str, max_level)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    if isinstance(e, HttpException):\n        return str(e)\n\n    if isinstance(e, Exception):\n        return str(e)\n\n    return ''\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    if isinstance(e, Exception):\n        return cls.__extostr__(e, max_level=max_level, max_path_level=max_path_level)\n    else:\n        return str(e)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    if isinstance(e, str):\n        return e\n\n    if not isinstance(e, Exception):\n        return str(e)\n\n    lines = []\n    for attr, value in sorted(e.__dict__.items()):\n        if attr in ('__dict__', '__weakref__'):\n            continue\n\n        if isinstance(value, Exception):\n            lines.append('{}: {}'.format(attr, value))\n        else:\n            lines.append('{}: {}'.format(attr, value))\n\n    return '{}: {}'.format(cls.__name__, '\\n  '.join(lines))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    return ''.join(traceback.format_exception(cls, e, max_path_level))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    if isinstance(e, Exception):\n        return \"%s: %s\" % (cls.__name__, e)\n    else:\n        return str(e)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def extostr(cls, e, max_level=30, max_path_level=5):\n    return ''.join(traceback.format_exception(cls, e, max_level))\n", "is_pass": true, "return_code": 0}]}
{"file_path": "pysolbase/FileUtility.py", "project": "champax/pysolbase", "name": "append_text_to_file", "docstring": "Write to the specified filename, the provided binary buffer\nCreate the file if required.\n:param file_name:  File name.\n:type file_name: str\n:param text_buffer: Text buffer to write.\n:type text_buffer: str\n:param encoding: The encoding to use.\n:type encoding: str\n:param overwrite: If true, file is overwritten.\n:type overwrite: bool\n:return: The number of bytes written or lt 0 if error.\n:rtype int", "ques_id": "62b8bbbfe0d34b282c181210", "code": ["def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    try:\n        file_handle = open(file_name, 'ab')\n    except OSError as err:\n        raise FileOpenError(err)\n\n    try:\n        text_buffer = text_buffer.encode(encoding)\n    except (UnicodeEncodeError, AttributeError):\n        pass\n\n    file_handle.write(text_buffer)\n\n    if overwrite:\n        os.remove(file_name)\n\n    return len(text_buffer)\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    try:\n        with open(file_name, \"ab\") as f:\n            if overwrite or not os.path.exists(file_name):\n                f.write(text_buffer)\n                return len(text_buffer)\n            else:\n                return 0\n    except Exception as e:\n        return 0\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not overwrite and os.path.exists(file_name):\n        # If the file already exists write to it.\n        try:\n            with open(file_name, 'r', encoding=encoding) as f:\n                f.write(text_buffer)\n            return len(text_buffer)\n        except UnicodeEncodeError:\n            print('Encoding error: {}'.format(encoding))\n            return 0\n\n    # Write the file if it does not exist.\n    with open(file_name, 'wb', encoding=encoding) as f:\n        return f.write(text_buffer)\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    try:\n        with open(file_name, 'ab') as f:\n            return f.write(text_buffer.encode(encoding))\n    except OSError as e:\n        if e.errno == errno.ENOENT:\n            return 0\n        raise\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    try:\n        with open(file_name, 'ab') as f:\n            if overwrite or not os.path.exists(file_name):\n                f.write(text_buffer)\n                return len(text_buffer)\n            else:\n                return 0\n    except (OSError, IOError) as e:\n        print_and_log('ERROR: Unable to write to file \"{0}\": {1}'.format(\n            file_name, e), 'ERROR')\n        return 0\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if overwrite or not os.path.exists(file_name):\n        with open(file_name, 'wb') as file:\n            file.write(text_buffer)\n        return len(text_buffer)\n    else:\n        return 0\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not overwrite and os.path.isfile(file_name):\n        return 0\n\n    try:\n        with open(file_name, \"ab\") as file_handle:\n            file_handle.write(text_buffer.encode(encoding))\n        return len(text_buffer)\n    except UnicodeEncodeError:\n        return 0\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not overwrite and os.path.exists(file_name):\n        raise FileExistsError(\"File {} already exists\".format(file_name))\n\n    with open(file_name, 'wb') as file:\n        return file.write(text_buffer)\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    return _write_bytes_to_file(file_name, text_buffer, encoding, False)\n", "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not overwrite and os.path.isfile(file_name):\n        return 0\n\n    try:\n        with open(file_name, 'ab') as file_handle:\n            file_handle.write(text_buffer)\n    except UnicodeEncodeError as error:\n        print(error)\n        return 0\n    except IOError as error:\n        print('Could not write to file: {0}'.format(error))\n        return 0\n    return len(text_buffer)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    try:\n        file_handle = open(file_name, 'ab')\n    except OSError as err:\n        raise FileOpenError(err)\n\n    try:\n        text_buffer = text_buffer.encode(encoding)\n    except (UnicodeEncodeError, AttributeError):\n        pass\n\n    file_handle.write(text_buffer)\n\n    if overwrite:\n        os.remove(file_name)\n\n    return len(text_buffer)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    try:\n        with open(file_name, \"ab\") as f:\n            if overwrite or not os.path.exists(file_name):\n                f.write(text_buffer)\n                return len(text_buffer)\n            else:\n                return 0\n    except Exception as e:\n        return 0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not overwrite and os.path.exists(file_name):\n        # If the file already exists write to it.\n        try:\n            with open(file_name, 'r', encoding=encoding) as f:\n                f.write(text_buffer)\n            return len(text_buffer)\n        except UnicodeEncodeError:\n            print('Encoding error: {}'.format(encoding))\n            return 0\n\n    # Write the file if it does not exist.\n    with open(file_name, 'wb', encoding=encoding) as f:\n        return f.write(text_buffer)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    try:\n        with open(file_name, 'ab') as f:\n            return f.write(text_buffer.encode(encoding))\n    except OSError as e:\n        if e.errno == errno.ENOENT:\n            return 0\n        raise\n", "is_pass": false, "return_code": 1}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    try:\n        with open(file_name, 'ab') as f:\n            if overwrite or not os.path.exists(file_name):\n                f.write(text_buffer)\n                return len(text_buffer)\n            else:\n                return 0\n    except (OSError, IOError) as e:\n        print_and_log('ERROR: Unable to write to file \"{0}\": {1}'.format(\n            file_name, e), 'ERROR')\n        return 0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if overwrite or not os.path.exists(file_name):\n        with open(file_name, 'wb') as file:\n            file.write(text_buffer)\n        return len(text_buffer)\n    else:\n        return 0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not overwrite and os.path.isfile(file_name):\n        return 0\n\n    try:\n        with open(file_name, \"ab\") as file_handle:\n            file_handle.write(text_buffer.encode(encoding))\n        return len(text_buffer)\n    except UnicodeEncodeError:\n        return 0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not overwrite and os.path.exists(file_name):\n        raise FileExistsError(\"File {} already exists\".format(file_name))\n\n    with open(file_name, 'wb') as file:\n        return file.write(text_buffer)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    return _write_bytes_to_file(file_name, text_buffer, encoding, False)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def append_text_to_file(file_name, text_buffer, encoding, overwrite=False):\n    if not overwrite and os.path.isfile(file_name):\n        return 0\n\n    try:\n        with open(file_name, 'ab') as file_handle:\n            file_handle.write(text_buffer)\n    except UnicodeEncodeError as error:\n        print(error)\n        return 0\n    except IOError as error:\n        print('Could not write to file: {0}'.format(error))\n        return 0\n    return len(text_buffer)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "pysolbase/FileUtility.py", "project": "champax/pysolbase", "name": "file_to_textbuffer", "docstring": "Load a file toward a text buffer (UTF-8), using the specify encoding while reading.\nCAUTION : This will read the whole file IN MEMORY.\n:param file_name: File name.\n:type file_name: str\n:param encoding: Encoding to use.\n:type encoding: str\n:return: A text buffer or None in case of error.\n:rtype str", "ques_id": "62b8bbbfe0d34b282c18120f", "code": ["def file_to_textbuffer(file_name, encoding):\n    try:\n        buffer = gtk.TextBuffer()\n        with open(file_name, 'r', encoding=encoding) as f:\n            buffer.set_text(f.read())\n        buffer.set_modified(False)\n    except Exception as exc:\n        print('Unable to load file: {}'.format(file_name))\n        print(exc)\n        buffer.set_modified(True)\n        return None\n    return buffer\n", "def file_to_textbuffer(file_name, encoding):\n    try:\n        return codecs.open(file_name, \"r\", encoding).read()\n    except Exception:\n        return None\n", "def file_to_textbuffer(file_name, encoding):\n    try:\n        file = codecs.open(file_name, 'r', encoding)\n    except IOError:\n        return None\n    try:\n        text = file.read()\n    finally:\n        file.close()\n    return text\n", "def file_to_textbuffer(file_name, encoding):\n    try:\n        buffer = gtk.TextBuffer()\n        buffer.set_text(file_name)\n        buffer.set_chars_from_name(file_name, encoding)\n        return buffer\n    except Exception:\n        return None\n", "def file_to_textbuffer(file_name, encoding):\n    try:\n        file = codecs.open(file_name, encoding=encoding)\n    except Exception as e:\n        print(\"Cannot open file '{}'. Error: {}\".format(file_name, e))\n        return None\n    else:\n        text = file.read()\n        file.close()\n        return text\n", "def file_to_textbuffer(file_name, encoding):\n    try:\n        buffer = None\n        with open(file_name, \"r\", encoding=encoding) as f:\n            buffer = f.read()\n    except FileNotFoundError as e:\n        print(\"Can't find the file {}. Please check the file path and try again\".format(file_name))\n        print(e)\n        return None\n    return buffer\n", "def file_to_textbuffer(file_name, encoding):\n    try:\n        return gfile.GFile(file_name, 'rb').read().decode(encoding)\n    except IOError:\n        return None\n", "def file_to_textbuffer(file_name, encoding):\n    try:\n        with io.open(file_name, mode='r', encoding=encoding) as f:\n            text_buffer = f.read()\n    except IOError:\n        return None\n    return text_buffer\n", "def file_to_textbuffer(file_name, encoding):\n    try:\n        with io.open(file_name, encoding=encoding) as f:\n            return f.read()\n    except IOError:\n        return None\n", "def file_to_textbuffer(file_name, encoding):\n    try:\n        return Gio.file_parse_name(file_name).get_contents_as(\n            encoding=encoding)\n    except GLib.GError as ex:\n        if ex.code == Gio.FILE_NOT_FOUND:\n            return None\n        raise\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def file_to_textbuffer(file_name, encoding):\n    try:\n        buffer = gtk.TextBuffer()\n        with open(file_name, 'r', encoding=encoding) as f:\n            buffer.set_text(f.read())\n        buffer.set_modified(False)\n    except Exception as exc:\n        print('Unable to load file: {}'.format(file_name))\n        print(exc)\n        buffer.set_modified(True)\n        return None\n    return buffer\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    try:\n        return codecs.open(file_name, \"r\", encoding).read()\n    except Exception:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    try:\n        file = codecs.open(file_name, 'r', encoding)\n    except IOError:\n        return None\n    try:\n        text = file.read()\n    finally:\n        file.close()\n    return text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    try:\n        buffer = gtk.TextBuffer()\n        buffer.set_text(file_name)\n        buffer.set_chars_from_name(file_name, encoding)\n        return buffer\n    except Exception:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    try:\n        file = codecs.open(file_name, encoding=encoding)\n    except Exception as e:\n        print(\"Cannot open file '{}'. Error: {}\".format(file_name, e))\n        return None\n    else:\n        text = file.read()\n        file.close()\n        return text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    try:\n        buffer = None\n        with open(file_name, \"r\", encoding=encoding) as f:\n            buffer = f.read()\n    except FileNotFoundError as e:\n        print(\"Can't find the file {}. Please check the file path and try again\".format(file_name))\n        print(e)\n        return None\n    return buffer\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    try:\n        return gfile.GFile(file_name, 'rb').read().decode(encoding)\n    except IOError:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    try:\n        with io.open(file_name, mode='r', encoding=encoding) as f:\n            text_buffer = f.read()\n    except IOError:\n        return None\n    return text_buffer\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    try:\n        with io.open(file_name, encoding=encoding) as f:\n            return f.read()\n    except IOError:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def file_to_textbuffer(file_name, encoding):\n    try:\n        return Gio.file_parse_name(file_name).get_contents_as(\n            encoding=encoding)\n    except GLib.GError as ex:\n        if ex.code == Gio.FILE_NOT_FOUND:\n            return None\n        raise\n", "is_pass": false, "return_code": 1}]}
{"file_path": "pysolbase/FileUtility.py", "project": "champax/pysolbase", "name": "is_file_exist", "docstring": "Check if file name exist.\n:param file_name: File name.\n:type file_name: str\n:return: Return true (exist), false (do not exist, or invalid file name)\n:rtype bool", "ques_id": "62b8bbbce0d34b282c18120d", "code": ["def is_file_exist(file_name):\n    if not isinstance(file_name, str):\n        return False\n\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    if not file_name:\n        return False\n\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    if not isinstance(file_name, str):\n        return False\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def is_file_exist(file_name):\n    if not isinstance(file_name, str):\n        return False\n\n    return os.path.isfile(file_name)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_file_exist(file_name):\n    if not file_name:\n        return False\n\n    return os.path.isfile(file_name)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_file_exist(file_name):\n    if not isinstance(file_name, str):\n        return False\n    return os.path.isfile(file_name)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_file_exist(file_name):\n    return os.path.isfile(file_name)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "pysolbase/SolBase.py", "project": "champax/pysolbase", "name": "_reset_logging", "docstring": "Reset", "ques_id": "62b8b99de0d34b282c1811f8", "code": ["def _reset_logging(cls):\n    logging.disable(logging.CRITICAL)\n", "def _reset_logging(cls):\n    logging.disable(logging.CRITICAL)\n", "def _reset_logging(cls):\n    logging.disable(logging.CRITICAL)\n", "def _reset_logging(cls):\n    logging.disable(logging.NOTSET)\n", "def _reset_logging(cls):\n    logging.getLogger().removeHandler(cls._log_handler)\n", "def _reset_logging(cls):\n    logging.getLogger().removeHandler(cls._log_handler)\n", "def _reset_logging(cls):\n    logging.disable(logging.CRITICAL)\n", "def _reset_logging(cls):\n    logging.getLogger().removeHandler(cls._log_handler)\n", "def _reset_logging(cls):\n    if '_logging_context' in cls.__dict__:\n        cls._logging_context.pop('loggers', None)\n        cls._logging_context.pop('handlers', None)\n", "def _reset_logging(cls):\n    global _logger\n    _logger = logging.getLogger(cls.__name__)\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def _reset_logging(cls):\n    logging.disable(logging.CRITICAL)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    logging.disable(logging.CRITICAL)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    logging.disable(logging.CRITICAL)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    logging.disable(logging.NOTSET)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    logging.getLogger().removeHandler(cls._log_handler)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    logging.getLogger().removeHandler(cls._log_handler)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    logging.disable(logging.CRITICAL)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    logging.getLogger().removeHandler(cls._log_handler)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    if '_logging_context' in cls.__dict__:\n        cls._logging_context.pop('loggers', None)\n        cls._logging_context.pop('handlers', None)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _reset_logging(cls):\n    global _logger\n    _logger = logging.getLogger(cls.__name__)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "src/zope/interface/tests/test_declarations.py", "project": "pexip/os-zope", "name": "_getTargetClass", "docstring": "Define this to return the implementation in use,\nwithout the 'Py' or 'Fallback' suffix.", "ques_id": "62b8b59feb7e40a82d2d1291", "code": ["def _getTargetClass(self):\n    return html.Link\n", "def _getTargetClass(self):\n    return JavaScriptScriptTextTarget\n", "def _getTargetClass(self):\n    return TextTestResult\n", "def _getTargetClass(self):\n    return html.Target\n", "def _getTargetClass(self):\n    return html.Target\n", "def _getTargetClass(self):\n    return TextTestResult\n", "def _getTargetClass(self):\n    return Template\n", "def _getTargetClass(self):\n    return DataTarget\n", "def _getTargetClass(self):\n    return html.Join\n", "def _getTargetClass(self):\n    return html.Target\n"], "level": "self_contained", "generate_results": [{"generate_code": "def _getTargetClass(self):\n    return html.Link\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return JavaScriptScriptTextTarget\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return TextTestResult\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return html.Target\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return html.Target\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return TextTestResult\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return Template\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return DataTarget\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return html.Join\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _getTargetClass(self):\n    return html.Target\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/ro.py", "project": "pexip/os-zope", "name": "_legacy_mergeOrderings", "docstring": "Merge multiple orderings so that within-ordering order is preserved\n\nOrderings are constrained in such a way that if an object appears\nin two or more orderings, then the suffix that begins with the\nobject must be in both orderings.\n\nFor example:\n\n>>> _mergeOrderings([\n... ['x', 'y', 'z'],\n... ['q', 'z'],\n... [1, 3, 5],\n... ['z']\n... ])\n['x', 'y', 'q', 1, 3, 5, 'z']", "ques_id": "62b8b590eb7e40a82d2d1275", "code": ["def _legacy_mergeOrderings(orderings):\n    merged = []\n    current = []\n\n    for ordering in orderings:\n        if len(current) == 0:\n            continue\n        elif len(current) == 1:\n            merged.append(current[0])\n            current = []\n        else:\n            merged.append(current[0])\n            merged.append(ordering[0])\n            current.pop(0)\n\n    if current:\n        merged.append(current)\n\n    return merged\n", "def _legacy_mergeOrderings(orderings):\n    result = []\n    for o in orderings:\n        for e in o:\n            if e not in result:\n                result.append(e)\n    return result\n", "def _legacy_mergeOrderings(orderings):\n    orderings = [_convert.convert(o) for o in orderings]\n\n    # Find the longest common suffix\n    common_suffix = None\n    longest_common_suffix = None\n    for index, o in enumerate(orderings):\n        if len(o) == 1:\n            continue\n        for other_o in orderings[index + 1:]:\n            if len(o) < len(other_o) and o[-1]!= other_o[-1]:\n                if common_suffix is None or o[-1] < common_suffix:\n                    common_suffix = o[-1]\n                    longest_common_suffix = other_o[-1]\n    if common_suffix is None:\n        return orderings\n\n    # Merge the two sorted orderings together\n    merged_orderings = []\n    for o in orderings:\n        if len(o) == 1:\n            merged_orderings.append(o[0])\n        else:\n   ", "def _legacy_mergeOrderings(orderings):\n    result = []\n    for ordering in orderings:\n        result.extend(ordering)\n\n    return result\n", "def _legacy_mergeOrderings(orderings):\n    # We can't use set.intersection because that would remove duplicates, while\n    # set.intersection returns all items in the set\n    return sorted(set([o[0] for o in orderings] + [o[1] for o in orderings]))\n", "def _legacy_mergeOrderings(orderings):\n    # get rid of duplicates and remove any empty orderings\n    orderings = list(set(orderings))\n    while len(orderings) > 1:\n        first = orderings.pop(0)\n        second = orderings.pop(0)\n        for e in second:\n            if e not in first:\n                orderings.append(e)\n    return orderings\n", "def _legacy_mergeOrderings(orderings):\n    orderings.sort(key=lambda o: o[0].lower())\n    merged = []\n    prev_end = 0\n    for o in orderings:\n        if (o[0].lower() == prev_end.lower() or\n            o[1].lower() == prev_end.lower()):\n            # Object appears in the same ordering twice\n            merged.append(o)\n        else:\n            # Object appears in different orderings or is this one merged?\n            # We should add the object to the previous one and return the previous one\n            prev_end = o[1]\n            merged.append(o)\n    return merged\n", "def _legacy_mergeOrderings(orderings):\n    orderings = [_fix_ordering(o) for o in orderings]\n    result = []\n    for o in orderings:\n        for e in o:\n            if e not in result:\n                result.append(e)\n    return result\n", "def _legacy_mergeOrderings(orderings):\n    if len(orderings) < 2:\n        return orderings\n\n    result = []\n    suffix = []\n    for ordering in orderings:\n        for i in range(len(ordering)):\n            if i == 0 or ordering[i][0] <= ordering[i - 1][0]:\n                suffix.append(ordering[i][1])\n            else:\n                result.append(ordering[i])\n\n    return result + suffix\n", "def _legacy_mergeOrderings(orderings):\n    orderings = [orderings] if isinstance(orderings, list) else orderings\n    result = []\n    for o in orderings:\n        for e in o:\n            if e not in result:\n                result.append(e)\n    return result\n"], "level": "self_contained", "generate_results": [{"generate_code": "def _legacy_mergeOrderings(orderings):\n    merged = []\n    current = []\n\n    for ordering in orderings:\n        if len(current) == 0:\n            continue\n        elif len(current) == 1:\n            merged.append(current[0])\n            current = []\n        else:\n            merged.append(current[0])\n            merged.append(ordering[0])\n            current.pop(0)\n\n    if current:\n        merged.append(current)\n\n    return merged\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    result = []\n    for o in orderings:\n        for e in o:\n            if e not in result:\n                result.append(e)\n    return result\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    orderings = [_convert.convert(o) for o in orderings]\n\n    # Find the longest common suffix\n    common_suffix = None\n    longest_common_suffix = None\n    for index, o in enumerate(orderings):\n        if len(o) == 1:\n            continue\n        for other_o in orderings[index + 1:]:\n            if len(o) < len(other_o) and o[-1]!= other_o[-1]:\n                if common_suffix is None or o[-1] < common_suffix:\n                    common_suffix = o[-1]\n                    longest_common_suffix = other_o[-1]\n    if common_suffix is None:\n        return orderings\n\n    # Merge the two sorted orderings together\n    merged_orderings = []\n    for o in orderings:\n        if len(o) == 1:\n            merged_orderings.append(o[0])\n        else:\n   ", "is_pass": false, "return_code": 1}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    result = []\n    for ordering in orderings:\n        result.extend(ordering)\n\n    return result\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    # We can't use set.intersection because that would remove duplicates, while\n    # set.intersection returns all items in the set\n    return sorted(set([o[0] for o in orderings] + [o[1] for o in orderings]))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    # get rid of duplicates and remove any empty orderings\n    orderings = list(set(orderings))\n    while len(orderings) > 1:\n        first = orderings.pop(0)\n        second = orderings.pop(0)\n        for e in second:\n            if e not in first:\n                orderings.append(e)\n    return orderings\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    orderings.sort(key=lambda o: o[0].lower())\n    merged = []\n    prev_end = 0\n    for o in orderings:\n        if (o[0].lower() == prev_end.lower() or\n            o[1].lower() == prev_end.lower()):\n            # Object appears in the same ordering twice\n            merged.append(o)\n        else:\n            # Object appears in different orderings or is this one merged?\n            # We should add the object to the previous one and return the previous one\n            prev_end = o[1]\n            merged.append(o)\n    return merged\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    orderings = [_fix_ordering(o) for o in orderings]\n    result = []\n    for o in orderings:\n        for e in o:\n            if e not in result:\n                result.append(e)\n    return result\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    if len(orderings) < 2:\n        return orderings\n\n    result = []\n    suffix = []\n    for ordering in orderings:\n        for i in range(len(ordering)):\n            if i == 0 or ordering[i][0] <= ordering[i - 1][0]:\n                suffix.append(ordering[i][1])\n            else:\n                result.append(ordering[i])\n\n    return result + suffix\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _legacy_mergeOrderings(orderings):\n    orderings = [orderings] if isinstance(orderings, list) else orderings\n    result = []\n    for o in orderings:\n        for e in o:\n            if e not in result:\n                result.append(e)\n    return result\n", "is_pass": true, "return_code": 0}]}
{"file_path": "src/zope/interface/declarations.py", "project": "pexip/os-zope", "name": "directlyProvidedBy", "docstring": "Return the interfaces directly provided by the given object\n\nThe value returned is an `~zope.interface.interfaces.IDeclaration`.", "ques_id": "62b8b58deb7e40a82d2d1269", "code": ["def directlyProvidedBy(object):\n    return providedBy(object)\n", "def directlyProvidedBy(object):\n    providedBy = getattr(object, '__providedBy__', None)\n    if providedBy is not None:\n        return providedBy\n    providedByIfaces = providedBy.__provides__\n    if providedByIfaces is not None:\n        return providedByIfaces[1]\n    raise TypeError(\n        \"%r does not provide an implementation of '.__provides__'\" % (\n            object,\n        ))\n", "def directlyProvidedBy(object):\n    return providedBy(object)\n", "def directlyProvidedBy(object):\n    providedBy = getattr(object, '__providedBy__', None)\n    if providedBy is not None:\n        return providedBy\n    spec = providedBySpec = getattr(object, '__provides__', None)\n    if providedBySpec is not None:\n        return providedBySpec.__self__.__class__\n    raise TypeError(\"%r has no direct providedBy() concept\" % (object,))\n", "def directlyProvidedBy(object):\n    providedBy = getattr(object, '__providedBy__', None)\n    if providedBy is not None:\n        return providedBy\n    spec = providedBySpec = getattr(object, '__providedBy__spec__', None)\n    if providedBySpec is not None:\n        return providedBySpec.__implementation__\n", "def directlyProvidedBy(object):\n    return providedBy(object)\n", "def directlyProvidedBy(object):\n    providedBy = getattr(object, '__providedBy__', None)\n    if providedBy is None:\n        providedBy = getattr(object, 'providedBy', None)\n    if providedBy is None:\n        return None\n    return providedBy()\n", "def directlyProvidedBy(object):\n    return providedBy(object)\n", "def directlyProvidedBy(object):\n    return providedBy(object)\n", "def directlyProvidedBy(object):\n    return providedBy(object)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def directlyProvidedBy(object):\n    return providedBy(object)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    providedBy = getattr(object, '__providedBy__', None)\n    if providedBy is not None:\n        return providedBy\n    providedByIfaces = providedBy.__provides__\n    if providedByIfaces is not None:\n        return providedByIfaces[1]\n    raise TypeError(\n        \"%r does not provide an implementation of '.__provides__'\" % (\n            object,\n        ))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    return providedBy(object)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    providedBy = getattr(object, '__providedBy__', None)\n    if providedBy is not None:\n        return providedBy\n    spec = providedBySpec = getattr(object, '__provides__', None)\n    if providedBySpec is not None:\n        return providedBySpec.__self__.__class__\n    raise TypeError(\"%r has no direct providedBy() concept\" % (object,))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    providedBy = getattr(object, '__providedBy__', None)\n    if providedBy is not None:\n        return providedBy\n    spec = providedBySpec = getattr(object, '__providedBy__spec__', None)\n    if providedBySpec is not None:\n        return providedBySpec.__implementation__\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    return providedBy(object)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    providedBy = getattr(object, '__providedBy__', None)\n    if providedBy is None:\n        providedBy = getattr(object, 'providedBy', None)\n    if providedBy is None:\n        return None\n    return providedBy()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    return providedBy(object)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    return providedBy(object)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def directlyProvidedBy(object):\n    return providedBy(object)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/advice.py", "project": "pexip/os-zope", "name": "minimalBases", "docstring": "Reduce a list of base classes to its ordered minimum equivalent", "ques_id": "62b8b559eb7e40a82d2d11f8", "code": ["def minimalBases(classes):\n    minBases = classes[0]\n    for c in classes[1:]:\n        if c < minBases:\n            minBases = c\n    return minBases\n", "def minimalBases(classes):\n    classes = list(classes)\n    classes.sort()\n    return [c for c in classes if issubclass(c, Base)]\n", "def minimalBases(classes):\n    classes = list(classes)\n    classes.sort()\n    return [c for c in classes if issubclass(c, Class)]\n", "def minimalBases(classes):\n    if len(classes) == 1:\n        return classes\n    else:\n        b = classes[1]\n        for x in classes[2:]:\n            if b.__class__ == x.__class__:\n                b = b.__bases__[0]\n            else:\n                b = None\n        return classes[:1] + [b]\n", "def minimalBases(classes):\n    return sorted(classes, key=lambda x: x.priority)\n", "def minimalBases(classes):\n\n    minbases = []\n\n    for c in classes:\n        if c not in minbases:\n            minbases += [c]\n\n    return min(minbases)\n", "def minimalBases(classes):\n    if len(classes) == 1:\n        return classes\n\n    ordered = []\n    for c in classes:\n        ordered.extend([c, c.__bases__[0]])\n\n    return sorted(ordered, key=lambda x: x.__name__)\n", "def minimalBases(classes):\n    return sorted(classes, key=lambda b: b.order)[0:1]\n", "def minimalBases(classes):\n    return sorted(classes, key=lambda x: x.__order)\n", "def minimalBases(classes):\n    classes = list(classes)\n    bases = sorted(classes, key=lambda x: x.order)\n    if len(bases) == 0:\n        return classes\n\n    for i in range(len(bases) - 1):\n        if bases[i].order > bases[i + 1].order:\n            return bases[i + 1:]\n    return bases\n"], "level": "self_contained", "generate_results": [{"generate_code": "def minimalBases(classes):\n    minBases = classes[0]\n    for c in classes[1:]:\n        if c < minBases:\n            minBases = c\n    return minBases\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n    classes = list(classes)\n    classes.sort()\n    return [c for c in classes if issubclass(c, Base)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n    classes = list(classes)\n    classes.sort()\n    return [c for c in classes if issubclass(c, Class)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n    if len(classes) == 1:\n        return classes\n    else:\n        b = classes[1]\n        for x in classes[2:]:\n            if b.__class__ == x.__class__:\n                b = b.__bases__[0]\n            else:\n                b = None\n        return classes[:1] + [b]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n    return sorted(classes, key=lambda x: x.priority)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n\n    minbases = []\n\n    for c in classes:\n        if c not in minbases:\n            minbases += [c]\n\n    return min(minbases)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n    if len(classes) == 1:\n        return classes\n\n    ordered = []\n    for c in classes:\n        ordered.extend([c, c.__bases__[0]])\n\n    return sorted(ordered, key=lambda x: x.__name__)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n    return sorted(classes, key=lambda b: b.order)[0:1]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n    return sorted(classes, key=lambda x: x.__order)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def minimalBases(classes):\n    classes = list(classes)\n    bases = sorted(classes, key=lambda x: x.order)\n    if len(bases) == 0:\n        return classes\n\n    for i in range(len(bases) - 1):\n        if bases[i].order > bases[i + 1].order:\n            return bases[i + 1:]\n    return bases\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/interface.py", "project": "pexip/os-zope", "name": "namesAndDescriptions", "docstring": "Return attribute names and descriptions defined by interface.", "ques_id": "62b8b4b9eb7e40a82d2d1134", "code": ["def namesAndDescriptions(self, all=False):\n    names = []\n    descs = []\n    for iface in self.__class__.__mro__:\n        try:\n            names.extend(iface.__dict__.keys())\n            descs.extend(getattr(iface, '__doc__', None) or '')\n        except AttributeError:\n            pass\n    if all:\n        return list(set(names + descs))\n    return dict(list(zip(names, descs)))\n", "def namesAndDescriptions(self, all=False):\n    names = []\n    descs = []\n    for iface in self.__class__.__mro__:\n        try:\n            i = iface()\n            names.append(i.__name__)\n            descs.append(i.__doc__)\n        except TypeError:\n            pass\n    if all:\n        return tuple(names), tuple(descs)\n    return names, descs\n", "def namesAndDescriptions(self, all=False):\n    names = []\n    descriptions = []\n    for iface in self.__class__.__mro__:\n        try:\n            names.extend(iface.__dict__.keys())\n            descriptions.extend(iface.__doc__.splitlines())\n        except AttributeError:\n            pass\n    if all:\n        return names, descriptions\n    return names, descriptions, sorted(names)\n", "def namesAndDescriptions(self, all=False):\n    names = []\n    descs = []\n    for iface in self.__class__.__mro__:\n        try:\n            attrs = iface.__dict__\n        except AttributeError:\n            # not a subclass of IInterface\n            continue\n        for attr in attrs.keys():\n            if not attr.startswith('__') and not \\\n                    attr.startswith('providedBy') and \\\n                    attr!= 'providedBy':\n                names.append(attr)\n                descs.append(attrs[attr])\n    if not all:\n        return (names, descs)\n    return (('Name',), ('Description',) + tuple(descs))\n", "def namesAndDescriptions(self, all=False):\n    names = []\n    descs = []\n    for iface in self.__class__.__mro__:\n        try:\n            names.extend(iface.__dict__.keys())\n            descs.extend(iface.__doc__.splitlines())\n        except AttributeError:\n            pass\n    if not all:\n        names = list(set(names))\n        descs = list(set(descs))\n    return (sorted(names), sorted(descs))\n", "def namesAndDescriptions(self, all=False):\n    names = []\n    descs = []\n    for iface in self.__class__.__mro__:\n        try:\n            names.extend(iface.__dict__.keys())\n            descs.extend(iface.__dict__.values())\n        except AttributeError:\n            pass\n    if all:\n        return list(set(names + descs))\n    else:\n        return dict(list(zip(names, descs)))\n", "def namesAndDescriptions(self, all=False):\n    names = []\n    descriptions = []\n    for iface in self.__class__.__mro__:\n        try:\n            i = iface()\n        except TypeError:\n            i = iface\n        if hasattr(i, 'name'):\n            names.append(i.name)\n        if hasattr(i, 'description'):\n            descriptions.append(i.description)\n    if all:\n        return (names, descriptions)\n    return dict(zip(names, descriptions))\n", "def namesAndDescriptions(self, all=False):\n    names = []\n    descs = []\n    for iface in self.__class__.__mro__:\n        if issubclass(iface, Interface):\n            for name, obj in iface.__dict__.items():\n                if ((names and name not in names) or\n                        (descs and name not in descs)):\n                    if (isinstance(obj, Attribute) and\n                            not (all and name in all)):\n                        yield name, obj.__doc__\n                    names.append(name)\n                    descs.append(obj.__doc__)\n", "def namesAndDescriptions(self, all=False):\n    names = []\n    descs = []\n    for iface in self.__class__.__mro__:\n        try:\n            i = iface(self)\n        except AttributeError:\n            continue\n        names.append(i.__name__)\n        descs.append(i.__doc__)\n    return '\\n'.join(names), '\\n'.join(descs)\n", "def namesAndDescriptions(self, all=False):\n    names = []\n    descrs = []\n    for iface in self.__class__.__mro__:\n        try:\n            attrs = iface.__dict__\n        except AttributeError:\n            # iface doesn't define __dict__, so skip it\n            continue\n        for attr in attrs.keys():\n            if not attr.startswith('__') and \\\n                    attr!= '__interfaces__' and \\\n                    attr not in self.__interfaces__:\n                names.append(attr)\n                descrs.append(attrs[attr])\n    if all:\n        return names, descrs\n    return names, descrs, (names, descrs)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def namesAndDescriptions(self, all=False):\n    names = []\n    descs = []\n    for iface in self.__class__.__mro__:\n        try:\n            names.extend(iface.__dict__.keys())\n            descs.extend(getattr(iface, '__doc__', None) or '')\n        except AttributeError:\n            pass\n    if all:\n        return list(set(names + descs))\n    return dict(list(zip(names, descs)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    names = []\n    descs = []\n    for iface in self.__class__.__mro__:\n        try:\n            i = iface()\n            names.append(i.__name__)\n            descs.append(i.__doc__)\n        except TypeError:\n            pass\n    if all:\n        return tuple(names), tuple(descs)\n    return names, descs\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    names = []\n    descriptions = []\n    for iface in self.__class__.__mro__:\n        try:\n            names.extend(iface.__dict__.keys())\n            descriptions.extend(iface.__doc__.splitlines())\n        except AttributeError:\n            pass\n    if all:\n        return names, descriptions\n    return names, descriptions, sorted(names)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    names = []\n    descs = []\n    for iface in self.__class__.__mro__:\n        try:\n            attrs = iface.__dict__\n        except AttributeError:\n            # not a subclass of IInterface\n            continue\n        for attr in attrs.keys():\n            if not attr.startswith('__') and not \\\n                    attr.startswith('providedBy') and \\\n                    attr!= 'providedBy':\n                names.append(attr)\n                descs.append(attrs[attr])\n    if not all:\n        return (names, descs)\n    return (('Name',), ('Description',) + tuple(descs))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    names = []\n    descs = []\n    for iface in self.__class__.__mro__:\n        try:\n            names.extend(iface.__dict__.keys())\n            descs.extend(iface.__doc__.splitlines())\n        except AttributeError:\n            pass\n    if not all:\n        names = list(set(names))\n        descs = list(set(descs))\n    return (sorted(names), sorted(descs))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    names = []\n    descs = []\n    for iface in self.__class__.__mro__:\n        try:\n            names.extend(iface.__dict__.keys())\n            descs.extend(iface.__dict__.values())\n        except AttributeError:\n            pass\n    if all:\n        return list(set(names + descs))\n    else:\n        return dict(list(zip(names, descs)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    names = []\n    descriptions = []\n    for iface in self.__class__.__mro__:\n        try:\n            i = iface()\n        except TypeError:\n            i = iface\n        if hasattr(i, 'name'):\n            names.append(i.name)\n        if hasattr(i, 'description'):\n            descriptions.append(i.description)\n    if all:\n        return (names, descriptions)\n    return dict(zip(names, descriptions))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    names = []\n    descs = []\n    for iface in self.__class__.__mro__:\n        if issubclass(iface, Interface):\n            for name, obj in iface.__dict__.items():\n                if ((names and name not in names) or\n                        (descs and name not in descs)):\n                    if (isinstance(obj, Attribute) and\n                            not (all and name in all)):\n                        yield name, obj.__doc__\n                    names.append(name)\n                    descs.append(obj.__doc__)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    names = []\n    descs = []\n    for iface in self.__class__.__mro__:\n        try:\n            i = iface(self)\n        except AttributeError:\n            continue\n        names.append(i.__name__)\n        descs.append(i.__doc__)\n    return '\\n'.join(names), '\\n'.join(descs)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def namesAndDescriptions(self, all=False):\n    names = []\n    descrs = []\n    for iface in self.__class__.__mro__:\n        try:\n            attrs = iface.__dict__\n        except AttributeError:\n            # iface doesn't define __dict__, so skip it\n            continue\n        for attr in attrs.keys():\n            if not attr.startswith('__') and \\\n                    attr!= '__interfaces__' and \\\n                    attr not in self.__interfaces__:\n                names.append(attr)\n                descrs.append(attrs[attr])\n    if all:\n        return names, descrs\n    return names, descrs, (names, descrs)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/interface.py", "project": "pexip/os-zope", "name": "names", "docstring": "Return the attribute names defined by the interface.", "ques_id": "62b8b416eb7e40a82d2d1129", "code": ["def names(self, all=False):\n    if all:\n        return dir(Interface)\n    return Interface._names\n", "def names(self, all=False):\n    if all:\n        return dir(type(self))\n    else:\n        return dir(self)\n", "def names(self, all=False):\n    if all:\n        return dir(Interface)\n    return dir(self)\n", "def names(self, all=False):\n    names = []\n    for iface in self:\n        names += iface.names(all)\n    return names\n", "def names(self, all=False):\n    return [k for k in dir(self) if not k.startswith('_') and\n            isinstance(getattr(self, k), interfaces.IInterface)]\n", "def names(self, all=False):\n    return [name for name, _ in self.items(all=all)]\n", "def names(self, all=False):\n    if all:\n        return dir(Interface)\n    return list(Interface.__dict__.keys())\n", "def names(self, all=False):\n    if all:\n        return dir(Interface)\n    return Interface.__dict__.keys()\n", "def names(self, all=False):\n    if all:\n        return dir(type(self))\n    return dir(self)\n", "def names(self, all=False):\n    if all:\n        return dir(self)\n    return [name for name, _ in self.__dict__.items()\n            if isinstance(name, str) and not name.startswith('_')]\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def names(self, all=False):\n    if all:\n        return dir(Interface)\n    return Interface._names\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    if all:\n        return dir(type(self))\n    else:\n        return dir(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    if all:\n        return dir(Interface)\n    return dir(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    names = []\n    for iface in self:\n        names += iface.names(all)\n    return names\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    return [k for k in dir(self) if not k.startswith('_') and\n            isinstance(getattr(self, k), interfaces.IInterface)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    return [name for name, _ in self.items(all=all)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    if all:\n        return dir(Interface)\n    return list(Interface.__dict__.keys())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    if all:\n        return dir(Interface)\n    return Interface.__dict__.keys()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    if all:\n        return dir(type(self))\n    return dir(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def names(self, all=False):\n    if all:\n        return dir(self)\n    return [name for name, _ in self.__dict__.items()\n            if isinstance(name, str) and not name.startswith('_')]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/declarations.py", "project": "pexip/os-zope", "name": "_normalizeargs", "docstring": "Normalize declaration arguments\n\nNormalization arguments might contain Declarions, tuples, or single\ninterfaces.\n\nAnything but individial interfaces or implements specs will be expanded.", "ques_id": "62b8b3d6eb7e40a82d2d111c", "code": ["def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    for arg in sequence:\n        if isinstance(arg, InterfaceClass):\n            arg = arg.implementation\n        elif isinstance(arg, tuple):\n            arg = _normalizeargs(arg, output=output + [arg])\n        elif isinstance(arg, types.Spec):\n            pass\n        else:\n            output.append(arg)\n\n    return output\n", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    for x in sequence:\n        if isinstance(x, InterfaceClass):\n            x = x._implicit_interface\n        if isinstance(x, tuple):\n            y = _normalizeargs(x, output)\n            if y is not None:\n                output.append(y)\n            continue\n        output.append(x)\n\n    return output\n", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    def expand(arg):\n        if isinstance(arg, InterfaceClass):\n            output.append(arg)\n            return\n        for subseq in arg._subsequents:\n            expand(subseq)\n\n    expand(sequence)\n    return output\n", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    declared = set([])\n    for x in sequence:\n        try:\n            iterable = _normalizearg(x, output)\n        except TypeError:\n            iterable = [x]\n        declared.update(iterable)\n\n    if declared - declared.intersection(output):\n        # some declarations are missing\n        derived = set(output) - declared\n        raise TypeError(\"Missing declarations: %s\" % ', '.join(derived))\n\n    return output\n", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    def expand(item):\n        if isinstance(item, InterfaceClass):\n            output.append(item.impl)\n        elif isinstance(item, (tuple, list)):\n            for i in item:\n                expand(i)\n        else:\n            try:\n                output.append(item.normalize())\n            except NormalizationError:\n                raise TypeError(\"Cannot normalize %r\" % item)\n\n    for item in sequence:\n        expand(item)\n    return output\n", "def _normalizeargs(sequence, output=None):\n    output = output or []\n    for x in sequence:\n        if isinstance(x, (InterfaceClass, Implements)):\n            x = expand_interface(x)\n        output.append(x)\n    return output\n", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    for x in sequence:\n        if isinstance(x, InterfaceClass):\n            output.append(x._impl)\n        elif isinstance(x, Declaration):\n            output.append(x)\n        elif isinstance(x, tuple):\n            output.extend(_normalizeargs(x, output))\n        else:\n            output.append(x)\n    return output\n", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    def recurse(item, output):\n        if isinstance(item, InterfaceClass):\n            output.append(item)\n            return\n        for i in item._declaration_args:\n            recurse(i, output)\n\n    for item in sequence:\n        recurse(item, output)\n    return output\n", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    for x in sequence:\n        if isinstance(x, Interface):\n            output.append(x._normalizeargs())\n        elif isinstance(x, Declaration):\n            output.append(x)\n        elif isinstance(x, tuple):\n            output.extend(_normalizeargs(x, output))\n        else:\n            output.append(x)\n\n    return output\n", "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    for x in sequence:\n        if isinstance(x, InterfaceClass):\n            x = x._implementation\n        elif isinstance(x, tuple):\n            x = _normalizeargs(x, output)\n        elif isinstance(x, type) and issubclass(x, Declaration):\n            pass\n        else:\n            output.append(x)\n\n    return output\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    for arg in sequence:\n        if isinstance(arg, InterfaceClass):\n            arg = arg.implementation\n        elif isinstance(arg, tuple):\n            arg = _normalizeargs(arg, output=output + [arg])\n        elif isinstance(arg, types.Spec):\n            pass\n        else:\n            output.append(arg)\n\n    return output\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    for x in sequence:\n        if isinstance(x, InterfaceClass):\n            x = x._implicit_interface\n        if isinstance(x, tuple):\n            y = _normalizeargs(x, output)\n            if y is not None:\n                output.append(y)\n            continue\n        output.append(x)\n\n    return output\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    def expand(arg):\n        if isinstance(arg, InterfaceClass):\n            output.append(arg)\n            return\n        for subseq in arg._subsequents:\n            expand(subseq)\n\n    expand(sequence)\n    return output\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    declared = set([])\n    for x in sequence:\n        try:\n            iterable = _normalizearg(x, output)\n        except TypeError:\n            iterable = [x]\n        declared.update(iterable)\n\n    if declared - declared.intersection(output):\n        # some declarations are missing\n        derived = set(output) - declared\n        raise TypeError(\"Missing declarations: %s\" % ', '.join(derived))\n\n    return output\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    def expand(item):\n        if isinstance(item, InterfaceClass):\n            output.append(item.impl)\n        elif isinstance(item, (tuple, list)):\n            for i in item:\n                expand(i)\n        else:\n            try:\n                output.append(item.normalize())\n            except NormalizationError:\n                raise TypeError(\"Cannot normalize %r\" % item)\n\n    for item in sequence:\n        expand(item)\n    return output\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    output = output or []\n    for x in sequence:\n        if isinstance(x, (InterfaceClass, Implements)):\n            x = expand_interface(x)\n        output.append(x)\n    return output\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    for x in sequence:\n        if isinstance(x, InterfaceClass):\n            output.append(x._impl)\n        elif isinstance(x, Declaration):\n            output.append(x)\n        elif isinstance(x, tuple):\n            output.extend(_normalizeargs(x, output))\n        else:\n            output.append(x)\n    return output\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    def recurse(item, output):\n        if isinstance(item, InterfaceClass):\n            output.append(item)\n            return\n        for i in item._declaration_args:\n            recurse(i, output)\n\n    for item in sequence:\n        recurse(item, output)\n    return output\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    for x in sequence:\n        if isinstance(x, Interface):\n            output.append(x._normalizeargs())\n        elif isinstance(x, Declaration):\n            output.append(x)\n        elif isinstance(x, tuple):\n            output.extend(_normalizeargs(x, output))\n        else:\n            output.append(x)\n\n    return output\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _normalizeargs(sequence, output=None):\n    if output is None:\n        output = []\n\n    for x in sequence:\n        if isinstance(x, InterfaceClass):\n            x = x._implementation\n        elif isinstance(x, tuple):\n            x = _normalizeargs(x, output)\n        elif isinstance(x, type) and issubclass(x, Declaration):\n            pass\n        else:\n            output.append(x)\n\n    return output\n", "is_pass": true, "return_code": 0}]}
{"file_path": "src/zope/interface/_compat.py", "project": "pexip/os-zope", "name": "_c_optimizations_available", "docstring": "Return the C optimization module, if available, otherwise\na false value.\n\nIf the optimizations are required but not available, this\nraises the ImportError.\n\nThis does not say whether they should be used or not.", "ques_id": "62b8b3d5eb7e40a82d2d1110", "code": ["def _c_optimizations_available():\n    try:\n        from pyapi import c_api\n    except ImportError:\n        # No C extension available. Can't use c_api\n        return False\n    else:\n        return c_api\n", "def _c_optimizations_available():\n    try:\n        from c_opt import c_opt as c_opt\n        return c_opt\n    except ImportError:\n        pass\n    try:\n        from c_opt_native import c_opt as c_opt\n        return c_opt\n    except ImportError:\n        pass\n    raise ImportError(\"Could not find C optimizations package\")\n", "def _c_optimizations_available():\n    from.c_opt import COptimizations\n\n    return COptimizations\n", "def _c_optimizations_available():\n    try:\n        from c_optimizations import Optimizations\n        return Optimizations\n    except ImportError:\n        return False\n", "def _c_optimizations_available():\n    try:\n        from c_opt import c_opt as c_opt\n    except ImportError:\n        from c_opt_old import c_opt as c_opt\n\n    return c_opt\n", "def _c_optimizations_available():\n    try:\n        import c_opt\n        return c_opt\n    except ImportError:\n        return False\n", "def _c_optimizations_available():\n    from c_opt import c_opt\n    return c_opt\n", "def _c_optimizations_available():\n    try:\n        import c_opt\n        return c_opt\n    except ImportError:\n        return False\n", "def _c_optimizations_available():\n    try:\n        from.c_optimizations import COptimizations\n        return COptimizations\n    except ImportError:\n        pass\n    raise ImportError(\"This does not seem to be a C optimizations package. \"\n                      \"Please install it to use this package.\")\n", "def _c_optimizations_available():\n    try:\n        from.c_optimizations import COptimizations\n    except ImportError:\n        return False\n    else:\n        return COptimizations\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _c_optimizations_available():\n    try:\n        from pyapi import c_api\n    except ImportError:\n        # No C extension available. Can't use c_api\n        return False\n    else:\n        return c_api\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    try:\n        from c_opt import c_opt as c_opt\n        return c_opt\n    except ImportError:\n        pass\n    try:\n        from c_opt_native import c_opt as c_opt\n        return c_opt\n    except ImportError:\n        pass\n    raise ImportError(\"Could not find C optimizations package\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    from.c_opt import COptimizations\n\n    return COptimizations\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    try:\n        from c_optimizations import Optimizations\n        return Optimizations\n    except ImportError:\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    try:\n        from c_opt import c_opt as c_opt\n    except ImportError:\n        from c_opt_old import c_opt as c_opt\n\n    return c_opt\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    try:\n        import c_opt\n        return c_opt\n    except ImportError:\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    from c_opt import c_opt\n    return c_opt\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    try:\n        import c_opt\n        return c_opt\n    except ImportError:\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    try:\n        from.c_optimizations import COptimizations\n        return COptimizations\n    except ImportError:\n        pass\n    raise ImportError(\"This does not seem to be a C optimizations package. \"\n                      \"Please install it to use this package.\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_available():\n    try:\n        from.c_optimizations import COptimizations\n    except ImportError:\n        return False\n    else:\n        return COptimizations\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/_compat.py", "project": "pexip/os-zope", "name": "_should_attempt_c_optimizations", "docstring": "Return a true value if we should attempt to use the C optimizations.\n\nThis takes into account whether we're on PyPy and the value of the\n``PURE_PYTHON`` environment variable, as defined in `_use_c_impl`.", "ques_id": "62b8b3d4eb7e40a82d2d110f", "code": ["def _should_attempt_c_optimizations():\n    pypy = sys.version_info >= (3, 0)\n    pure_pypy = _use_c_impl.__name__ == \"PURE_PYTHON\"\n    return pypy or pure_pypy\n", "def _should_attempt_c_optimizations():\n    pure_env = os.environ.get('PURE_PYTHON')\n    return pure_env is not None and pure_env!= '0'\n", "def _should_attempt_c_optimizations():\n    pure_env_name = \"PURE_PYTHON\"\n    return (os.environ.get(pure_env_name) == \"true\" or\n            pure_env_name in _use_c_impl)\n", "def _should_attempt_c_optimizations():\n    pypy = sys.version_info >= (3, )\n    pure_pypy = _use_c_impl.PURE_PYTHON\n    return pypy or pure_pypy\n", "def _should_attempt_c_optimizations():\n    pure_env = os.environ.get('PURE_PYTHON')\n    if pure_env is not None:\n        return pure_env == '1'\n    return c_optimizations is not None\n", "def _should_attempt_c_optimizations():\n    return (os.environ.get(\"PURE_PYTHON\") == \"1\" and\n            _use_c_impl is not None)\n", "def _should_attempt_c_optimizations():\n    # PyPy has a separate OptimizeResult for use of C implementations. On\n    # PyPy we need to make sure we're on PyPy and not with the C implementation\n    return (sys.version_info >= (3, 0) and\n            not os.environ.get('PURE_PYTHON') and\n            _use_c_impl)\n", "def _should_attempt_c_optimizations():\n    return not _use_c_impl\n", "def _should_attempt_c_optimizations():\n    return os.environ.get('PURE_PYTHON') == 'true'\n", "def _should_attempt_c_optimizations():\n    pypy_env = os.environ.get('PURE_PYTHON')\n    if pypy_env is not None:\n        return pypy_env == '1'\n    return _use_c_impl\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _should_attempt_c_optimizations():\n    pypy = sys.version_info >= (3, 0)\n    pure_pypy = _use_c_impl.__name__ == \"PURE_PYTHON\"\n    return pypy or pure_pypy\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _should_attempt_c_optimizations():\n    pure_env = os.environ.get('PURE_PYTHON')\n    return pure_env is not None and pure_env!= '0'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _should_attempt_c_optimizations():\n    pure_env_name = \"PURE_PYTHON\"\n    return (os.environ.get(pure_env_name) == \"true\" or\n            pure_env_name in _use_c_impl)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _should_attempt_c_optimizations():\n    pypy = sys.version_info >= (3, )\n    pure_pypy = _use_c_impl.PURE_PYTHON\n    return pypy or pure_pypy\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _should_attempt_c_optimizations():\n    pure_env = os.environ.get('PURE_PYTHON')\n    if pure_env is not None:\n        return pure_env == '1'\n    return c_optimizations is not None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _should_attempt_c_optimizations():\n    return (os.environ.get(\"PURE_PYTHON\") == \"1\" and\n            _use_c_impl is not None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _should_attempt_c_optimizations():\n    # PyPy has a separate OptimizeResult for use of C implementations. On\n    # PyPy we need to make sure we're on PyPy and not with the C implementation\n    return (sys.version_info >= (3, 0) and\n            not os.environ.get('PURE_PYTHON') and\n            _use_c_impl)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _should_attempt_c_optimizations():\n    return not _use_c_impl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _should_attempt_c_optimizations():\n    return os.environ.get('PURE_PYTHON') == 'true'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _should_attempt_c_optimizations():\n    pypy_env = os.environ.get('PURE_PYTHON')\n    if pypy_env is not None:\n        return pypy_env == '1'\n    return _use_c_impl\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/_compat.py", "project": "pexip/os-zope", "name": "_c_optimizations_ignored", "docstring": "The opposite of `_c_optimizations_required`.", "ques_id": "62b8b3d4eb7e40a82d2d110e", "code": ["def _c_optimizations_ignored():\n    return 0\n", "def _c_optimizations_ignored():\n    return 0\n", "def _c_optimizations_ignored():\n    return 0\n", "def _c_optimizations_ignored():\n    return 0\n", "def _c_optimizations_ignored():\n    return 0\n", "def _c_optimizations_ignored():\n    return 0\n", "def _c_optimizations_ignored():\n    return 0\n", "def _c_optimizations_ignored():\n    return 0\n", "def _c_optimizations_ignored():\n    return 0\n", "def _c_optimizations_ignored():\n    return 0\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def _c_optimizations_ignored():\n    return 0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_ignored():\n    return 0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_ignored():\n    return 0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_ignored():\n    return 0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_ignored():\n    return 0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_ignored():\n    return 0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_ignored():\n    return 0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_ignored():\n    return 0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_ignored():\n    return 0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _c_optimizations_ignored():\n    return 0\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/_compat.py", "project": "pexip/os-zope", "name": "_c_optimizations_required", "docstring": "Return a true value if the C optimizations are required.\n\nThis uses the ``PURE_PYTHON`` variable as documented in `_use_c_impl`.", "ques_id": "62b8b3d4eb7e40a82d2d110d", "code": ["def _c_optimizations_required():\n    pure_env = os.environ.get('PURE_PYTHON')\n    if pure_env is None:\n        return False\n    return pure_env == '1'\n", "def _c_optimizations_required():\n    pure_env = os.environ.get('PURE_PYTHON')\n    if pure_env is not None:\n        return pure_env == '0'\n    return False\n", "def _c_optimizations_required():\n    pure_env = os.environ.get('PURE_PYTHON')\n    if pure_env is not None:\n        return pure_env == \"true\"\n    return False\n", "def _c_optimizations_required():\n    pure_env = os.environ.get(\"PURE_PYTHON\", None)\n    return pure_env is not None and pure_env!= \"0\"\n", "def _c_optimizations_required():\n    pure_env = os.environ.get('PURE_PYTHON')\n    if pure_env is not None:\n        return pure_env == '1'\n    else:\n        return False\n", "def _c_optimizations_required():\n\n    pure_env = os.environ.get('PURE_PYTHON')\n    if pure_env is not None:\n        return pure_env == '1'\n    else:\n        return False\n", "def _c_optimizations_required():\n    pure_env = os.environ.get('PURE_PYTHON')\n    return pure_env is not None and pure_env!= \"0\"\n", "def _c_optimizations_required():\n    pure_env = os.environ.get('PURE_PYTHON')\n    return pure_env is not None and pure_env!= \"0\"\n", "def _c_optimizations_required():\n    pure_env = os.environ.get('PURE_PYTHON')\n    return pure_env is not None and pure_env!= '0'\n", "def _c_optimizations_required():\n    pure_env = os.environ.get('PURE_PYTHON')\n    if pure_env is not None:\n        return pure_env == '1'\n    return False\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def _c_optimizations_required():\n    pure_env = os.environ.get('PURE_PYTHON')\n    if pure_env is None:\n        return False\n    return pure_env == '1'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _c_optimizations_required():\n    pure_env = os.environ.get('PURE_PYTHON')\n    if pure_env is not None:\n        return pure_env == '0'\n    return False\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _c_optimizations_required():\n    pure_env = os.environ.get('PURE_PYTHON')\n    if pure_env is not None:\n        return pure_env == \"true\"\n    return False\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _c_optimizations_required():\n    pure_env = os.environ.get(\"PURE_PYTHON\", None)\n    return pure_env is not None and pure_env!= \"0\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _c_optimizations_required():\n    pure_env = os.environ.get('PURE_PYTHON')\n    if pure_env is not None:\n        return pure_env == '1'\n    else:\n        return False\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _c_optimizations_required():\n\n    pure_env = os.environ.get('PURE_PYTHON')\n    if pure_env is not None:\n        return pure_env == '1'\n    else:\n        return False\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _c_optimizations_required():\n    pure_env = os.environ.get('PURE_PYTHON')\n    return pure_env is not None and pure_env!= \"0\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _c_optimizations_required():\n    pure_env = os.environ.get('PURE_PYTHON')\n    return pure_env is not None and pure_env!= \"0\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _c_optimizations_required():\n    pure_env = os.environ.get('PURE_PYTHON')\n    return pure_env is not None and pure_env!= '0'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def _c_optimizations_required():\n    pure_env = os.environ.get('PURE_PYTHON')\n    if pure_env is not None:\n        return pure_env == '1'\n    return False\n", "is_pass": true, "return_code": 0}]}
{"file_path": "lena/structures/histogram.py", "project": "ynikitenko/lena", "name": "reset", "docstring": "Reset the histogram.\n\nCurrent context is reset to an empty dict.\nBins are reinitialized with the *initial_value*\nor with *make_bins()* (depending on the initialization).", "ques_id": "62b87b989a0c4fa8b80b35ee", "code": ["def reset(self):\n    self._hist.clear()\n", "def reset(self):\n    self._hist.clear()\n", "def reset(self):\n    self._hist.clear()\n", "def reset(self):\n    self._hist.clear()\n", "def reset(self):\n    self.hist.reset()\n", "def reset(self):\n    self._hist.clear()\n", "def reset(self):\n    self._hist.clear()\n", "def reset(self):\n    self._hist.clear()\n", "def reset(self):\n    self._hist.clear()\n", "def reset(self):\n    self._hist.clear()\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def reset(self):\n    self._hist.clear()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def reset(self):\n    self._hist.clear()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def reset(self):\n    self._hist.clear()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def reset(self):\n    self._hist.clear()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def reset(self):\n    self.hist.reset()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def reset(self):\n    self._hist.clear()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def reset(self):\n    self._hist.clear()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def reset(self):\n    self._hist.clear()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def reset(self):\n    self._hist.clear()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def reset(self):\n    self._hist.clear()\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/structures/graph.py", "project": "ynikitenko/lena", "name": "to_csv", "docstring": ".. deprecated:: 0.5 in Lena 0.5 to_csv is not used.\n      Iterables are converted to tables.\n\nConvert graph's points to CSV.\n\n*separator* delimits values, the default is comma.\n\n*header*, if not ``None``, is the first string of the output\n(new line is added automatically).\n\nSince a graph can be multidimensional,\nfor each point first its coordinate is converted to string\n(separated by *separator*), then each part of its value.\n\nTo convert :class:`Graph` to CSV inside a Lena sequence,\nuse :class:`lena.output.ToCSV`.", "ques_id": "62b87b859a0c4fa8b80b35d7", "code": ["def to_csv(self, separator=\",\", header=None):\n    from.output.ToCSV import ToCSV\n    return ToCSV(separator=separator, header=header, graph=self)\n", "def to_csv(self, separator=\",\", header=None):\n    from lena.output.utils import ToCSV\n\n    return ToCSV(separator=separator, header=header).dumps(self)\n", "def to_csv(self, separator=\",\", header=None):\n    from..output import ToCSV\n    return ToCSV(self, separator=separator, header=header)\n", "def to_csv(self, separator=\",\", header=None):\n    from..utils import to_csv\n    return to_csv(self, separator=separator, header=header)\n", "def to_csv(self, separator=\",\", header=None):\n    msg = (\n        \"Graph.to_csv() is deprecated. Use 'lena.output.ToCSV' instead.\"\n    )\n    warnings.warn(msg, DeprecationWarning)\n    from lena.output.utils import ToCSV\n\n    return ToCSV(separator=separator, header=header, graph=self)\n", "def to_csv(self, separator=\",\", header=None):\n    from.output import ToCSV\n\n    return ToCSV(separator=separator, header=header, graph=self)\n", "def to_csv(self, separator=\",\", header=None):\n    from..output._graph_core import ToCSV\n    return ToCSV(separator, header).dumps(self)\n", "def to_csv(self, separator=\",\", header=None):\n    from..output.ToCSV import ToCSV\n    return ToCSV(separator=separator, header=header, graph=self)\n", "def to_csv(self, separator=\",\", header=None):\n    from..utils.io import StringIO\n\n    StringIO().write(self.to_string(header=header))\n    return StringIO(\"\")\n", "def to_csv(self, separator=\",\", header=None):\n    import warnings\n    warnings.warn(\n        \"Graph.to_csv is deprecated; use Graph.to_csv_iterable instead.\",\n        DeprecationWarning,\n    )\n    return self.to_csv_iterable(separator=separator, header=header)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def to_csv(self, separator=\",\", header=None):\n    from.output.ToCSV import ToCSV\n    return ToCSV(separator=separator, header=header, graph=self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    from lena.output.utils import ToCSV\n\n    return ToCSV(separator=separator, header=header).dumps(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    from..output import ToCSV\n    return ToCSV(self, separator=separator, header=header)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    from..utils import to_csv\n    return to_csv(self, separator=separator, header=header)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    msg = (\n        \"Graph.to_csv() is deprecated. Use 'lena.output.ToCSV' instead.\"\n    )\n    warnings.warn(msg, DeprecationWarning)\n    from lena.output.utils import ToCSV\n\n    return ToCSV(separator=separator, header=header, graph=self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    from.output import ToCSV\n\n    return ToCSV(separator=separator, header=header, graph=self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    from..output._graph_core import ToCSV\n    return ToCSV(separator, header).dumps(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    from..output.ToCSV import ToCSV\n    return ToCSV(separator=separator, header=header, graph=self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    from..utils.io import StringIO\n\n    StringIO().write(self.to_string(header=header))\n    return StringIO(\"\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def to_csv(self, separator=\",\", header=None):\n    import warnings\n    warnings.warn(\n        \"Graph.to_csv is deprecated; use Graph.to_csv_iterable instead.\",\n        DeprecationWarning,\n    )\n    return self.to_csv_iterable(separator=separator, header=header)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/structures/graph.py", "project": "ynikitenko/lena", "name": "_get_err_indices", "docstring": "Get error indices corresponding to a coordinate.", "ques_id": "62b87b839a0c4fa8b80b35cb", "code": ["def _get_err_indices(self, coord_name):\n    if coord_name in self._cache:\n        return self._cache[coord_name]\n\n    if coord_name in self._err_indices:\n        return self._err_indices[coord_name]\n\n    raise ValueError('Coordinate {} not found.'.format(coord_name))\n", "def _get_err_indices(self, coord_name):\n    if coord_name == 'x':\n        return [0, 1, 2, 3, 4, 5, 6, 7, 8]\n    elif coord_name == 'y':\n        return [0, 1, 2, 3, 4, 5, 6, 7, 8]\n    elif coord_name == 'z':\n        return [0, 1, 2, 3, 4, 5, 6, 7, 8]\n    else:\n        raise ValueError('coordinate name {} not supported'.format(coord_name))\n", "def _get_err_indices(self, coord_name):\n    if coord_name == \"x\":\n        return [0, 1, 2, 3, 4, 5, 6, 7]\n    elif coord_name == \"y\":\n        return [1, 2, 3, 4, 5, 6, 7]\n    else:\n        raise ValueError(\"Invalid coordinate name {}\".format(coord_name))\n", "def _get_err_indices(self, coord_name):\n    if coord_name in self._err_dict:\n        return self._err_dict[coord_name]\n    return None\n", "def _get_err_indices(self, coord_name):\n    if coord_name in self:\n        return self[coord_name]._get_err_indices()\n    else:\n        raise KeyError(coord_name)\n", "def _get_err_indices(self, coord_name):\n    return self._coord_names_to_err_indices[coord_name]\n", "def _get_err_indices(self, coord_name):\n    if coord_name not in self._cache:\n        err_names = ['x', 'y', 'z']\n        if coord_name in ['x', 'y', 'z']:\n            err_names = ['x', 'y']\n        elif coord_name in ['r', 't']:\n            err_names = ['r', 't']\n        elif coord_name in ['v', 'q']:\n            err_names = ['v', 'q']\n        elif coord_name in ['a', 'e']:\n            err_names = ['a', 'e']\n        elif coord_name in ['u', 'p']:\n            err_names = ['u', 'p']\n        self._cache[coord_name] = err_names\n    return self._cache[coord_name]\n", "def _get_err_indices(self, coord_name):\n    if coord_name in self._coord_names:\n        return self._coord_names.index(coord_name)\n    else:\n        raise ValueError(\"Coordinate {} is not a recognised coordinate \"\n                         \"name.\".format(coord_name))\n", "def _get_err_indices(self, coord_name):\n    if coord_name == 'x':\n        return np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    elif coord_name == 'y':\n        return np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    elif coord_name == 'z':\n        return np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    else:\n        raise KeyError('coordinate {} not supported'.format(coord_name))\n", "def _get_err_indices(self, coord_name):\n    if coord_name in self._coord_errs:\n        return self._coord_errs[coord_name]\n    elif coord_name in self._coord_vars:\n        return self._coord_vars[coord_name]\n    else:\n        raise ValueError(\"Unknown coordinate {}\".format(coord_name))\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def _get_err_indices(self, coord_name):\n    if coord_name in self._cache:\n        return self._cache[coord_name]\n\n    if coord_name in self._err_indices:\n        return self._err_indices[coord_name]\n\n    raise ValueError('Coordinate {} not found.'.format(coord_name))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n    if coord_name == 'x':\n        return [0, 1, 2, 3, 4, 5, 6, 7, 8]\n    elif coord_name == 'y':\n        return [0, 1, 2, 3, 4, 5, 6, 7, 8]\n    elif coord_name == 'z':\n        return [0, 1, 2, 3, 4, 5, 6, 7, 8]\n    else:\n        raise ValueError('coordinate name {} not supported'.format(coord_name))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n    if coord_name == \"x\":\n        return [0, 1, 2, 3, 4, 5, 6, 7]\n    elif coord_name == \"y\":\n        return [1, 2, 3, 4, 5, 6, 7]\n    else:\n        raise ValueError(\"Invalid coordinate name {}\".format(coord_name))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n    if coord_name in self._err_dict:\n        return self._err_dict[coord_name]\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n    if coord_name in self:\n        return self[coord_name]._get_err_indices()\n    else:\n        raise KeyError(coord_name)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n    return self._coord_names_to_err_indices[coord_name]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n    if coord_name not in self._cache:\n        err_names = ['x', 'y', 'z']\n        if coord_name in ['x', 'y', 'z']:\n            err_names = ['x', 'y']\n        elif coord_name in ['r', 't']:\n            err_names = ['r', 't']\n        elif coord_name in ['v', 'q']:\n            err_names = ['v', 'q']\n        elif coord_name in ['a', 'e']:\n            err_names = ['a', 'e']\n        elif coord_name in ['u', 'p']:\n            err_names = ['u', 'p']\n        self._cache[coord_name] = err_names\n    return self._cache[coord_name]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n    if coord_name in self._coord_names:\n        return self._coord_names.index(coord_name)\n    else:\n        raise ValueError(\"Coordinate {} is not a recognised coordinate \"\n                         \"name.\".format(coord_name))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n    if coord_name == 'x':\n        return np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    elif coord_name == 'y':\n        return np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    elif coord_name == 'z':\n        return np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    else:\n        raise KeyError('coordinate {} not supported'.format(coord_name))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_err_indices(self, coord_name):\n    if coord_name in self._coord_errs:\n        return self._coord_errs[coord_name]\n    elif coord_name in self._coord_vars:\n        return self._coord_vars[coord_name]\n    else:\n        raise ValueError(\"Unknown coordinate {}\".format(coord_name))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/structures/graph.py", "project": "ynikitenko/lena", "name": "_update_context", "docstring": "Update *context* with the properties of this graph.\n\n*context.error* is appended with indices of errors.\nExample subcontext for a graph with fields \"E,t,error_E_low\":\n{\"error\": {\"x_low\": {\"index\": 2}}}.\nNote that error names are called \"x\", \"y\" and \"z\"\n(this corresponds to first three coordinates,\nif they are present), which allows to simplify plotting.\nExisting values are not removed\nfrom *context.value* and its subcontexts.\n\nCalled on \"destruction\" of the graph (for example,\nin :class:`.ToCSV`). By destruction we mean conversion\nto another structure (like text) in the flow.\nThe graph object is not really destroyed in this process.", "ques_id": "62b87b7e9a0c4fa8b80b35bc", "code": ["def _update_context(self, context):\n    context.error = []\n", "def _update_context(self, context):\n    context.error = {}\n    context.value = {}\n    context.indices = []\n", "def _update_context(self, context):\n    context.error = []\n    context.value = {}\n    context.value[\"x\"] = []\n    context.value[\"y\"] = []\n    context.value[\"z\"] = []\n", "def _update_context(self, context):\n    context.error = {}\n", "def _update_context(self, context):\n    context.error = []\n", "def _update_context(self, context):\n    context.error = []\n", "def _update_context(self, context):\n    context.error = []\n", "def _update_context(self, context):\n    context.error = []\n    context.value = {}\n    context.fields = []\n", "def _update_context(self, context):\n    context.error = {}\n", "def _update_context(self, context):\n    # Keep a copy of the context so we don't lose its contents.\n    context.value = {}\n    context.error = {}\n    context._graph = context.graph.copy()\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def _update_context(self, context):\n    context.error = []\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n    context.error = {}\n    context.value = {}\n    context.indices = []\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n    context.error = []\n    context.value = {}\n    context.value[\"x\"] = []\n    context.value[\"y\"] = []\n    context.value[\"z\"] = []\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n    context.error = {}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n    context.error = []\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n    context.error = []\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n    context.error = []\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n    context.error = []\n    context.value = {}\n    context.fields = []\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n    context.error = {}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _update_context(self, context):\n    # Keep a copy of the context so we don't lose its contents.\n    context.value = {}\n    context.error = {}\n    context._graph = context.graph.copy()\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/structures/hist_functions.py", "project": "ynikitenko/lena", "name": "integral", "docstring": "Compute integral (scale for a histogram).\n\n*bins* contain values, and *edges* form the mesh\nfor the integration.\nTheir format is defined in :class:`.histogram` description.", "ques_id": "62b87b4f9a0c4fa8b80b3580", "code": ["def integral(bins, edges):\n    return sum(edges[1:]-edges[:-1])*0.5*(bins[1:]+bins[:-1])\n", "def integral(bins, edges):\n    return np.diff(bins) * edges[1:] + np.diff(bins) * edges[:-1]\n", "def integral(bins, edges):\n    # compute the denominator of the sum of the values\n    denominator = numpy.add.reduce(bins)\n    if denominator:\n        return numpy.add.reduce(bins * edges) / denominator\n    else:\n        return 0.0\n", "def integral(bins, edges):\n    xedges, yedges = edges\n    xmid = (xedges[1:] + xedges[:-1]) / 2.\n    ymid = (yedges[1:] + yedges[:-1]) / 2.\n    return 0.5 * (xmid[1:] + xmid[:-1]) * bins[:-1] + 0.5 * (ymid[1:] + ymid[:-1]) * bins[1:]\n", "def integral(bins, edges):\n    return _np.diff(bins) * edges / bins[-1]\n", "def integral(bins, edges):\n    return bins[:-1] + edges[1:]\n", "def integral(bins, edges):\n    return np.diff(edges) * bins\n", "def integral(bins, edges):\n    return trapz(bins * edges, edges)\n", "def integral(bins, edges):\n    return (edges[1:] - edges[:-1]) * bins[1:] + edges[:-1] * bins[:-1]\n", "def integral(bins, edges):\n    return (edges[1:] - edges[:-1]) * bins[:-1] + edges[:-1] * bins[1:]\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def integral(bins, edges):\n    return sum(edges[1:]-edges[:-1])*0.5*(bins[1:]+bins[:-1])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    return np.diff(bins) * edges[1:] + np.diff(bins) * edges[:-1]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    # compute the denominator of the sum of the values\n    denominator = numpy.add.reduce(bins)\n    if denominator:\n        return numpy.add.reduce(bins * edges) / denominator\n    else:\n        return 0.0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    xedges, yedges = edges\n    xmid = (xedges[1:] + xedges[:-1]) / 2.\n    ymid = (yedges[1:] + yedges[:-1]) / 2.\n    return 0.5 * (xmid[1:] + xmid[:-1]) * bins[:-1] + 0.5 * (ymid[1:] + ymid[:-1]) * bins[1:]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    return _np.diff(bins) * edges / bins[-1]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    return bins[:-1] + edges[1:]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    return np.diff(edges) * bins\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    return trapz(bins * edges, edges)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    return (edges[1:] - edges[:-1]) * bins[1:] + edges[:-1] * bins[:-1]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def integral(bins, edges):\n    return (edges[1:] - edges[:-1]) * bins[:-1] + edges[:-1] * bins[1:]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/core/check_sequence_type.py", "project": "ynikitenko/lena", "name": "is_fill_request_seq", "docstring": "Test whether *seq* can be converted to a FillRequestSeq.\n\nTrue only if it is a FillRequest element\nor contains at least one such,\nand it is not a Source sequence.", "ques_id": "62b87b199a0c4fa8b80b354e", "code": ["def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequestSeq) and not isinstance(seq, SourceSeq)\n", "def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequest) or (isinstance(seq, Source) and seq.is_fill_request())\n", "def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequest) or (isinstance(seq, Source) and seq.is_fill_request())\n", "def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequest) or (\n        isinstance(seq, Source) and any(s.is_fill_request() for s in seq)\n    )\n", "def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequest) or (isinstance(seq, Source) and seq.is_fill_request())\n", "def is_fill_request_seq(seq):\n    return (isinstance(seq, FillRequest) or\n            any(isinstance(x, Source) for x in seq))\n", "def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequest) or (isinstance(seq, Source) and seq.is_source)\n", "def is_fill_request_seq(seq):\n    return (isinstance(seq, FillRequest) or\n            (isinstance(seq, Source) and any(s.is_fill_request()\n                                           for s in seq)))\n", "def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequest) or (\n        isinstance(seq, Source) and any([s.is_fill_request() for s in seq])\n    )\n", "def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequest) or (isinstance(seq, Source) and seq.is_source)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequestSeq) and not isinstance(seq, SourceSeq)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequest) or (isinstance(seq, Source) and seq.is_fill_request())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequest) or (isinstance(seq, Source) and seq.is_fill_request())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequest) or (\n        isinstance(seq, Source) and any(s.is_fill_request() for s in seq)\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequest) or (isinstance(seq, Source) and seq.is_fill_request())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    return (isinstance(seq, FillRequest) or\n            any(isinstance(x, Source) for x in seq))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequest) or (isinstance(seq, Source) and seq.is_source)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    return (isinstance(seq, FillRequest) or\n            (isinstance(seq, Source) and any(s.is_fill_request()\n                                           for s in seq)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequest) or (\n        isinstance(seq, Source) and any([s.is_fill_request() for s in seq])\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_seq(seq):\n    return isinstance(seq, FillRequest) or (isinstance(seq, Source) and seq.is_source)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/core/check_sequence_type.py", "project": "ynikitenko/lena", "name": "is_fill_request_el", "docstring": "Object contains executable methods 'fill' and 'request'.", "ques_id": "62b87b099a0c4fa8b80b3538", "code": ["def is_fill_request_el(obj):\n    return isinstance(obj, dict) and obj.get('method') == 'fill'\n", "def is_fill_request_el(obj):\n    return obj.tag == 'fill' or obj.tag =='request'\n", "def is_fill_request_el(obj):\n    return isinstance(obj, dict) and obj.get('method') == 'fill' \\\n        and obj.get('params') is not None\n", "def is_fill_request_el(obj):\n    return isinstance(obj, dict) and obj.get('method') == 'fill' and obj.get('params') is not None\n", "def is_fill_request_el(obj):\n    return isinstance(obj, dict) and obj.get('method', None) == 'fill'\n", "def is_fill_request_el(obj):\n    return obj.tag == 'fill' and obj.attrib['method'] =='request'\n", "def is_fill_request_el(obj):\n    return isinstance(obj, dict) and obj.get('method') == 'fill' \\\n        and obj.get('params') is not None\n", "def is_fill_request_el(obj):\n    return obj.tag == 'fill' and obj.attrib['method'] =='request'\n", "def is_fill_request_el(obj):\n    return obj.tag == 'fill' and obj.attrib['method'] =='request'\n", "def is_fill_request_el(obj):\n    return obj.tag == 'fill' and obj.get('method') =='request'\n"], "level": "self_contained", "generate_results": [{"generate_code": "def is_fill_request_el(obj):\n    return isinstance(obj, dict) and obj.get('method') == 'fill'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_el(obj):\n    return obj.tag == 'fill' or obj.tag =='request'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_el(obj):\n    return isinstance(obj, dict) and obj.get('method') == 'fill' \\\n        and obj.get('params') is not None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_el(obj):\n    return isinstance(obj, dict) and obj.get('method') == 'fill' and obj.get('params') is not None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_el(obj):\n    return isinstance(obj, dict) and obj.get('method', None) == 'fill'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_el(obj):\n    return obj.tag == 'fill' and obj.attrib['method'] =='request'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_el(obj):\n    return isinstance(obj, dict) and obj.get('method') == 'fill' \\\n        and obj.get('params') is not None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_el(obj):\n    return obj.tag == 'fill' and obj.attrib['method'] =='request'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_el(obj):\n    return obj.tag == 'fill' and obj.attrib['method'] =='request'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_request_el(obj):\n    return obj.tag == 'fill' and obj.get('method') =='request'\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/core/check_sequence_type.py", "project": "ynikitenko/lena", "name": "is_run_el", "docstring": "Object contains executable method 'run'.", "ques_id": "62b87af99a0c4fa8b80b3524", "code": ["def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return isinstance(obj, BaseRunner) and hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return isinstance(obj, types.FunctionType) and \\\n        obj.__name__ == 'run'\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return isinstance(obj, BaseExecutor) and hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "def is_run_el(obj):\n    return isinstance(obj, Element) and hasattr(obj, 'run')\n"], "level": "self_contained", "generate_results": [{"generate_code": "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_run_el(obj):\n    return isinstance(obj, BaseRunner) and hasattr(obj, 'run')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_run_el(obj):\n    return isinstance(obj, types.FunctionType) and \\\n        obj.__name__ == 'run'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_run_el(obj):\n    return isinstance(obj, BaseExecutor) and hasattr(obj, 'run')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_run_el(obj):\n    return hasattr(obj, 'run')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_run_el(obj):\n    return isinstance(obj, Element) and hasattr(obj, 'run')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/core/check_sequence_type.py", "project": "ynikitenko/lena", "name": "is_fill_compute_el", "docstring": "Object contains executable methods 'fill' and 'compute'.", "ques_id": "62b87af69a0c4fa8b80b351a", "code": ["def is_fill_compute_el(obj):\n    return (isinstance(obj, FillElement) or\n            (isinstance(obj, ShapeElement) and obj.fill) or\n            (isinstance(obj, ComputeElement) and obj.compute))\n", "def is_fill_compute_el(obj):\n    return hasattr(obj, 'fill') and hasattr(obj, 'compute')\n", "def is_fill_compute_el(obj):\n    return isinstance(obj, FillElement) and obj.fill is not None\n", "def is_fill_compute_el(obj):\n    return (isinstance(obj, FillCompute) or\n            (isinstance(obj, Compute) and obj.fill))\n", "def is_fill_compute_el(obj):\n    return (isinstance(obj, FillElement) or\n            isinstance(obj, ComputeElement))\n", "def is_fill_compute_el(obj):\n    return isinstance(obj, FillComputeEl)\n", "def is_fill_compute_el(obj):\n    return isinstance(obj, FillComputeEl)\n", "def is_fill_compute_el(obj):\n    return (isinstance(obj, FillBase) or\n            (isinstance(obj, InternalFillBase) and\n             obj.fill is not None) or\n            (isinstance(obj, ComputeBase) and obj.compute is not None))\n", "def is_fill_compute_el(obj):\n    return (isinstance(obj, FillBase) or\n            (isinstance(obj, ComputeBase) and obj.fill))\n", "def is_fill_compute_el(obj):\n    return hasattr(obj, 'fill') and hasattr(obj, 'compute')\n"], "level": "self_contained", "generate_results": [{"generate_code": "def is_fill_compute_el(obj):\n    return (isinstance(obj, FillElement) or\n            (isinstance(obj, ShapeElement) and obj.fill) or\n            (isinstance(obj, ComputeElement) and obj.compute))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_compute_el(obj):\n    return hasattr(obj, 'fill') and hasattr(obj, 'compute')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_fill_compute_el(obj):\n    return isinstance(obj, FillElement) and obj.fill is not None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_compute_el(obj):\n    return (isinstance(obj, FillCompute) or\n            (isinstance(obj, Compute) and obj.fill))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_compute_el(obj):\n    return (isinstance(obj, FillElement) or\n            isinstance(obj, ComputeElement))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_compute_el(obj):\n    return isinstance(obj, FillComputeEl)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_compute_el(obj):\n    return isinstance(obj, FillComputeEl)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_compute_el(obj):\n    return (isinstance(obj, FillBase) or\n            (isinstance(obj, InternalFillBase) and\n             obj.fill is not None) or\n            (isinstance(obj, ComputeBase) and obj.compute is not None))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_compute_el(obj):\n    return (isinstance(obj, FillBase) or\n            (isinstance(obj, ComputeBase) and obj.fill))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_fill_compute_el(obj):\n    return hasattr(obj, 'fill') and hasattr(obj, 'compute')\n", "is_pass": true, "return_code": 0}]}
{"file_path": "lena/context/functions.py", "project": "ynikitenko/lena", "name": "difference", "docstring": "Return a dictionary with items from *d1* not contained in *d2*.\n\n*level* sets the maximum depth of recursion. For infinite recursion,\nset that to -1. For level 1,\nif a key is present both in *d1* and *d2* but has different values,\nit is included into the difference.\nSee :func:`intersection` for more details.\n\n*d1* and *d2* remain unchanged. However, *d1* or some of its\nsubdictionaries may be returned directly.\nMake a deep copy of the result when appropriate.\n\n.. versionadded:: 0.5\n   add keyword argument *level*.", "ques_id": "62b87af19a0c4fa8b80b34f7", "code": ["def difference(d1, d2, level=-1):\n    d = OrderedDict()\n    if not d1:\n        return d\n    if level == 0:\n        d.update(d1)\n        d.update(d2)\n    else:\n        for key in d1:\n            if key not in d2:\n                d[key] = d1[key]\n        for key in d2:\n            if key not in d1:\n                d[key] = d2[key]\n    return d\n", "def difference(d1, d2, level=-1):\n    if not d1:\n        return d2\n    if not d2:\n        return d1\n\n    d1_keys = set(d1.keys())\n    d2_keys = set(d2.keys())\n    diff = {}\n\n    for key in d1_keys - d2_keys:\n        val1 = d1[key]\n        val2 = d2[key]\n        if level < 0:\n            # Infinite recursion.\n            if val1 in d2:\n                diff[key] = diff.get(key, []) + [val1]\n            else:\n                diff[key] = [val1]\n        elif val1 in d2:\n            # Same value as before, so do not add it to the result.\n            diff[key].append(val1)\n        else:\n            # Not so simple recursion.\n            diff[key] = [val1]\n\n    for key in d2_keys -", "def difference(d1, d2, level=-1):\n    if not d1:\n        return d2\n    if not d2:\n        return d1\n\n    d1_copy = d1.copy()\n    d2_copy = d2.copy()\n    keys_to_delete = set()\n\n    while level >= 0:\n        keys_to_delete |= set(d1_copy.keys())\n        keys_to_delete -= set(d2_copy.keys())\n\n        for key in keys_to_delete:\n            del d1_copy[key]\n            d2_copy.pop(key)\n            if level == 0:\n                break\n\n        level -= 1\n\n    return d1_copy if not keys_to_delete else d2_copy\n", "def difference(d1, d2, level=-1):\n    d1_copy = dict(d1)\n    if level < 0:\n        for key in d2:\n            if key in d1_copy:\n                del d1_copy[key]\n        return d1_copy\n    for key in d2:\n        if key not in d1_copy:\n            d1_copy[key] = d2[key]\n            if isinstance(d1_copy[key], dict) and isinstance(d2[key], dict):\n                d1_copy[key] = difference(d1_copy[key], d2[key], level + 1)\n    return d1_copy\n", "def difference(d1, d2, level=-1):\n    if level < 0:\n        level = max(d1.keys() & d2.keys()) + level\n\n    d2_copy = d2.copy()\n    for key in d1:\n        if d1[key] not in d2_copy:\n            d2_copy[d1[key]] = None\n        elif d1[key] == d2[key]:\n            d2_copy[d1[key]] = d1[key]\n        else:\n            d2_copy[d1[key]] = intersection(d2[key], d1[key])\n    return d2_copy\n", "def difference(d1, d2, level=-1):\n    d1copy = d1.copy()\n    if level == 0:\n        return d1copy\n    for key in d2:\n        if key not in d1copy:\n            d1copy[key] = d2[key]\n        elif d1copy[key]!= d2[key]:\n            d1copy[key] = intersection(d1copy[key], d2[key])\n    return d1copy\n", "def difference(d1, d2, level=-1):\n    result = dict(d1)\n    if level < 0:\n        for key in d2:\n            if key not in d1:\n                result[key] = d2[key]\n    else:\n        for key in d1:\n            if key not in d2:\n                result[key] = d1[key]\n    return result\n", "def difference(d1, d2, level=-1):\n    d2copy = d2.copy()\n    if not d1:\n        return d2copy\n    for k, v in d1.items():\n        if k in d2copy and v!= d2copy[k]:\n            d2copy[k] = v\n            if level == 0:\n                yield d2copy\n            elif level < 0:\n                return\n            else:\n                level -= 1\n", "def difference(d1, d2, level=-1):\n    if not d1:\n        return d2\n    if not d2:\n        return d1\n\n    d1_values = d1.pop(level, None)\n    d2_values = d2.pop(level, None)\n\n    if d1_values is None and d2_values is None:\n        return d1\n    if d1_values is None:\n        return d2\n    if d2_values is None:\n        return d1\n\n    if isinstance(d1_values, dict) and isinstance(d2_values, dict):\n        d1_values.update(d2_values)\n        return d1\n\n    return dict(list(d1.items()) + list(d2.items()))\n", "def difference(d1, d2, level=-1):\n    d2copy = dict(d2)\n    if level == 0:\n        return d1\n    for k in d1:\n        if k in d2copy:\n            d2copy[k] = intersection(d1[k], d2copy[k])\n    return d2copy\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def difference(d1, d2, level=-1):\n    d = OrderedDict()\n    if not d1:\n        return d\n    if level == 0:\n        d.update(d1)\n        d.update(d2)\n    else:\n        for key in d1:\n            if key not in d2:\n                d[key] = d1[key]\n        for key in d2:\n            if key not in d1:\n                d[key] = d2[key]\n    return d\n", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    if not d1:\n        return d2\n    if not d2:\n        return d1\n\n    d1_keys = set(d1.keys())\n    d2_keys = set(d2.keys())\n    diff = {}\n\n    for key in d1_keys - d2_keys:\n        val1 = d1[key]\n        val2 = d2[key]\n        if level < 0:\n            # Infinite recursion.\n            if val1 in d2:\n                diff[key] = diff.get(key, []) + [val1]\n            else:\n                diff[key] = [val1]\n        elif val1 in d2:\n            # Same value as before, so do not add it to the result.\n            diff[key].append(val1)\n        else:\n            # Not so simple recursion.\n            diff[key] = [val1]\n\n    for key in d2_keys -", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    if not d1:\n        return d2\n    if not d2:\n        return d1\n\n    d1_copy = d1.copy()\n    d2_copy = d2.copy()\n    keys_to_delete = set()\n\n    while level >= 0:\n        keys_to_delete |= set(d1_copy.keys())\n        keys_to_delete -= set(d2_copy.keys())\n\n        for key in keys_to_delete:\n            del d1_copy[key]\n            d2_copy.pop(key)\n            if level == 0:\n                break\n\n        level -= 1\n\n    return d1_copy if not keys_to_delete else d2_copy\n", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    d1_copy = dict(d1)\n    if level < 0:\n        for key in d2:\n            if key in d1_copy:\n                del d1_copy[key]\n        return d1_copy\n    for key in d2:\n        if key not in d1_copy:\n            d1_copy[key] = d2[key]\n            if isinstance(d1_copy[key], dict) and isinstance(d2[key], dict):\n                d1_copy[key] = difference(d1_copy[key], d2[key], level + 1)\n    return d1_copy\n", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    if level < 0:\n        level = max(d1.keys() & d2.keys()) + level\n\n    d2_copy = d2.copy()\n    for key in d1:\n        if d1[key] not in d2_copy:\n            d2_copy[d1[key]] = None\n        elif d1[key] == d2[key]:\n            d2_copy[d1[key]] = d1[key]\n        else:\n            d2_copy[d1[key]] = intersection(d2[key], d1[key])\n    return d2_copy\n", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    d1copy = d1.copy()\n    if level == 0:\n        return d1copy\n    for key in d2:\n        if key not in d1copy:\n            d1copy[key] = d2[key]\n        elif d1copy[key]!= d2[key]:\n            d1copy[key] = intersection(d1copy[key], d2[key])\n    return d1copy\n", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    result = dict(d1)\n    if level < 0:\n        for key in d2:\n            if key not in d1:\n                result[key] = d2[key]\n    else:\n        for key in d1:\n            if key not in d2:\n                result[key] = d1[key]\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    d2copy = d2.copy()\n    if not d1:\n        return d2copy\n    for k, v in d1.items():\n        if k in d2copy and v!= d2copy[k]:\n            d2copy[k] = v\n            if level == 0:\n                yield d2copy\n            elif level < 0:\n                return\n            else:\n                level -= 1\n", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    if not d1:\n        return d2\n    if not d2:\n        return d1\n\n    d1_values = d1.pop(level, None)\n    d2_values = d2.pop(level, None)\n\n    if d1_values is None and d2_values is None:\n        return d1\n    if d1_values is None:\n        return d2\n    if d2_values is None:\n        return d1\n\n    if isinstance(d1_values, dict) and isinstance(d2_values, dict):\n        d1_values.update(d2_values)\n        return d1\n\n    return dict(list(d1.items()) + list(d2.items()))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def difference(d1, d2, level=-1):\n    d2copy = dict(d2)\n    if level == 0:\n        return d1\n    for k in d1:\n        if k in d2copy:\n            d2copy[k] = intersection(d1[k], d2copy[k])\n    return d2copy\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/structures/histogram.py", "project": "ynikitenko/lena", "name": "fill", "docstring": "Fill histogram at *coord* with the given *weight*.\n\nCoordinates outside the histogram edges are ignored.", "ques_id": "62b87af09a0c4fa8b80b34f1", "code": ["def fill(self, coord, weight=1):\n    self[coord] = weight\n", "def fill(self, coord, weight=1):\n    self[coord] = weight\n", "def fill(self, coord, weight=1):\n    # TODO: use bin_coords instead\n    for i in range(self.nbins):\n        if i < self.nbins - 1:\n            self.hist[coord + (i,)] += weight\n        else:\n            self.hist[coord + (i,)] = weight\n", "def fill(self, coord, weight=1):\n    self[coord] = weight\n", "def fill(self, coord, weight=1):\n    self[coord] = weight\n", "def fill(self, coord, weight=1):\n    # fill histogram\n    self[coord] += weight\n", "def fill(self, coord, weight=1):\n    if self._min is None or coord < self._min:\n        self._min = coord\n    if self._max is None or coord > self._max:\n        self._max = coord\n", "def fill(self, coord, weight=1):\n    self[coord] = weight\n", "def fill(self, coord, weight=1):\n    self[coord] = weight\n", "def fill(self, coord, weight=1):\n    self[coord] = weight\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def fill(self, coord, weight=1):\n    self[coord] = weight\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    self[coord] = weight\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    # TODO: use bin_coords instead\n    for i in range(self.nbins):\n        if i < self.nbins - 1:\n            self.hist[coord + (i,)] += weight\n        else:\n            self.hist[coord + (i,)] = weight\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    self[coord] = weight\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    self[coord] = weight\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    # fill histogram\n    self[coord] += weight\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    if self._min is None or coord < self._min:\n        self._min = coord\n    if self._max is None or coord > self._max:\n        self._max = coord\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    self[coord] = weight\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    self[coord] = weight\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fill(self, coord, weight=1):\n    self[coord] = weight\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/data/core.py", "project": "rak-n-rok/Krake", "name": "_validate_labels", "docstring": "Check that keys and values in the given labels match against their corresponding\nregular expressions.\n\nArgs:\n    labels (dict): the different labels to validate.\n\nRaises:\n    ValidationError: if any of the keys and labels does not match their respective\n        regular expression. The error contains as message the list of all errors\n        which occurred in the labels. Each element of the list is a dictionary with\n        one key-value pair:\n        - key: the label key or label value for which an error occurred as string.\n        - value: the error message.\n\n        .. code:: python\n\n            # Example:\n            labels = {\n                \"key1\": \"valid\",\n                \"key2\": [\"invalid\"],\n                \"$$\": \"invalid\",\n                True: True,\n            }\n            try:\n                _validate_labels(labels)\n            except ValidationError as err:\n                assert err.messages == [\n                    {\"['invalid']\": 'expected string or bytes-like object'},\n                    {'$$': \"Label key '$$' does not match the regex [...]\"},\n                    {'True': 'expected string or bytes-like object'},\n                    {'True': 'expected string or bytes-like object'},\n                ]", "ques_id": "62b86aa3b4d922cb0e688d36", "code": ["def _validate_labels(labels):\n    for key, regex in labels.items():\n        if not isinstance(key, str):\n            raise ValidationError(\"labels keys must be strings: {!r}\".format(key))\n        if not isinstance(regex, list):\n            raise ValidationError(\"labels values must be lists: {!r}\".format(regex))\n\n        for err in regex:\n            if not isinstance(err, dict):\n                raise ValidationError(\"labels values must be lists: {!r}\".format(err))\n\n            for key_value in err.items():\n                if not isinstance(key_value[0], str):\n                    raise ValidationError(\"labels values must be strings: {!r}\".format(key_value))\n", "def _validate_labels(labels):\n    for key, regexps in labels.items():\n        for regexp in regexps:\n            if not re.match(regexp[0], key):\n                raise ValidationError(\n                    \"Label key '%s' does not match regexp '%s'\" % (key, regexp[0])\n                )\n\n        for err in regexps:\n            if not re.match(err[1], key):\n                raise ValidationError(\n                    \"Label value '%s' does not match regexp '%s'\" % (key, err[1])\n                )\n", "def _validate_labels(labels):\n    for key, value in labels.items():\n        for err in _validate_label(key, value):\n            yield err\n", "def _validate_labels(labels):\n    for key, regexp in labels.items():\n        errors = []\n        for err in regexp:\n            try:\n                _validate_label(key, err['value'], err['error'])\n            except ValueError:\n                errors.append(err)\n        if errors:\n            raise ValidationError(errors)\n", "def _validate_labels(labels):\n    for key, regex in labels.items():\n        if not re.match(regex, key):\n            raise ValidationError(\"{} does not match the regex: {}\".format(key, regex))\n", "def _validate_labels(labels):\n    errors = []\n    for key, value_iter in six.iteritems(labels):\n        regex = label_regex[key]\n        for value in value_iter:\n            try:\n                re.compile(value)\n            except re.error as err:\n                errors.append({\n                    \"message\": \"{} key '{}' does not match regex '{}'\".format(\n                        labels, key, regex),\n                    \"cause\": err,\n                })\n    if errors:\n        raise ValidationError(errors)\n", "def _validate_labels(labels):\n    for key, expected in six.iteritems(labels):\n        found = re.compile(expected)\n        if not found.search(labels[key]):\n            raise ValidationError(\"{} has an invalid label '{}'\".format(key, expected))\n", "def _validate_labels(labels):\n    for key, regexps in labels.items():\n        for regexp in regexps:\n            if not re.match(regexp[\"regexp\"], key):\n                raise ValidationError(\n                    \"Invalid label key: '{}'. Valid keys are: {}.\".format(\n                        key, \", \".join(regexp[\"errors\"])\n                    )\n                )\n", "def _validate_labels(labels):\n    for key, regex in labels.items():\n        if key not in labels:\n            raise ValidationError(\n                \"Label key '{}' does not match the regex '{}'.\".format(\n                    key, regex\n                )\n            )\n\n        try:\n            for error in re.findall(regex, labels[key]):\n                raise ValidationError(\n                    \"Label key '{}' error: {}\".format(key, error)\n                )\n        except TypeError:\n            raise ValidationError(\"Label key '{}' has a type error.\".format(key))\n", "def _validate_labels(labels):\n    for key, values in labels.items():\n        if isinstance(key, bytes):\n            key = key.decode(\"utf-8\")\n        if isinstance(values, bytes):\n            values = values.decode(\"utf-8\")\n\n        for pattern, message in _LABEL_REGEX_AND_ERRORS:\n            if not re.match(pattern, key):\n                raise ValidationError(message)\n            for value in values:\n                try:\n                    if not re.match(pattern, value):\n                        raise ValidationError(message)\n                except ValueError as err:\n                    raise ValidationError(\"{} for label '{}'\".format(err, key))\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _validate_labels(labels):\n    for key, regex in labels.items():\n        if not isinstance(key, str):\n            raise ValidationError(\"labels keys must be strings: {!r}\".format(key))\n        if not isinstance(regex, list):\n            raise ValidationError(\"labels values must be lists: {!r}\".format(regex))\n\n        for err in regex:\n            if not isinstance(err, dict):\n                raise ValidationError(\"labels values must be lists: {!r}\".format(err))\n\n            for key_value in err.items():\n                if not isinstance(key_value[0], str):\n                    raise ValidationError(\"labels values must be strings: {!r}\".format(key_value))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    for key, regexps in labels.items():\n        for regexp in regexps:\n            if not re.match(regexp[0], key):\n                raise ValidationError(\n                    \"Label key '%s' does not match regexp '%s'\" % (key, regexp[0])\n                )\n\n        for err in regexps:\n            if not re.match(err[1], key):\n                raise ValidationError(\n                    \"Label value '%s' does not match regexp '%s'\" % (key, err[1])\n                )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    for key, value in labels.items():\n        for err in _validate_label(key, value):\n            yield err\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    for key, regexp in labels.items():\n        errors = []\n        for err in regexp:\n            try:\n                _validate_label(key, err['value'], err['error'])\n            except ValueError:\n                errors.append(err)\n        if errors:\n            raise ValidationError(errors)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    for key, regex in labels.items():\n        if not re.match(regex, key):\n            raise ValidationError(\"{} does not match the regex: {}\".format(key, regex))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    errors = []\n    for key, value_iter in six.iteritems(labels):\n        regex = label_regex[key]\n        for value in value_iter:\n            try:\n                re.compile(value)\n            except re.error as err:\n                errors.append({\n                    \"message\": \"{} key '{}' does not match regex '{}'\".format(\n                        labels, key, regex),\n                    \"cause\": err,\n                })\n    if errors:\n        raise ValidationError(errors)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    for key, expected in six.iteritems(labels):\n        found = re.compile(expected)\n        if not found.search(labels[key]):\n            raise ValidationError(\"{} has an invalid label '{}'\".format(key, expected))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    for key, regexps in labels.items():\n        for regexp in regexps:\n            if not re.match(regexp[\"regexp\"], key):\n                raise ValidationError(\n                    \"Invalid label key: '{}'. Valid keys are: {}.\".format(\n                        key, \", \".join(regexp[\"errors\"])\n                    )\n                )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    for key, regex in labels.items():\n        if key not in labels:\n            raise ValidationError(\n                \"Label key '{}' does not match the regex '{}'.\".format(\n                    key, regex\n                )\n            )\n\n        try:\n            for error in re.findall(regex, labels[key]):\n                raise ValidationError(\n                    \"Label key '{}' error: {}\".format(key, error)\n                )\n        except TypeError:\n            raise ValidationError(\"Label key '{}' has a type error.\".format(key))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _validate_labels(labels):\n    for key, values in labels.items():\n        if isinstance(key, bytes):\n            key = key.decode(\"utf-8\")\n        if isinstance(values, bytes):\n            values = values.decode(\"utf-8\")\n\n        for pattern, message in _LABEL_REGEX_AND_ERRORS:\n            if not re.match(pattern, key):\n                raise ValidationError(message)\n            for value in values:\n                try:\n                    if not re.match(pattern, value):\n                        raise ValidationError(message)\n                except ValueError as err:\n                    raise ValidationError(\"{} for label '{}'\".format(err, key))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/data/core.py", "project": "rak-n-rok/Krake", "name": "_get_resource_name_regex", "docstring": "Build or return the regular expressions that are used to validate\nthe name of the Krake resources.\n\nReturns:\n    (re.Pattern): the compiled regular expressions, to validate\n    the resource name.", "ques_id": "62b86a9eb4d922cb0e688d25", "code": ["def _get_resource_name_regex():\n    # type: () -> Pattern\n    \"\"\"Build or return the regular expressions that are used to validate\n    the name of the Krake resources.\n\n    Returns:\n        (re.Pattern): the compiled regular expressions, to validate the\n            resource name.\n    \"\"\"\n    # pylint: disable=invalid-name\n    if not Krake.NAME_REGEX:\n        # Create a regular expression for name validation\n        Krake.NAME_REGEX = re.compile(r'^((?:(?:{}|{})\\.)?(.*))$'.format(\n            Krake.PREFIX,\n            Krake.RESOURCE_NAME_PATTERN,\n        ))\n    return Krake.NAME_REGEX\n", "def _get_resource_name_regex():\n    # type: () -> Pattern\n    \"\"\"Build or return the regular expressions that are used to validate the\n    name of the Krake resources.\n\n    Returns:\n        (re.Pattern): the compiled regular expressions, to validate the\n            resource name.\n    \"\"\"\n    if not Krake._name_regex:\n        Krake._name_regex = re.compile(\n            r'^((?:(?:(?:%s)|(?P<name>[a-zA-Z0-9_]+)(\\.)?%s))\\.)*$' %\n            ('|'.join(Krake.Krake.PREFIXES)),\n            flags=re.IGNORECASE)\n    return Krake._name_regex\n", "def _get_resource_name_regex():\n    global _name_regex\n    if not _name_regex:\n        _name_regex = re.compile(r'(?i)^(?!Krake\\.)([a-z0-9]{10})$')\n    return _name_regex\n", "def _get_resource_name_regex():\n    if not utils.IS_PYTHON_3:\n        return re.compile(r'(?i)^(?!Krake|hdfs|hdfs|s3|sas|ssh|http|file)$')\n    else:\n        return re.compile(r'^(?i)^(?!Krake|hdfs|hdfs|s3|sas|ssh|http|file)$')\n", "def _get_resource_name_regex():\n    global name_regex\n    if not name_regex:\n        name_regex = re.compile(r'(?i)^(?P<name>.+?)$')\n    return name_regex\n", "def _get_resource_name_regex():\n    global KrakeRegex\n    if KrakeRegex is None:\n        KrakeRegex = re.compile(r\"(?i)^(?:km|kr)://|\\.(?:km|kr)$\")\n    return KrakeRegex\n", "def _get_resource_name_regex():\n    global _KRAKE_NAME_REGEX\n    if not _KRAKE_NAME_REGEX:\n        _KRAKE_NAME_REGEX = re.compile(r'[A-Za-z0-9\\-]{1,63}[A-Za-z0-9\\-]{1,63}')\n    return _KRAKE_NAME_REGEX\n", "def _get_resource_name_regex():\n    # type: () -> Pattern\n    \"\"\"Build or return the regular expressions that are used to validate the\n       name of the Krake resources.\n    \"\"\"\n    # Build the regex for the name of the Krake resources.\n    return get_regex('kraken', 'krake-([a-z0-9]+).yaml')\n", "def _get_resource_name_regex():\n    return get_regex(KrakeConstants.NAME_REGEX)\n", "def _get_resource_name_regex():\n    global KrakeNameResourceNameRegex\n    if KrakeNameResourceNameRegex is None:\n        KrakeNameResourceNameRegex = re.compile(r'^(?P<name>.+?)-(?P<version>.+?)$')\n    return KrakeNameResourceNameRegex\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _get_resource_name_regex():\n    # type: () -> Pattern\n    \"\"\"Build or return the regular expressions that are used to validate\n    the name of the Krake resources.\n\n    Returns:\n        (re.Pattern): the compiled regular expressions, to validate the\n            resource name.\n    \"\"\"\n    # pylint: disable=invalid-name\n    if not Krake.NAME_REGEX:\n        # Create a regular expression for name validation\n        Krake.NAME_REGEX = re.compile(r'^((?:(?:{}|{})\\.)?(.*))$'.format(\n            Krake.PREFIX,\n            Krake.RESOURCE_NAME_PATTERN,\n        ))\n    return Krake.NAME_REGEX\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    # type: () -> Pattern\n    \"\"\"Build or return the regular expressions that are used to validate the\n    name of the Krake resources.\n\n    Returns:\n        (re.Pattern): the compiled regular expressions, to validate the\n            resource name.\n    \"\"\"\n    if not Krake._name_regex:\n        Krake._name_regex = re.compile(\n            r'^((?:(?:(?:%s)|(?P<name>[a-zA-Z0-9_]+)(\\.)?%s))\\.)*$' %\n            ('|'.join(Krake.Krake.PREFIXES)),\n            flags=re.IGNORECASE)\n    return Krake._name_regex\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    global _name_regex\n    if not _name_regex:\n        _name_regex = re.compile(r'(?i)^(?!Krake\\.)([a-z0-9]{10})$')\n    return _name_regex\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    if not utils.IS_PYTHON_3:\n        return re.compile(r'(?i)^(?!Krake|hdfs|hdfs|s3|sas|ssh|http|file)$')\n    else:\n        return re.compile(r'^(?i)^(?!Krake|hdfs|hdfs|s3|sas|ssh|http|file)$')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    global name_regex\n    if not name_regex:\n        name_regex = re.compile(r'(?i)^(?P<name>.+?)$')\n    return name_regex\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    global KrakeRegex\n    if KrakeRegex is None:\n        KrakeRegex = re.compile(r\"(?i)^(?:km|kr)://|\\.(?:km|kr)$\")\n    return KrakeRegex\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    global _KRAKE_NAME_REGEX\n    if not _KRAKE_NAME_REGEX:\n        _KRAKE_NAME_REGEX = re.compile(r'[A-Za-z0-9\\-]{1,63}[A-Za-z0-9\\-]{1,63}')\n    return _KRAKE_NAME_REGEX\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    # type: () -> Pattern\n    \"\"\"Build or return the regular expressions that are used to validate the\n       name of the Krake resources.\n    \"\"\"\n    # Build the regex for the name of the Krake resources.\n    return get_regex('kraken', 'krake-([a-z0-9]+).yaml')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    return get_regex(KrakeConstants.NAME_REGEX)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_resource_name_regex():\n    global KrakeNameResourceNameRegex\n    if KrakeNameResourceNameRegex is None:\n        KrakeNameResourceNameRegex = re.compile(r'^(?P<name>.+?)-(?P<version>.+?)$')\n    return KrakeNameResourceNameRegex\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/data/core.py", "project": "rak-n-rok/Krake", "name": "validate_value", "docstring": "Validate the given value against the corresponding regular expression.\n\nArgs:\n    value: the string to validate\n\nRaises:\n    ValidationError: if the given value is not conform to the regular expression.", "ques_id": "62b86a4fb4d922cb0e688cf8", "code": ["def validate_value(value):\n    pattern = re.compile(get_setting('MULTIPLE_VALIDATOR_REGEX'))\n    if pattern.match(value) is None:\n        raise ValidationError('Invalid value.')\n", "def validate_value(value):\n    if not constants.REGEX_PARAM_LIST.match(value):\n        raise ValidationError(\n            'Invalid regular expression \\'{}\\'. Valid regular expressions '\n            'are of the form \\'{}\\'.'.format(value, constants.REGEX_PARAM_LIST.pattern)\n        )\n", "def validate_value(value):\n    if not REGEX.match(value):\n        raise ValidationError('Must match the regular expression.')\n", "def validate_value(value):\n    pattern = re.compile(value)\n    if pattern.match(value) is None:\n        raise ValidationError('Value \\'{}\\' is not a valid regular expression'.format(value))\n", "def validate_value(value):\n    pattern = re.compile(get_setting('REGEX'))\n\n    if pattern.match(value) is None:\n        raise ValidationError('The value \"{}\" is not a valid regular expression'.format(value))\n", "def validate_value(value):\n    regex = get_regex()\n\n    if not regex.search(value):\n        raise ValidationError('Value does not match the regular expression.')\n", "def validate_value(value):\n    pattern = re.compile(get_regex_pattern())\n\n    if pattern.match(value) is None:\n        raise ValidationError(\"Invalid value\")\n", "def validate_value(value):\n    if value is None:\n        return\n\n    if not isinstance(value, str):\n        raise ValidationError('Value must be a string')\n\n    regex = getattr(settings, 'HELIX_VALIDATOR_REGEX', '[^/]+')\n    m = re.match(regex, value)\n    if not m:\n        raise ValidationError('Invalid value for HELIX_VALIDATOR_REGEX')\n", "def validate_value(value):\n    match = re.match(REGEX, value)\n    if not match:\n        raise ValidationError(\"Invalid value '{}'\".format(value))\n", "def validate_value(value):\n    return _regex.match(value)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def validate_value(value):\n    pattern = re.compile(get_setting('MULTIPLE_VALIDATOR_REGEX'))\n    if pattern.match(value) is None:\n        raise ValidationError('Invalid value.')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    if not constants.REGEX_PARAM_LIST.match(value):\n        raise ValidationError(\n            'Invalid regular expression \\'{}\\'. Valid regular expressions '\n            'are of the form \\'{}\\'.'.format(value, constants.REGEX_PARAM_LIST.pattern)\n        )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    if not REGEX.match(value):\n        raise ValidationError('Must match the regular expression.')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    pattern = re.compile(value)\n    if pattern.match(value) is None:\n        raise ValidationError('Value \\'{}\\' is not a valid regular expression'.format(value))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    pattern = re.compile(get_setting('REGEX'))\n\n    if pattern.match(value) is None:\n        raise ValidationError('The value \"{}\" is not a valid regular expression'.format(value))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    regex = get_regex()\n\n    if not regex.search(value):\n        raise ValidationError('Value does not match the regular expression.')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    pattern = re.compile(get_regex_pattern())\n\n    if pattern.match(value) is None:\n        raise ValidationError(\"Invalid value\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    if value is None:\n        return\n\n    if not isinstance(value, str):\n        raise ValidationError('Value must be a string')\n\n    regex = getattr(settings, 'HELIX_VALIDATOR_REGEX', '[^/]+')\n    m = re.match(regex, value)\n    if not m:\n        raise ValidationError('Invalid value for HELIX_VALIDATOR_REGEX')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    match = re.match(REGEX, value)\n    if not match:\n        raise ValidationError(\"Invalid value '{}'\".format(value))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_value(value):\n    return _regex.match(value)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/data/core.py", "project": "rak-n-rok/Krake", "name": "validate_key", "docstring": "Validate the given key against the corresponding regular expression.\n\nArgs:\n    key: the string to validate\n\nRaises:\n    ValidationError: if the given key is not conform to the regular expression.", "ques_id": "62b86a4fb4d922cb0e688cf7", "code": ["def validate_key(key):\n    if not KEY_RE.match(key):\n        raise ValidationError('Invalid key: %s' % key)\n", "def validate_key(key):\n    if not isinstance(key, str):\n        raise ValidationError('Expected a string. Received %s.' % type(key))\n    if not re.match(_key_regex, key):\n        raise ValidationError('Invalid key. Expected %s. Received %s.' % (_key_regex, key))\n", "def validate_key(key):\n    if not KEY_RE.match(key):\n        raise ValidationError('Invalid key: {}'.format(key))\n", "def validate_key(key):\n    key_re = re.compile(SCHEMA_KEY_RE)\n    if not key_re.match(key):\n        raise ValidationError(\"Invalid key {}\".format(key))\n", "def validate_key(key):\n    regex = re.compile(REGEX)\n    if not regex.match(key):\n        raise ValidationError('Invalid key: %r' % key)\n", "def validate_key(key):\n    if not re.match(REGEX, key):\n        raise ValidationError(\"Invalid regex: '{}'\".format(key))\n", "def validate_key(key):\n    if not re.match(REGEX, key):\n        raise ValidationError('Invalid key: {}'.format(key))\n", "def validate_key(key):\n    match = re.match(REGEX, key)\n    if not match:\n        raise ValidationError('Invalid key: {!r}'.format(key))\n", "def validate_key(key):\n    if not KEY_RE.match(key):\n        raise ValidationError('Invalid key: {}'.format(key))\n", "def validate_key(key):\n    if not key:\n        raise ValidationError('Empty key given')\n    for char in key:\n        if char not in SECRET_KEY_CHARACTERS:\n            raise ValidationError('Invalid character %s' % char)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def validate_key(key):\n    if not KEY_RE.match(key):\n        raise ValidationError('Invalid key: %s' % key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    if not isinstance(key, str):\n        raise ValidationError('Expected a string. Received %s.' % type(key))\n    if not re.match(_key_regex, key):\n        raise ValidationError('Invalid key. Expected %s. Received %s.' % (_key_regex, key))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    if not KEY_RE.match(key):\n        raise ValidationError('Invalid key: {}'.format(key))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    key_re = re.compile(SCHEMA_KEY_RE)\n    if not key_re.match(key):\n        raise ValidationError(\"Invalid key {}\".format(key))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    regex = re.compile(REGEX)\n    if not regex.match(key):\n        raise ValidationError('Invalid key: %r' % key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    if not re.match(REGEX, key):\n        raise ValidationError(\"Invalid regex: '{}'\".format(key))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    if not re.match(REGEX, key):\n        raise ValidationError('Invalid key: {}'.format(key))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    match = re.match(REGEX, key)\n    if not match:\n        raise ValidationError('Invalid key: {!r}'.format(key))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    if not KEY_RE.match(key):\n        raise ValidationError('Invalid key: {}'.format(key))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_key(key):\n    if not key:\n        raise ValidationError('Empty key given')\n    for char in key:\n        if char not in SECRET_KEY_CHARACTERS:\n            raise ValidationError('Invalid character %s' % char)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/controller/kubernetes/hooks.py", "project": "rak-n-rok/Krake", "name": "generate_default_observer_schema_dict", "docstring": "Together with :func:``generate_default_observer_schema_list``, this function is\ncalled recursively to generate part of a default ``observer_schema`` from part of a\nKubernetes resource, defined respectively by ``manifest_dict`` or ``manifest_list``.\n\nArgs:\n    manifest_dict (dict): Partial Kubernetes resources\n    first_level (bool, optional): If True, indicates that the dictionary represents\n        the whole observer schema of a Kubernetes resource\n\nReturns:\n    dict: Generated partial observer_schema\n\nThis function creates a new dictionary from ``manifest_dict`` and replaces all\nnon-list and non-dict values by ``None``.\n\nIn case of ``first_level`` dictionary (i.e. complete ``observer_schema`` for a\nresource), the values of the identifying fields are copied from the manifest file.", "ques_id": "62b86a01b4d922cb0e688ccc", "code": ["def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if first_level:\n        return {'metadata': manifest_dict}\n\n    return {'metadata': {k: v for k, v in manifest_dict.items()\n                         if not isinstance(v, dict)}}\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    # type: (dict, bool) -> dict\n    \"\"\"\n    Recursively generates part of a default ``observer_schema`` from part of\n    a Kubernetes resource, defined below.\n\n    Args:\n        manifest_dict (dict): Partial Kubernetes resource\n\n    Returns:\n        dict: Generated partial observer_schema\n\n    This function creates a new dictionary from ``manifest_dict`` and replaces\n    all non-list and non-dict values by ``None``. In case of ``first_level``\n    dictionary (i.e. complete ``observer_schema`` for a resource), the\n    values of the identifying fields are copied from the manifest file.\n\n    In case of ``first_level`` dictionary (i.e. complete ``observer_schema``\n    for a resource), the values of the identifying fields are copied from\n    the manifest file.\n    \"\"\"\n    if manifest_dict is None:\n        return manifest_dict\n\n    if isinstance(manifest_dict, dict):\n        if not first_level:\n            return {", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if not first_level:\n        return {manifest_dict.get('metadata', {}).get('namespace', None): manifest_dict}\n    else:\n        return manifest_dict\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    observer_schema = manifest_dict\n    for field in manifest_dict:\n        if isinstance(manifest_dict[field], dict) and not first_level:\n            observer_schema[field] = generate_default_observer_schema_dict(\n                manifest_dict[field], first_level=True\n            )\n        elif not first_level and field in manifest_dict:\n            observer_schema[field] = manifest_dict[field]\n    return observer_schema\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if manifest_dict is None:\n        return None\n\n    manifest_list = manifest_dict.get('manifestList', None)\n    if manifest_list is not None:\n        for manifest in manifest_list:\n            manifest_dict = manifest_dict.copy()\n            manifest_dict['manifestVersion'] = manifest.get('manifestVersion', None)\n\n    if first_level:\n        return {\n            'kind': 'observerSchema',\n           'spec': manifest_dict\n        }\n    else:\n        return manifest_dict\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if manifest_dict is None:\n        return None\n\n    if first_level:\n        manifest_dict = {**manifest_dict, **{\"type\": \"ObserverSchema\"}}\n\n    if \"ObserverSchema\" in manifest_dict:\n        for key, value in manifest_dict[\"ObserverSchema\"].items():\n            if isinstance(value, dict):\n                manifest_dict[key] = generate_default_observer_schema_dict(\n                    value, first_level=first_level\n                )\n\n    return manifest_dict\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if first_level:\n        return {\n           'metadata': {},\n           'spec': {},\n           'status': {}\n        }\n    else:\n        return {\n           'metadata': {\n                'name': manifest_dict.get('name'),\n                'namespace': manifest_dict.get('namespace'),\n                'apiVersion': manifest_dict.get('apiVersion'),\n                'kind': manifest_dict.get('kind'),\n               'selector': manifest_dict.get('selector'),\n                'labels': manifest_dict.get('labels'),\n                'annotations': manifest_dict.get('annotations'),\n                'timeout': manifest_dict.get('timeout')\n            }\n        }\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if first_level:\n        return {\n           'metadata': {},\n           'spec': {},\n            'updated_at': None,\n            'updated_by': None,\n            'labels': {},\n            'name': None,\n            'namespace': None,\n           'resources': {},\n           'replicas': {},\n            'type': None,\n        }\n    else:\n        return {\n           'metadata': {\n                'name': manifest_dict['metadata']['name'],\n                'namespace': manifest_dict['metadata']['namespace'],\n               'resources': {\n                    k: manifest_dict['metadata'][k] for k in manifest_dict['metadata'].keys()\n                },\n           ", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if first_level:\n        schema = manifest_dict\n    else:\n        schema = manifest_dict.copy()\n\n    for k, v in schema.items():\n        if isinstance(v, dict):\n            schema[k] = generate_default_observer_schema_dict(v, first_level=False)\n        elif isinstance(v, list):\n            schema[k] = [generate_default_observer_schema_dict(item, first_level=False) for item in v]\n\n    return schema\n", "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if first_level:\n        return {\n            k: v if not isinstance(v, list) else generate_default_observer_schema_dict(v, True)\n            for k, v in manifest_dict.items()\n        }\n\n    return {\n        k: v if not isinstance(v, dict) else None\n        for k, v in manifest_dict.items()\n    }\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if first_level:\n        return {'metadata': manifest_dict}\n\n    return {'metadata': {k: v for k, v in manifest_dict.items()\n                         if not isinstance(v, dict)}}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    # type: (dict, bool) -> dict\n    \"\"\"\n    Recursively generates part of a default ``observer_schema`` from part of\n    a Kubernetes resource, defined below.\n\n    Args:\n        manifest_dict (dict): Partial Kubernetes resource\n\n    Returns:\n        dict: Generated partial observer_schema\n\n    This function creates a new dictionary from ``manifest_dict`` and replaces\n    all non-list and non-dict values by ``None``. In case of ``first_level``\n    dictionary (i.e. complete ``observer_schema`` for a resource), the\n    values of the identifying fields are copied from the manifest file.\n\n    In case of ``first_level`` dictionary (i.e. complete ``observer_schema``\n    for a resource), the values of the identifying fields are copied from\n    the manifest file.\n    \"\"\"\n    if manifest_dict is None:\n        return manifest_dict\n\n    if isinstance(manifest_dict, dict):\n        if not first_level:\n            return {", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if not first_level:\n        return {manifest_dict.get('metadata', {}).get('namespace', None): manifest_dict}\n    else:\n        return manifest_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    observer_schema = manifest_dict\n    for field in manifest_dict:\n        if isinstance(manifest_dict[field], dict) and not first_level:\n            observer_schema[field] = generate_default_observer_schema_dict(\n                manifest_dict[field], first_level=True\n            )\n        elif not first_level and field in manifest_dict:\n            observer_schema[field] = manifest_dict[field]\n    return observer_schema\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if manifest_dict is None:\n        return None\n\n    manifest_list = manifest_dict.get('manifestList', None)\n    if manifest_list is not None:\n        for manifest in manifest_list:\n            manifest_dict = manifest_dict.copy()\n            manifest_dict['manifestVersion'] = manifest.get('manifestVersion', None)\n\n    if first_level:\n        return {\n            'kind': 'observerSchema',\n           'spec': manifest_dict\n        }\n    else:\n        return manifest_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if manifest_dict is None:\n        return None\n\n    if first_level:\n        manifest_dict = {**manifest_dict, **{\"type\": \"ObserverSchema\"}}\n\n    if \"ObserverSchema\" in manifest_dict:\n        for key, value in manifest_dict[\"ObserverSchema\"].items():\n            if isinstance(value, dict):\n                manifest_dict[key] = generate_default_observer_schema_dict(\n                    value, first_level=first_level\n                )\n\n    return manifest_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if first_level:\n        return {\n           'metadata': {},\n           'spec': {},\n           'status': {}\n        }\n    else:\n        return {\n           'metadata': {\n                'name': manifest_dict.get('name'),\n                'namespace': manifest_dict.get('namespace'),\n                'apiVersion': manifest_dict.get('apiVersion'),\n                'kind': manifest_dict.get('kind'),\n               'selector': manifest_dict.get('selector'),\n                'labels': manifest_dict.get('labels'),\n                'annotations': manifest_dict.get('annotations'),\n                'timeout': manifest_dict.get('timeout')\n            }\n        }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if first_level:\n        return {\n           'metadata': {},\n           'spec': {},\n            'updated_at': None,\n            'updated_by': None,\n            'labels': {},\n            'name': None,\n            'namespace': None,\n           'resources': {},\n           'replicas': {},\n            'type': None,\n        }\n    else:\n        return {\n           'metadata': {\n                'name': manifest_dict['metadata']['name'],\n                'namespace': manifest_dict['metadata']['namespace'],\n               'resources': {\n                    k: manifest_dict['metadata'][k] for k in manifest_dict['metadata'].keys()\n                },\n           ", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if first_level:\n        schema = manifest_dict\n    else:\n        schema = manifest_dict.copy()\n\n    for k, v in schema.items():\n        if isinstance(v, dict):\n            schema[k] = generate_default_observer_schema_dict(v, first_level=False)\n        elif isinstance(v, list):\n            schema[k] = [generate_default_observer_schema_dict(item, first_level=False) for item in v]\n\n    return schema\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema_dict(manifest_dict, first_level=False):\n    if first_level:\n        return {\n            k: v if not isinstance(v, list) else generate_default_observer_schema_dict(v, True)\n            for k, v in manifest_dict.items()\n        }\n\n    return {\n        k: v if not isinstance(v, dict) else None\n        for k, v in manifest_dict.items()\n    }\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/controller/kubernetes/hooks.py", "project": "rak-n-rok/Krake", "name": "update_last_applied_manifest_list_from_resp", "docstring": "Together with :func:``update_last_applied_manifest_dict_from_resp``, this\nfunction is called recursively to update a partial ``last_applied_manifest``\nfrom a partial Kubernetes response\n\nArgs:\n    last_applied_manifest (list): partial ``last_applied_manifest`` being\n        updated\n    observer_schema (list): partial ``observer_schema``\n    response (list): partial response from the Kubernetes API.\n\nThis function go through all observed fields, and initialized their value in\nlast_applied_manifest if they are not yet present", "ques_id": "62b869ebb4d922cb0e688cc6", "code": ["def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively updates a partial ``last_applied_manifest`` from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` response\n        response (list): partial response from the Kubernetes API. This function goes\n            through all observed fields, and initialized their value in last_applied_manifest\n            if they are not yet present\n    \"\"\"\n    for item in response:\n        if isinstance(item, dict) and item.get(\"version\"):\n            item[\"version\"] = int(item[\"version\"])\n        if isinstance(item, list) and isinstance(item[0], dict):\n            item[0] = update_last_applied_manifest_list_from_resp(\n                last_applied_manifest=last_applied_manifest,\n                observer_sche", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema``\n        response (list): partial response from the Kubernetes API. This function goes\n            through all observed fields, and initialized their value in last_applied_manifest\n            if they are not yet present\n    \"\"\"\n    for obs in observer_schema:\n        if obs not in last_applied_manifest:\n            last_applied_manifest.append(obs)\n\n        if obs in response:\n            response[obs] = last_applied_manifest.pop()\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` response\n        response (list): partial response from the Kubernetes API. This function gothrough\n        all observed fields, and initialized their value in last_applied_manifest if they are\n        not yet present\n    \"\"\"\n    for k, v in observer_schema.items():\n        if k not in last_applied_manifest and v!= '':\n            last_applied_manifest[k] = v\n        elif k in response and v!= '':\n            last_applied_manifest[k] = response[k]\n    return last_applied_manifest\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial \n    Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` response\n            from the Kubernetes API.\n        response (list): partial response from the Kubernetes API.\n            This function go through all observed fields, and initialized\n            their value in last_applied_manifest if they are not yet present\n\n    \"\"\"\n    for manifest_field in observer_schema:\n        if manifest_field in last_applied_manifest:\n            setattr(last_applied_manifest[manifest_field], manifest_field, response[manifest_field])\n        else:\n            setattr(last_applied_manifest[manifest_field], manifest_field, None)\n", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema``\n        response (list): partial response from the Kubernetes API\n\n    This function goes through all observed fields, and initialized their value in last_applied_manifest\n    if they are not yet present\n    \"\"\"\n    for obs in observer_schema:\n        if obs[\"name\"] not in last_applied_manifest:\n            last_applied_manifest.append(obs[\"name\"])\n            if \"spec\" in obs:\n                obs[\"spec\"] = update_last_applied_manifest_dict_from_resp(\n                    last_applied_manifest, obs[\"spec\"], response\n                )\n            if \"metadata\" in obs", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial\n    Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being\n        updated observer_schema (list): partial ``observer_schema``\n        response (list): partial response from the Kubernetes API. This function\n        goes through all observed fields, and initialized their value in\n        last_applied_manifest if they are not yet present\n    \"\"\"\n    for manifest in response:\n        if manifest[\"metadata\"][\"name\"] in last_applied_manifest:\n            manifest[\"metadata\"][\"last_applied_manifest\"] = last_applied_manifest[manifest[\"metadata\"][\"name\"]]\n            if \"name\" in manifest and manifest[\"metadata\"][\"name\"]!= manifest[\"name\"]:\n                manifest[\"metadata\"][\"name\"] = manifest[\"metadata\"][\"name\"]\n    ", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial\n    Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being\n            updated\n        observer_schema (list): partial ``observer_schema`` response\n            from the Kubernetes API.\n        response (list): partial response from the Kubernetes API.\n            This function go through all observed fields, and initialized\n            their value in last_applied_manifest if they are not yet\n            present\n    \"\"\"\n    for item in response:\n        if isinstance(item, dict):\n            if 'last_applied_manifest' in item:\n                item['last_applied_manifest'] = update_last_applied_manifest_dict_from_resp(\n                    last_applied_manifest, observer_schema, item\n ", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial \n    Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` response\n            from the Kubernetes API. This function go through all observed\n            fields, and initialized their value in last_applied_manifest if \n            it are not yet present\n        response (list): partial ``response`` from the Kubernetes API.\n            This function go through all observed fields, and initialized\n            their value in last_applied_manifest if it are not yet present\n    \"\"\"\n    for item in response:\n        if item not in last_applied_manifest:\n            last_applied_manifest.append(item)\n            update_last_applied_manifest_dict_from_resp(last", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema``\n        response (list): partial response from the Kubernetes API. This function goes\n            through all observed fields, and initialized their value in last_applied_manifest\n            if they are not yet present\n    \"\"\"\n    for manifest in response:\n        if manifest['metadata']['name'] not in last_applied_manifest:\n            last_applied_manifest.append(manifest['metadata']['name'])\n\n        if manifest['spec']['name'] not in last_applied_manifest:\n            last_applied_manifest.append(manifest['spec']['name'])\n\n        if manifest['status'] not in ['ACTIVE', 'UPDATING']:\n       ", "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial\n    Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being\n            updated\n        observer_schema (list): partial ``observer_schema``\n            response\n        response (list): partial ``response``\n    \"\"\"\n    for manifest in response:\n        if manifest[\"metadata\"][\"name\"] not in last_applied_manifest:\n            last_applied_manifest.append(manifest[\"metadata\"][\"name\"])\n            update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest, observer_schema, manifest\n            )\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively updates a partial ``last_applied_manifest`` from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` response\n        response (list): partial response from the Kubernetes API. This function goes\n            through all observed fields, and initialized their value in last_applied_manifest\n            if they are not yet present\n    \"\"\"\n    for item in response:\n        if isinstance(item, dict) and item.get(\"version\"):\n            item[\"version\"] = int(item[\"version\"])\n        if isinstance(item, list) and isinstance(item[0], dict):\n            item[0] = update_last_applied_manifest_list_from_resp(\n                last_applied_manifest=last_applied_manifest,\n                observer_sche", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema``\n        response (list): partial response from the Kubernetes API. This function goes\n            through all observed fields, and initialized their value in last_applied_manifest\n            if they are not yet present\n    \"\"\"\n    for obs in observer_schema:\n        if obs not in last_applied_manifest:\n            last_applied_manifest.append(obs)\n\n        if obs in response:\n            response[obs] = last_applied_manifest.pop()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` response\n        response (list): partial response from the Kubernetes API. This function gothrough\n        all observed fields, and initialized their value in last_applied_manifest if they are\n        not yet present\n    \"\"\"\n    for k, v in observer_schema.items():\n        if k not in last_applied_manifest and v!= '':\n            last_applied_manifest[k] = v\n        elif k in response and v!= '':\n            last_applied_manifest[k] = response[k]\n    return last_applied_manifest\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial \n    Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` response\n            from the Kubernetes API.\n        response (list): partial response from the Kubernetes API.\n            This function go through all observed fields, and initialized\n            their value in last_applied_manifest if they are not yet present\n\n    \"\"\"\n    for manifest_field in observer_schema:\n        if manifest_field in last_applied_manifest:\n            setattr(last_applied_manifest[manifest_field], manifest_field, response[manifest_field])\n        else:\n            setattr(last_applied_manifest[manifest_field], manifest_field, None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema``\n        response (list): partial response from the Kubernetes API\n\n    This function goes through all observed fields, and initialized their value in last_applied_manifest\n    if they are not yet present\n    \"\"\"\n    for obs in observer_schema:\n        if obs[\"name\"] not in last_applied_manifest:\n            last_applied_manifest.append(obs[\"name\"])\n            if \"spec\" in obs:\n                obs[\"spec\"] = update_last_applied_manifest_dict_from_resp(\n                    last_applied_manifest, obs[\"spec\"], response\n                )\n            if \"metadata\" in obs", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial\n    Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being\n        updated observer_schema (list): partial ``observer_schema``\n        response (list): partial response from the Kubernetes API. This function\n        goes through all observed fields, and initialized their value in\n        last_applied_manifest if they are not yet present\n    \"\"\"\n    for manifest in response:\n        if manifest[\"metadata\"][\"name\"] in last_applied_manifest:\n            manifest[\"metadata\"][\"last_applied_manifest\"] = last_applied_manifest[manifest[\"metadata\"][\"name\"]]\n            if \"name\" in manifest and manifest[\"metadata\"][\"name\"]!= manifest[\"name\"]:\n                manifest[\"metadata\"][\"name\"] = manifest[\"metadata\"][\"name\"]\n    ", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial\n    Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being\n            updated\n        observer_schema (list): partial ``observer_schema`` response\n            from the Kubernetes API.\n        response (list): partial response from the Kubernetes API.\n            This function go through all observed fields, and initialized\n            their value in last_applied_manifest if they are not yet\n            present\n    \"\"\"\n    for item in response:\n        if isinstance(item, dict):\n            if 'last_applied_manifest' in item:\n                item['last_applied_manifest'] = update_last_applied_manifest_dict_from_resp(\n                    last_applied_manifest, observer_schema, item\n ", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial \n    Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema`` response\n            from the Kubernetes API. This function go through all observed\n            fields, and initialized their value in last_applied_manifest if \n            it are not yet present\n        response (list): partial ``response`` from the Kubernetes API.\n            This function go through all observed fields, and initialized\n            their value in last_applied_manifest if it are not yet present\n    \"\"\"\n    for item in response:\n        if item not in last_applied_manifest:\n            last_applied_manifest.append(item)\n            update_last_applied_manifest_dict_from_resp(last", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being updated\n        observer_schema (list): partial ``observer_schema``\n        response (list): partial response from the Kubernetes API. This function goes\n            through all observed fields, and initialized their value in last_applied_manifest\n            if they are not yet present\n    \"\"\"\n    for manifest in response:\n        if manifest['metadata']['name'] not in last_applied_manifest:\n            last_applied_manifest.append(manifest['metadata']['name'])\n\n        if manifest['spec']['name'] not in last_applied_manifest:\n            last_applied_manifest.append(manifest['spec']['name'])\n\n        if manifest['status'] not in ['ACTIVE', 'UPDATING']:\n       ", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_list_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    \"\"\"\n    Recursively update a partial ``last_applied_manifest`` from a partial\n    Kubernetes response\n\n    Args:\n        last_applied_manifest (list): partial ``last_applied_manifest`` being\n            updated\n        observer_schema (list): partial ``observer_schema``\n            response\n        response (list): partial ``response``\n    \"\"\"\n    for manifest in response:\n        if manifest[\"metadata\"][\"name\"] not in last_applied_manifest:\n            last_applied_manifest.append(manifest[\"metadata\"][\"name\"])\n            update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest, observer_schema, manifest\n            )\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/controller/kubernetes/hooks.py", "project": "rak-n-rok/Krake", "name": "update_last_applied_manifest_dict_from_resp", "docstring": "Together with :func:``update_last_applied_manifest_list_from_resp``, this\nfunction is called recursively to update a partial ``last_applied_manifest``\nfrom a partial Kubernetes response\n\nArgs:\n    last_applied_manifest (dict): partial ``last_applied_manifest`` being\n        updated\n    observer_schema (dict): partial ``observer_schema``\n    response (dict): partial response from the Kubernetes API.\n\nRaises:\n    KeyError: If the observed field is not present in the Kubernetes response\n\nThis function go through all observed fields, and initialized their value in\nlast_applied_manifest if they are not yet present", "ques_id": "62b869eab4d922cb0e688cc5", "code": ["def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema:\n        if field in response:\n            if field == \"last_applied_manifest\":\n                last_applied_manifest[field] = response[field]\n            else:\n                setattr(last_applied_manifest, field, response[field])\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for key, value in response.items():\n        if key not in observer_schema:\n            last_applied_manifest[key] = value\n        elif isinstance(value, dict):\n            update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest=last_applied_manifest,\n                observer_schema=observer_schema[key],\n                response=value,\n            )\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for k, v in response.items():\n        if k in last_applied_manifest:\n            last_applied_manifest[k].update(v)\n        else:\n            last_applied_manifest[k] = v\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for manifest_field, observed_field in observer_schema.items():\n        if manifest_field not in response:\n            continue\n        if observed_field not in last_applied_manifest:\n            last_applied_manifest[manifest_field] = response[manifest_field]\n        elif last_applied_manifest[manifest_field]!= response[manifest_field]:\n            raise KeyError(\n                \"K8s manifest field '{}' has conflicting values ({}!= {})\".format(\n                    manifest_field, last_applied_manifest[manifest_field], response[manifest_field]\n                )\n            )\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema[\"fields\"]:\n        if field not in last_applied_manifest:\n            last_applied_manifest[field] = response[field]\n        elif last_applied_manifest[field]!= response[field]:\n            raise KeyError(\n                \"Observed field '{}' should be equal to last_applied_manifest['{}']\".format(\n                    field, field\n                )\n            )\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for key, value in response.items():\n        if key not in observer_schema:\n            last_applied_manifest[key] = value\n        elif isinstance(observer_schema[key], dict):\n            update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest[key], value, observer_schema[key]\n            )\n        else:\n            last_applied_manifest[key] = observer_schema[key]\n    return last_applied_manifest\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema['fields']:\n        if field not in last_applied_manifest:\n            last_applied_manifest[field] = response[field]\n        else:\n            last_applied_manifest[field] = last_applied_manifest[field]\\\n               .update(response[field])\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema:\n        if field not in last_applied_manifest:\n            last_applied_manifest[field] = response[field]\n        elif isinstance(last_applied_manifest[field], list):\n            last_applied_manifest[field].append(response[field])\n        else:\n            last_applied_manifest[field] = response[field]\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema[\"fields\"]:\n        if field not in last_applied_manifest:\n            last_applied_manifest[field] = response[field]\n        else:\n            last_applied_manifest[field] = update_last_applied_manifest_from_resp(\n                last_applied_manifest[field], observer_schema, response\n            )\n    return last_applied_manifest\n", "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema:\n        if field in last_applied_manifest:\n            last_applied_manifest[field] = response[field]\n        elif field not in response:\n            last_applied_manifest[field] = response[field]\n    return last_applied_manifest\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema:\n        if field in response:\n            if field == \"last_applied_manifest\":\n                last_applied_manifest[field] = response[field]\n            else:\n                setattr(last_applied_manifest, field, response[field])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for key, value in response.items():\n        if key not in observer_schema:\n            last_applied_manifest[key] = value\n        elif isinstance(value, dict):\n            update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest=last_applied_manifest,\n                observer_schema=observer_schema[key],\n                response=value,\n            )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for k, v in response.items():\n        if k in last_applied_manifest:\n            last_applied_manifest[k].update(v)\n        else:\n            last_applied_manifest[k] = v\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for manifest_field, observed_field in observer_schema.items():\n        if manifest_field not in response:\n            continue\n        if observed_field not in last_applied_manifest:\n            last_applied_manifest[manifest_field] = response[manifest_field]\n        elif last_applied_manifest[manifest_field]!= response[manifest_field]:\n            raise KeyError(\n                \"K8s manifest field '{}' has conflicting values ({}!= {})\".format(\n                    manifest_field, last_applied_manifest[manifest_field], response[manifest_field]\n                )\n            )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema[\"fields\"]:\n        if field not in last_applied_manifest:\n            last_applied_manifest[field] = response[field]\n        elif last_applied_manifest[field]!= response[field]:\n            raise KeyError(\n                \"Observed field '{}' should be equal to last_applied_manifest['{}']\".format(\n                    field, field\n                )\n            )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for key, value in response.items():\n        if key not in observer_schema:\n            last_applied_manifest[key] = value\n        elif isinstance(observer_schema[key], dict):\n            update_last_applied_manifest_dict_from_resp(\n                last_applied_manifest[key], value, observer_schema[key]\n            )\n        else:\n            last_applied_manifest[key] = observer_schema[key]\n    return last_applied_manifest\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema['fields']:\n        if field not in last_applied_manifest:\n            last_applied_manifest[field] = response[field]\n        else:\n            last_applied_manifest[field] = last_applied_manifest[field]\\\n               .update(response[field])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema:\n        if field not in last_applied_manifest:\n            last_applied_manifest[field] = response[field]\n        elif isinstance(last_applied_manifest[field], list):\n            last_applied_manifest[field].append(response[field])\n        else:\n            last_applied_manifest[field] = response[field]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema[\"fields\"]:\n        if field not in last_applied_manifest:\n            last_applied_manifest[field] = response[field]\n        else:\n            last_applied_manifest[field] = update_last_applied_manifest_from_resp(\n                last_applied_manifest[field], observer_schema, response\n            )\n    return last_applied_manifest\n", "is_pass": false, "return_code": 1}, {"generate_code": "def update_last_applied_manifest_dict_from_resp(\n    last_applied_manifest, observer_schema, response\n):\n    for field in observer_schema:\n        if field in last_applied_manifest:\n            last_applied_manifest[field] = response[field]\n        elif field not in response:\n            last_applied_manifest[field] = response[field]\n    return last_applied_manifest\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/controller/kubernetes/hooks.py", "project": "rak-n-rok/Krake", "name": "generate_default_observer_schema", "docstring": "Generate the default observer schema for each Kubernetes resource present in\n``spec.manifest`` for which a custom observer schema hasn't been specified.\n\nArgs:\n    app (krake.data.kubernetes.Application): The application for which to generate a\n        default observer schema", "ques_id": "62b869eab4d922cb0e688cbf", "code": ["def generate_default_observer_schema(app):\n    for filename in app.spec.manifest.get('templates', []):\n        if not filename.endswith('.yaml'):\n            continue\n        try:\n            yield load_template(filename, app.namespace, app.context)\n        except (yaml.YAMLError, IOError) as exc:\n            app.logger.warning(\n                'Error loading Kubernetes template file %s:\\n%s',\n                filename, exc\n            )\n", "def generate_default_observer_schema(app):\n    if app.config.get('KubernetesResourceObserver'):\n        return app.config['KubernetesResourceObserver']\n\n    for kubernetes_resource in app.resources:\n        if kubernetes_resource.type in KubernetesResource.OBSERVER_TYPES:\n            return kubernetes_resource.type.observer_schema\n", "def generate_default_observer_schema(app):\n    for kubernetes_resource in app.configuration.get('kubernetes_resources', []):\n        if kubernetes_resource.get('custom_observer', False):\n            continue\n\n        yield Schema({\n            Required('name'): kubernetes_resource['name'],\n            Required('type'): kubernetes_resource['type'],\n            Required('apiVersion'): kubernetes_resource['apiVersion'],\n            Optional('observer'): kubernetes_resource.get('observer', {})\n        })\n", "def generate_default_observer_schema(app):\n    spec = app.spec\n    if 'observer' not in spec:\n        return\n\n    observer_schema = {\n        'type': 'object',\n        'properties': {\n            'api_endpoint': {\n                'type':'string',\n                'format': 'uri'\n            },\n            'api_token': {\n                'type':'string',\n                'format': 'uri'\n            },\n            'api_ver': {\n                'type':'string',\n                'format':'version'\n            },\n            'timeout': {\n                'type': 'integer',\n               'minimum': 0,\n               'maximum': 30000,\n                'default': 30000,\n            },\n   ", "def generate_default_observer_schema(app):\n    app.add_component('observer', KubernetesObserverComponent(app))\n", "def generate_default_observer_schema(app):\n    if app.config.observer_schema is None:\n        return None\n    return app.config.observer_schema.schema()\n", "def generate_default_observer_schema(app):\n    if 'observer' not in app.config:\n        return\n    for manifest_filename in app.config['observer']:\n        if manifest_filename.endswith('.yaml'):\n            continue\n        with open(manifest_filename, 'r') as manifest_file:\n            yield load_and_validate_schema(manifest_file, app.name, app.namespace)\n", "def generate_default_observer_schema(app):\n    if app.config.get('Kubernetes'):\n        if app.config.get('Kubernetes.observer_schema'):\n            yield app.config.get('Kubernetes.observer_schema')\n", "def generate_default_observer_schema(app):\n    from. import common\n\n    spec = app.spec\n    apis = spec.get('apis', {})\n    for api in apis.keys():\n        if 'observer' not in apis[api]:\n            spec['apis'][api]['observer'] = {\n                'type': 'custom-observer'\n            }\n\n    app.add_schema(common.KubernetesObserverSchema())\n", "def generate_default_observer_schema(app):\n    custom_schema_filename = app.config.get('Kubernetes', 'custom_schema')\n    if custom_schema_filename is None:\n        return\n\n    with open(custom_schema_filename) as f:\n        custom_schema = json.load(f)\n\n    schema = {\n        'type': 'object',\n        'properties': {\n            k: {\n                'type':'string',\n                'format': 'date-time'\n            }\n            for k in custom_schema.keys()\n        },\n       'required': {\n            'type': 'boolean'\n        },\n        'additionalProperties': {\n            'type': 'object',\n            'properties': {\n                k: {\n                    'type':'string',\n                    'format': 'date-time'\n          "], "level": "file_runnable", "generate_results": [{"generate_code": "def generate_default_observer_schema(app):\n    for filename in app.spec.manifest.get('templates', []):\n        if not filename.endswith('.yaml'):\n            continue\n        try:\n            yield load_template(filename, app.namespace, app.context)\n        except (yaml.YAMLError, IOError) as exc:\n            app.logger.warning(\n                'Error loading Kubernetes template file %s:\\n%s',\n                filename, exc\n            )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    if app.config.get('KubernetesResourceObserver'):\n        return app.config['KubernetesResourceObserver']\n\n    for kubernetes_resource in app.resources:\n        if kubernetes_resource.type in KubernetesResource.OBSERVER_TYPES:\n            return kubernetes_resource.type.observer_schema\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    for kubernetes_resource in app.configuration.get('kubernetes_resources', []):\n        if kubernetes_resource.get('custom_observer', False):\n            continue\n\n        yield Schema({\n            Required('name'): kubernetes_resource['name'],\n            Required('type'): kubernetes_resource['type'],\n            Required('apiVersion'): kubernetes_resource['apiVersion'],\n            Optional('observer'): kubernetes_resource.get('observer', {})\n        })\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    spec = app.spec\n    if 'observer' not in spec:\n        return\n\n    observer_schema = {\n        'type': 'object',\n        'properties': {\n            'api_endpoint': {\n                'type':'string',\n                'format': 'uri'\n            },\n            'api_token': {\n                'type':'string',\n                'format': 'uri'\n            },\n            'api_ver': {\n                'type':'string',\n                'format':'version'\n            },\n            'timeout': {\n                'type': 'integer',\n               'minimum': 0,\n               'maximum': 30000,\n                'default': 30000,\n            },\n   ", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    app.add_component('observer', KubernetesObserverComponent(app))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    if app.config.observer_schema is None:\n        return None\n    return app.config.observer_schema.schema()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    if 'observer' not in app.config:\n        return\n    for manifest_filename in app.config['observer']:\n        if manifest_filename.endswith('.yaml'):\n            continue\n        with open(manifest_filename, 'r') as manifest_file:\n            yield load_and_validate_schema(manifest_file, app.name, app.namespace)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    if app.config.get('Kubernetes'):\n        if app.config.get('Kubernetes.observer_schema'):\n            yield app.config.get('Kubernetes.observer_schema')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    from. import common\n\n    spec = app.spec\n    apis = spec.get('apis', {})\n    for api in apis.keys():\n        if 'observer' not in apis[api]:\n            spec['apis'][api]['observer'] = {\n                'type': 'custom-observer'\n            }\n\n    app.add_schema(common.KubernetesObserverSchema())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def generate_default_observer_schema(app):\n    custom_schema_filename = app.config.get('Kubernetes', 'custom_schema')\n    if custom_schema_filename is None:\n        return\n\n    with open(custom_schema_filename) as f:\n        custom_schema = json.load(f)\n\n    schema = {\n        'type': 'object',\n        'properties': {\n            k: {\n                'type':'string',\n                'format': 'date-time'\n            }\n            for k in custom_schema.keys()\n        },\n       'required': {\n            'type': 'boolean'\n        },\n        'additionalProperties': {\n            'type': 'object',\n            'properties': {\n                k: {\n                    'type':'string',\n                    'format': 'date-time'\n          ", "is_pass": false, "return_code": 1}]}
{"file_path": "sqlparams/__init__.py", "project": "cpburnz/python-sql-parameters", "name": "format", "docstring": "Convert the SQL query to use the out-style parameters instead of\nthe in-style parameters.\n\n*sql* (:class:`str` or :class:`bytes`) is the SQL query.\n\n*params* (:class:`~collections.abc.Mapping` or :class:`~collections.abc.Sequence`)\ncontains the set of in-style parameters. It maps each parameter\n(:class:`str` or :class:`int`) to value. If :attr:`.SQLParams.in_style`\nis a named parameter style. then *params* must be a :class:`~collections.abc.Mapping`.\nIf :attr:`.SQLParams.in_style` is an ordinal parameter style, then\n*params* must be a :class:`~collections.abc.Sequence`.\n\nReturns a :class:`tuple` containing:\n\n-       The formatted SQL query (:class:`str` or :class:`bytes`).\n\n-       The set of converted out-style parameters (:class:`dict` or\n        :class:`list`).", "ques_id": "62b43427903eeb48555d3ea5", "code": ["def format(\n\t\tself,\n\t\tsql: Union[bytes, str],\nparams: Mapping[Union[str, int], Any]\n) -> Tuple[bytes, Sequence[Any]]:\nraise NotImplementedError()\n", "def format(\n\t\tself,\n\t\tsql: Union[str, bytes],\nparams: Mapping[Union[str, int], Union[str, int]]\n) -> Tuple[str, Sequence[Mapping[Union[str, int], Union[str, int]]]]:\nout_style = self.in_style\n\nif out_style is None:\nreturn sql, params\n\nelif out_style == 'ordinal':\nreturn sql, params\n\nelse:\nreturn sql, dict(out_style)\n", "def format(\n\t\tself,\n\t\tsql: Union[str, bytes],\nparams: Mapping[str, int] = None\n) -> Tuple[str, Sequence[Mapping[str, int]]]:\nif self.in_style is None:\nreturn sql, params\nelif self.in_style == 'ordinal':\nreturn sql, {self._params_to_ord(params)}\nelse:\nraise ValueError('Unsupported in-style \"{0}\"'.format(self.in_style))\n", "def format(\n\t\tself,\n\t\tsql: Union[bytes, str],\nparams: Mapping[str, int] = None\n) -> Tuple[bytes, Mapping[str, int]]:\nif self.in_style is None:\nreturn sql, params\n\nif self.in_style == 'ordinal':\nreturn sql, self.__ordinal_params_to_converted_params(params)\n\nreturn sql, self.__params_to_converted_params(params)\n", "def format(\n\t\tself,\n\t\tsql: Union[str, bytes],\nparams: Mapping[str, int] = None\n) -> Tuple[str, Sequence[Mapping[str, int]]]:\nif params is None:\nparams = {}\n\nif self.in_style == 'ordinal':\nif isinstance(sql, bytes):\nparams = {str(ord(x)): None for x in sql}\nelse:\nparams = {str(x): None for x in sql}\n\nreturn sql, params\n\nelif self.in_style =='sql':\nreturn sql, params\n\nelse:\nraise ValueError('in_style must be \"sql\" or \"ordinal\"')\n", "def format(\n\t\tself,\n\t\tsql: Union[bytes, str],\nparams: Mapping[Union[str, int], Union[str, int]]\n) -> Tuple[bytes, Mapping[Union[str, int], Union[str, int]]]:\n# Convert the SQL query to SQL parameters.\nout_params = self._to_params(params)\n\n# Convert the SQL query to a bytes object.\nout_sql = self._to_sql(sql)\n\n# Return the formatted SQL query and the set of converted out-style parameters.\nreturn out_sql, out_params\n", "def format(\n\t\tself,\n\t\tsql: Union[str, bytes],\nparams: Mapping[Union[str, int], Any] = None\n) -> Tuple[str, Sequence[Any]]:\n# NOTE: We really want to do this in a better way, but we don't\n# want to lose any extra formatting of the SQL query to the\n# out-style parameters.\nif isinstance(sql, bytes):\nsql = sql.decode('utf-8')\n\nif params is None:\nparams = {}\n\nif isinstance(params, Mapping):\nparams = params.items()\n\nreturn (\n# SQL query is just the raw string.\n# This is important for out-style parameter formatting, and is\n# required by the in-style parameter formatting anyway.\n# This is because the SQLParams constructor doesn't know about\n# the raw string as it is passed to the params argument.\n# (It is not a SQL query, so it must be passed to the out-style\n# parameter formatting.)\n# Although the SQLParams constructor doesn't know about the\n# raw string, the in-style parameter formatting is also ignored\n# by the out-style parameter formatting.\n#\n'\"{", "def format(\n\t\tself,\n\t\tsql: Union[str, bytes],\nparams: Mapping = None,\n) -> Tuple[str, Mapping[str, int]]:\n# pylint: disable=missing-docstring\nif self.in_style is None:\nraise NotImplementedError(\"no params to be converted into SQL queries yet\")\n\nif params is None:\nif isinstance(sql, bytes):\nparams = {str(i): i for i in range(len(sql))}\nelse:\nparams = sql\n\nif isinstance(self.in_style, OrdinalParams):\nparams = self.in_style.params\n\nreturn sql, params\n", "def format(\n\t\tself,\n\t\tsql: Union[bytes, str],\nparams: Mapping[str, int] = None\n) -> Tuple[bytes, Mapping[str, int]]:\nif params is None:\nparams = {}\n\nif self.in_style == \"ordinal\":\nparams = OrderedDict(params)\n\nreturn sql, params\n", "def format(\n\t\tself,\n\t\tsql: Union[str, bytes],\nparams: Mapping[Union[str, int], Union[str, int]]\n) -> Tuple[str, Mapping[Union[str, int], Union[str, int]]]:\nreturn sql, params\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def format(\n\t\tself,\n\t\tsql: Union[bytes, str],\nparams: Mapping[Union[str, int], Any]\n) -> Tuple[bytes, Sequence[Any]]:\nraise NotImplementedError()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: Union[str, bytes],\nparams: Mapping[Union[str, int], Union[str, int]]\n) -> Tuple[str, Sequence[Mapping[Union[str, int], Union[str, int]]]]:\nout_style = self.in_style\n\nif out_style is None:\nreturn sql, params\n\nelif out_style == 'ordinal':\nreturn sql, params\n\nelse:\nreturn sql, dict(out_style)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: Union[str, bytes],\nparams: Mapping[str, int] = None\n) -> Tuple[str, Sequence[Mapping[str, int]]]:\nif self.in_style is None:\nreturn sql, params\nelif self.in_style == 'ordinal':\nreturn sql, {self._params_to_ord(params)}\nelse:\nraise ValueError('Unsupported in-style \"{0}\"'.format(self.in_style))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: Union[bytes, str],\nparams: Mapping[str, int] = None\n) -> Tuple[bytes, Mapping[str, int]]:\nif self.in_style is None:\nreturn sql, params\n\nif self.in_style == 'ordinal':\nreturn sql, self.__ordinal_params_to_converted_params(params)\n\nreturn sql, self.__params_to_converted_params(params)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: Union[str, bytes],\nparams: Mapping[str, int] = None\n) -> Tuple[str, Sequence[Mapping[str, int]]]:\nif params is None:\nparams = {}\n\nif self.in_style == 'ordinal':\nif isinstance(sql, bytes):\nparams = {str(ord(x)): None for x in sql}\nelse:\nparams = {str(x): None for x in sql}\n\nreturn sql, params\n\nelif self.in_style =='sql':\nreturn sql, params\n\nelse:\nraise ValueError('in_style must be \"sql\" or \"ordinal\"')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: Union[bytes, str],\nparams: Mapping[Union[str, int], Union[str, int]]\n) -> Tuple[bytes, Mapping[Union[str, int], Union[str, int]]]:\n# Convert the SQL query to SQL parameters.\nout_params = self._to_params(params)\n\n# Convert the SQL query to a bytes object.\nout_sql = self._to_sql(sql)\n\n# Return the formatted SQL query and the set of converted out-style parameters.\nreturn out_sql, out_params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: Union[str, bytes],\nparams: Mapping[Union[str, int], Any] = None\n) -> Tuple[str, Sequence[Any]]:\n# NOTE: We really want to do this in a better way, but we don't\n# want to lose any extra formatting of the SQL query to the\n# out-style parameters.\nif isinstance(sql, bytes):\nsql = sql.decode('utf-8')\n\nif params is None:\nparams = {}\n\nif isinstance(params, Mapping):\nparams = params.items()\n\nreturn (\n# SQL query is just the raw string.\n# This is important for out-style parameter formatting, and is\n# required by the in-style parameter formatting anyway.\n# This is because the SQLParams constructor doesn't know about\n# the raw string as it is passed to the params argument.\n# (It is not a SQL query, so it must be passed to the out-style\n# parameter formatting.)\n# Although the SQLParams constructor doesn't know about the\n# raw string, the in-style parameter formatting is also ignored\n# by the out-style parameter formatting.\n#\n'\"{", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: Union[str, bytes],\nparams: Mapping = None,\n) -> Tuple[str, Mapping[str, int]]:\n# pylint: disable=missing-docstring\nif self.in_style is None:\nraise NotImplementedError(\"no params to be converted into SQL queries yet\")\n\nif params is None:\nif isinstance(sql, bytes):\nparams = {str(i): i for i in range(len(sql))}\nelse:\nparams = sql\n\nif isinstance(self.in_style, OrdinalParams):\nparams = self.in_style.params\n\nreturn sql, params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: Union[bytes, str],\nparams: Mapping[str, int] = None\n) -> Tuple[bytes, Mapping[str, int]]:\nif params is None:\nparams = {}\n\nif self.in_style == \"ordinal\":\nparams = OrderedDict(params)\n\nreturn sql, params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format(\n\t\tself,\n\t\tsql: Union[str, bytes],\nparams: Mapping[Union[str, int], Union[str, int]]\n) -> Tuple[str, Mapping[Union[str, int], Union[str, int]]]:\nreturn sql, params\n", "is_pass": false, "return_code": 1}]}
{"file_path": "sqlparams/__init__.py", "project": "cpburnz/python-sql-parameters", "name": "formatmany", "docstring": "Convert the SQL query to use the out-style parameters instead of the\nin-style parameters.\n\n*sql* (:class:`str` or :class:`bytes`) is the SQL query.\n\n*many_params* (:class:`~collections.abc.Iterable`) contains each set\nof in-style parameters (*params*).\n\n-       *params* (:class:`~collections.abc.Mapping` or :class:`~collections.abc.Sequence`)\n        contains the set of in-style parameters. It maps each parameter\n        (:class:`str` or :class:`int`) to value. If :attr:`.SQLParams.in_style`\n        is a named parameter style. then *params* must be a :class:`~collections.abc.Mapping`.\n        If :attr:`.SQLParams.in_style` is an ordinal parameter style. then\n        *params* must be a :class:`~collections.abc.Sequence`.\n\nReturns a :class:`tuple` containing:\n\n-       The formatted SQL query (:class:`str` or :class:`bytes`).\n\n-       A :class:`list` containing each set of converted out-style\n        parameters (:class:`dict` or :class:`list`).", "ques_id": "62b43428903eeb48555d3eaa", "code": ["def formatmany(\n\t\tself,\n\t\tsql: bytes,\nmany_params: Iterable[bytes],\nparams: Mapping[bytes, int] = None\n) -> Tuple[bytes, List[Mapping[bytes, int]]]:\n\"\"\"\nConvert the SQL query to use the out-style parameters instead of the\nin-style parameters.\n\n*sql* (:class:`str` or :class:`bytes`) is the SQL query.\n\n*many_params* (:class:`~collections.abc.Iterable`) contains each\nSet of in-style parameters (*params*).  - *params* (:class:`~collections.abc.Mapping` or\n:class:`~collections.abc.Sequence`) contains the set of in-style parameters.\nIt maps each parameter (:class:`str` or :class:`int`) to value.\n\nif :attr:`.SQLParams.in_style` is a named parameter style.\nthen *params* must be a\n:class:`~collections.abc.Mapping`. If :attr:`.SQLParams.in_style` is\nordinal parameter style.then *params* must be a\n:class:`~collections.abc.Sequence`.\n\nReturns a :class:`tuple` containing:\n\n- The formatted SQL query (:class:`str` or :class:`bytes`).\n- A :class:`list` containin", "def formatmany(\n\t\tself,\n\t\tsql: Union[str, bytes],\nmany_params: Iterable[Union[str, int]] = (),\nparams: Mapping[Union[str, int], Union[str, int]] = ()\n) -> Tuple[str, list]:\nout = []\nfor p in many_params:\nout.append(self._format(sql, p, params))\nreturn sql, out\n", "def formatmany(\n\t\tself,\n\t\tsql: Union[str, bytes],\nmany_params: Iterable[Union[str, int]] = None,\nparams: Mapping[Union[str, int], Any] = None\n) -> Tuple[str, list]:\nreturn self._format(sql, many_params, params)\n", "def formatmany(\n\t\tself,\n\t\tsql: Union[bytes, str],\nmany_params: Mapping[str, int],\nparams: Mapping[str, Union[int, Mapping[str, int]]]\n) -> Tuple[bytes, List[Mapping[str, int]]]:\nif self.in_style == 'ordinal':\nreturn sql, [params]\n\nif self.in_style == 'named':\nreturn sql, [dict(p, **params) for p in params]\n\nreturn sql, params\n", "def formatmany(\n\t\tself,\n\t\tsql: Union[str, bytes],\nmany_params: Iterable[Union[str, int]],\nparams: Mapping[Union[str, int], Any]\n) -> Tuple[bytes, list]:\nreturn self._format(sql, many_params, params)\n", "def formatmany(\n\t\tself,\n\t\tsql: Union[bytes, str],\nmany_params: Mapping[str, int] = None,\nparams: Mapping[str, int] = None\n) -> Tuple[bytes, List[dict]]:\nif many_params is None:\nmany_params = {}\n\nif params is None:\nparams = many_params\n\nparam_lst = []\nfor param in params:\nparam_lst.append(self.formatparam(param, many_params))\n\nif not many_params:\nreturn sql, param_lst\n\nreturn sql.format(*param_lst), param_lst\n", "def formatmany(\n\t\tself,\n\t\tsql: Union[bytes, str, Iterable[Any]],\nmany_params: Mapping[Any, Any] = None,\nparams: Mapping[Any, Any] = None\n) -> Tuple[bytes, list]:\nif self.in_style == 'ordinal':\nreturn self._formatmany_ordinal(sql, many_params, params)\nelse:\nreturn self._formatmany_params(sql, many_params, params)\n", "def formatmany(\n\t\tself,\n\t\tsql: bytes,\nmany_params: Iterable[bytes] = None,\nparams: Mapping[str, int] = None\n) -> Tuple[bytes, list]:\nif self.in_style:\nif isinstance(self.in_style, SQLParams.ordinal_params):\nreturn (sql, [params])\nelse:\nraise TypeError('SQLParams.in_style has no named parameter style')\nelif self.out_style:\nraise TypeError('SQLParams.out_style has no named parameter style')\nelse:\nraise TypeError('Must specify out_style parameter')\n\nreturn sql, []\n", "def formatmany(\n\t\tself,\n\t\tsql: Union[str, bytes],\nmany_params: Iterable[Union[str, int]] = (),\nparams: Mapping[Union[str, int], Any] = ()\n) -> Tuple[str, list]:\nraise NotImplementedError()\n", "def formatmany(\n\t\tself,\n\t\tsql: Union[bytes, str],\nmany_params: Iterable[Union[str, int]] = (),\nparams: Mapping[Union[str, int], Any] = ()\n) -> Tuple[bytes, List[Dict[str, Any]]]:\nout_params = self._select_many(sql, many_params)\nout_sql = []\nfor param in out_params:\nout_sql.append(self._format(param))\n\nreturn (sql, out_params)\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: bytes,\nmany_params: Iterable[bytes],\nparams: Mapping[bytes, int] = None\n) -> Tuple[bytes, List[Mapping[bytes, int]]]:\n\"\"\"\nConvert the SQL query to use the out-style parameters instead of the\nin-style parameters.\n\n*sql* (:class:`str` or :class:`bytes`) is the SQL query.\n\n*many_params* (:class:`~collections.abc.Iterable`) contains each\nSet of in-style parameters (*params*).  - *params* (:class:`~collections.abc.Mapping` or\n:class:`~collections.abc.Sequence`) contains the set of in-style parameters.\nIt maps each parameter (:class:`str` or :class:`int`) to value.\n\nif :attr:`.SQLParams.in_style` is a named parameter style.\nthen *params* must be a\n:class:`~collections.abc.Mapping`. If :attr:`.SQLParams.in_style` is\nordinal parameter style.then *params* must be a\n:class:`~collections.abc.Sequence`.\n\nReturns a :class:`tuple` containing:\n\n- The formatted SQL query (:class:`str` or :class:`bytes`).\n- A :class:`list` containin", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: Union[str, bytes],\nmany_params: Iterable[Union[str, int]] = (),\nparams: Mapping[Union[str, int], Union[str, int]] = ()\n) -> Tuple[str, list]:\nout = []\nfor p in many_params:\nout.append(self._format(sql, p, params))\nreturn sql, out\n", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: Union[str, bytes],\nmany_params: Iterable[Union[str, int]] = None,\nparams: Mapping[Union[str, int], Any] = None\n) -> Tuple[str, list]:\nreturn self._format(sql, many_params, params)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: Union[bytes, str],\nmany_params: Mapping[str, int],\nparams: Mapping[str, Union[int, Mapping[str, int]]]\n) -> Tuple[bytes, List[Mapping[str, int]]]:\nif self.in_style == 'ordinal':\nreturn sql, [params]\n\nif self.in_style == 'named':\nreturn sql, [dict(p, **params) for p in params]\n\nreturn sql, params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: Union[str, bytes],\nmany_params: Iterable[Union[str, int]],\nparams: Mapping[Union[str, int], Any]\n) -> Tuple[bytes, list]:\nreturn self._format(sql, many_params, params)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: Union[bytes, str],\nmany_params: Mapping[str, int] = None,\nparams: Mapping[str, int] = None\n) -> Tuple[bytes, List[dict]]:\nif many_params is None:\nmany_params = {}\n\nif params is None:\nparams = many_params\n\nparam_lst = []\nfor param in params:\nparam_lst.append(self.formatparam(param, many_params))\n\nif not many_params:\nreturn sql, param_lst\n\nreturn sql.format(*param_lst), param_lst\n", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: Union[bytes, str, Iterable[Any]],\nmany_params: Mapping[Any, Any] = None,\nparams: Mapping[Any, Any] = None\n) -> Tuple[bytes, list]:\nif self.in_style == 'ordinal':\nreturn self._formatmany_ordinal(sql, many_params, params)\nelse:\nreturn self._formatmany_params(sql, many_params, params)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: bytes,\nmany_params: Iterable[bytes] = None,\nparams: Mapping[str, int] = None\n) -> Tuple[bytes, list]:\nif self.in_style:\nif isinstance(self.in_style, SQLParams.ordinal_params):\nreturn (sql, [params])\nelse:\nraise TypeError('SQLParams.in_style has no named parameter style')\nelif self.out_style:\nraise TypeError('SQLParams.out_style has no named parameter style')\nelse:\nraise TypeError('Must specify out_style parameter')\n\nreturn sql, []\n", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: Union[str, bytes],\nmany_params: Iterable[Union[str, int]] = (),\nparams: Mapping[Union[str, int], Any] = ()\n) -> Tuple[str, list]:\nraise NotImplementedError()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def formatmany(\n\t\tself,\n\t\tsql: Union[bytes, str],\nmany_params: Iterable[Union[str, int]] = (),\nparams: Mapping[Union[str, int], Any] = ()\n) -> Tuple[bytes, List[Dict[str, Any]]]:\nout_params = self._select_many(sql, many_params)\nout_sql = []\nfor param in out_params:\nout_sql.append(self._format(param))\n\nreturn (sql, out_params)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/validator.py", "project": "zimeon/ocfl-py", "name": "validate", "docstring": "Validate OCFL object at path or pyfs root.\n\nReturns True if valid (warnings permitted), False otherwise.", "ques_id": "62b45df05108cfac7f2109ce", "code": ["def validate(self, path):\n    return False\n", "def validate(self, path):\n    try:\n        return super(OCFL, self).validate(path)\n    except (OSError, ValueError):\n        return False\n", "def validate(self, path):\n    return True\n", "def validate(self, path):\n    return False\n", "def validate(self, path):\n    return True\n", "def validate(self, path):\n    return True\n", "def validate(self, path):\n    return True\n", "def validate(self, path):\n    if not isfile(path):\n        return False\n    return True\n", "def validate(self, path):\n    return True\n", "def validate(self, path):\n    return True\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate(self, path):\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    try:\n        return super(OCFL, self).validate(path)\n    except (OSError, ValueError):\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    if not isfile(path):\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, path):\n    return True\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/validation_logger.py", "project": "zimeon/ocfl-py", "name": "status_str", "docstring": "Return string of validator status, with optional prefix.", "ques_id": "62b45df15108cfac7f2109dc", "code": ["def status_str(self, prefix=''):\n    return 'Validator status: {}'.format('on' if self.is_valid else 'off')\n", "def status_str(self, prefix=''):\n    s = ''\n    if self.status == 'valid':\n        s += prefix + 'Passed validation checks. '\n    elif self.status == 'invalid':\n        s += prefix + 'Failed validation checks. '\n    elif self.status == 'unknown':\n        s += prefix + 'Skipped validation checks. '\n    return s\n", "def status_str(self, prefix=''):\n    s = ''\n    if self.valid:\n        s += '(valid)'\n    else:\n        s += '(invalid)'\n    if self.__prefix:\n        s = prefix +'' + s\n    return s\n", "def status_str(self, prefix=''):\n    return 'validator {} is not ready for use'.format(self._validator)\n", "def status_str(self, prefix=''):\n    return 'validator'+ prefix + str(self)\n", "def status_str(self, prefix=''):\n    return ', '.join(\n        i.status_str(prefix=prefix + '. ') for i in self.validators)\n", "def status_str(self, prefix=''):\n    return 'validator {} status: {}'.format(prefix, self.status)\n", "def status_str(self, prefix=''):\n    if self._validator is None:\n        return ''\n    else:\n        return 'validator {} '.format(self._validator.status_str(prefix))\n", "def status_str(self, prefix=''):\n    return ', '.join([s.status_str(prefix=prefix) for s in self.validators])\n", "def status_str(self, prefix=''):\n    return ', '.join([s.status_str(prefix=prefix) for s in self.validators])\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def status_str(self, prefix=''):\n    return 'Validator status: {}'.format('on' if self.is_valid else 'off')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    s = ''\n    if self.status == 'valid':\n        s += prefix + 'Passed validation checks. '\n    elif self.status == 'invalid':\n        s += prefix + 'Failed validation checks. '\n    elif self.status == 'unknown':\n        s += prefix + 'Skipped validation checks. '\n    return s\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    s = ''\n    if self.valid:\n        s += '(valid)'\n    else:\n        s += '(invalid)'\n    if self.__prefix:\n        s = prefix +'' + s\n    return s\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return 'validator {} is not ready for use'.format(self._validator)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return 'validator'+ prefix + str(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return ', '.join(\n        i.status_str(prefix=prefix + '. ') for i in self.validators)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return 'validator {} status: {}'.format(prefix, self.status)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    if self._validator is None:\n        return ''\n    else:\n        return 'validator {} '.format(self._validator.status_str(prefix))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return ', '.join([s.status_str(prefix=prefix) for s in self.validators])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return ', '.join([s.status_str(prefix=prefix) for s in self.validators])\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/validator.py", "project": "zimeon/ocfl-py", "name": "status_str", "docstring": "Return string representation of validation log, with optional prefix.", "ques_id": "62b45df15108cfac7f2109dd", "code": ["def status_str(self, prefix=''):\n    s = ''\n    for i, (k, v) in enumerate(self.results):\n        s += '{}: {} ({})\\n'.format(prefix + k, v, self.status_map[k])\n    return s\n", "def status_str(self, prefix=''):\n    return''.join([str(v) for v in self._validations])\n", "def status_str(self, prefix=''):\n    return ''.join([prefix, 'Validation log:\\n', '-' * 70])\n", "def status_str(self, prefix=''):\n    s = ''\n    for line in self.output:\n        s += line + '\\n'\n    return prefix + s\n", "def status_str(self, prefix=''):\n    l = []\n    for s in self.validation_log:\n        l.append('%s%s' % (prefix, str(s)))\n    return ', '.join(l)\n", "def status_str(self, prefix=''):\n    result = []\n    for entry in self:\n        result.append('{}{}'.format(prefix, entry.status))\n    return ', '.join(result)\n", "def status_str(self, prefix=''):\n    s = 'Validation log for \"{}\"'.format(self.__class__.__name__)\n    if prefix:\n        s = '{} {}'.format(prefix, s)\n    return s\n", "def status_str(self, prefix=''):\n    s = ''\n    for i, l in enumerate(self._val_log):\n        if i > 0:\n            s += '\\n'\n        s += l\n    return prefix + s\n", "def status_str(self, prefix=''):\n    return '\\n'.join(str(e) for e in self) + '\\n' + prefix\n", "def status_str(self, prefix=''):\n    return ''.join([prefix, 'Validation log:\\n', '-' * 60])\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def status_str(self, prefix=''):\n    s = ''\n    for i, (k, v) in enumerate(self.results):\n        s += '{}: {} ({})\\n'.format(prefix + k, v, self.status_map[k])\n    return s\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return''.join([str(v) for v in self._validations])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return ''.join([prefix, 'Validation log:\\n', '-' * 70])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    s = ''\n    for line in self.output:\n        s += line + '\\n'\n    return prefix + s\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    l = []\n    for s in self.validation_log:\n        l.append('%s%s' % (prefix, str(s)))\n    return ', '.join(l)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    result = []\n    for entry in self:\n        result.append('{}{}'.format(prefix, entry.status))\n    return ', '.join(result)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    s = 'Validation log for \"{}\"'.format(self.__class__.__name__)\n    if prefix:\n        s = '{} {}'.format(prefix, s)\n    return s\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    s = ''\n    for i, l in enumerate(self._val_log):\n        if i > 0:\n            s += '\\n'\n        s += l\n    return prefix + s\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return '\\n'.join(str(e) for e in self) + '\\n' + prefix\n", "is_pass": false, "return_code": 1}, {"generate_code": "def status_str(self, prefix=''):\n    return ''.join([prefix, 'Validation log:\\n', '-' * 60])\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/dispositor.py", "project": "zimeon/ocfl-py", "name": "is_valid", "docstring": "Return True if identifier is valid, always True in this base implementation.", "ques_id": "62b45e135108cfac7f2109f4", "code": ["def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n", "def is_valid(self, identifier):\n    return True\n"], "level": "self_contained", "generate_results": [{"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_valid(self, identifier):\n    return True\n", "is_pass": true, "return_code": 0}]}
{"file_path": "ocfl/inventory_validator.py", "project": "zimeon/ocfl-py", "name": "validate", "docstring": "Validate a given inventory.\n\nIf extract_spec_version is True then will look at the type value to determine\nthe specification version. In the case that there is no type value or it isn't\nvalid, then other tests will be based on the version given in self.spec_version.", "ques_id": "62b45e145108cfac7f210a07", "code": ["def validate(self, inventory, extract_spec_version=False):\n    return super(InventoryModule, self).validate(inventory,\n                                                 extract_spec_version=extract_spec_version)\n", "def validate(self, inventory, extract_spec_version=False):\n    try:\n        inventory_type = inventory.get('type', None)\n        validate_inventory_type(inventory_type)\n    except AttributeError:\n        pass\n\n    if extract_spec_version:\n        try:\n            validate_inventory_version(self.spec_version)\n        except AttributeError:\n            pass\n\n    try:\n        validate_keys(inventory)\n    except AttributeError:\n        pass\n", "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        try:\n            return inventory.extract_specific_version()\n        except Exception:\n            pass\n    try:\n        return inventory.validate()\n    except AnsibleInventoryException as e:\n        raise AnsibleInventoryException(str(e))\n", "def validate(self, inventory, extract_spec_version=False):\n    inventory = super(InventoryModule, self).validate(inventory, extract_spec_version=extract_spec_version)\n\n    if not inventory.get('ansible_ssh_host'):\n        raise AnsibleInventoryError('A valid inventory does not contain an ansible_ssh_host field.')\n\n    return inventory\n", "def validate(self, inventory, extract_spec_version=False):\n    # TODO: should be able to validate a list of hosts without spec_version\n    # TODO: does not validate all nodes in the inventory\n    pass\n", "def validate(self, inventory, extract_spec_version=False):\n    inventory = super(InventoryModule, self).validate(inventory, extract_spec_version=extract_spec_version)\n\n    if 'type' in inventory:\n        type_value = inventory['type']\n        if type_value in self.spec_version:\n            return inventory\n\n    return inventory\n", "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        try:\n            return inventory.extract_specific_version()\n        except AttributeError:\n            return inventory.extract_version()\n    else:\n        try:\n            return inventory.extract_version()\n        except AttributeError:\n            return inventory.extract_type()\n", "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        try:\n            return inventory['_meta']['version']\n        except KeyError:\n            return inventory['_meta']['version'] or '0.0.0'\n    else:\n        return inventory['_meta']['version'] or '0.0.0'\n", "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        try:\n            return inventory['_meta']['version']\n        except KeyError:\n            return None\n    else:\n        try:\n            return inventory['version']\n        except KeyError:\n            return None\n", "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        try:\n            return inventory['type']['value']\n        except KeyError:\n            return inventory['version']\n    else:\n        return inventory\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    return super(InventoryModule, self).validate(inventory,\n                                                 extract_spec_version=extract_spec_version)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    try:\n        inventory_type = inventory.get('type', None)\n        validate_inventory_type(inventory_type)\n    except AttributeError:\n        pass\n\n    if extract_spec_version:\n        try:\n            validate_inventory_version(self.spec_version)\n        except AttributeError:\n            pass\n\n    try:\n        validate_keys(inventory)\n    except AttributeError:\n        pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        try:\n            return inventory.extract_specific_version()\n        except Exception:\n            pass\n    try:\n        return inventory.validate()\n    except AnsibleInventoryException as e:\n        raise AnsibleInventoryException(str(e))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    inventory = super(InventoryModule, self).validate(inventory, extract_spec_version=extract_spec_version)\n\n    if not inventory.get('ansible_ssh_host'):\n        raise AnsibleInventoryError('A valid inventory does not contain an ansible_ssh_host field.')\n\n    return inventory\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    # TODO: should be able to validate a list of hosts without spec_version\n    # TODO: does not validate all nodes in the inventory\n    pass\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    inventory = super(InventoryModule, self).validate(inventory, extract_spec_version=extract_spec_version)\n\n    if 'type' in inventory:\n        type_value = inventory['type']\n        if type_value in self.spec_version:\n            return inventory\n\n    return inventory\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        try:\n            return inventory.extract_specific_version()\n        except AttributeError:\n            return inventory.extract_version()\n    else:\n        try:\n            return inventory.extract_version()\n        except AttributeError:\n            return inventory.extract_type()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        try:\n            return inventory['_meta']['version']\n        except KeyError:\n            return inventory['_meta']['version'] or '0.0.0'\n    else:\n        return inventory['_meta']['version'] or '0.0.0'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        try:\n            return inventory['_meta']['version']\n        except KeyError:\n            return None\n    else:\n        try:\n            return inventory['version']\n        except KeyError:\n            return None\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate(self, inventory, extract_spec_version=False):\n    if extract_spec_version:\n        try:\n            return inventory['type']['value']\n        except KeyError:\n            return inventory['version']\n    else:\n        return inventory\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/inventory_validator.py", "project": "zimeon/ocfl-py", "name": "check_digests_present_and_used", "docstring": "Check all digests in manifest that are needed are present and used.", "ques_id": "62b45e145108cfac7f210a09", "code": ["def check_digests_present_and_used(self, manifest_files, digests_used):\n    for filename in manifest_files:\n        with open(filename, \"rb\") as f:\n            manifest = f.read()\n        digests = parse_digests(manifest)\n        for digest in digests:\n            if digest not in digests_used:\n                raise ManifestInvalidDigest(\"Manifest file {} contained invalid digest {}\".format(\n                    filename, digest))\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for manifest_file in manifest_files:\n        manifest = Manifest.load(manifest_file)\n        for digest in manifest.digests:\n            if digest not in digests_used:\n                raise ManifestParseError(\n                    \"Manifest does not contain a digest '{}'\".format(digest)\n                )\n            digests_used.remove(digest)\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for manifest in manifest_files:\n        for digest in manifest.get(\"digests\", []):\n            if digest not in digests_used:\n                print(\"Digest {} is needed but is not used in manifest file {}\".format(digest, manifest[\"filename\"]))\n                return False\n    return True\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in manifest_files:\n        if digest in digests_used:\n            continue\n        else:\n            raise errors.DigestNotFound(\n                \"Digest {} not found in manifest files\".format(digest)\n            )\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in manifest_files:\n        if digest in digests_used:\n            continue\n        else:\n            raise CheckFailed(\"Digest '%s' not found in manifest files\" % digest)\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for filename in manifest_files:\n        with open(filename) as manifest_file:\n            manifest = json.load(manifest_file)\n            digest_count = 0\n            for digest in manifest['digests']:\n                if digest['file_hash'] not in digests_used:\n                    digest_count += 1\n                    print('Digest {} not present and used.'.format(digest['file_hash']))\n                    digests_used.add(digest['file_hash'])\n            if digest_count > 0:\n                print('Digests not found in manifest and used. '\n                      'Digests used: {}.'.format(digest_count))\n            else:\n                print('Digests not found in manifest and used.')\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in digests_used:\n        if digest not in manifest_files:\n            raise ManifestInvalidException(\n                \"Manifest contains a file with a bad digest: %s\" % digest)\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for manifest_file in manifest_files:\n        digest = manifest_file.get(\"digest\")\n        if digest:\n            file_digest = digests_used.get(digest, None)\n            if file_digest:\n                digests_used[digest] = file_digest\n                check_digest_present(manifest_file, digest)\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in digests_used:\n        if digest not in manifest_files:\n            raise ManifestParseError(\n                \"Manifest file {} contains a digest {} that doesn't \"\n                \"exist in the manifest.\".format(\n                    digest, manifest_files[digest].hexdigest()))\n", "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for manifest_file in manifest_files:\n        for digest in manifest_file.get('digests', []):\n            if digest not in digests_used:\n                raise exceptions.ManifestInvalidDigestError(\n                    manifest_file.get('filename'),\n                    digest\n                )\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for filename in manifest_files:\n        with open(filename, \"rb\") as f:\n            manifest = f.read()\n        digests = parse_digests(manifest)\n        for digest in digests:\n            if digest not in digests_used:\n                raise ManifestInvalidDigest(\"Manifest file {} contained invalid digest {}\".format(\n                    filename, digest))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for manifest_file in manifest_files:\n        manifest = Manifest.load(manifest_file)\n        for digest in manifest.digests:\n            if digest not in digests_used:\n                raise ManifestParseError(\n                    \"Manifest does not contain a digest '{}'\".format(digest)\n                )\n            digests_used.remove(digest)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for manifest in manifest_files:\n        for digest in manifest.get(\"digests\", []):\n            if digest not in digests_used:\n                print(\"Digest {} is needed but is not used in manifest file {}\".format(digest, manifest[\"filename\"]))\n                return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in manifest_files:\n        if digest in digests_used:\n            continue\n        else:\n            raise errors.DigestNotFound(\n                \"Digest {} not found in manifest files\".format(digest)\n            )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in manifest_files:\n        if digest in digests_used:\n            continue\n        else:\n            raise CheckFailed(\"Digest '%s' not found in manifest files\" % digest)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for filename in manifest_files:\n        with open(filename) as manifest_file:\n            manifest = json.load(manifest_file)\n            digest_count = 0\n            for digest in manifest['digests']:\n                if digest['file_hash'] not in digests_used:\n                    digest_count += 1\n                    print('Digest {} not present and used.'.format(digest['file_hash']))\n                    digests_used.add(digest['file_hash'])\n            if digest_count > 0:\n                print('Digests not found in manifest and used. '\n                      'Digests used: {}.'.format(digest_count))\n            else:\n                print('Digests not found in manifest and used.')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in digests_used:\n        if digest not in manifest_files:\n            raise ManifestInvalidException(\n                \"Manifest contains a file with a bad digest: %s\" % digest)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for manifest_file in manifest_files:\n        digest = manifest_file.get(\"digest\")\n        if digest:\n            file_digest = digests_used.get(digest, None)\n            if file_digest:\n                digests_used[digest] = file_digest\n                check_digest_present(manifest_file, digest)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for digest in digests_used:\n        if digest not in manifest_files:\n            raise ManifestParseError(\n                \"Manifest file {} contains a digest {} that doesn't \"\n                \"exist in the manifest.\".format(\n                    digest, manifest_files[digest].hexdigest()))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_digests_present_and_used(self, manifest_files, digests_used):\n    for manifest_file in manifest_files:\n        for digest in manifest_file.get('digests', []):\n            if digest not in digests_used:\n                raise exceptions.ManifestInvalidDigestError(\n                    manifest_file.get('filename'),\n                    digest\n                )\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/inventory_validator.py", "project": "zimeon/ocfl-py", "name": "validate_as_prior_version", "docstring": "Check that prior is a valid prior version of the current inventory object.\n\nThe input variable prior is also expected to be an InventoryValidator object\nand both self and prior inventories are assumed to have been checked for\ninternal consistency.", "ques_id": "62b45e165108cfac7f210a16", "code": ["def validate_as_prior_version(self, prior):\n    pass\n", "def validate_as_prior_version(self, prior):\n    return True\n", "def validate_as_prior_version(self, prior):\n\n    pass\n", "def validate_as_prior_version(self, prior):\n    pass\n", "def validate_as_prior_version(self, prior):\n    pass\n", "def validate_as_prior_version(self, prior):\n\n    pass\n", "def validate_as_prior_version(self, prior):\n    pass\n", "def validate_as_prior_version(self, prior):\n    pass\n", "def validate_as_prior_version(self, prior):\n    pass\n", "def validate_as_prior_version(self, prior):\n    if prior is None:\n        raise ValueError(\"prior cannot be None\")\n\n    if not isinstance(prior, InventoryValidator):\n        raise ValueError(\"prior must be an instance of InventoryValidator\")\n\n    if prior.inventory!= self:\n        raise ValueError(\n            \"prior inventory does not match the inventory this object is in (%s)\"\n            % prior.inventory.name\n        )\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def validate_as_prior_version(self, prior):\n    pass\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_as_prior_version(self, prior):\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_as_prior_version(self, prior):\n\n    pass\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_as_prior_version(self, prior):\n    pass\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_as_prior_version(self, prior):\n    pass\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_as_prior_version(self, prior):\n\n    pass\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_as_prior_version(self, prior):\n    pass\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_as_prior_version(self, prior):\n    pass\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_as_prior_version(self, prior):\n    pass\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_as_prior_version(self, prior):\n    if prior is None:\n        raise ValueError(\"prior cannot be None\")\n\n    if not isinstance(prior, InventoryValidator):\n        raise ValueError(\"prior must be an instance of InventoryValidator\")\n\n    if prior.inventory!= self:\n        raise ValueError(\n            \"prior inventory does not match the inventory this object is in (%s)\"\n            % prior.inventory.name\n        )\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/inventory_validator.py", "project": "zimeon/ocfl-py", "name": "get_logical_path_map", "docstring": "Get a map of logical paths in state to files on disk for version in inventory.\n\nReturns a dictionary: logical_path_in_state -> set(content_files)\n\nThe set of content_files may includes references to duplicate files in\nlater versions than the version being described.", "ques_id": "62b45e165108cfac7f210a17", "code": ["def get_logical_path_map(inventory, version):\n    result = {}\n    for key in inventory:\n        if isinstance(inventory[key], dict):\n            if version in inventory[key]:\n                result[key] = inventory[key]\n        else:\n            if inventory[key].is_duplicate:\n                result[key] = inventory[key]\n\n    return result\n", "def get_logical_path_map(inventory, version):\n    inventory_dir = inventory.get_inventory_directory(version)\n    return {\n        os.path.join(inventory_dir, f): set(content_files)\n        for f, content_files in inventory.get_file_map(version).items()\n    }\n", "def get_logical_path_map(inventory, version):\n    # TODO: use a custom storage backend instead\n    content_files = inventory.get_content_files(version)\n    return {\n        '/'.join(content_file.path.split('/')[1:-1]): set(content_files)\n    }\n", "def get_logical_path_map(inventory, version):\n    if version.content is None:\n        return {}\n\n    # A version with no content can have logical paths in it.\n    if version.content.paths is None:\n        return {}\n\n    return {\n        path\n        for path in inventory.get_file_paths_for_version(version)\n        if path in version.content.paths\n    }\n", "def get_logical_path_map(inventory, version):\n    content_files = inventory.get_content_files_for_version(version)\n\n    return {\n        content_file.logical_path: content_files\n        for content_file in content_files\n    }\n", "def get_logical_path_map(inventory, version):\n    content_files = inventory.get_content_files(version.content_version)\n    return {\n        content_file.logical_path: content_files\n        for content_file in content_files\n    }\n", "def get_logical_path_map(inventory, version):\n    content_files = inventory.get_content_files(version)\n    return {\n        path: set(content_files[path])\n        for path in content_files\n    }\n", "def get_logical_path_map(inventory, version):\n    return {\n        path: set(content_files)\n        for path, content_files in inventory.items()\n        if version in content_files\n    }\n", "def get_logical_path_map(inventory, version):\n    return {\n        logical_path: set(content_files)\n        for logical_path, content_files in six.iteritems(inventory)\n        if version in content_files\n    }\n", "def get_logical_path_map(inventory, version):\n    return inventory.get('logical_path_map', {})\n"], "level": "self_contained", "generate_results": [{"generate_code": "def get_logical_path_map(inventory, version):\n    result = {}\n    for key in inventory:\n        if isinstance(inventory[key], dict):\n            if version in inventory[key]:\n                result[key] = inventory[key]\n        else:\n            if inventory[key].is_duplicate:\n                result[key] = inventory[key]\n\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    inventory_dir = inventory.get_inventory_directory(version)\n    return {\n        os.path.join(inventory_dir, f): set(content_files)\n        for f, content_files in inventory.get_file_map(version).items()\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    # TODO: use a custom storage backend instead\n    content_files = inventory.get_content_files(version)\n    return {\n        '/'.join(content_file.path.split('/')[1:-1]): set(content_files)\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    if version.content is None:\n        return {}\n\n    # A version with no content can have logical paths in it.\n    if version.content.paths is None:\n        return {}\n\n    return {\n        path\n        for path in inventory.get_file_paths_for_version(version)\n        if path in version.content.paths\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    content_files = inventory.get_content_files_for_version(version)\n\n    return {\n        content_file.logical_path: content_files\n        for content_file in content_files\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    content_files = inventory.get_content_files(version.content_version)\n    return {\n        content_file.logical_path: content_files\n        for content_file in content_files\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    content_files = inventory.get_content_files(version)\n    return {\n        path: set(content_files[path])\n        for path in content_files\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    return {\n        path: set(content_files)\n        for path, content_files in inventory.items()\n        if version in content_files\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    return {\n        logical_path: set(content_files)\n        for logical_path, content_files in six.iteritems(inventory)\n        if version in content_files\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_logical_path_map(inventory, version):\n    return inventory.get('logical_path_map', {})\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/inventory_validator.py", "project": "zimeon/ocfl-py", "name": "validate_fixity", "docstring": "Validate fixity block in inventory.\n\nCheck the structure of the fixity block and makes sure that only files\nlisted in the manifest are referenced.", "ques_id": "62b45e175108cfac7f210a19", "code": ["def validate_fixity(self, fixity, manifest_files):\n    def is_referenced(filename):\n        return filename in manifest_files\n\n    return list(filter(is_referenced, fixity))\n", "def validate_fixity(self, fixity, manifest_files):\n    for filename, contents in fixity.items():\n        if filename in manifest_files:\n            raise exceptions.FixityError(\n                \"Referenced fixity file {} found in manifest {}\".format(\n                    filename, manifest_files[filename]))\n", "def validate_fixity(self, fixity, manifest_files):\n    referenced_files = {}\n\n    for filename, contents in fixity.items():\n        file_path = os.path.join(manifest_files, filename)\n\n        if not os.path.exists(file_path):\n            raise Exception('File does not exist: {}'.format(file_path))\n\n        if not filename.endswith('.txt'):\n            raise Exception('Invalid fixity file format: {}'.format(filename))\n\n        with open(file_path, 'r') as f:\n            content = f.read()\n\n        if content.startswith('# FIXITIY'):\n            referenced_files[filename] = content\n\n    return referenced_files\n", "def validate_fixity(self, fixity, manifest_files):\n    # TODO: validate fixity in inventory\n    return fixity\n", "def validate_fixity(self, fixity, manifest_files):\n    if 'files' in fixity:\n        referenced_files = set(fixity['files'])\n        unreferenced_files = referenced_files.difference(manifest_files)\n        if unreferenced_files:\n            msg = 'Unreferenced files: {}'.format(unreferenced_files)\n            raise ValueError(msg)\n\n    if 'files' in fixity:\n        return\n\n    msg = 'Fixity block missing required fields: {}'.format(fixity)\n    raise ValueError(msg)\n", "def validate_fixity(self, fixity, manifest_files):\n    def referenced_files(file_path):\n        return [path for path in manifest_files if path.startswith(file_path)]\n\n    for fixity_file in fixity.get('fixity', []):\n        file_path = fixity_file['path']\n\n        if file_path in referenced_files(fixity_file['path']):\n            continue\n\n        print('Fixity file {0} is not referenced in manifest'.format(file_path))\n        sys.exit(1)\n", "def validate_fixity(self, fixity, manifest_files):\n    for f in manifest_files:\n        if f in fixity:\n            raise ValueError(\n                'Fixity block contains file {} that is not part of the manifest'.format(f)\n            )\n", "def validate_fixity(self, fixity, manifest_files):\n    referenced_files = []\n    for filename, contents in fixity.items():\n        if not contents.get('files'):\n            referenced_files.append(filename)\n\n    if referenced_files:\n        raise FixityError('Files {} are referenced in the fixity block {}'.format(\n            ', '.join(referenced_files),\n            fixity['filename']\n        ))\n", "def validate_fixity(self, fixity, manifest_files):\n    for f in manifest_files:\n        if f in fixity:\n            raise errors.FixityError(\n                'Fixity block contains multiple files '\n               'referencing the same file \"{}\". '\n                'Only one file can be references in a fixity '\n                'block.'.format(f)\n            )\n", "def validate_fixity(self, fixity, manifest_files):\n    for file_name in fixity.files:\n        if file_name in manifest_files:\n            raise exceptions.FixityValidationError(\n                \"Fixity block contains file {} that should not \"\n                \"be referenced anymore\".format(file_name)\n            )\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    def is_referenced(filename):\n        return filename in manifest_files\n\n    return list(filter(is_referenced, fixity))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    for filename, contents in fixity.items():\n        if filename in manifest_files:\n            raise exceptions.FixityError(\n                \"Referenced fixity file {} found in manifest {}\".format(\n                    filename, manifest_files[filename]))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    referenced_files = {}\n\n    for filename, contents in fixity.items():\n        file_path = os.path.join(manifest_files, filename)\n\n        if not os.path.exists(file_path):\n            raise Exception('File does not exist: {}'.format(file_path))\n\n        if not filename.endswith('.txt'):\n            raise Exception('Invalid fixity file format: {}'.format(filename))\n\n        with open(file_path, 'r') as f:\n            content = f.read()\n\n        if content.startswith('# FIXITIY'):\n            referenced_files[filename] = content\n\n    return referenced_files\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    # TODO: validate fixity in inventory\n    return fixity\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    if 'files' in fixity:\n        referenced_files = set(fixity['files'])\n        unreferenced_files = referenced_files.difference(manifest_files)\n        if unreferenced_files:\n            msg = 'Unreferenced files: {}'.format(unreferenced_files)\n            raise ValueError(msg)\n\n    if 'files' in fixity:\n        return\n\n    msg = 'Fixity block missing required fields: {}'.format(fixity)\n    raise ValueError(msg)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    def referenced_files(file_path):\n        return [path for path in manifest_files if path.startswith(file_path)]\n\n    for fixity_file in fixity.get('fixity', []):\n        file_path = fixity_file['path']\n\n        if file_path in referenced_files(fixity_file['path']):\n            continue\n\n        print('Fixity file {0} is not referenced in manifest'.format(file_path))\n        sys.exit(1)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    for f in manifest_files:\n        if f in fixity:\n            raise ValueError(\n                'Fixity block contains file {} that is not part of the manifest'.format(f)\n            )\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    referenced_files = []\n    for filename, contents in fixity.items():\n        if not contents.get('files'):\n            referenced_files.append(filename)\n\n    if referenced_files:\n        raise FixityError('Files {} are referenced in the fixity block {}'.format(\n            ', '.join(referenced_files),\n            fixity['filename']\n        ))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    for f in manifest_files:\n        if f in fixity:\n            raise errors.FixityError(\n                'Fixity block contains multiple files '\n               'referencing the same file \"{}\". '\n                'Only one file can be references in a fixity '\n                'block.'.format(f)\n            )\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_fixity(self, fixity, manifest_files):\n    for file_name in fixity.files:\n        if file_name in manifest_files:\n            raise exceptions.FixityValidationError(\n                \"Fixity block contains file {} that should not \"\n                \"be referenced anymore\".format(file_name)\n            )\n", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/file_utils.py", "project": "scieloorg/packtools", "name": "files_list", "docstring": "Return the files in `path`", "ques_id": "62b463153879012d19481498", "code": ["def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "def files_list(path):\n    return [os.path.join(path, f) for f in os.listdir(path)]\n", "def files_list(path):\n    return [f for f in listdir(path) if isfile(join(path, f))]\n", "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "def files_list(path):\n    return [os.path.join(path, f)\n            for f in os.listdir(path)\n            if os.path.isfile(os.path.join(path, f))]\n", "def files_list(path):\n    return [f for f in listdir(path) if isfile(join(path, f))]\n", "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    return [os.path.join(path, f) for f in os.listdir(path)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    return [f for f in listdir(path) if isfile(join(path, f))]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    return [os.path.join(path, f)\n            for f in os.listdir(path)\n            if os.path.isfile(os.path.join(path, f))]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    return [f for f in listdir(path) if isfile(join(path, f))]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list(path):\n    return [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f))]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/sps/models/packages.py", "project": "scieloorg/packtools", "name": "_group_files_by_xml_filename", "docstring": "Group files by their XML basename\n\nGroups files by their XML basename and returns data in dict format.\n\nParameters\n----------\nxml_filename : str\n    XML filenames\nfiles : list\n    list of files in the folder or zipfile\n\nReturns\n-------\ndict\n    key: name of the XML files\n    value: Package", "ques_id": "62b463153879012d1948149a", "code": ["def _group_files_by_xml_filename(source, xmls, files):\n    file_groups = {}\n    for xml in xmls:\n        file_groups[os.path.basename(xml)] = files[os.path.splitext(xml)[0]]\n    return file_groups\n", "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for file in files:\n        filename = os.path.basename(file)\n        for xml in xmls:\n            if filename == xml.get('name'):\n                data[filename] = xml\n    return data\n", "def _group_files_by_xml_filename(source, xmls, files):\n    # Get filename splits\n    filename_splits = {}\n    for file in files:\n        filename_splits[file] = os.path.splitext(os.path.basename(file))[0]\n    # Get all packages\n    packages = []\n    for xml in xmls:\n        packages.extend([filename_splits[f] for f in xml.split('_') if f])\n\n    # Get filenames in order of filenames (filenames are in lowercase)\n    filenames = [f for f in packages if f in filename_splits]\n\n    # Iterate through files and record data\n    results = {}\n    for file in filenames:\n        filename = filename_splits[file]\n        results[filename] = []\n        for xml in xmls:\n            if filename in xml.split('_'):\n                results[filename].append(filename)\n\n    # Return results in dict\n    return results\n", "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for filename in files:\n        filename = os.path.basename(filename)\n        xml_filename = os.path.basename(xml_filename)\n        package = os.path.splitext(filename)[0]\n        if package not in data:\n            data[package] = []\n        data[package].append(filename)\n    for package in data:\n        data[package] = sorted(data[package], key=lambda x: x[0])\n    return data\n", "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for filename in files:\n        filename = os.path.basename(filename)\n        xml_filename = filename.replace('.xml', '')\n        if xml_filename in xmls:\n            data[filename] = xmls[xml_filename]\n\n    return data\n", "def _group_files_by_xml_filename(source, xmls, files):\n    package_dict = {}\n    for f in files:\n        pkg_file = os.path.basename(f)\n        if pkg_file in package_dict.keys():\n            package_dict[pkg_file].append(f)\n        else:\n            package_dict[pkg_file] = [f]\n\n    for k, v in package_dict.items():\n        xml_file = [f for f in v if os.path.splitext(f)[1] == '.xml']\n        if len(xml_file) == 0:\n            continue\n        package = os.path.splitext(k)[0]\n        package_dict[package] = xml_file\n\n    return package_dict\n", "def _group_files_by_xml_filename(source, xmls, files):\n    files = [x for x in files if x.endswith(\".xml\")]\n    data = {}\n    for xml_filename in files:\n        data[xml_filename] = Package(os.path.join(source, xml_filename))\n    return data\n", "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for file in files:\n        name = os.path.basename(file)\n        for xml in xmls:\n            if name.endswith(xml):\n                data[name] = source[file]\n    return data\n", "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for f in files:\n        fn = os.path.basename(f)\n        xml_fn = fn.replace('.xml', '')\n        if xml_fn in xmls:\n            data[fn] = source[xmls.index(xml_fn)]\n    return data\n", "def _group_files_by_xml_filename(source, xmls, files):\n    packages = defaultdict(Package)\n    for filename in files:\n        xml_basename = os.path.basename(filename).rstrip('.xml')\n        for package in packages:\n            if package.xml_filename == xml_basename:\n                packages[package].files.append(filename)\n                packages[package].total_files += 1\n                break\n    packages = {key: Package(files=[filename]) for key, filename in packages.items()}\n    for package in packages.values():\n        package.total_files = package.files.__len__()\n        package.total_bytes = package.files.__len__() * package.files.__len__()\n        package.total_bytes_avg = package.total_bytes / package.total_files\n    return packages\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    file_groups = {}\n    for xml in xmls:\n        file_groups[os.path.basename(xml)] = files[os.path.splitext(xml)[0]]\n    return file_groups\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for file in files:\n        filename = os.path.basename(file)\n        for xml in xmls:\n            if filename == xml.get('name'):\n                data[filename] = xml\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    # Get filename splits\n    filename_splits = {}\n    for file in files:\n        filename_splits[file] = os.path.splitext(os.path.basename(file))[0]\n    # Get all packages\n    packages = []\n    for xml in xmls:\n        packages.extend([filename_splits[f] for f in xml.split('_') if f])\n\n    # Get filenames in order of filenames (filenames are in lowercase)\n    filenames = [f for f in packages if f in filename_splits]\n\n    # Iterate through files and record data\n    results = {}\n    for file in filenames:\n        filename = filename_splits[file]\n        results[filename] = []\n        for xml in xmls:\n            if filename in xml.split('_'):\n                results[filename].append(filename)\n\n    # Return results in dict\n    return results\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for filename in files:\n        filename = os.path.basename(filename)\n        xml_filename = os.path.basename(xml_filename)\n        package = os.path.splitext(filename)[0]\n        if package not in data:\n            data[package] = []\n        data[package].append(filename)\n    for package in data:\n        data[package] = sorted(data[package], key=lambda x: x[0])\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for filename in files:\n        filename = os.path.basename(filename)\n        xml_filename = filename.replace('.xml', '')\n        if xml_filename in xmls:\n            data[filename] = xmls[xml_filename]\n\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    package_dict = {}\n    for f in files:\n        pkg_file = os.path.basename(f)\n        if pkg_file in package_dict.keys():\n            package_dict[pkg_file].append(f)\n        else:\n            package_dict[pkg_file] = [f]\n\n    for k, v in package_dict.items():\n        xml_file = [f for f in v if os.path.splitext(f)[1] == '.xml']\n        if len(xml_file) == 0:\n            continue\n        package = os.path.splitext(k)[0]\n        package_dict[package] = xml_file\n\n    return package_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    files = [x for x in files if x.endswith(\".xml\")]\n    data = {}\n    for xml_filename in files:\n        data[xml_filename] = Package(os.path.join(source, xml_filename))\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for file in files:\n        name = os.path.basename(file)\n        for xml in xmls:\n            if name.endswith(xml):\n                data[name] = source[file]\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    data = {}\n    for f in files:\n        fn = os.path.basename(f)\n        xml_fn = fn.replace('.xml', '')\n        if xml_fn in xmls:\n            data[fn] = source[xmls.index(xml_fn)]\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _group_files_by_xml_filename(source, xmls, files):\n    packages = defaultdict(Package)\n    for filename in files:\n        xml_basename = os.path.basename(filename).rstrip('.xml')\n        for package in packages:\n            if package.xml_filename == xml_basename:\n                packages[package].files.append(filename)\n                packages[package].total_files += 1\n                break\n    packages = {key: Package(files=[filename]) for key, filename in packages.items()}\n    for package in packages.values():\n        package.total_files = package.files.__len__()\n        package.total_bytes = package.files.__len__() * package.files.__len__()\n        package.total_bytes_avg = package.total_bytes / package.total_files\n    return packages\n", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/sps/models/packages.py", "project": "scieloorg/packtools", "name": "match_file_by_prefix", "docstring": "Identify if a `file_path` belongs to a document package by a given `prefix`\n\nRetorna `True` para documentos pertencentes a um pacote.\n\nParameters\n----------\nprefix : str\n    Filename prefix\nfile_path : str\n    File path\nReturns\n-------\nbool\n    True - file belongs to the package", "ques_id": "62b463153879012d1948149b", "code": ["def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + '/')\n", "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix)\n", "def match_file_by_prefix(prefix, file_path):\n    return prefix in [f.split(os.sep)[-1] for f in os.listdir(file_path)]\n", "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix)\n", "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix)\n", "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + '/')\n", "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix)\n", "def match_file_by_prefix(prefix, file_path):\n    return prefix in file_path.split(os.sep)\n", "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + '/')\n", "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix)\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + '/')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return prefix in [f.split(os.sep)[-1] for f in os.listdir(file_path)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + '/')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return prefix in file_path.split(os.sep)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix + '/')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_file_by_prefix(prefix, file_path):\n    return file_path.startswith(prefix)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "packtools/sps/models/packages.py", "project": "scieloorg/packtools", "name": "select_filenames_by_prefix", "docstring": "Get files which belongs to a document package.\n\nRetorna os arquivos da lista `files` cujos nomes iniciam com `prefix`\n\nParameters\n----------\nprefix : str\n    Filename prefix\nfiles : str list\n    Files paths\nReturns\n-------\nlist\n    files paths which basename files matches to prefix", "ques_id": "62b463153879012d1948149c", "code": ["def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    files = [f for f in files if f.startswith(prefix)]\n    return files\n", "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    return [file for file in files if file.startswith(prefix)]\n", "def select_filenames_by_prefix(prefix, files):\n    return [filename for filename in files if filename.startswith(prefix)]\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    files = [f for f in files if f.startswith(prefix)]\n    return files\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [f for f in files if f.startswith(prefix)]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [file for file in files if file.startswith(prefix)]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def select_filenames_by_prefix(prefix, files):\n    return [filename for filename in files if filename.startswith(prefix)]\n", "is_pass": true, "return_code": 0}]}
{"file_path": "packtools/sps/models/packages.py", "project": "scieloorg/packtools", "name": "_explore_folder", "docstring": "Get packages' data from folder\n\nGroups files by their XML basename and returns data in dict format.\n\nParameters\n----------\nfolder : str\n    Folder of the package\nReturns\n-------\ndict", "ques_id": "62b463153879012d1948149d", "code": ["def _explore_folder(folder):\n    data = {}\n    for root, dirs, files in os.walk(folder):\n        for f in files:\n            if f.endswith(\".xml\"):\n                file_path = os.path.join(root, f)\n                data[os.path.basename(file_path)] = read_xml(file_path)\n    return data\n", "def _explore_folder(folder):\n    data = {}\n    for file in os.listdir(folder):\n        file_path = os.path.join(folder, file)\n        if os.path.isfile(file_path):\n            data[file] = _read_xml(file_path)\n    return data\n", "def _explore_folder(folder):\n    pkgs = {}\n    for filename in os.listdir(folder):\n        if filename.endswith('.xml'):\n            pkgs[filename[:-4]] = _parse_xml(os.path.join(folder, filename))\n    return pkgs\n", "def _explore_folder(folder):\n    result = {}\n    for file in os.listdir(folder):\n        if file.endswith(\".xml\"):\n            result[file[:-4]] = _read_xml_file(os.path.join(folder, file))\n    return result\n", "def _explore_folder(folder):\n    result = {}\n    for root, dirs, files in os.walk(folder):\n        for f in files:\n            path = os.path.join(root, f)\n            result[os.path.basename(path)] = _read_package_xml(path)\n    return result\n", "def _explore_folder(folder):\n    result = {}\n    for filename in os.listdir(folder):\n        if not filename.endswith(\".xml\"):\n            continue\n\n        filepath = os.path.join(folder, filename)\n        with open(filepath, \"r\") as f:\n            result[filename[:-4]] = xmltodict.parse(f.read())\n\n    return result\n", "def _explore_folder(folder):\n    data = {}\n    for root, dirs, files in os.walk(folder):\n        for filename in files:\n            if filename.endswith(\".xml\"):\n                filepath = os.path.join(root, filename)\n                data[os.path.basename(filepath)] = _read_xml(filepath)\n    return data\n", "def _explore_folder(folder):\n    data = OrderedDict()\n    for root, dirs, files in os.walk(folder):\n        for file_ in files:\n            if file_.endswith(\".xml\"):\n                path = os.path.join(root, file_)\n                data[file_] = _read_xml(path)\n    return data\n", "def _explore_folder(folder):\n    packages = {}\n    for root, _, files in os.walk(folder):\n        for file in files:\n            if file.endswith(\".xml\"):\n                with open(os.path.join(root, file), \"r\") as f:\n                    packages[file] = etree.parse(f).getroot()\n    return packages\n", "def _explore_folder(folder):\n    data = {}\n    for root, dirs, files in os.walk(folder):\n        for f in files:\n            file_path = os.path.join(root, f)\n            data[os.path.basename(file_path).replace('.xml', '')] = _read_xml(file_path)\n    return data\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _explore_folder(folder):\n    data = {}\n    for root, dirs, files in os.walk(folder):\n        for f in files:\n            if f.endswith(\".xml\"):\n                file_path = os.path.join(root, f)\n                data[os.path.basename(file_path)] = read_xml(file_path)\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    data = {}\n    for file in os.listdir(folder):\n        file_path = os.path.join(folder, file)\n        if os.path.isfile(file_path):\n            data[file] = _read_xml(file_path)\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    pkgs = {}\n    for filename in os.listdir(folder):\n        if filename.endswith('.xml'):\n            pkgs[filename[:-4]] = _parse_xml(os.path.join(folder, filename))\n    return pkgs\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    result = {}\n    for file in os.listdir(folder):\n        if file.endswith(\".xml\"):\n            result[file[:-4]] = _read_xml_file(os.path.join(folder, file))\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    result = {}\n    for root, dirs, files in os.walk(folder):\n        for f in files:\n            path = os.path.join(root, f)\n            result[os.path.basename(path)] = _read_package_xml(path)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    result = {}\n    for filename in os.listdir(folder):\n        if not filename.endswith(\".xml\"):\n            continue\n\n        filepath = os.path.join(folder, filename)\n        with open(filepath, \"r\") as f:\n            result[filename[:-4]] = xmltodict.parse(f.read())\n\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    data = {}\n    for root, dirs, files in os.walk(folder):\n        for filename in files:\n            if filename.endswith(\".xml\"):\n                filepath = os.path.join(root, filename)\n                data[os.path.basename(filepath)] = _read_xml(filepath)\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    data = OrderedDict()\n    for root, dirs, files in os.walk(folder):\n        for file_ in files:\n            if file_.endswith(\".xml\"):\n                path = os.path.join(root, file_)\n                data[file_] = _read_xml(path)\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    packages = {}\n    for root, _, files in os.walk(folder):\n        for file in files:\n            if file.endswith(\".xml\"):\n                with open(os.path.join(root, file), \"r\") as f:\n                    packages[file] = etree.parse(f).getroot()\n    return packages\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_folder(folder):\n    data = {}\n    for root, dirs, files in os.walk(folder):\n        for f in files:\n            file_path = os.path.join(root, f)\n            data[os.path.basename(file_path).replace('.xml', '')] = _read_xml(file_path)\n    return data\n", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/sps/models/packages.py", "project": "scieloorg/packtools", "name": "_eval_file", "docstring": "Identifica o tipo de arquivo do pacote: `asset` ou `rendition`.\n\nIdentifica o tipo de arquivo do pacote e atualiza `packages` com o tipo e\no endere\u00e7o do arquivo em an\u00e1lise.\n\nParameters\n----------\nprefix : str\n    nome do arquivo XML sem extens\u00e3o\nfilename : str\n    filename\nfile_folder : str\n    file folder\n\nReturns\n-------\ndict", "ques_id": "62b463153879012d1948149f", "code": ["def _eval_file(prefix, file_path):\n    filename = path.basename(file_path)\n    filename_lower = filename.lower()\n    package = filename_lower.split('.')[0]\n    file_type = 'asset'\n    if 'asset' in filename_lower:\n        file_type = 'asset_file'\n    elif'rendition' in filename_lower:\n        file_type ='rendition'\n\n    return {\n        'package': package,\n        'file_type': file_type,\n        'filename': filename,\n        'file_path': file_path\n    }\n", "def _eval_file(prefix, file_path):\n    if 'asset' in prefix:\n        return {'packages': [file_path]}\n\n    elif'rendition' in prefix:\n        return {'packages': [file_path, file_path.rsplit('.', 1)[0] + '.jpg']}\n\n    else:\n        return {'packages': [file_path]}\n", "def _eval_file(prefix, file_path):\n    filename = os.path.join(file_path, 'filename')\n    file_type = os.path.splitext(filename)[1].lower()\n    filetype = {'asset': 'asset.xml','rendition':'rendition.xml'}\n    if file_type in filetype:\n        if filename.endswith('.xml'):\n            return eval(prefix + '.' + file_type[file_type])\n        elif filename.endswith('.yml'):\n            return eval(prefix + '.' + file_type[file_type])\n        else:\n            raise Exception('File type not supported')\n    else:\n        raise Exception('Filename not supported')\n", "def _eval_file(prefix, file_path):\n    filename = os.path.join(file_path, 'packages.xml')\n\n    # Identifica o tipo da arquivo\n    try:\n        package = parse(filename)[prefix]\n    except KeyError:\n        raise ValueError(\"File does not contain a package: {}\".format(filename))\n\n    # Em como um dos assets, um dos renditions\n    if package['package_type'] == 'asset':\n        return {\n            'type': 'asset',\n            'path': file_path,\n            'file_path': filename\n        }\n    elif package['package_type'] =='rendition':\n        return {\n            'type':'rendition',\n            'path': file_path,\n            'file_path': filename\n        }\n    else:\n        raise ValueError(\n            \"Invalid package type: {}\".format(package['package_type'])\n        )\n", "def _eval_file(prefix, file_path):\n    filename = file_path.replace(prefix, '')\n    if filename.endswith('.yaml'):\n        filename = filename[:-4]\n    if filename.endswith('.yml'):\n        filename = filename[:-4]\n    if filename in ('', '../../'):\n        filename = 'assets'\n    filename = os.path.join(file_path, filename)\n    if not os.path.exists(filename):\n        raise ValueError('{} not found'.format(filename))\n    return {\n        'package': filename,\n        'filename': filename,\n    }\n", "def _eval_file(prefix, file_path):\n    ext = os.path.splitext(file_path)[-1]\n    if ext in ['.xml', '.xml.bz2']:\n        packages = {'asset': 'asset-xml','rendition': 'asset-xml-rendition'}\n    else:\n        packages = {'asset': 'asset-file','rendition': 'file-asset'}\n\n    filename = os.path.basename(file_path)\n    return packages.get(prefix, packages.get('asset', 'asset')) + '-' + filename\n", "def _eval_file(prefix, file_path):\n    filename = os.path.basename(file_path)\n    filename = filename.split('.')[0]\n\n    if filename in ['asset','rendition']:\n        # Asserta se o endere\u00e7o foi identificado\n        if '@' in file_path:\n            em_endereco = file_path.split('@')[1]\n            if em_endereco.lower() == 'enc:base64':\n                em_endereco = 'base64'\n            if em_endereco.lower()!= 'base64':\n                raise Exception('Endere\u00e7o do arquivo n \u2047 o \u00e9 base64.')\n\n        return {\n            'packages': [\n                {\n                    'filename': filename,\n                    'path': file_path\n                }\n            ]\n        }\n\n    return {\n        'packages': [\n       ", "def _eval_file(prefix, file_path):\n    if prefix in ('asset','rendition'):\n        file_name = file_path.replace('asset', '').replace('rendition', '')\n        file_name = file_name.replace('.xml', '')\n\n        file_type = 'asset'\n    else:\n        file_name = os.path.basename(file_path)\n        file_type = 'file'\n\n    file_type = file_type.lower()\n\n    file_dict = {'packages': file_name, 'file_type': file_type}\n    return file_dict\n", "def _eval_file(prefix, file_path):\n    file_path = os.path.join(file_path, 'packages.xml')\n    tree = etree.parse(file_path)\n    root = tree.getroot()\n\n    # Verifica se existe o arquivo do XML\n    for package in root:\n        if package.tag == 'package' and \\\n                package.attrib['name'] == prefix:\n            package_name = package.attrib['name']\n            break\n\n    # Verifica se existe o endereco de XML\n    if 'endereco' in root.attrib:\n        endereco_name = root.attrib['endereco']\n        if package_name == endereco_name:\n            packages[package_name] = root\n\n            # Atualizar endereco com o endere\u00e7o do arquivo\n            if 'endereco_id' in package.attrib:\n                endereco_id = package.attrib['endereco_id']\n                if endereco_id in packages.keys():\n ", "def _eval_file(prefix, file_path):\n    filename = os.path.basename(file_path)\n    filename_in_packages = filename.split('.')[0]\n    filename_in_analyses = filename.split('.')[1]\n    filename_in_prefix = filename.split('.')[2]\n\n    if filename == filename_in_packages + '.xml':\n        if filename_in_analyses == 'asset':\n            return {\n                'package': 'assets',\n                'file_type': 'asset'\n            }\n        elif filename_in_analyses =='rendition':\n            return {\n                'package':'renditions',\n                'file_type':'rendition'\n            }\n        else:\n            return {\n                'package': 'assets',\n                'file_type': 'asset'\n            }\n    elif filename.startswith(filename_in_prefi"], "level": "file_runnable", "generate_results": [{"generate_code": "def _eval_file(prefix, file_path):\n    filename = path.basename(file_path)\n    filename_lower = filename.lower()\n    package = filename_lower.split('.')[0]\n    file_type = 'asset'\n    if 'asset' in filename_lower:\n        file_type = 'asset_file'\n    elif'rendition' in filename_lower:\n        file_type ='rendition'\n\n    return {\n        'package': package,\n        'file_type': file_type,\n        'filename': filename,\n        'file_path': file_path\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    if 'asset' in prefix:\n        return {'packages': [file_path]}\n\n    elif'rendition' in prefix:\n        return {'packages': [file_path, file_path.rsplit('.', 1)[0] + '.jpg']}\n\n    else:\n        return {'packages': [file_path]}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    filename = os.path.join(file_path, 'filename')\n    file_type = os.path.splitext(filename)[1].lower()\n    filetype = {'asset': 'asset.xml','rendition':'rendition.xml'}\n    if file_type in filetype:\n        if filename.endswith('.xml'):\n            return eval(prefix + '.' + file_type[file_type])\n        elif filename.endswith('.yml'):\n            return eval(prefix + '.' + file_type[file_type])\n        else:\n            raise Exception('File type not supported')\n    else:\n        raise Exception('Filename not supported')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    filename = os.path.join(file_path, 'packages.xml')\n\n    # Identifica o tipo da arquivo\n    try:\n        package = parse(filename)[prefix]\n    except KeyError:\n        raise ValueError(\"File does not contain a package: {}\".format(filename))\n\n    # Em como um dos assets, um dos renditions\n    if package['package_type'] == 'asset':\n        return {\n            'type': 'asset',\n            'path': file_path,\n            'file_path': filename\n        }\n    elif package['package_type'] =='rendition':\n        return {\n            'type':'rendition',\n            'path': file_path,\n            'file_path': filename\n        }\n    else:\n        raise ValueError(\n            \"Invalid package type: {}\".format(package['package_type'])\n        )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    filename = file_path.replace(prefix, '')\n    if filename.endswith('.yaml'):\n        filename = filename[:-4]\n    if filename.endswith('.yml'):\n        filename = filename[:-4]\n    if filename in ('', '../../'):\n        filename = 'assets'\n    filename = os.path.join(file_path, filename)\n    if not os.path.exists(filename):\n        raise ValueError('{} not found'.format(filename))\n    return {\n        'package': filename,\n        'filename': filename,\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    ext = os.path.splitext(file_path)[-1]\n    if ext in ['.xml', '.xml.bz2']:\n        packages = {'asset': 'asset-xml','rendition': 'asset-xml-rendition'}\n    else:\n        packages = {'asset': 'asset-file','rendition': 'file-asset'}\n\n    filename = os.path.basename(file_path)\n    return packages.get(prefix, packages.get('asset', 'asset')) + '-' + filename\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    filename = os.path.basename(file_path)\n    filename = filename.split('.')[0]\n\n    if filename in ['asset','rendition']:\n        # Asserta se o endere\u00e7o foi identificado\n        if '@' in file_path:\n            em_endereco = file_path.split('@')[1]\n            if em_endereco.lower() == 'enc:base64':\n                em_endereco = 'base64'\n            if em_endereco.lower()!= 'base64':\n                raise Exception('Endere\u00e7o do arquivo n \u2047 o \u00e9 base64.')\n\n        return {\n            'packages': [\n                {\n                    'filename': filename,\n                    'path': file_path\n                }\n            ]\n        }\n\n    return {\n        'packages': [\n       ", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    if prefix in ('asset','rendition'):\n        file_name = file_path.replace('asset', '').replace('rendition', '')\n        file_name = file_name.replace('.xml', '')\n\n        file_type = 'asset'\n    else:\n        file_name = os.path.basename(file_path)\n        file_type = 'file'\n\n    file_type = file_type.lower()\n\n    file_dict = {'packages': file_name, 'file_type': file_type}\n    return file_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    file_path = os.path.join(file_path, 'packages.xml')\n    tree = etree.parse(file_path)\n    root = tree.getroot()\n\n    # Verifica se existe o arquivo do XML\n    for package in root:\n        if package.tag == 'package' and \\\n                package.attrib['name'] == prefix:\n            package_name = package.attrib['name']\n            break\n\n    # Verifica se existe o endereco de XML\n    if 'endereco' in root.attrib:\n        endereco_name = root.attrib['endereco']\n        if package_name == endereco_name:\n            packages[package_name] = root\n\n            # Atualizar endereco com o endere\u00e7o do arquivo\n            if 'endereco_id' in package.attrib:\n                endereco_id = package.attrib['endereco_id']\n                if endereco_id in packages.keys():\n ", "is_pass": false, "return_code": 1}, {"generate_code": "def _eval_file(prefix, file_path):\n    filename = os.path.basename(file_path)\n    filename_in_packages = filename.split('.')[0]\n    filename_in_analyses = filename.split('.')[1]\n    filename_in_prefix = filename.split('.')[2]\n\n    if filename == filename_in_packages + '.xml':\n        if filename_in_analyses == 'asset':\n            return {\n                'package': 'assets',\n                'file_type': 'asset'\n            }\n        elif filename_in_analyses =='rendition':\n            return {\n                'package':'renditions',\n                'file_type':'rendition'\n            }\n        else:\n            return {\n                'package': 'assets',\n                'file_type': 'asset'\n            }\n    elif filename.startswith(filename_in_prefi", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/sps/models/packages.py", "project": "scieloorg/packtools", "name": "add_rendition", "docstring": "{\n    \"original\": \"artigo02.pdf\",\n    \"en\": \"artigo02-en.pdf\",\n}", "ques_id": "62b463153879012d194814a1", "code": ["def add_rendition(self, lang, file_path):\n    self.renditions.setdefault(lang, []).append(file_path)\n", "def add_rendition(self, lang, file_path):\n    files = {\"original\": open(file_path, \"rb\"), \"en\": open(file_path.replace(\".pdf\", \".png\"), \"rb\")}\n    return self.post(\"/v1/images/add-rendition/\", files=files, params={\"lang\": lang})\n", "def add_rendition(self, lang, file_path):\n    if not lang:\n        raise ValueError(\"lang is required\")\n    if not file_path:\n        raise ValueError(\"file_path is required\")\n    try:\n        filename = \"{}.{}\".format(lang, file_path.split('.')[-1])\n        return self._get_file(filename)\n    except Exception as e:\n        raise ValueError(e)\n", "def add_rendition(self, lang, file_path):\n    url = \"http://io.media-img.com/media/{}/{}\".format(lang, file_path)\n    try:\n        response = requests.get(url)\n        if response.status_code == 200:\n            return response.content\n        return None\n    except requests.ConnectionError as e:\n        return None\n", "def add_rendition(self, lang, file_path):\n    if not file_path.endswith('.pdf'):\n        raise ValueError(\"file_path must be a.pdf\")\n\n    if lang not in settings.LANGUAGES:\n        raise ValueError(\"lang must be in {}\".format(settings.LANGUAGES))\n\n    renditions = {lang: file_path}\n    return self.add_to_store(renditions)\n", "def add_rendition(self, lang, file_path):\n    if not self.renditions:\n        self.renditions = {}\n    self.renditions[lang] = file_path\n", "def add_rendition(self, lang, file_path):\n    if not file_path:\n        return\n\n    if lang not in self.renditions:\n        self.renditions[lang] = {}\n\n    if not isinstance(self.renditions[lang], dict):\n        raise Exception(\"Language must be in dict.\")\n\n    if lang == \"en\":\n        self.renditions[lang][\"en\"] = file_path\n    elif lang == \"original\":\n        self.renditions[lang][\"original\"] = file_path\n", "def add_rendition(self, lang, file_path):\n    return self.add_item('renditions', {\n        'original': file_path,\n        'en': file_path\n    })\n", "def add_rendition(self, lang, file_path):\n    try:\n        en = Enclosure.objects.get(file_path=file_path)\n        if lang == \"en\":\n            return en\n        else:\n            return en.original\n    except Enclosure.DoesNotExist:\n        return Enclosure(file_path=file_path)\n", "def add_rendition(self, lang, file_path):\n    try:\n        ext = file_path.split('.')[-1]\n    except AttributeError:\n        ext = ''\n\n    if ext not in ['pdf', 'png']:\n        raise ValueError('Unsupported file extension \"{}\". Choose from {}'.format(ext, ['pdf', 'png']))\n\n    if not file_path.startswith('/'):\n        file_path = '/' + file_path\n\n    if ext == 'png':\n        return self.add_png_rendition(lang, file_path)\n    elif ext == 'pdf':\n        return self.add_pdf_rendition(lang, file_path)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def add_rendition(self, lang, file_path):\n    self.renditions.setdefault(lang, []).append(file_path)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_rendition(self, lang, file_path):\n    files = {\"original\": open(file_path, \"rb\"), \"en\": open(file_path.replace(\".pdf\", \".png\"), \"rb\")}\n    return self.post(\"/v1/images/add-rendition/\", files=files, params={\"lang\": lang})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def add_rendition(self, lang, file_path):\n    if not lang:\n        raise ValueError(\"lang is required\")\n    if not file_path:\n        raise ValueError(\"file_path is required\")\n    try:\n        filename = \"{}.{}\".format(lang, file_path.split('.')[-1])\n        return self._get_file(filename)\n    except Exception as e:\n        raise ValueError(e)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def add_rendition(self, lang, file_path):\n    url = \"http://io.media-img.com/media/{}/{}\".format(lang, file_path)\n    try:\n        response = requests.get(url)\n        if response.status_code == 200:\n            return response.content\n        return None\n    except requests.ConnectionError as e:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def add_rendition(self, lang, file_path):\n    if not file_path.endswith('.pdf'):\n        raise ValueError(\"file_path must be a.pdf\")\n\n    if lang not in settings.LANGUAGES:\n        raise ValueError(\"lang must be in {}\".format(settings.LANGUAGES))\n\n    renditions = {lang: file_path}\n    return self.add_to_store(renditions)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def add_rendition(self, lang, file_path):\n    if not self.renditions:\n        self.renditions = {}\n    self.renditions[lang] = file_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def add_rendition(self, lang, file_path):\n    if not file_path:\n        return\n\n    if lang not in self.renditions:\n        self.renditions[lang] = {}\n\n    if not isinstance(self.renditions[lang], dict):\n        raise Exception(\"Language must be in dict.\")\n\n    if lang == \"en\":\n        self.renditions[lang][\"en\"] = file_path\n    elif lang == \"original\":\n        self.renditions[lang][\"original\"] = file_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def add_rendition(self, lang, file_path):\n    return self.add_item('renditions', {\n        'original': file_path,\n        'en': file_path\n    })\n", "is_pass": false, "return_code": 1}, {"generate_code": "def add_rendition(self, lang, file_path):\n    try:\n        en = Enclosure.objects.get(file_path=file_path)\n        if lang == \"en\":\n            return en\n        else:\n            return en.original\n    except Enclosure.DoesNotExist:\n        return Enclosure(file_path=file_path)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def add_rendition(self, lang, file_path):\n    try:\n        ext = file_path.split('.')[-1]\n    except AttributeError:\n        ext = ''\n\n    if ext not in ['pdf', 'png']:\n        raise ValueError('Unsupported file extension \"{}\". Choose from {}'.format(ext, ['pdf', 'png']))\n\n    if not file_path.startswith('/'):\n        file_path = '/' + file_path\n\n    if ext == 'png':\n        return self.add_png_rendition(lang, file_path)\n    elif ext == 'pdf':\n        return self.add_pdf_rendition(lang, file_path)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/sps/models/packages.py", "project": "scieloorg/packtools", "name": "add_asset", "docstring": "\"{\n    \"artigo02-gf03.tiff\": \"/path/artigo02-gf03.tiff\",\n    \"artigo02-gf03.jpg\": \"/path/artigo02-gf03.jpg\",\n    \"artigo02-gf03.png\": \"/path/artigo02-gf03.png\",\n}", "ques_id": "62b463163879012d194814a2", "code": ["def add_asset(self, basename, file_path):\n    asset_name = os.path.splitext(os.path.basename(file_path))[0]\n    if asset_name.endswith('-gf01.tif'):\n        asset_name = asset_name[:-4]\n    elif asset_name.endswith('-gf02.tif'):\n        asset_name = asset_name[:-4]\n    elif asset_name.endswith('-gf03.tif'):\n        asset_name = asset_name[:-4]\n    elif asset_name.endswith('-gf04.tif'):\n        asset_name = asset_name[:-4]\n    elif asset_name.endswith('-gf5.tif'):\n        asset_name = asset_name[:-4]\n\n    asset_path = os.path.join(self.assets_path, asset_name)\n    if not os.path.exists(asset_path):\n        os.makedirs(asset_path)\n    shutil.copy2(file_path, asset_path)\n    return asset_name\n", "def add_asset(self, basename, file_path):\n    asset = Asset(file_path)\n    asset.basename = basename\n    self[basename] = asset\n", "def add_asset(self, basename, file_path):\n    assets = self.get_assets()\n    assets[basename] = file_path\n    self.set_assets(assets)\n", "def add_asset(self, basename, file_path):\n    file_name, ext = os.path.splitext(basename)\n    file_path = os.path.join(self._assets_dir, file_name + ext)\n    return {file_name: file_path}\n", "def add_asset(self, basename, file_path):\n    asset_path = file_path.replace('.tif', '')\n    asset_path = os.path.join(self.assets_dir, asset_path)\n    if not os.path.exists(asset_path):\n        with open(file_path, 'wb+') as f:\n            f.write(b'')\n\n    self.assets[asset_path] = basename\n", "def add_asset(self, basename, file_path):\n    assets_dir = os.path.join(self.assets_path, basename)\n    if not os.path.exists(assets_dir):\n        os.makedirs(assets_dir)\n\n    if not isinstance(file_path, (list, tuple)):\n        file_path = [file_path]\n\n    for file_path_item in file_path:\n        file_path_item = os.path.join(assets_dir, file_path_item)\n        if not isinstance(file_path_item, (list, tuple)):\n            file_path_item = [file_path_item]\n\n        for file_name in file_path_item:\n            if not os.path.exists(file_name):\n                print(\"Asset \" + file_name + \" not found.\")\n                continue\n\n            with open(file_name, 'rb') as file_:\n                with open(file_path_item, 'wb+') as output_file:\n                    output_file.write(file_.read())\n", "def add_asset(self, basename, file_path):\n    assert file_path.startswith(\"/\")\n    asset = Asset(basename, file_path)\n    self[basename] = asset\n    return asset\n", "def add_asset(self, basename, file_path):\n    if not file_path:\n        raise ValueError('file_path can not be empty')\n    file_name, file_ext = os.path.splitext(basename)\n    asset_name = file_name + '-' + file_ext\n    asset_path = os.path.join(self.asset_path, asset_name)\n    if not os.path.exists(asset_path):\n        os.makedirs(asset_path)\n    if not os.path.exists(file_path):\n        with open(file_path, 'wb') as f:\n            f.write(open(file_path, 'rb').read())\n    if os.path.exists(file_path):\n        os.remove(file_path)\n", "def add_asset(self, basename, file_path):\n    asset_path = join(self.assets_dir, basename)\n    if exists(asset_path):\n        raise ValueError(\"Asset \" + basename + \" already exists.\")\n    with open(file_path, \"rb\") as f:\n        with open(asset_path, \"wb\") as w:\n            w.write(f.read())\n", "def add_asset(self, basename, file_path):\n    asset_path = self.assets_path + basename\n    asset_path = os.path.join(self.assets_path, asset_path)\n\n    if not os.path.exists(asset_path):\n        os.makedirs(asset_path)\n\n    with open(file_path, \"wb\") as f:\n        f.write(base64.decodestring(open(file_path, \"rb\").read()))\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def add_asset(self, basename, file_path):\n    asset_name = os.path.splitext(os.path.basename(file_path))[0]\n    if asset_name.endswith('-gf01.tif'):\n        asset_name = asset_name[:-4]\n    elif asset_name.endswith('-gf02.tif'):\n        asset_name = asset_name[:-4]\n    elif asset_name.endswith('-gf03.tif'):\n        asset_name = asset_name[:-4]\n    elif asset_name.endswith('-gf04.tif'):\n        asset_name = asset_name[:-4]\n    elif asset_name.endswith('-gf5.tif'):\n        asset_name = asset_name[:-4]\n\n    asset_path = os.path.join(self.assets_path, asset_name)\n    if not os.path.exists(asset_path):\n        os.makedirs(asset_path)\n    shutil.copy2(file_path, asset_path)\n    return asset_name\n", "is_pass": false, "return_code": 1}, {"generate_code": "def add_asset(self, basename, file_path):\n    asset = Asset(file_path)\n    asset.basename = basename\n    self[basename] = asset\n", "is_pass": false, "return_code": 1}, {"generate_code": "def add_asset(self, basename, file_path):\n    assets = self.get_assets()\n    assets[basename] = file_path\n    self.set_assets(assets)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def add_asset(self, basename, file_path):\n    file_name, ext = os.path.splitext(basename)\n    file_path = os.path.join(self._assets_dir, file_name + ext)\n    return {file_name: file_path}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def add_asset(self, basename, file_path):\n    asset_path = file_path.replace('.tif', '')\n    asset_path = os.path.join(self.assets_dir, asset_path)\n    if not os.path.exists(asset_path):\n        with open(file_path, 'wb+') as f:\n            f.write(b'')\n\n    self.assets[asset_path] = basename\n", "is_pass": false, "return_code": 1}, {"generate_code": "def add_asset(self, basename, file_path):\n    assets_dir = os.path.join(self.assets_path, basename)\n    if not os.path.exists(assets_dir):\n        os.makedirs(assets_dir)\n\n    if not isinstance(file_path, (list, tuple)):\n        file_path = [file_path]\n\n    for file_path_item in file_path:\n        file_path_item = os.path.join(assets_dir, file_path_item)\n        if not isinstance(file_path_item, (list, tuple)):\n            file_path_item = [file_path_item]\n\n        for file_name in file_path_item:\n            if not os.path.exists(file_name):\n                print(\"Asset \" + file_name + \" not found.\")\n                continue\n\n            with open(file_name, 'rb') as file_:\n                with open(file_path_item, 'wb+') as output_file:\n                    output_file.write(file_.read())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def add_asset(self, basename, file_path):\n    assert file_path.startswith(\"/\")\n    asset = Asset(basename, file_path)\n    self[basename] = asset\n    return asset\n", "is_pass": false, "return_code": 1}, {"generate_code": "def add_asset(self, basename, file_path):\n    if not file_path:\n        raise ValueError('file_path can not be empty')\n    file_name, file_ext = os.path.splitext(basename)\n    asset_name = file_name + '-' + file_ext\n    asset_path = os.path.join(self.asset_path, asset_name)\n    if not os.path.exists(asset_path):\n        os.makedirs(asset_path)\n    if not os.path.exists(file_path):\n        with open(file_path, 'wb') as f:\n            f.write(open(file_path, 'rb').read())\n    if os.path.exists(file_path):\n        os.remove(file_path)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def add_asset(self, basename, file_path):\n    asset_path = join(self.assets_dir, basename)\n    if exists(asset_path):\n        raise ValueError(\"Asset \" + basename + \" already exists.\")\n    with open(file_path, \"rb\") as f:\n        with open(asset_path, \"wb\") as w:\n            w.write(f.read())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def add_asset(self, basename, file_path):\n    asset_path = self.assets_path + basename\n    asset_path = os.path.join(self.assets_path, asset_path)\n\n    if not os.path.exists(asset_path):\n        os.makedirs(asset_path)\n\n    with open(file_path, \"wb\") as f:\n        f.write(base64.decodestring(open(file_path, \"rb\").read()))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/sps/models/packages.py", "project": "scieloorg/packtools", "name": "_explore_zipfile", "docstring": "Get packages' data from zip_path\n\nGroups files by their XML basename and returns data in dict format.\n\nParameters\n----------\nzip_path : str\n    zip file path\nReturns\n-------\ndict", "ques_id": "62b463163879012d194814a4", "code": ["def _explore_zipfile(zip_path):\n    data = {}\n    with zipfile.ZipFile(zip_path) as zf:\n        for name in zf.namelist():\n            # Ignore files that are not in the package\n            if name.startswith('__init__.py'):\n                continue\n            data[name] = zf.open(name).read()\n\n    return data\n", "def _explore_zipfile(zip_path):\n    tree = ET.parse(zip_path)\n    root = tree.getroot()\n    data = {}\n    for item in root.findall('item'):\n        data[item.attrib['filename']] = item.text\n    return data\n", "def _explore_zipfile(zip_path):\n    zip_path = _os.path.basename(zip_path)\n    zip_data = {}\n    for root, _, files in _shell.walk(zip_path):\n        for f in files:\n            if _os.path.splitext(f)[1] == '.xml':\n                with open(os.path.join(root, f)) as fp:\n                    zip_data.update(_xml_to_dict(fp.read()))\n    return zip_data\n", "def _explore_zipfile(zip_path):\n    # remove compression from zip file name\n    zip_path = zip_path.replace(\"\\\\\", \"/\")\n    with zipfile.ZipFile(zip_path) as zf:\n        # get files from zip\n        files = zf.namelist()\n        # get data from zip file\n        data = {}\n        for f in files:\n            if f.endswith(\".xml\"):\n                data[f] = zf.open(f).read()\n    return data\n", "def _explore_zipfile(zip_path):\n    zip_path = Path(zip_path)\n    result = {}\n    for filename in zip_path.glob('*'):\n        filename = filename.with_suffix('')\n        try:\n            data = _read_xml_data(filename)\n        except ValueError:\n            data = None\n        result[filename.name] = data\n    return result\n", "def _explore_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        pkgs = {}\n        for name in zf.namelist():\n            pkg_path = os.path.join(zip_path, name)\n            if os.path.isdir(pkg_path):\n                pkgs[name] = _explore_zipfile(pkg_path)\n            else:\n                pkgs[name] = zf.open(name)\n    return pkgs\n", "def _explore_zipfile(zip_path):\n    tree = ET.parse(zip_path)\n    root = tree.getroot()\n\n    packages = {}\n\n    for child in root:\n        if child.tag == 'package':\n            packages[child.attrib['name']] = child.text\n\n    return packages\n", "def _explore_zipfile(zip_path):\n    zf = zipfile.ZipFile(zip_path)\n    data = {}\n    for filename in zf.namelist():\n        # Ignore the file if it doesn't have a valid content\n        if zf.read(filename).decode() == '':\n            continue\n        path = os.path.dirname(filename)\n        if path == '':\n            path = '.'\n        elif path == '.':\n            path = ''\n        elif path == '..':\n            path = '..'\n        elif path is not None:\n            path = os.path.join(path, filename)\n        data[os.path.basename(filename)] = path\n    return data\n", "def _explore_zipfile(zip_path):\n    tree = ET.parse(zip_path)\n    root = tree.getroot()\n    packages = {}\n\n    for file in root.iter('file'):\n        package = file.attrib['name'].split('-')[0]\n        if not package in packages:\n            packages[package] = [file.attrib['name']]\n        else:\n            packages[package].append(file.attrib['name'])\n\n    return packages\n", "def _explore_zipfile(zip_path):\n    tree = ET.parse(zip_path)\n    root = tree.getroot()\n    data = {}\n    for item in root:\n        if item.tag in ['files','metadata']:\n            data[item.tag] = {}\n            for child in item:\n                if child.tag == 'name':\n                    data[item.tag][child.text] = child.attrib['name']\n                elif child.tag =='version':\n                    data[item.tag][child.text] = child.attrib['version']\n                elif child.tag == 'author':\n                    data[item.tag][child.text] = child.attrib['author']\n                elif child.tag == 'author_email':\n                    data[item.tag][child.text] = child.attrib['author_email']\n                elif child.tag == 'license':\n           "], "level": "file_runnable", "generate_results": [{"generate_code": "def _explore_zipfile(zip_path):\n    data = {}\n    with zipfile.ZipFile(zip_path) as zf:\n        for name in zf.namelist():\n            # Ignore files that are not in the package\n            if name.startswith('__init__.py'):\n                continue\n            data[name] = zf.open(name).read()\n\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    tree = ET.parse(zip_path)\n    root = tree.getroot()\n    data = {}\n    for item in root.findall('item'):\n        data[item.attrib['filename']] = item.text\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    zip_path = _os.path.basename(zip_path)\n    zip_data = {}\n    for root, _, files in _shell.walk(zip_path):\n        for f in files:\n            if _os.path.splitext(f)[1] == '.xml':\n                with open(os.path.join(root, f)) as fp:\n                    zip_data.update(_xml_to_dict(fp.read()))\n    return zip_data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    # remove compression from zip file name\n    zip_path = zip_path.replace(\"\\\\\", \"/\")\n    with zipfile.ZipFile(zip_path) as zf:\n        # get files from zip\n        files = zf.namelist()\n        # get data from zip file\n        data = {}\n        for f in files:\n            if f.endswith(\".xml\"):\n                data[f] = zf.open(f).read()\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    zip_path = Path(zip_path)\n    result = {}\n    for filename in zip_path.glob('*'):\n        filename = filename.with_suffix('')\n        try:\n            data = _read_xml_data(filename)\n        except ValueError:\n            data = None\n        result[filename.name] = data\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        pkgs = {}\n        for name in zf.namelist():\n            pkg_path = os.path.join(zip_path, name)\n            if os.path.isdir(pkg_path):\n                pkgs[name] = _explore_zipfile(pkg_path)\n            else:\n                pkgs[name] = zf.open(name)\n    return pkgs\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    tree = ET.parse(zip_path)\n    root = tree.getroot()\n\n    packages = {}\n\n    for child in root:\n        if child.tag == 'package':\n            packages[child.attrib['name']] = child.text\n\n    return packages\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    zf = zipfile.ZipFile(zip_path)\n    data = {}\n    for filename in zf.namelist():\n        # Ignore the file if it doesn't have a valid content\n        if zf.read(filename).decode() == '':\n            continue\n        path = os.path.dirname(filename)\n        if path == '':\n            path = '.'\n        elif path == '.':\n            path = ''\n        elif path == '..':\n            path = '..'\n        elif path is not None:\n            path = os.path.join(path, filename)\n        data[os.path.basename(filename)] = path\n    return data\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    tree = ET.parse(zip_path)\n    root = tree.getroot()\n    packages = {}\n\n    for file in root.iter('file'):\n        package = file.attrib['name'].split('-')[0]\n        if not package in packages:\n            packages[package] = [file.attrib['name']]\n        else:\n            packages[package].append(file.attrib['name'])\n\n    return packages\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _explore_zipfile(zip_path):\n    tree = ET.parse(zip_path)\n    root = tree.getroot()\n    data = {}\n    for item in root:\n        if item.tag in ['files','metadata']:\n            data[item.tag] = {}\n            for child in item:\n                if child.tag == 'name':\n                    data[item.tag][child.text] = child.attrib['name']\n                elif child.tag =='version':\n                    data[item.tag][child.text] = child.attrib['version']\n                elif child.tag == 'author':\n                    data[item.tag][child.text] = child.attrib['author']\n                elif child.tag == 'author_email':\n                    data[item.tag][child.text] = child.attrib['author_email']\n                elif child.tag == 'license':\n           ", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/file_utils.py", "project": "scieloorg/packtools", "name": "files_list_from_zipfile", "docstring": "Return the files in `zip_path`\n\nExample:\n\n```\n[\n    '2318-0889-tinf-33-0421/2318-0889-tinf-33-e200069.pdf',\n    '2318-0889-tinf-33-0421/2318-0889-tinf-33-e200069.xml',\n    '2318-0889-tinf-33-0421/2318-0889-tinf-33-e200071.pdf',\n    '2318-0889-tinf-33-0421/2318-0889-tinf-33-e200071.xml',\n    '2318-0889-tinf-33-0421/2318-0889-tinf-33-e200071-gf01.tif',\n    '2318-0889-tinf-33-0421/2318-0889-tinf-33-e200071-gf02.tif',\n    '2318-0889-tinf-33-0421/2318-0889-tinf-33-e200071-gf03.tif',\n    '2318-0889-tinf-33-0421/2318-0889-tinf-33-e200071-gf04.tif',\n]\n```", "ques_id": "62b463163879012d194814a6", "code": ["def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return [fname.filename for fname in zf.namelist()]\n", "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return zf.namelist()\n", "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return [f.filename for f in zf.infolist()]\n", "def files_list_from_zipfile(zip_path):\n    with ZipFile(zip_path) as zf:\n        return [fname.filename for fname in zf.filelist]\n", "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        files = zf.namelist()\n    return files\n", "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return [f.filename for f in zf.infolist()]\n", "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zip:\n        return [fname.filename for fname in zip.filelist]\n", "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        names = zf.namelist()\n    return names\n", "def files_list_from_zipfile(zip_path):\n    with ZipFile(zip_path) as zf:\n        files = zf.namelist()\n    return files\n", "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return list(zf.namelist())\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return [fname.filename for fname in zf.namelist()]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return zf.namelist()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return [f.filename for f in zf.infolist()]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with ZipFile(zip_path) as zf:\n        return [fname.filename for fname in zf.filelist]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        files = zf.namelist()\n    return files\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return [f.filename for f in zf.infolist()]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zip:\n        return [fname.filename for fname in zip.filelist]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        names = zf.namelist()\n    return names\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with ZipFile(zip_path) as zf:\n        files = zf.namelist()\n    return files\n", "is_pass": false, "return_code": 1}, {"generate_code": "def files_list_from_zipfile(zip_path):\n    with zipfile.ZipFile(zip_path) as zf:\n        return list(zf.namelist())\n", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/sps/utils/xml_utils.py", "project": "scieloorg/packtools", "name": "fix_namespace_prefix_w", "docstring": "Convert text that defaults to 'w:st=\"' to 'w-st=\"'", "ques_id": "62b4631b3879012d194814dd", "code": ["def fix_namespace_prefix_w(content):\n    return content.replace(' w:st=\"','w-st=\"')\n", "def fix_namespace_prefix_w(content):\n    return re.sub(r'( w:(st=\")(.+?)(\"))', r'\\1-w-st=\"\\2\"', content)\n", "def fix_namespace_prefix_w(content):\n    if content is None:\n        return None\n\n    return content.replace('w:st=\"', 'w-st=\"')\n", "def fix_namespace_prefix_w(content):\n    return content.replace(' w:st=\"','w-st=\"')\n", "def fix_namespace_prefix_w(content):\n    return content.replace(' w:st=\"','w-st=\"')\n", "def fix_namespace_prefix_w(content):\n    return content.replace(' w:st=\"','w-st=\"')\n", "def fix_namespace_prefix_w(content):\n    return content.replace(' w:st=\"','w-st=\"')\n", "def fix_namespace_prefix_w(content):\n    return content.replace(' w:st=\"','w-st=\"')\n", "def fix_namespace_prefix_w(content):\n    return re.sub(r'\\b(w:|st=\")([^\"]+)(\"|\\s+)',\n                  r'\\1-\\2-w-st=\"\\3\"', content)\n", "def fix_namespace_prefix_w(content):\n    return content.replace('w:st=\"', 'w-st=\"')\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def fix_namespace_prefix_w(content):\n    return content.replace(' w:st=\"','w-st=\"')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    return re.sub(r'( w:(st=\")(.+?)(\"))', r'\\1-w-st=\"\\2\"', content)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    if content is None:\n        return None\n\n    return content.replace('w:st=\"', 'w-st=\"')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    return content.replace(' w:st=\"','w-st=\"')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    return content.replace(' w:st=\"','w-st=\"')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    return content.replace(' w:st=\"','w-st=\"')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    return content.replace(' w:st=\"','w-st=\"')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    return content.replace(' w:st=\"','w-st=\"')\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    return re.sub(r'\\b(w:|st=\")([^\"]+)(\"|\\s+)',\n                  r'\\1-\\2-w-st=\"\\3\"', content)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fix_namespace_prefix_w(content):\n    return content.replace('w:st=\"', 'w-st=\"')\n", "is_pass": true, "return_code": 0}]}
{"file_path": "packtools/sps/utils/xml_utils.py", "project": "scieloorg/packtools", "name": "match_pubdate", "docstring": "Returns the first match in the pubdate_xpaths list", "ques_id": "62b463283879012d1948153d", "code": ["def match_pubdate(node, pubdate_xpaths):\n    return next(\n        (\n            elem\n            for elem in node\n            if isinstance(elem, Pubdate)\n            and elem.xpath(pubdate_xpaths)\n        ),\n        None,\n    )\n", "def match_pubdate(node, pubdate_xpaths):\n    return next((x for x in pubdate_xpaths if x.match(node)), None)\n", "def match_pubdate(node, pubdate_xpaths):\n    return next((\n        x for x in pubdate_xpaths\n        if x.match(node)\n    ), None)\n", "def match_pubdate(node, pubdate_xpaths):\n    return next(\n        (\n            x\n            for x in pubdate_xpaths\n            if x.search(node.text)\n        ),\n        None,\n    )\n", "def match_pubdate(node, pubdate_xpaths):\n    for pubdate_xpath in pubdate_xpaths:\n        result = pubdate_xpath(node)\n        if result:\n            return result\n", "def match_pubdate(node, pubdate_xpaths):\n    return next((x for x in pubdate_xpaths if x.match(node)), None)\n", "def match_pubdate(node, pubdate_xpaths):\n    return next((item for item in pubdate_xpaths if match_path(node, item)), None)\n", "def match_pubdate(node, pubdate_xpaths):\n    return next((x for x in pubdate_xpaths if x.match(node)), None)\n", "def match_pubdate(node, pubdate_xpaths):\n    for pubdate_xpath in pubdate_xpaths:\n        match = pubdate_xpath(node)\n        if match:\n            return match\n", "def match_pubdate(node, pubdate_xpaths):\n    return next((\n        node.xpath(pubdate_xpaths[0]),\n        node.xpath(pubdate_xpaths[1])\n    ), None)\n"], "level": "self_contained", "generate_results": [{"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    return next(\n        (\n            elem\n            for elem in node\n            if isinstance(elem, Pubdate)\n            and elem.xpath(pubdate_xpaths)\n        ),\n        None,\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    return next((x for x in pubdate_xpaths if x.match(node)), None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    return next((\n        x for x in pubdate_xpaths\n        if x.match(node)\n    ), None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    return next(\n        (\n            x\n            for x in pubdate_xpaths\n            if x.search(node.text)\n        ),\n        None,\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    for pubdate_xpath in pubdate_xpaths:\n        result = pubdate_xpath(node)\n        if result:\n            return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    return next((x for x in pubdate_xpaths if x.match(node)), None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    return next((item for item in pubdate_xpaths if match_path(node, item)), None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    return next((x for x in pubdate_xpaths if x.match(node)), None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    for pubdate_xpath in pubdate_xpaths:\n        match = pubdate_xpath(node)\n        if match:\n            return match\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match_pubdate(node, pubdate_xpaths):\n    return next((\n        node.xpath(pubdate_xpaths[0]),\n        node.xpath(pubdate_xpaths[1])\n    ), None)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "packtools/sps/models/front_articlemeta_issue.py", "project": "scieloorg/packtools", "name": "_extract_number_and_supplment_from_issue_element", "docstring": "Extract the possible values of number and suppl from the contents of issue.", "ques_id": "62b463303879012d19481579", "code": ["def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('number').text\n    suppl = issue.find('suppl').text\n    return number, suppl\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = ''\n    suppl = ''\n    for element in issue:\n        if element.tag == 'number':\n            number = element.text\n        elif element.tag =='supplement':\n            suppl = element.text\n    return number, suppl\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('.//number').text\n    suppl = issue.find('.//suppl').text\n    return number, suppl\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = ''\n    suppl = ''\n    if issue.find('xbrli:Number', namespaces=NSMAP) is not None:\n        number = issue.find('xbrli:Number', namespaces=NSMAP).text\n    if issue.find('xbrli:Supplement', namespaces=NSMAP) is not None:\n        suppl = issue.find('xbrli:Supplement', namespaces=NSMAP).text\n    return number, suppl\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = None\n    suppl = None\n    for element in issue.find_all('element'):\n        if 'type' in element.attrib:\n            if element.attrib['type'] == 'number':\n                number = element.text\n            elif element.attrib['type'] =='supplement':\n                suppl = element.text\n    return number, suppl\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = None\n    suppl = None\n\n    if \"number\" in issue.attrib:\n        number = issue.attrib[\"number\"]\n\n    if \"suppl\" in issue.attrib:\n        suppl = issue.attrib[\"suppl\"]\n\n    return number, suppl\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('Number').text\n    suppl = issue.find('Supply').text\n\n    return number, suppl\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('number').text\n    suppl = issue.find('suppl').text\n\n    return number, suppl\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = None\n    suppl = None\n    for element in issue.iter('field'):\n        if element.attrib['name'].lower() == 'number':\n            number = element.text\n        elif element.attrib['name'].lower() =='suppl':\n            suppl = element.text\n    return number, suppl\n", "def _extract_number_and_supplment_from_issue_element(issue):\n    number = ''\n    suppl = ''\n\n    if 'number' in issue.attrib:\n        number = issue.attrib['number']\n\n    if'suppl' in issue.attrib:\n        suppl = issue.attrib['suppl']\n\n    return number, suppl\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('number').text\n    suppl = issue.find('suppl').text\n    return number, suppl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = ''\n    suppl = ''\n    for element in issue:\n        if element.tag == 'number':\n            number = element.text\n        elif element.tag =='supplement':\n            suppl = element.text\n    return number, suppl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('.//number').text\n    suppl = issue.find('.//suppl').text\n    return number, suppl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = ''\n    suppl = ''\n    if issue.find('xbrli:Number', namespaces=NSMAP) is not None:\n        number = issue.find('xbrli:Number', namespaces=NSMAP).text\n    if issue.find('xbrli:Supplement', namespaces=NSMAP) is not None:\n        suppl = issue.find('xbrli:Supplement', namespaces=NSMAP).text\n    return number, suppl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = None\n    suppl = None\n    for element in issue.find_all('element'):\n        if 'type' in element.attrib:\n            if element.attrib['type'] == 'number':\n                number = element.text\n            elif element.attrib['type'] =='supplement':\n                suppl = element.text\n    return number, suppl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = None\n    suppl = None\n\n    if \"number\" in issue.attrib:\n        number = issue.attrib[\"number\"]\n\n    if \"suppl\" in issue.attrib:\n        suppl = issue.attrib[\"suppl\"]\n\n    return number, suppl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('Number').text\n    suppl = issue.find('Supply').text\n\n    return number, suppl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = issue.find('number').text\n    suppl = issue.find('suppl').text\n\n    return number, suppl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = None\n    suppl = None\n    for element in issue.iter('field'):\n        if element.attrib['name'].lower() == 'number':\n            number = element.text\n        elif element.attrib['name'].lower() =='suppl':\n            suppl = element.text\n    return number, suppl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _extract_number_and_supplment_from_issue_element(issue):\n    number = ''\n    suppl = ''\n\n    if 'number' in issue.attrib:\n        number = issue.attrib['number']\n\n    if'suppl' in issue.attrib:\n        suppl = issue.attrib['suppl']\n\n    return number, suppl\n", "is_pass": false, "return_code": 1}]}
{"file_path": "boolean/boolean.py", "project": "bastikr/boolean", "name": "pretty", "docstring": "Return a pretty formatted representation of self.", "ques_id": "62b46740d2f69a53b466171a", "code": ["def pretty(self, indent=0, debug=False):\n    spaces = \" \" * indent\n    return \"{}{}\".format(spaces, self.__class__.__name__)\n", "def pretty(self, indent=0, debug=False):\n    lines = []\n    for child in self:\n        if isinstance(child, list):\n            lines.append(child.pretty(indent=indent+1, debug=debug))\n        else:\n            lines.append(\"{}{}\".format(\"  \" * indent, child))\n    return \"\\n\".join(lines)\n", "def pretty(self, indent=0, debug=False):\n    s = ''\n    if debug:\n        s +='' * indent\n        s +=''.join(['{}{}'.format(''* indent, k)\n                      for k in sorted(self)])\n        s += '\\n'\n    else:\n        s +='' * indent + '// {}'.format(self.__class__.__name__)\n        s += '\\n'\n    for k, v in sorted(self.items()):\n        s += '\\n'\n        s +='' * indent + '{}: {}'.format(k, v)\n        s += '\\n'\n    return s\n", "def pretty(self, indent=0, debug=False):\n    lines = []\n    for line in self:\n        if debug:\n            print(\" \" * indent + str(line))\n            lines.append(str(line))\n        else:\n            lines.append(line.pretty(indent))\n    return \"\\n\".join(lines)\n", "def pretty(self, indent=0, debug=False):\n    lines = []\n    indent_str = \" \" * indent\n    s = \"{}{}\".format(indent_str, self.name)\n    if self.description:\n        s += \"\\n{}\".format(indent_str)\n        s += self.description\n    lines.append(s)\n    for arg in self.arguments:\n        arg.pretty(indent + 2, debug)\n    return \"\\n\".join(lines)\n", "def pretty(self, indent=0, debug=False):\n    lines = []\n    for node in self:\n        if not isinstance(node, AST):\n            continue\n        lines.append(\"%s%s\" % (\" \" * indent, node))\n        for line in node.pretty(indent + 2, debug):\n            lines.append(line)\n    return \"\\n\".join(lines)\n", "def pretty(self, indent=0, debug=False):\n    result = \"\"\n    if debug:\n        result += \"  \" * indent + \"-- \" + str(self) + \"\\n\"\n\n    for child in self.children:\n        result += child.pretty(indent + 2, debug)\n    return result\n", "def pretty(self, indent=0, debug=False):\n    output = ''\n    if debug:\n        output +='' * indent + '-- INPUT: %s -- OUTPUT:\\n' % self.name\n        output += pprint.pformat(self.input, indent=indent)\n        output +='' * indent + '-- OUTPUT: %s -- DURATION: %s\\n' % (self.name, self.duration)\n        output +='' * indent + '-- OUTPUT: %s -- STATE: %s\\n' % (self.name, self.state)\n        output +='' * indent + '-- OUTPUT: %s -- STATE TIME: %s\\n' % (self.name, self.state_time)\n        output +='' * indent + '-- OUTPUT: %s -- EXPECTED OUTPUT: %s\\n' % (self.name, self.expected_output)\n        output +='' * indent + '-- OUTPUT: %s -- CLASS: %s\\n' % (self.name, self.expected_output_class)\n        output +='' * indent + '-- OUTPUT: %s -- METHOD: %s\\n' % ", "def pretty(self, indent=0, debug=False):\n    indent_str ='' * indent\n    s = '{}(\\n'.format(self.__class__.__name__)\n    for k in sorted(self.__dict__):\n        v = self.__dict__[k]\n        if isinstance(v, Tensor):\n            s += '\\t' + k + ':'+ str(v) + ',\\n'\n        else:\n            s += '\\t' + k + ':'+ repr(v) + ',\\n'\n    s += ')'\n    return indent_str + s\n", "def pretty(self, indent=0, debug=False):\n    string = \"\"\n    if self.name:\n        string += \"{}: \".format(self.name)\n    string += \"{}\".format(self.value)\n    if self.comment:\n        string += \" / {}\".format(self.comment)\n    if indent:\n        string += \"\\n\" + (\" \" * indent)\n    return string\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def pretty(self, indent=0, debug=False):\n    spaces = \" \" * indent\n    return \"{}{}\".format(spaces, self.__class__.__name__)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    lines = []\n    for child in self:\n        if isinstance(child, list):\n            lines.append(child.pretty(indent=indent+1, debug=debug))\n        else:\n            lines.append(\"{}{}\".format(\"  \" * indent, child))\n    return \"\\n\".join(lines)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    s = ''\n    if debug:\n        s +='' * indent\n        s +=''.join(['{}{}'.format(''* indent, k)\n                      for k in sorted(self)])\n        s += '\\n'\n    else:\n        s +='' * indent + '// {}'.format(self.__class__.__name__)\n        s += '\\n'\n    for k, v in sorted(self.items()):\n        s += '\\n'\n        s +='' * indent + '{}: {}'.format(k, v)\n        s += '\\n'\n    return s\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    lines = []\n    for line in self:\n        if debug:\n            print(\" \" * indent + str(line))\n            lines.append(str(line))\n        else:\n            lines.append(line.pretty(indent))\n    return \"\\n\".join(lines)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    lines = []\n    indent_str = \" \" * indent\n    s = \"{}{}\".format(indent_str, self.name)\n    if self.description:\n        s += \"\\n{}\".format(indent_str)\n        s += self.description\n    lines.append(s)\n    for arg in self.arguments:\n        arg.pretty(indent + 2, debug)\n    return \"\\n\".join(lines)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    lines = []\n    for node in self:\n        if not isinstance(node, AST):\n            continue\n        lines.append(\"%s%s\" % (\" \" * indent, node))\n        for line in node.pretty(indent + 2, debug):\n            lines.append(line)\n    return \"\\n\".join(lines)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    result = \"\"\n    if debug:\n        result += \"  \" * indent + \"-- \" + str(self) + \"\\n\"\n\n    for child in self.children:\n        result += child.pretty(indent + 2, debug)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    output = ''\n    if debug:\n        output +='' * indent + '-- INPUT: %s -- OUTPUT:\\n' % self.name\n        output += pprint.pformat(self.input, indent=indent)\n        output +='' * indent + '-- OUTPUT: %s -- DURATION: %s\\n' % (self.name, self.duration)\n        output +='' * indent + '-- OUTPUT: %s -- STATE: %s\\n' % (self.name, self.state)\n        output +='' * indent + '-- OUTPUT: %s -- STATE TIME: %s\\n' % (self.name, self.state_time)\n        output +='' * indent + '-- OUTPUT: %s -- EXPECTED OUTPUT: %s\\n' % (self.name, self.expected_output)\n        output +='' * indent + '-- OUTPUT: %s -- CLASS: %s\\n' % (self.name, self.expected_output_class)\n        output +='' * indent + '-- OUTPUT: %s -- METHOD: %s\\n' % ", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    indent_str ='' * indent\n    s = '{}(\\n'.format(self.__class__.__name__)\n    for k in sorted(self.__dict__):\n        v = self.__dict__[k]\n        if isinstance(v, Tensor):\n            s += '\\t' + k + ':'+ str(v) + ',\\n'\n        else:\n            s += '\\t' + k + ':'+ repr(v) + ',\\n'\n    s += ')'\n    return indent_str + s\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pretty(self, indent=0, debug=False):\n    string = \"\"\n    if self.name:\n        string += \"{}: \".format(self.name)\n    string += \"{}\".format(self.value)\n    if self.comment:\n        string += \" / {}\".format(self.comment)\n    if indent:\n        string += \"\\n\" + (\" \" * indent)\n    return string\n", "is_pass": false, "return_code": 1}]}
{"file_path": "boolean/boolean.py", "project": "bastikr/boolean", "name": "absorb", "docstring": "Given an `args` sequence of expressions, return a new list of expression\napplying absorption and negative absorption.\n\nSee https://en.wikipedia.org/wiki/Absorption_law\n\nAbsorption::\n\n    A & (A | B) = A, A | (A & B) = A\n\nNegative absorption::\n\n    A & (~A | B) = A & B, A | (~A & B) = A | B", "ques_id": "62b46746d2f69a53b4661722", "code": ["def absorb(self, args):\n    return [absorb_expr(arg) for arg in args]\n", "def absorb(self, args):\n    if len(args) == 1:\n        return args[0] | self\n    else:\n        return AND(self, args[0]) | AND(args[1], self)\n", "def absorb(self, args):\n    if len(args) == 1:\n        return args[0] | self\n    elif len(args) == 2:\n        return args[0] & args[1]\n    else:\n        raise ValueError(\"Cannot absorb more than two expressions\")\n", "def absorb(self, args):\n    return [a | b for a, b in zip(args[:-1], args[1:])]\n", "def absorb(self, args):\n    return [arg | ~arg for arg in args]\n", "def absorb(self, args):\n    return [a | b for a, b in zip(args[:-1], args[1:])]\n", "def absorb(self, args):\n    return [a | b for a, b in zip(args[:-1], args[1:])]\n", "def absorb(self, args):\n\n    if len(args) == 1:\n        return args[0] | self\n    elif len(args) == 2:\n        return args[0] & args[1]\n    else:\n        raise NotImplementedError(\"Not yet implemented\")\n", "def absorb(self, args):\n    if len(args) == 1:\n        return args[0]\n\n    result = []\n    for arg in args:\n        result.append(arg | ~arg)\n\n    return result\n", "def absorb(self, args):\n\n    args = list(args)\n\n    if len(args) == 1:\n        return args[0]\n\n    if len(args) % 2!= 0:\n        args.append(~args[-1])\n\n    return Expression(*args)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def absorb(self, args):\n    return [absorb_expr(arg) for arg in args]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def absorb(self, args):\n    if len(args) == 1:\n        return args[0] | self\n    else:\n        return AND(self, args[0]) | AND(args[1], self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def absorb(self, args):\n    if len(args) == 1:\n        return args[0] | self\n    elif len(args) == 2:\n        return args[0] & args[1]\n    else:\n        raise ValueError(\"Cannot absorb more than two expressions\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def absorb(self, args):\n    return [a | b for a, b in zip(args[:-1], args[1:])]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def absorb(self, args):\n    return [arg | ~arg for arg in args]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def absorb(self, args):\n    return [a | b for a, b in zip(args[:-1], args[1:])]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def absorb(self, args):\n    return [a | b for a, b in zip(args[:-1], args[1:])]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def absorb(self, args):\n\n    if len(args) == 1:\n        return args[0] | self\n    elif len(args) == 2:\n        return args[0] & args[1]\n    else:\n        raise NotImplementedError(\"Not yet implemented\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def absorb(self, args):\n    if len(args) == 1:\n        return args[0]\n\n    result = []\n    for arg in args:\n        result.append(arg | ~arg)\n\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def absorb(self, args):\n\n    args = list(args)\n\n    if len(args) == 1:\n        return args[0]\n\n    if len(args) % 2!= 0:\n        args.append(~args[-1])\n\n    return Expression(*args)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/krake/controller/kubernetes/hooks.py", "project": "rak-n-rok/Krake", "name": "on", "docstring": "Decorator function to add a new handler to the registry.\n\nArgs:\n    hook (HookType): Hook attribute for which to register the handler.\n\nReturns:\n    callable: Decorator for registering listeners for the specified\n    hook.", "ques_id": "62b86707b4d922cb0e688c2a", "code": ["def on(self, hook):\n    def register_listener(listener):\n        self._hooks[hook].append(listener)\n    return register_listener\n", "def on(self, hook):\n    def register_listener(handler):\n        self._hooks[hook].append(handler)\n        return handler\n\n    return register_listener\n", "def on(self, hook):\n\n    def decorator(func):\n        if hook not in self._listeners:\n            self._listeners[hook] = []\n        self._listeners[hook].append(func)\n        return func\n\n    return decorator\n", "def on(self, hook):\n    def wrapper(callback):\n        self[hook].append(callback)\n        return callback\n    return wrapper\n", "def on(self, hook):\n\n    def register_listener(callback):\n        if hook not in self._listeners:\n            self._listeners[hook] = [callback]\n        else:\n            self._listeners[hook].append(callback)\n        return callback\n\n    return register_listener\n", "def on(self, hook):\n\n    def decorator(func):\n        if hook not in self._registry:\n            self._registry[hook] = []\n        self._registry[hook].append(func)\n        return func\n\n    return decorator\n", "def on(self, hook):\n    def register_listener(listener):\n        if hook not in self._listeners:\n            self._listeners[hook] = []\n        self._listeners[hook].append(listener)\n    return register_listener\n", "def on(self, hook):\n    def decorator(func):\n        self._hooks[hook].append(func)\n        return func\n    return decorator\n", "def on(self, hook):\n    def decorator(listener):\n        if hook not in self._listeners:\n            self._listeners[hook] = []\n        self._listeners[hook].append(listener)\n        return listener\n    return decorator\n", "def on(self, hook):\n    def register_listener(listener):\n        self._listeners[hook].append(listener)\n    return register_listener\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def on(self, hook):\n    def register_listener(listener):\n        self._hooks[hook].append(listener)\n    return register_listener\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n    def register_listener(handler):\n        self._hooks[hook].append(handler)\n        return handler\n\n    return register_listener\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n\n    def decorator(func):\n        if hook not in self._listeners:\n            self._listeners[hook] = []\n        self._listeners[hook].append(func)\n        return func\n\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n    def wrapper(callback):\n        self[hook].append(callback)\n        return callback\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n\n    def register_listener(callback):\n        if hook not in self._listeners:\n            self._listeners[hook] = [callback]\n        else:\n            self._listeners[hook].append(callback)\n        return callback\n\n    return register_listener\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n\n    def decorator(func):\n        if hook not in self._registry:\n            self._registry[hook] = []\n        self._registry[hook].append(func)\n        return func\n\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n    def register_listener(listener):\n        if hook not in self._listeners:\n            self._listeners[hook] = []\n        self._listeners[hook].append(listener)\n    return register_listener\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n    def decorator(func):\n        self._hooks[hook].append(func)\n        return func\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n    def decorator(listener):\n        if hook not in self._listeners:\n            self._listeners[hook] = []\n        self._listeners[hook].append(listener)\n        return listener\n    return decorator\n", "is_pass": false, "return_code": 1}, {"generate_code": "def on(self, hook):\n    def register_listener(listener):\n        self._listeners[hook].append(listener)\n    return register_listener\n", "is_pass": false, "return_code": 1}]}
{"file_path": "krake/tests/conftest.py", "project": "rak-n-rok/Krake", "name": "base_config", "docstring": "Creates a configuration with some simple parameters, which have a default value\nthat can be set.\n\nArgs:\n    user (str): the name of the user for the static authentication\n    etcd_host (str): the host for the database.\n    etcd_port (int): the port for the database.\n\nReturns:\n    dict: the created configuration.", "ques_id": "62b86729b4d922cb0e688c2f", "code": ["def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"database\": {\n            \"name\": \"test\",\n            \"user\": \"test\",\n            \"password\": \"test\",\n            \"host\": \"localhost\",\n            \"port\": etcd_port,\n            \"ssl\": False,\n            \"certificate\": \"\",\n            \"privatekey\": \"\",\n            \"ca\": \"\",\n            \"certificate_chain\": \"\",\n            \"key_password\": \"\",\n            \"retries\": 3,\n            \"timeout\": 3,\n            \"sudo\": True,\n            \"max_retries\": 1,\n        },\n    }\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"password\": \"\",\n        \"key\": \"\",\n        \"cert\": \"\",\n        \"cacert\": \"\",\n        \"certificate_chain\": \"\",\n    }\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"password\": \"password\",\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"database\": {\n            \"user\": \"user\",\n            \"password\": \"password\"\n        }\n    }\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"database_password\": \"password\",\n    }\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"host\": etcd_host,\n        \"port\": etcd_port,\n        \"db\": \"testdb\",\n        \"prefix\": \"prefix\",\n        \"password\": \"password\",\n        \"write_only\": False,\n        \"ssl\": False,\n        \"verify\": False,\n        \"cert\": \"\",\n        \"key\": \"\",\n        \"cert_chain\": \"\",\n        \"node_cert\": \"\",\n        \"node_key\": \"\",\n        \"cert_chain_password\": \"\",\n        \"node_cert_password\": \"\",\n        \"secure\": False,\n        \"secure_ca_cert\": \"\",\n        \"secure_ca_key\": \"\",\n        \"secure_cert_chain\": \"\",\n        \"secure_cert_key\": \"\",\n        \"secure_ca_cert_password\": \"\",\n    }\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"auth\": {\n            \"user\": \"\",\n            \"password\": \"\"\n        }\n    }\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"api_key\": None,\n        \"api_secret\": None,\n        \"expiration\": None,\n        \"refresh\": None,\n        \"token\": None,\n        \"token_expiration\": None,\n    }\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"password\": \"\",\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n    }\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"static_auth\": {\n            \"user\": {\"default\": \"\"},\n            \"password\": {\"default\": \"\"},\n        },\n        \"auth_secret\": {\"default\": \"\"},\n        \"auth_secret_expire\": {\"default\": \"\"},\n        \"auth_secret_type\": {\"default\": \"\"},\n    }\n", "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    config = {\n        \"user\": user,\n        \"password\": \"\",\n        \"encryption\": {\n            \"mode\": \"AES256\",\n            \"key\": \"\",\n            \"iv\": \"\",\n            \"key_pass\": \"\",\n        },\n        \"recovery_strategy\": {\n            \"mode\": \"SYNCHRONIZE\",\n            \"recovery_database\": {\n                \"host\": etcd_host,\n                \"port\": etcd_port,\n            },\n        },\n    }\n    return config\n"], "level": "self_contained", "generate_results": [{"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"database\": {\n            \"name\": \"test\",\n            \"user\": \"test\",\n            \"password\": \"test\",\n            \"host\": \"localhost\",\n            \"port\": etcd_port,\n            \"ssl\": False,\n            \"certificate\": \"\",\n            \"privatekey\": \"\",\n            \"ca\": \"\",\n            \"certificate_chain\": \"\",\n            \"key_password\": \"\",\n            \"retries\": 3,\n            \"timeout\": 3,\n            \"sudo\": True,\n            \"max_retries\": 1,\n        },\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"password\": \"\",\n        \"key\": \"\",\n        \"cert\": \"\",\n        \"cacert\": \"\",\n        \"certificate_chain\": \"\",\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"password\": \"password\",\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"database\": {\n            \"user\": \"user\",\n            \"password\": \"password\"\n        }\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"database_password\": \"password\",\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"host\": etcd_host,\n        \"port\": etcd_port,\n        \"db\": \"testdb\",\n        \"prefix\": \"prefix\",\n        \"password\": \"password\",\n        \"write_only\": False,\n        \"ssl\": False,\n        \"verify\": False,\n        \"cert\": \"\",\n        \"key\": \"\",\n        \"cert_chain\": \"\",\n        \"node_cert\": \"\",\n        \"node_key\": \"\",\n        \"cert_chain_password\": \"\",\n        \"node_cert_password\": \"\",\n        \"secure\": False,\n        \"secure_ca_cert\": \"\",\n        \"secure_ca_key\": \"\",\n        \"secure_cert_chain\": \"\",\n        \"secure_cert_key\": \"\",\n        \"secure_ca_cert_password\": \"\",\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"auth\": {\n            \"user\": \"\",\n            \"password\": \"\"\n        }\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"api_key\": None,\n        \"api_secret\": None,\n        \"expiration\": None,\n        \"refresh\": None,\n        \"token\": None,\n        \"token_expiration\": None,\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"password\": \"\",\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    return {\n        \"user\": user,\n        \"etcd_host\": etcd_host,\n        \"etcd_port\": etcd_port,\n        \"static_auth\": {\n            \"user\": {\"default\": \"\"},\n            \"password\": {\"default\": \"\"},\n        },\n        \"auth_secret\": {\"default\": \"\"},\n        \"auth_secret_expire\": {\"default\": \"\"},\n        \"auth_secret_type\": {\"default\": \"\"},\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def base_config(user, etcd_host=\"localhost\", etcd_port=2379):\n    config = {\n        \"user\": user,\n        \"password\": \"\",\n        \"encryption\": {\n            \"mode\": \"AES256\",\n            \"key\": \"\",\n            \"iv\": \"\",\n            \"key_pass\": \"\",\n        },\n        \"recovery_strategy\": {\n            \"mode\": \"SYNCHRONIZE\",\n            \"recovery_database\": {\n                \"host\": etcd_host,\n                \"port\": etcd_port,\n            },\n        },\n    }\n    return config\n", "is_pass": false, "return_code": 1}]}
{"file_path": "dateutil/tz/_common.py", "project": "pexip/os-python-dateutil", "name": "_fromutc", "docstring": "Given a timezone-aware datetime in a given timezone, calculates a\ntimezone-aware datetime in a new timezone.\n\nSince this is the one time that we *know* we have an unambiguous\ndatetime object, we take this opportunity to determine whether the\ndatetime is ambiguous and in a \"fold\" state (e.g. if it's the first\noccurrence, chronologically, of the ambiguous datetime).\n\n:param dt:\n    A timezone-aware :class:`datetime.datetime` object.", "ques_id": "62b8a4a4755ee91dce50a3d2", "code": ["def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=UTC)\n    return dt.astimezone(UTC)\n", "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        # For consistency with pytz, this is always the case.\n        return dt\n\n    return dt.astimezone(self)\n", "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=utc)\n\n    return dt.astimezone(self)\n", "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=timezone.utc)\n\n    return dt.astimezone(timezone.utc)\n", "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=pytz.utc)\n\n    return dt.astimezone(pytz.utc)\n", "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self)\n    return dt.astimezone(self)\n", "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=UTC)\n    else:\n        return dt.astimezone(UTC)\n", "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=timezone.utc)\n\n    return dt.astimezone(timezone.utc)\n", "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=UTC)\n\n    return dt.astimezone(UTC)\n", "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=UTC)\n\n    return dt.astimezone(self)\n"], "level": "self_contained", "generate_results": [{"generate_code": "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=UTC)\n    return dt.astimezone(UTC)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        # For consistency with pytz, this is always the case.\n        return dt\n\n    return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=utc)\n\n    return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=timezone.utc)\n\n    return dt.astimezone(timezone.utc)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=pytz.utc)\n\n    return dt.astimezone(pytz.utc)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=self)\n    return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=UTC)\n    else:\n        return dt.astimezone(UTC)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=timezone.utc)\n\n    return dt.astimezone(timezone.utc)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=UTC)\n\n    return dt.astimezone(UTC)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _fromutc(self, dt):\n    if dt.tzinfo is None:\n        return dt.replace(tzinfo=UTC)\n\n    return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "dateutil/relativedelta.py", "project": "pexip/os-python-dateutil", "name": "normalized", "docstring": "Return a version of this object represented entirely using integer\nvalues for the relative attributes.\n\n>>> relativedelta(days=1.5, hours=2).normalized()\nrelativedelta(days=+1, hours=+14)\n\n:return:\n    Returns a :class:`dateutil.relativedelta.relativedelta` object.", "ques_id": "62b8982f755ee91dce50a241", "code": ["def normalized(self):\n    return relativedelta(**dict([(key, getattr(self, key)) for key in self._relative_keys]))\n", "def normalized(self):\n    return relativedelta(**{k: v for k, v in vars(self).items() if not k.startswith('_')})\n", "def normalized(self):\n    return relativedelta(days=self.days, hours=self.hours)\n", "def normalized(self):\n\n    return relativedelta(\n        days=self.days,\n        hours=self.hours,\n        minutes=self.minutes,\n        seconds=self.seconds,\n        microseconds=self.microseconds,\n    )\n", "def normalized(self):\n    return relativedelta(**dict(self))\n", "def normalized(self):\n\n    return relativedelta(**{k: int(v) for k, v in self.__dict__.items() if not k.startswith('_')})\n", "def normalized(self):\n    return relativedelta(**{k: getattr(self, k) for k in self.RELATIVE_ATTRS})\n", "def normalized(self):\n    return relativedelta(**{k: int(v) for k, v in self._attributes.items()})\n", "def normalized(self):\n    return relativedelta(**{k: int(v) for k, v in vars(self).items() if not k.startswith('_')})\n", "def normalized(self):\n    return relativedelta(days=self.days, hours=self.hours)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def normalized(self):\n    return relativedelta(**dict([(key, getattr(self, key)) for key in self._relative_keys]))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n    return relativedelta(**{k: v for k, v in vars(self).items() if not k.startswith('_')})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n    return relativedelta(days=self.days, hours=self.hours)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n\n    return relativedelta(\n        days=self.days,\n        hours=self.hours,\n        minutes=self.minutes,\n        seconds=self.seconds,\n        microseconds=self.microseconds,\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n    return relativedelta(**dict(self))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n\n    return relativedelta(**{k: int(v) for k, v in self.__dict__.items() if not k.startswith('_')})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n    return relativedelta(**{k: getattr(self, k) for k in self.RELATIVE_ATTRS})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n    return relativedelta(**{k: int(v) for k, v in self._attributes.items()})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n    return relativedelta(**{k: int(v) for k, v in vars(self).items() if not k.startswith('_')})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def normalized(self):\n    return relativedelta(days=self.days, hours=self.hours)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "dateutil/tz/_common.py", "project": "pexip/os-python-dateutil", "name": "tzname_in_python2", "docstring": "Change unicode output into bytestrings in Python 2\n\ntzname() API changed in Python 3. It used to return bytes, but was changed\nto unicode strings", "ques_id": "62b89640755ee91dce50a114", "code": ["def tzname_in_python2(namefunc):\n    def adjust_encoding(*args, **kwargs):\n        name = namefunc(*args, **kwargs)\n        if name is not None:\n            name = name.encode()\n        return name\n\n    return adjust_encoding\n", "def tzname_in_python2(namefunc):\n    namefunc(lambda x: x.encode(\"utf-8\"))\n", "def tzname_in_python2(namefunc):\n\n    def wrapper(self, dt):\n        if self.tzinfo is None:\n            return namefunc(self, dt)\n        else:\n            return namefunc(self, dt).astimezone(self.tzinfo)\n\n    return wrapper\n", "def tzname_in_python2(namefunc):\n    def inner(self, dt):\n        return namefunc(self._name_unicode(dt))\n    return inner\n", "def tzname_in_python2(namefunc):\n\n    def wrapper(self, name=None):\n        name = name or self.name\n        return namefunc(name)\n\n    return wrapper\n", "def tzname_in_python2(namefunc):\n    def wrapper(self, *args, **kwargs):\n        name = namefunc(self, *args, **kwargs)\n        if not PY3:\n            name = name.encode()\n        return name\n    return wrapper\n", "def tzname_in_python2(namefunc):\n    def _wrapper(self, *args, **kwargs):\n        name = namefunc(self, *args, **kwargs)\n        if name is not None and not PY3:\n            name = name.encode()\n\n        return name\n\n    return _wrapper\n", "def tzname_in_python2(namefunc):\n    name = namefunc()\n\n    def _convert(value, force=False):\n        if force or (name is not None and isinstance(value, bytes)):\n            return value\n        if isinstance(value, datetime):\n            return value.astimezone(tzlocal()).encode('utf-8')\n        if isinstance(value, date):\n            return value.astimezone(tzlocal()).encode('utf-8')\n        return value\n\n    return _convert\n", "def tzname_in_python2(namefunc):\n\n    def wrapper(self):\n        name = namefunc(self)\n        if name is not None:\n            self.name = __builtin__.bytestr(name)\n\n    return wrapper\n", "def tzname_in_python2(namefunc):\n\n    def inner(self, dt_arg):\n        name = namefunc(self, dt_arg)\n        if name is not None:\n            name = name.encode('utf-8')\n        return name\n\n    return inner\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def tzname_in_python2(namefunc):\n    def adjust_encoding(*args, **kwargs):\n        name = namefunc(*args, **kwargs)\n        if name is not None:\n            name = name.encode()\n        return name\n\n    return adjust_encoding\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n    namefunc(lambda x: x.encode(\"utf-8\"))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n\n    def wrapper(self, dt):\n        if self.tzinfo is None:\n            return namefunc(self, dt)\n        else:\n            return namefunc(self, dt).astimezone(self.tzinfo)\n\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n    def inner(self, dt):\n        return namefunc(self._name_unicode(dt))\n    return inner\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n\n    def wrapper(self, name=None):\n        name = name or self.name\n        return namefunc(name)\n\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n    def wrapper(self, *args, **kwargs):\n        name = namefunc(self, *args, **kwargs)\n        if not PY3:\n            name = name.encode()\n        return name\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n    def _wrapper(self, *args, **kwargs):\n        name = namefunc(self, *args, **kwargs)\n        if name is not None and not PY3:\n            name = name.encode()\n\n        return name\n\n    return _wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n    name = namefunc()\n\n    def _convert(value, force=False):\n        if force or (name is not None and isinstance(value, bytes)):\n            return value\n        if isinstance(value, datetime):\n            return value.astimezone(tzlocal()).encode('utf-8')\n        if isinstance(value, date):\n            return value.astimezone(tzlocal()).encode('utf-8')\n        return value\n\n    return _convert\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n\n    def wrapper(self):\n        name = namefunc(self)\n        if name is not None:\n            self.name = __builtin__.bytestr(name)\n\n    return wrapper\n", "is_pass": false, "return_code": 1}, {"generate_code": "def tzname_in_python2(namefunc):\n\n    def inner(self, dt_arg):\n        name = namefunc(self, dt_arg)\n        if name is not None:\n            name = name.encode('utf-8')\n        return name\n\n    return inner\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/prestoplot/_version.py", "project": "eykd/prestoplot", "name": "get_versions", "docstring": "Get version information or return default if unable to do so.", "ques_id": "62b87d24d292efb640a55670", "code": ["def get_versions():\n    try:\n        from pkg_resources import iter_entry_points\n    except ImportError:\n        return {\n           'version': __version__,\n            'dependencies': {},\n        }\n    return {\n       'version': next(iter_entry_points('lms.version')).name,\n        'dependencies': {\n            k: getattr(v, 'name', v)\n            for k, v in iter_entry_points('lms.version').load().items()\n        },\n    }\n", "def get_versions():\n    try:\n        from pkg_resources import get_distribution\n    except ImportError:\n        from pkg_resources import Distribution as get_distribution\n    versions = OrderedDict()\n    for ver in ['pytz', 'pytz_requirements', 'pytz_requires_all']:\n        try:\n            versions[ver] = get_distribution(ver).version\n        except DistributionNotFound:\n            versions[ver] = ''\n    return versions\n", "def get_versions():\n    try:\n        from invenio.modules.records.api import get_versions\n    except ImportError:\n        return {}\n    else:\n        return get_versions()\n", "def get_versions():\n    try:\n        from pkg_resources import iter_entry_points\n        return dict((ep.name, ep.load()) for ep in iter_entry_points('matplotlib.version'))\n    except ImportError:\n        return {'__version__': 'unknown'}\n", "def get_versions():\n    try:\n        from invenio.modules.jwplayer import __version__\n    except ImportError:\n        from invenio.modules.jwplayer_compat.version import __version__\n    return __version__\n", "def get_versions():\n    try:\n        return importlib.import_module('tower_cli.resources.version')\n    except ImportError:\n        return default_versions()\n", "def get_versions():\n    try:\n        from invenio.modules.workflows.models import version\n        return {'version': version}\n    except ImportError:\n        return {'version': DEFAULT_VERSION}\n", "def get_versions():\n    try:\n        from invenio.modules.workflows.models import versions as module_versions\n        return module_versions\n    except:\n        return default_versions\n", "def get_versions():\n    try:\n        from pkg_resources import parse_version\n    except ImportError:\n        from pkg_resources import VersionInfo\n        return VersionInfo.from_pip_string(\"0.0.1\")\n    else:\n        return parse_version(pkg_resources.get_distribution(\"pytz\").version)\n", "def get_versions():\n    try:\n        from invenio_ext import version\n        return {'invenio_version': version}\n    except ImportError:\n        return {'invenio_version': default_version}\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def get_versions():\n    try:\n        from pkg_resources import iter_entry_points\n    except ImportError:\n        return {\n           'version': __version__,\n            'dependencies': {},\n        }\n    return {\n       'version': next(iter_entry_points('lms.version')).name,\n        'dependencies': {\n            k: getattr(v, 'name', v)\n            for k, v in iter_entry_points('lms.version').load().items()\n        },\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        from pkg_resources import get_distribution\n    except ImportError:\n        from pkg_resources import Distribution as get_distribution\n    versions = OrderedDict()\n    for ver in ['pytz', 'pytz_requirements', 'pytz_requires_all']:\n        try:\n            versions[ver] = get_distribution(ver).version\n        except DistributionNotFound:\n            versions[ver] = ''\n    return versions\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        from invenio.modules.records.api import get_versions\n    except ImportError:\n        return {}\n    else:\n        return get_versions()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        from pkg_resources import iter_entry_points\n        return dict((ep.name, ep.load()) for ep in iter_entry_points('matplotlib.version'))\n    except ImportError:\n        return {'__version__': 'unknown'}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        from invenio.modules.jwplayer import __version__\n    except ImportError:\n        from invenio.modules.jwplayer_compat.version import __version__\n    return __version__\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        return importlib.import_module('tower_cli.resources.version')\n    except ImportError:\n        return default_versions()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        from invenio.modules.workflows.models import version\n        return {'version': version}\n    except ImportError:\n        return {'version': DEFAULT_VERSION}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        from invenio.modules.workflows.models import versions as module_versions\n        return module_versions\n    except:\n        return default_versions\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        from pkg_resources import parse_version\n    except ImportError:\n        from pkg_resources import VersionInfo\n        return VersionInfo.from_pip_string(\"0.0.1\")\n    else:\n        return parse_version(pkg_resources.get_distribution(\"pytz\").version)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_versions():\n    try:\n        from invenio_ext import version\n        return {'invenio_version': version}\n    except ImportError:\n        return {'invenio_version': default_version}\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/prestoplot/_version.py", "project": "eykd/prestoplot", "name": "render", "docstring": "Render the given version pieces into the requested style.", "ques_id": "62b87d24d292efb640a5566f", "code": ["def render(pieces, style):\n    if style == 'default':\n        return '\\n'.join(pieces)\n\n    styles = {\n        'default': '\\n'.join([\n            style,\n            '\\n'.join(pieces),\n        ])\n    }\n\n    try:\n        return styles[style]\n    except KeyError:\n        raise UnknownStyle('unknown style: %r' % style)\n", "def render(pieces, style):\n\n    if style == \"default\":\n        return \"\\n\".join(pieces)\n\n    if style == \"table\":\n        style = \"|\".join([\"{{\", style, \"}}\"])\n\n    if style == \"json\":\n        return json.dumps(pieces)\n\n    if style == \"markdown\":\n        return markdown(pieces)\n\n    raise ValueError(f\"Unknown style: '{style}'\")\n", "def render(pieces, style):\n    if style == \"default\":\n        style = \"full\"\n\n    if style == \"full\":\n        return render_full(pieces)\n    elif style == \"rst\":\n        return render_rst(pieces)\n    elif style == \"jinja\":\n        return render_jinja(pieces)\n    elif style == \"latex\":\n        return render_latex(pieces)\n    else:\n        raise ValueError(f\"unknown style '{style}'\")\n", "def render(pieces, style):\n    if not style or style == 'default':\n        style = 'default'\n\n    style = get_style(style)\n\n    if not style:\n        raise Exception('Style {} not found.'.format(style))\n\n    return style.render(pieces)\n", "def render(pieces, style):\n    return ''.join([style.format(piece) for piece in pieces])\n", "def render(pieces, style):\n    return style.format(**pieces)\n", "def render(pieces, style):\n    if style == \"default\":\n        return pieces\n\n    if style == \"native\":\n        return [\n            (\"text-decoration: none;\", \"\"),\n            (\"background-color: rgb(%s, %s, %s);\" % (\n                piece[\"color\"][\"r\"],\n                piece[\"color\"][\"g\"],\n                piece[\"color\"][\"b\"]),\n                piece[\"text\"])\n            for piece in pieces\n        ]\n    elif style == \"native-alpha\":\n        return [\n            (\"background-color: rgb(%s, %s, %s);\" % (\n                piece[\"color\"][\"r\"],\n                piece[\"color\"][\"g\"],\n                piece[\"color\"][\"b\"]),\n                \"\".join([\"\\n\", \"\".join(piece[\"text\"]), \"\\n\"]))\n            for piece in piece", "def render(pieces, style):\n    if style == 'html':\n        return pieces\n    elif style == 'xml':\n        return \"\".join(pieces)\n    else:\n        raise ValueError(\"unknown style: %r\" % style)\n", "def render(pieces, style):\n\n    if style == \"html\":\n        return \"\".join(pieces)\n\n    if style == \"odp\":\n        return \"\".join([\"<!-- {} -->\".format(piece) for piece in pieces])\n\n    if style == \"xml\":\n        return \"\".join([\"<!DOCTYPE html>\\n\\n{}\\n</html>\".format(piece) for piece in pieces])\n\n    raise ValueError(\"Unknown style: {}\".format(style))\n", "def render(pieces, style):\n    if not style:\n        return pieces\n\n    if style == 'default':\n        return pieces\n\n    if style == 'native':\n        return ['\\\\' + s for s in pieces]\n\n    if style == 'block':\n        if 'block_start' in pieces:\n            raise Exception(\"Unexpected block style %s, \"\n                            \"only one style can be 'block'. \"\n                            \"Found %s\" % (style, pieces))\n        pieces.insert(0, '\\\\block')\n        if 'block_end' in pieces:\n            raise Exception(\"Unexpected block style %s, \"\n                            \"only one style can be 'block'. \"\n                            \"Found %s\" % (style, pieces))\n        pieces.insert(1, '{')\n        if 'block_start' in pieces:\n            piece"], "level": "file_runnable", "generate_results": [{"generate_code": "def render(pieces, style):\n    if style == 'default':\n        return '\\n'.join(pieces)\n\n    styles = {\n        'default': '\\n'.join([\n            style,\n            '\\n'.join(pieces),\n        ])\n    }\n\n    try:\n        return styles[style]\n    except KeyError:\n        raise UnknownStyle('unknown style: %r' % style)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n\n    if style == \"default\":\n        return \"\\n\".join(pieces)\n\n    if style == \"table\":\n        style = \"|\".join([\"{{\", style, \"}}\"])\n\n    if style == \"json\":\n        return json.dumps(pieces)\n\n    if style == \"markdown\":\n        return markdown(pieces)\n\n    raise ValueError(f\"Unknown style: '{style}'\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n    if style == \"default\":\n        style = \"full\"\n\n    if style == \"full\":\n        return render_full(pieces)\n    elif style == \"rst\":\n        return render_rst(pieces)\n    elif style == \"jinja\":\n        return render_jinja(pieces)\n    elif style == \"latex\":\n        return render_latex(pieces)\n    else:\n        raise ValueError(f\"unknown style '{style}'\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n    if not style or style == 'default':\n        style = 'default'\n\n    style = get_style(style)\n\n    if not style:\n        raise Exception('Style {} not found.'.format(style))\n\n    return style.render(pieces)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n    return ''.join([style.format(piece) for piece in pieces])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n    return style.format(**pieces)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n    if style == \"default\":\n        return pieces\n\n    if style == \"native\":\n        return [\n            (\"text-decoration: none;\", \"\"),\n            (\"background-color: rgb(%s, %s, %s);\" % (\n                piece[\"color\"][\"r\"],\n                piece[\"color\"][\"g\"],\n                piece[\"color\"][\"b\"]),\n                piece[\"text\"])\n            for piece in pieces\n        ]\n    elif style == \"native-alpha\":\n        return [\n            (\"background-color: rgb(%s, %s, %s);\" % (\n                piece[\"color\"][\"r\"],\n                piece[\"color\"][\"g\"],\n                piece[\"color\"][\"b\"]),\n                \"\".join([\"\\n\", \"\".join(piece[\"text\"]), \"\\n\"]))\n            for piece in piece", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n    if style == 'html':\n        return pieces\n    elif style == 'xml':\n        return \"\".join(pieces)\n    else:\n        raise ValueError(\"unknown style: %r\" % style)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n\n    if style == \"html\":\n        return \"\".join(pieces)\n\n    if style == \"odp\":\n        return \"\".join([\"<!-- {} -->\".format(piece) for piece in pieces])\n\n    if style == \"xml\":\n        return \"\".join([\"<!DOCTYPE html>\\n\\n{}\\n</html>\".format(piece) for piece in pieces])\n\n    raise ValueError(\"Unknown style: {}\".format(style))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def render(pieces, style):\n    if not style:\n        return pieces\n\n    if style == 'default':\n        return pieces\n\n    if style == 'native':\n        return ['\\\\' + s for s in pieces]\n\n    if style == 'block':\n        if 'block_start' in pieces:\n            raise Exception(\"Unexpected block style %s, \"\n                            \"only one style can be 'block'. \"\n                            \"Found %s\" % (style, pieces))\n        pieces.insert(0, '\\\\block')\n        if 'block_end' in pieces:\n            raise Exception(\"Unexpected block style %s, \"\n                            \"only one style can be 'block'. \"\n                            \"Found %s\" % (style, pieces))\n        pieces.insert(1, '{')\n        if 'block_start' in pieces:\n            piece", "is_pass": false, "return_code": 1}]}
{"file_path": "src/prestoplot/_version.py", "project": "eykd/prestoplot", "name": "plus_or_dot", "docstring": "Return a + if we don't already have one, else return a .", "ques_id": "62b87d24d292efb640a5566d", "code": ["def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n"], "level": "self_contained", "generate_results": [{"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plus_or_dot(pieces):\n    if \"+\" in pieces.get(\"closest-tag\", \"\"):\n        return \".\"\n    return \"+\"\n", "is_pass": true, "return_code": 0}]}
{"file_path": "src/prestoplot/_version.py", "project": "eykd/prestoplot", "name": "run_command", "docstring": "Call the given command(s).", "ques_id": "62b87d23d292efb640a5566b", "code": ["def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/prestoplot/_version.py", "project": "eykd/prestoplot", "name": "get_config", "docstring": "Create, populate and return the VersioneerConfig() object.", "ques_id": "62b87d23d292efb640a55668", "code": ["def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"aws_s3_sdk/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/datalad_synthetics/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"semicolon_pnl/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/yotta/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"eradicate/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"seminario/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"django_select2/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"wnl_review/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"node_tree_exporter/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"singletag/_version.py\"\n    cfg.verbose = False\n    return cfg\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"aws_s3_sdk/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/datalad_synthetics/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"semicolon_pnl/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"src/yotta/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"eradicate/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"seminario/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"django_select2/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"wnl_review/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"node_tree_exporter/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_config():\n    # these strings are filled in when'setup.py versioneer' creates\n    # _version.py\n    cfg = VersioneerConfig()\n    cfg.VCS = \"git\"\n    cfg.style = \"pep440-post\"\n    cfg.tag_prefix = \"v\"\n    cfg.parentdir_prefix = \"None\"\n    cfg.versionfile_source = \"singletag/_version.py\"\n    cfg.verbose = False\n    return cfg\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/prestoplot/_version.py", "project": "eykd/prestoplot", "name": "register_vcs_handler", "docstring": "Create decorator to mark a method as the handler of a VCS.", "ques_id": "62b87d23d292efb640a55667", "code": ["def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n"], "level": "self_contained", "generate_results": [{"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}, {"generate_code": "def register_vcs_handler(vcs, method):  # decorator\n    \"\"\"Create decorator to mark a method as the handler of a VCS.\"\"\"\n    def decorate(f):\n        HANDLERS.setdefault(vcs, {})[method] = f\n        return f\n    return decorate\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/store.py", "project": "zimeon/ocfl-py", "name": "validate_hierarchy", "docstring": "Validate storage root hierarchy.\n\nReturns:\n    num_objects - number of objects checked\n    good_objects - number of objects checked that were found to be valid", "ques_id": "62b45e945108cfac7f210a4a", "code": ["def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if validate_objects:\n        validate_objects = 'all'\n    if check_digests:\n        validate_digests = True\n    if show_warnings:\n        print('Validating storage tree using digest checks...')\n        self.validate_digest_checks(validate_objects, check_digests)\n\n    num_objects = self._validate_storage_tree_roots(validate_objects=validate_objects, check_digests=check_digests)\n    good_objects = self._validate_storage_tree_roots(validate_objects=validate_objects, check_digests=check_digests, show_warnings=False)\n    return num_objects, good_objects\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    # First validate the root object.\n    root_obj = self.get_root_object()\n    root_object_path = root_obj.get_full_path()\n\n    # Then validate the digest tree.\n    if not validate_digests:\n        return 0, 0, []\n\n    return self.validate_tree(\n        root_object_path,\n        check_digests=check_digests,\n        validate_objects=validate_objects,\n        show_warnings=show_warnings,\n    )\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    validate_objects = int(validate_objects)\n    check_digests = int(check_digests)\n    validate_objects = int(validate_objects)\n    good_objects = 0\n    if validate_objects:\n        good_objects = self.storage.count_objects()\n    if check_digests:\n        for _, _, object in self.storage.walk_hierarchy(max_depth=0):\n            good_objects += 1\n            if not object.is_valid_digest():\n                print(\"{} has invalid digest: {}\".format(object.path, object.digest))\n    return good_objects, validate_objects, good_objects == validate_objects\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if validate_objects:\n        for root_id in self.storage_roots:\n            self.validate_object_hierarchy(root_id=root_id, check_digests=check_digests, show_warnings=show_warnings)\n    if check_digests:\n        for root_id in self.storage_roots:\n            self.validate_digest_hierarchy(root_id=root_id, show_warnings=show_warnings)\n    return len(self.storage_roots), len(self.storage_roots)\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    validate_objects = int(validate_objects)\n    check_digests = bool(check_digests)\n    object_list = self.list_storage()\n    num_objects = len(object_list)\n\n    good_objects = 0\n    if validate_objects:\n        for o in object_list:\n            try:\n                self.validate_object(o)\n            except ChecksumMismatch:\n                good_objects += 1\n                if not check_digests:\n                    break\n                if show_warnings:\n                    print(\"WARNING: Checksum mismatch detected for object: {0}\".format(o.path))\n            except Exception:\n                raise\n\n    return num_objects, good_objects\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if validate_objects:\n        self.validate_objects(show_warnings)\n\n    num_objects = self.storage_root.count_objects()\n    good_objects = self.storage_root.count_good_objects()\n\n    if check_digests:\n        self.check_digests()\n\n    return num_objects, good_objects\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if not validate_objects:\n        return None, None\n\n    if not check_digests:\n        return None, None\n\n    try:\n        return len(self), len(self) - len(self._find_new_digests())\n    except AttributeError:\n        return len(self), len(self)\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if validate_objects:\n        validate_objects = VALID_OBJECTS\n    else:\n        validate_objects = 0\n\n    if check_digests:\n        validate_digests = VALID_DIGESTS\n    else:\n        validate_digests = 0\n\n    num_objects = len(self._storage_root.list_objects())\n\n    good_objects = 0\n    for node in self._storage_root.list_nodes():\n        if node.is_filesystem_object():\n            continue\n        try:\n            self._storage_root.get_object(node.name)\n        except (DaemonError, HdfsError, FileSystemError):\n            continue\n        else:\n            good_objects += 1\n\n    if show_warnings:\n        if num_objects == 0:\n            print(\"Skipping empty storage root\")\n        elif num_objects > validate_objects:\n            print(\n                \"Storage root contains %", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    validate_objects = self._validate_objects\n    check_digests = self._check_digests\n    show_warnings = self._show_warnings\n\n    if validate_objects:\n        validation_results = validate_objects_in_storage(\n            self.storage, self.root_dir, self._checksum_algos, show_warnings\n        )\n        if not validation_results:\n            return (0, 0)\n        validation_results = validate_objects_in_storage(\n            self.storage, self.root_dir, self._checksum_algos, check_warnings\n        )\n        if not validation_results:\n            return (0, 0)\n    if check_digests:\n        validation_results = check_digests_in_storage(self.storage, self.root_dir)\n        if not validation_results:\n            return (0, 0)\n    return (len(validation_results), len(validation_results))\n", "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    num_objects = 0\n    good_objects = 0\n    for storage_root in self:\n        if storage_root.is_valid:\n            num_objects += 1\n            if validate_objects:\n                if storage_root.object_count > 0:\n                    good_objects += 1\n            if check_digests:\n                if storage_root.digest_valid():\n                    good_objects += 1\n            if show_warnings:\n                print(\"%s: %s (%s)\" % (storage_root.__repr__(), storage_root.status, storage_root.path))\n    return (num_objects, good_objects)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if validate_objects:\n        validate_objects = 'all'\n    if check_digests:\n        validate_digests = True\n    if show_warnings:\n        print('Validating storage tree using digest checks...')\n        self.validate_digest_checks(validate_objects, check_digests)\n\n    num_objects = self._validate_storage_tree_roots(validate_objects=validate_objects, check_digests=check_digests)\n    good_objects = self._validate_storage_tree_roots(validate_objects=validate_objects, check_digests=check_digests, show_warnings=False)\n    return num_objects, good_objects\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    # First validate the root object.\n    root_obj = self.get_root_object()\n    root_object_path = root_obj.get_full_path()\n\n    # Then validate the digest tree.\n    if not validate_digests:\n        return 0, 0, []\n\n    return self.validate_tree(\n        root_object_path,\n        check_digests=check_digests,\n        validate_objects=validate_objects,\n        show_warnings=show_warnings,\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    validate_objects = int(validate_objects)\n    check_digests = int(check_digests)\n    validate_objects = int(validate_objects)\n    good_objects = 0\n    if validate_objects:\n        good_objects = self.storage.count_objects()\n    if check_digests:\n        for _, _, object in self.storage.walk_hierarchy(max_depth=0):\n            good_objects += 1\n            if not object.is_valid_digest():\n                print(\"{} has invalid digest: {}\".format(object.path, object.digest))\n    return good_objects, validate_objects, good_objects == validate_objects\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if validate_objects:\n        for root_id in self.storage_roots:\n            self.validate_object_hierarchy(root_id=root_id, check_digests=check_digests, show_warnings=show_warnings)\n    if check_digests:\n        for root_id in self.storage_roots:\n            self.validate_digest_hierarchy(root_id=root_id, show_warnings=show_warnings)\n    return len(self.storage_roots), len(self.storage_roots)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    validate_objects = int(validate_objects)\n    check_digests = bool(check_digests)\n    object_list = self.list_storage()\n    num_objects = len(object_list)\n\n    good_objects = 0\n    if validate_objects:\n        for o in object_list:\n            try:\n                self.validate_object(o)\n            except ChecksumMismatch:\n                good_objects += 1\n                if not check_digests:\n                    break\n                if show_warnings:\n                    print(\"WARNING: Checksum mismatch detected for object: {0}\".format(o.path))\n            except Exception:\n                raise\n\n    return num_objects, good_objects\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if validate_objects:\n        self.validate_objects(show_warnings)\n\n    num_objects = self.storage_root.count_objects()\n    good_objects = self.storage_root.count_good_objects()\n\n    if check_digests:\n        self.check_digests()\n\n    return num_objects, good_objects\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if not validate_objects:\n        return None, None\n\n    if not check_digests:\n        return None, None\n\n    try:\n        return len(self), len(self) - len(self._find_new_digests())\n    except AttributeError:\n        return len(self), len(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    if validate_objects:\n        validate_objects = VALID_OBJECTS\n    else:\n        validate_objects = 0\n\n    if check_digests:\n        validate_digests = VALID_DIGESTS\n    else:\n        validate_digests = 0\n\n    num_objects = len(self._storage_root.list_objects())\n\n    good_objects = 0\n    for node in self._storage_root.list_nodes():\n        if node.is_filesystem_object():\n            continue\n        try:\n            self._storage_root.get_object(node.name)\n        except (DaemonError, HdfsError, FileSystemError):\n            continue\n        else:\n            good_objects += 1\n\n    if show_warnings:\n        if num_objects == 0:\n            print(\"Skipping empty storage root\")\n        elif num_objects > validate_objects:\n            print(\n                \"Storage root contains %", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    validate_objects = self._validate_objects\n    check_digests = self._check_digests\n    show_warnings = self._show_warnings\n\n    if validate_objects:\n        validation_results = validate_objects_in_storage(\n            self.storage, self.root_dir, self._checksum_algos, show_warnings\n        )\n        if not validation_results:\n            return (0, 0)\n        validation_results = validate_objects_in_storage(\n            self.storage, self.root_dir, self._checksum_algos, check_warnings\n        )\n        if not validation_results:\n            return (0, 0)\n    if check_digests:\n        validation_results = check_digests_in_storage(self.storage, self.root_dir)\n        if not validation_results:\n            return (0, 0)\n    return (len(validation_results), len(validation_results))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_hierarchy(self, validate_objects=True, check_digests=True, show_warnings=False):\n    num_objects = 0\n    good_objects = 0\n    for storage_root in self:\n        if storage_root.is_valid:\n            num_objects += 1\n            if validate_objects:\n                if storage_root.object_count > 0:\n                    good_objects += 1\n            if check_digests:\n                if storage_root.digest_valid():\n                    good_objects += 1\n            if show_warnings:\n                print(\"%s: %s (%s)\" % (storage_root.__repr__(), storage_root.status, storage_root.path))\n    return (num_objects, good_objects)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/store.py", "project": "zimeon/ocfl-py", "name": "initialize", "docstring": "Create and initialize a new OCFL storage root.", "ques_id": "62b45e515108cfac7f210a3c", "code": ["def initialize(self):\n    pass\n", "def initialize(self):\n    pass\n", "def initialize(self):\n    pass\n", "def initialize(self):\n    return _opencl.ocl_initialize()\n", "def initialize(self):\n    pass\n", "def initialize(self):\n    return lib.ocfl_initialize()\n", "def initialize(self):\n    pass\n", "def initialize(self):\n    # type: () -> None\n    \"\"\"Create and initialize a new OCFL storage root.\"\"\"\n    if self._storage_root is not None:\n        return\n\n    self._storage_root = OCFLNode(None, None, None)\n    self._storage_root.initialize(self._build_storage_root())\n", "def initialize(self):\n    pass\n", "def initialize(self):\n    pass\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def initialize(self):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    return _opencl.ocl_initialize()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    return lib.ocfl_initialize()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    # type: () -> None\n    \"\"\"Create and initialize a new OCFL storage root.\"\"\"\n    if self._storage_root is not None:\n        return\n\n    self._storage_root = OCFLNode(None, None, None)\n    self._storage_root.initialize(self._build_storage_root())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def initialize(self):\n    pass\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/object_utils.py", "project": "zimeon/ocfl-py", "name": "next_version", "docstring": "Next version identifier following existing pattern.\n\nMust deal with both zero-prefixed and non-zero prefixed versions.", "ques_id": "62b45e2eb89c9fd354170232", "code": ["def next_version(version):\n    if version is None:\n        return ''\n\n    if not version.startswith('0'):\n        raise ValueError('Prefixed version must begin with 0')\n\n    if version.startswith('1'):\n        return version\n\n    n = int(version[1:])\n    m = len(version) - 1\n    return '0{0}'.format(n)\n", "def next_version(version):\n    while version and version[-1] in (\"0\", \"1\"):\n        version = version[:-1]\n    return version\n", "def next_version(version):\n    for prefix in ['', 'v']:\n        if version.startswith(prefix):\n            try:\n                return int(version[len(prefix):])\n            except ValueError:\n                raise ValueError('non-numeric version %s' % version)\n    raise ValueError('no next version %s' % version)\n", "def next_version(version):\n    m = re.match(r'^(\\d+)(-(\\d+))?$', version)\n    if not m:\n        raise ValueError('invalid version %r' % version)\n    return m.group(1) + m.group(2)\n", "def next_version(version):\n    m = re.match(r\"^(\\d+)$\", version)\n    if not m:\n        raise ValueError(\"Invalid version %s\" % version)\n    number = int(m.group(1))\n    if number > 9:\n        raise ValueError(\"Invalid version %s\" % version)\n    return \"v%s\" % number\n", "def next_version(version):\n    version = str(version)\n    if \".\" in version:\n        prefix, suffix = version.rsplit(\".\", 1)\n        if prefix == \"0\":\n            return suffix\n        else:\n            return prefix + \".\" + suffix\n    else:\n        return version\n", "def next_version(version):\n    # find index of last zero\n    idx = len(version) - 1\n    while version[idx] == 0:\n        idx -= 1\n    # find index of last zero\n    idx -= 1\n    while version[idx] == 0:\n        idx -= 1\n    return version[:idx+1]\n", "def next_version(version):\n    if not version.startswith('0'):\n        raise ValueError('Invalid version %r' % version)\n    version = version[1:]\n    while len(version) < 4:\n        version = '0' + version\n    return version\n", "def next_version(version):\n    if version:\n        return (version + \".\").rstrip(\".0\")\n    else:\n        return \"0\"\n", "def next_version(version):\n    m = re.match(r'^(\\d+)\\.(\\d+)$', version)\n    if not m:\n        raise ValueError('Invalid version %s' % version)\n    return m.group(1) + '.' + m.group(2)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def next_version(version):\n    if version is None:\n        return ''\n\n    if not version.startswith('0'):\n        raise ValueError('Prefixed version must begin with 0')\n\n    if version.startswith('1'):\n        return version\n\n    n = int(version[1:])\n    m = len(version) - 1\n    return '0{0}'.format(n)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    while version and version[-1] in (\"0\", \"1\"):\n        version = version[:-1]\n    return version\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    for prefix in ['', 'v']:\n        if version.startswith(prefix):\n            try:\n                return int(version[len(prefix):])\n            except ValueError:\n                raise ValueError('non-numeric version %s' % version)\n    raise ValueError('no next version %s' % version)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    m = re.match(r'^(\\d+)(-(\\d+))?$', version)\n    if not m:\n        raise ValueError('invalid version %r' % version)\n    return m.group(1) + m.group(2)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    m = re.match(r\"^(\\d+)$\", version)\n    if not m:\n        raise ValueError(\"Invalid version %s\" % version)\n    number = int(m.group(1))\n    if number > 9:\n        raise ValueError(\"Invalid version %s\" % version)\n    return \"v%s\" % number\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    version = str(version)\n    if \".\" in version:\n        prefix, suffix = version.rsplit(\".\", 1)\n        if prefix == \"0\":\n            return suffix\n        else:\n            return prefix + \".\" + suffix\n    else:\n        return version\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    # find index of last zero\n    idx = len(version) - 1\n    while version[idx] == 0:\n        idx -= 1\n    # find index of last zero\n    idx -= 1\n    while version[idx] == 0:\n        idx -= 1\n    return version[:idx+1]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    if not version.startswith('0'):\n        raise ValueError('Invalid version %r' % version)\n    version = version[1:]\n    while len(version) < 4:\n        version = '0' + version\n    return version\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    if version:\n        return (version + \".\").rstrip(\".0\")\n    else:\n        return \"0\"\n", "is_pass": false, "return_code": 1}, {"generate_code": "def next_version(version):\n    m = re.match(r'^(\\d+)\\.(\\d+)$', version)\n    if not m:\n        raise ValueError('Invalid version %s' % version)\n    return m.group(1) + '.' + m.group(2)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/validator.py", "project": "zimeon/ocfl-py", "name": "validate_version_inventories", "docstring": "Each version SHOULD have an inventory up to that point.\n\nAlso keep a record of any content digests different from those in the root inventory\nso that we can also check them when validating the content.\n\nversion_dirs is an array of version directory names and is assumed to be in\nversion sequence (1, 2, 3...).", "ques_id": "62b45e23e0d4551b0392c90a", "code": ["def validate_version_inventories(self, version_dirs):\n    pass\n", "def validate_version_inventories(self, version_dirs):\n    raise NotImplementedError\n", "def validate_version_inventories(self, version_dirs):\n    pass\n", "def validate_version_inventories(self, version_dirs):\n    raise NotImplementedError()\n", "def validate_version_inventories(self, version_dirs):\n    raise NotImplementedError()\n", "def validate_version_inventories(self, version_dirs):\n    raise NotImplementedError()\n", "def validate_version_inventories(self, version_dirs):\n    pass\n", "def validate_version_inventories(self, version_dirs):\n    pass\n", "def validate_version_inventories(self, version_dirs):\n    raise NotImplementedError()\n", "def validate_version_inventories(self, version_dirs):\n    pass\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_version_inventories(self, version_dirs):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    raise NotImplementedError\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    raise NotImplementedError()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    raise NotImplementedError()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    raise NotImplementedError()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    raise NotImplementedError()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_version_inventories(self, version_dirs):\n    pass\n", "is_pass": false, "return_code": 1}]}
{"file_path": "ocfl/object_utils.py", "project": "zimeon/ocfl-py", "name": "find_path_type", "docstring": "Return a string indicating the type of thing at the given path.\n\nReturn values:\n    'root' - looks like an OCFL Storage Root\n    'object' - looks like an OCFL Object\n    'file' - a file, might be an inventory\n    other string explains error description\n\nLooks only at \"0=*\" Namaste files to determine the directory type.", "ques_id": "62b45e21e0d4551b0392c8ed", "code": ["def find_path_type(path):\n    path = os.path.abspath(path)\n\n    # I can't seem like a good idea to do this without a trailing slash. I\n    # think it could be more elegant to just look at the file extension\n    # but that seems to be a problem for a filesystem shared by a user.\n    if not path.endswith('/'):\n        path += '/'\n\n    if not os.path.isfile(path):\n        return 'file'\n\n    if not os.access(path, os.R_OK):\n        return 'root'\n\n    # Try to determine the directory type\n    if os.path.isdir(path):\n        return 'object'\n\n    # Try to determine the file type\n    file_ext = os.path.splitext(path)[1]\n    if file_ext.startswith('.'):\n        return 'file'\n\n    return 'root'\n", "def find_path_type(path):\n    if path is None:\n        return 'root'\n    elif os.path.isfile(path):\n        return 'file'\n    elif os.path.isdir(path):\n        return 'object'\n    else:\n        return '?'\n", "def find_path_type(path):\n    if not os.path.isdir(path):\n        return 'root'\n    elif os.path.isfile(path):\n        return 'file'\n    else:\n        path_type = ''\n        for item in os.listdir(path):\n            if os.path.isdir(os.path.join(path, item)):\n                path_type += '0='\n            else:\n                path_type += '1='\n        if len(path_type) > 0:\n            return path_type\n", "def find_path_type(path):\n    if path is None:\n        return 'root'\n\n    if '0=' in path:\n        return 'file'\n\n    return 'object'\n", "def find_path_type(path):\n    if not os.path.isdir(path):\n        return 'object'\n    elif os.path.isfile(path):\n        return 'file'\n    elif os.path.isdir(path):\n        return 'root'\n    else:\n        raise IOError('{0} is not a directory'.format(path))\n", "def find_path_type(path):\n    for name in ('file', 'object', 'root'):\n        if path.startswith('0=' + name):\n            return name\n    # if we get here we didn't find a match\n    raise OCFLError('Could not determine storage type for path %s' % path)\n", "def find_path_type(path):\n    if '0=*' in path:\n        return 'root'\n    elif 'object' in path:\n        return 'object'\n    elif 'file' in path:\n        return 'file'\n    else:\n        return 'no_type'\n", "def find_path_type(path):\n\n    if not os.path.isdir(path):\n        return 'root'\n\n    for root, dirs, files in os.walk(path):\n        if '0=*' in root:\n            return 'object'\n        if '0=file' in root:\n            return 'file'\n\n    return ''\n", "def find_path_type(path):\n    if path.startswith('0='):\n        return 'object'\n    elif '/' in path:\n        return 'file'\n    else:\n        return 'root'\n", "def find_path_type(path):\n    if path is None:\n        return 'root'\n    elif os.path.isfile(path):\n        return 'file'\n    elif os.path.isdir(path):\n        return 'object'\n    else:\n        return '*'\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def find_path_type(path):\n    path = os.path.abspath(path)\n\n    # I can't seem like a good idea to do this without a trailing slash. I\n    # think it could be more elegant to just look at the file extension\n    # but that seems to be a problem for a filesystem shared by a user.\n    if not path.endswith('/'):\n        path += '/'\n\n    if not os.path.isfile(path):\n        return 'file'\n\n    if not os.access(path, os.R_OK):\n        return 'root'\n\n    # Try to determine the directory type\n    if os.path.isdir(path):\n        return 'object'\n\n    # Try to determine the file type\n    file_ext = os.path.splitext(path)[1]\n    if file_ext.startswith('.'):\n        return 'file'\n\n    return 'root'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n    if path is None:\n        return 'root'\n    elif os.path.isfile(path):\n        return 'file'\n    elif os.path.isdir(path):\n        return 'object'\n    else:\n        return '?'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n    if not os.path.isdir(path):\n        return 'root'\n    elif os.path.isfile(path):\n        return 'file'\n    else:\n        path_type = ''\n        for item in os.listdir(path):\n            if os.path.isdir(os.path.join(path, item)):\n                path_type += '0='\n            else:\n                path_type += '1='\n        if len(path_type) > 0:\n            return path_type\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n    if path is None:\n        return 'root'\n\n    if '0=' in path:\n        return 'file'\n\n    return 'object'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n    if not os.path.isdir(path):\n        return 'object'\n    elif os.path.isfile(path):\n        return 'file'\n    elif os.path.isdir(path):\n        return 'root'\n    else:\n        raise IOError('{0} is not a directory'.format(path))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n    for name in ('file', 'object', 'root'):\n        if path.startswith('0=' + name):\n            return name\n    # if we get here we didn't find a match\n    raise OCFLError('Could not determine storage type for path %s' % path)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n    if '0=*' in path:\n        return 'root'\n    elif 'object' in path:\n        return 'object'\n    elif 'file' in path:\n        return 'file'\n    else:\n        return 'no_type'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n\n    if not os.path.isdir(path):\n        return 'root'\n\n    for root, dirs, files in os.walk(path):\n        if '0=*' in root:\n            return 'object'\n        if '0=file' in root:\n            return 'file'\n\n    return ''\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n    if path.startswith('0='):\n        return 'object'\n    elif '/' in path:\n        return 'file'\n    else:\n        return 'root'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_path_type(path):\n    if path is None:\n        return 'root'\n    elif os.path.isfile(path):\n        return 'file'\n    elif os.path.isdir(path):\n        return 'object'\n    else:\n        return '*'\n", "is_pass": false, "return_code": 1}]}
{"file_path": "auto_nag/bzcleaner.py", "project": "mozilla/relman-auto-nag", "name": "amend_bzparams", "docstring": "Amend the Bugzilla params", "ques_id": "62b45b396decaeff903e1001", "code": ["def amend_bzparams(self, params, bug_ids):\n    if isinstance(bug_ids, int):\n        bug_ids = [bug_ids]\n    params['bugzilla_ids'] = ','.join(bug_ids)\n    return params\n", "def amend_bzparams(self, params, bug_ids):\n    for bug_id in bug_ids:\n        params[\"id\"] = bug_id\n        params[\"status\"] = \"Acknowledged\"\n\n    return params\n", "def amend_bzparams(self, params, bug_ids):\n    for bug_id in bug_ids:\n        params['id'] = bug_id\n        params['action'] = 'update'\n        params['status'] = 'closed'\n        params['priority'] = '0'\n        params['comment'] = 'Bugzilla updated'\n        params['bz_bug_id'] = bug_id\n    return params\n", "def amend_bzparams(self, params, bug_ids):\n    if not params.get('product'):\n        params['product'] = 'firefox'\n    if not params.get('version'):\n        params['version'] = '4'\n    if not params.get('launchpad_bug_ids'):\n        params['launchpad_bug_ids'] = bug_ids\n    return params\n", "def amend_bzparams(self, params, bug_ids):\n    if params.get('action') == 'update':\n        params['action'] ='reopen'\n    if params.get('action') =='resolve':\n        params['action'] ='resolvebugids'\n    if params.get('bug_ids') is not None:\n        params['bug_ids'] = [str(bug_id) for bug_id in params['bug_ids']]\n    return params\n", "def amend_bzparams(self, params, bug_ids):\n    if isinstance(bug_ids, dict):\n        bug_ids = [bug_ids]\n    for bug_id in bug_ids:\n        params['id'] = bug_id\n    return params\n", "def amend_bzparams(self, params, bug_ids):\n    params['bz_ids'] = bug_ids\n    return params\n", "def amend_bzparams(self, params, bug_ids):\n    if not params.get('bugzilla_ids'):\n        params['bugzilla_ids'] = bug_ids\n    return params\n", "def amend_bzparams(self, params, bug_ids):\n    if params.get('amend') =='major':\n        params['amend'] = 'never'\n    elif params.get('amend') =='minor':\n        params['amend'] = 'always'\n    return params\n", "def amend_bzparams(self, params, bug_ids):\n    if params.get('status') == 'open':\n        bug_ids.append(params.get('id'))\n    return bug_ids\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def amend_bzparams(self, params, bug_ids):\n    if isinstance(bug_ids, int):\n        bug_ids = [bug_ids]\n    params['bugzilla_ids'] = ','.join(bug_ids)\n    return params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    for bug_id in bug_ids:\n        params[\"id\"] = bug_id\n        params[\"status\"] = \"Acknowledged\"\n\n    return params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    for bug_id in bug_ids:\n        params['id'] = bug_id\n        params['action'] = 'update'\n        params['status'] = 'closed'\n        params['priority'] = '0'\n        params['comment'] = 'Bugzilla updated'\n        params['bz_bug_id'] = bug_id\n    return params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    if not params.get('product'):\n        params['product'] = 'firefox'\n    if not params.get('version'):\n        params['version'] = '4'\n    if not params.get('launchpad_bug_ids'):\n        params['launchpad_bug_ids'] = bug_ids\n    return params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    if params.get('action') == 'update':\n        params['action'] ='reopen'\n    if params.get('action') =='resolve':\n        params['action'] ='resolvebugids'\n    if params.get('bug_ids') is not None:\n        params['bug_ids'] = [str(bug_id) for bug_id in params['bug_ids']]\n    return params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    if isinstance(bug_ids, dict):\n        bug_ids = [bug_ids]\n    for bug_id in bug_ids:\n        params['id'] = bug_id\n    return params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    params['bz_ids'] = bug_ids\n    return params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    if not params.get('bugzilla_ids'):\n        params['bugzilla_ids'] = bug_ids\n    return params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    if params.get('amend') =='major':\n        params['amend'] = 'never'\n    elif params.get('amend') =='minor':\n        params['amend'] = 'always'\n    return params\n", "is_pass": false, "return_code": 1}, {"generate_code": "def amend_bzparams(self, params, bug_ids):\n    if params.get('status') == 'open':\n        bug_ids.append(params.get('id'))\n    return bug_ids\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/config/load.py", "project": "witten/atticmatic", "name": "deep_merge_nodes", "docstring": "Given a nested borgmatic configuration data structure as a list of tuples in the form of:\n\n    (\n        ruamel.yaml.nodes.ScalarNode as a key,\n        ruamel.yaml.nodes.MappingNode or other Node as a value,\n    ),\n\n... deep merge any node values corresponding to duplicate keys and return the result. If\nthere are colliding keys with non-MappingNode values (e.g., integers or strings), the last\nof the values wins.\n\nFor instance, given node values of:\n\n    [\n        (\n            ScalarNode(tag='tag:yaml.org,2002:str', value='retention'),\n            MappingNode(tag='tag:yaml.org,2002:map', value=[\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_hourly'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='24')\n                ),\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_daily'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='7')\n                ),\n            ]),\n        ),\n        (\n            ScalarNode(tag='tag:yaml.org,2002:str', value='retention'),\n            MappingNode(tag='tag:yaml.org,2002:map', value=[\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_daily'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='5')\n                ),\n            ]),\n        ),\n    ]\n\n... the returned result would be:\n\n    [\n        (\n            ScalarNode(tag='tag:yaml.org,2002:str', value='retention'),\n            MappingNode(tag='tag:yaml.org,2002:map', value=[\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_hourly'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='24')\n                ),\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_daily'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='5')\n                ),\n            ]),\n        ),\n    ]\n\nThe purpose of deep merging like this is to support, for instance, merging one borgmatic\nconfiguration file into another for reuse, such that a configuration section (\"retention\",\netc.) does not completely replace the corresponding section in a merged file.", "ques_id": "62b4567ed7d32e5b55cc83d9", "code": ["def deep_merge_nodes(nodes):\n\n    result = []\n\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            result.append((node, deep_merge_nodes(node.value)))\n        else:\n            result.append(node)\n\n    return result\n", "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            new_node = node.copy()\n            for k, v in node.items():\n                if k not in new_node:\n                    new_node[k] = v\n                else:\n                    new_node[k].extend(v)\n            result.append(new_node)\n        else:\n            result.append(node)\n    return result\n", "def deep_merge_nodes(nodes):\n    merge_result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            merge_result.append(deep_merge_nodes(node.value))\n        else:\n            merge_result.append(node)\n    return merge_result\n", "def deep_merge_nodes(nodes):\n    result = []\n    for node_list in nodes:\n        for node in node_list:\n            if isinstance(node, MappingNode):\n                if node.value in result:\n                    result[result.index(node.value)].append(node)\n                else:\n                    result.append(node)\n            else:\n                if node.value in result:\n                    result[result.index(node.value)].append(node)\n                else:\n                    result.append(node)\n    return result\n", "def deep_merge_nodes(nodes):\n\n    if not nodes:\n        return []\n\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            new_node = deep_merge_nodes(node.value)\n            if node.tag not in result:\n                result.append(node.tag)\n            else:\n                result[node.tag] = new_node\n            node.value = result[node.tag]\n        else:\n            result.append(node)\n\n    return result\n", "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            new_node = node.copy()\n            for key in node.keys():\n                if key in result and isinstance(result[key], MappingNode):\n                    result[key].update(new_node[key])\n                else:\n                    result[key] = new_node[key]\n            continue\n        result.append(node)\n    return result\n", "def deep_merge_nodes(nodes):\n\n    result = []\n\n    for node in nodes:\n        if isinstance(node, (MappingNode, ScalarNode)):\n            result.append((node, node.value))\n        elif isinstance(node, (ScalarNode, MappingNode)):\n            key = node.tag\n            value = node.value\n            if key in result:\n                result[key].extend(value)\n            else:\n                result.append((node, value))\n\n    return result\n", "def deep_merge_nodes(nodes):\n    # type: (list) -> list)\n    \"\"\"\n    Given a nested borgmatic configuration data structure as a list of tuples\n    in the form of:\n\n    :param nodes:\n        A list of tuples in the form of:\n\n            ( ruamel.yaml.nodes.ScalarNode as a key,\n              ruamel.yaml.nodes.MappingNode or other Node as a value,\n            )\n\n    :param copy:\n        If True, the result is a copy of the original list of tuples.\n        Otherwise, it is the result of a deep copy.\n    \"\"\"\n    result = []\n    for node in nodes:\n        if isinstance(node, list):\n            result.extend(deep_merge_nodes(node))\n        else:\n            if node.tag in RUAmelNode.__tags__:\n                node.tag = RUAmelNode.__tags__[node.tag]\n            re", "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node[0], MappingNode):\n            result.append(deep_merge_nodes(node[0]))\n        else:\n            result.append(node)\n    return result\n", "def deep_merge_nodes(nodes):\n\n    # type: (Iterable[Tuple[Node, MappingNode, Union[str, int]]]) -> List[Tuple[Node, MappingNode, Union[str, int]]]\n    \"\"\"\n    Given a nested borgmatic configuration data structure as a list of tuples in the\n    form of:\n\n        (\n            ruamel.yaml.nodes.ScalarNode as a key,\n            ruamel.yaml.nodes.MappingNode or other Node as a value,\n        )\n\n       .. deep merge any node values corresponding to duplicate keys and return\n            the result. If there are duplicate keys with non-MappingNode values\n            (e.g., integers or strings), the last of the values wins.\n\n    For instance, given node values of:\n\n        [\n            (\n                ScalarNode(tag='tag:yaml.org,2002:str', value='retention'),\n                MappingNode(tag='tag:yaml.org,2002:map', value=[("], "level": "file_runnable", "generate_results": [{"generate_code": "def deep_merge_nodes(nodes):\n\n    result = []\n\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            result.append((node, deep_merge_nodes(node.value)))\n        else:\n            result.append(node)\n\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            new_node = node.copy()\n            for k, v in node.items():\n                if k not in new_node:\n                    new_node[k] = v\n                else:\n                    new_node[k].extend(v)\n            result.append(new_node)\n        else:\n            result.append(node)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    merge_result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            merge_result.append(deep_merge_nodes(node.value))\n        else:\n            merge_result.append(node)\n    return merge_result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = []\n    for node_list in nodes:\n        for node in node_list:\n            if isinstance(node, MappingNode):\n                if node.value in result:\n                    result[result.index(node.value)].append(node)\n                else:\n                    result.append(node)\n            else:\n                if node.value in result:\n                    result[result.index(node.value)].append(node)\n                else:\n                    result.append(node)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n\n    if not nodes:\n        return []\n\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            new_node = deep_merge_nodes(node.value)\n            if node.tag not in result:\n                result.append(node.tag)\n            else:\n                result[node.tag] = new_node\n            node.value = result[node.tag]\n        else:\n            result.append(node)\n\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            new_node = node.copy()\n            for key in node.keys():\n                if key in result and isinstance(result[key], MappingNode):\n                    result[key].update(new_node[key])\n                else:\n                    result[key] = new_node[key]\n            continue\n        result.append(node)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n\n    result = []\n\n    for node in nodes:\n        if isinstance(node, (MappingNode, ScalarNode)):\n            result.append((node, node.value))\n        elif isinstance(node, (ScalarNode, MappingNode)):\n            key = node.tag\n            value = node.value\n            if key in result:\n                result[key].extend(value)\n            else:\n                result.append((node, value))\n\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    # type: (list) -> list)\n    \"\"\"\n    Given a nested borgmatic configuration data structure as a list of tuples\n    in the form of:\n\n    :param nodes:\n        A list of tuples in the form of:\n\n            ( ruamel.yaml.nodes.ScalarNode as a key,\n              ruamel.yaml.nodes.MappingNode or other Node as a value,\n            )\n\n    :param copy:\n        If True, the result is a copy of the original list of tuples.\n        Otherwise, it is the result of a deep copy.\n    \"\"\"\n    result = []\n    for node in nodes:\n        if isinstance(node, list):\n            result.extend(deep_merge_nodes(node))\n        else:\n            if node.tag in RUAmelNode.__tags__:\n                node.tag = RUAmelNode.__tags__[node.tag]\n            re", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node[0], MappingNode):\n            result.append(deep_merge_nodes(node[0]))\n        else:\n            result.append(node)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n\n    # type: (Iterable[Tuple[Node, MappingNode, Union[str, int]]]) -> List[Tuple[Node, MappingNode, Union[str, int]]]\n    \"\"\"\n    Given a nested borgmatic configuration data structure as a list of tuples in the\n    form of:\n\n        (\n            ruamel.yaml.nodes.ScalarNode as a key,\n            ruamel.yaml.nodes.MappingNode or other Node as a value,\n        )\n\n       .. deep merge any node values corresponding to duplicate keys and return\n            the result. If there are duplicate keys with non-MappingNode values\n            (e.g., integers or strings), the last of the values wins.\n\n    For instance, given node values of:\n\n        [\n            (\n                ScalarNode(tag='tag:yaml.org,2002:str', value='retention'),\n                MappingNode(tag='tag:yaml.org,2002:map', value=[(", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/generate_config.py", "project": "witten/atticmatic", "name": "parse_arguments", "docstring": "Given command-line arguments with which this script was invoked, parse the arguments and return\nthem as an ArgumentParser instance.", "ques_id": "62b4567ad7d32e5b55cc83af", "code": ["def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--version', action='version', version=VERSION)\n    for argument in arguments:\n        parser.add_argument(*argument.split())\n    return parser\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-i', '--input', type=str, required=True)\n    parser.add_argument('-o', '--output', type=str, required=True)\n    parser.add_argument('-l', '--limit', type=int, default=100)\n    parser.add_argument('-v', '--verbose', action='store_true')\n    parser.add_argument('-a', '--attributes', type=str, nargs='+')\n    parser.add_argument('-t', '--template', type=str, default='{name} {age}')\n    parser.add_argument('-s', '--start-at', type=str, default='')\n    parser.add_argument('-t', '--end-at', type=str, default='')\n    parser.add_argument('-v', '--version', action='store_true')\n    parser.add_argument('-s', '--short', action='store_true')\n    parser.add_argument('-a', '--all', action='store_true')\n    return parser.parse_args(*arguments)\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description='Check output of git commits under git.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    parser.add_argument(\n        '--rev', action='store', dest='rev', default=None,\n        help=(\n            'Commit revision to check out. If no rev is specified, '\n            'the latest commit is used.'\n        ),\n    )\n    parser.add_argument(\n        '--no-color', action='store_true',\n        help=(\n            'Don\\'t colorize output. Show output in color.'\n        ),\n    )\n    parser.add_argument(\n        '--show-changed', action='store_true',\n        help=(\n            'Show output in color. Show output in color.'\n        ),\n    )\n    parser.add_argument(\n        '--ignore-staged', action='store_true',", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description='Common User Password Authentication Tool'\n    )\n    parser.add_argument(\n        '-i', '--interactive',\n        action='store_true',\n        help='Interactive mode for user password auth'\n    )\n    parser.add_argument(\n        '-l', '--login-credentials',\n        nargs='+',\n        metavar='USERNAME',\n        type=str,\n        help='Usernames to login to the system',\n    )\n    parser.add_argument(\n        '-p', '--password',\n        nargs='+',\n        metavar='PASSWORD',\n        type=str,\n        help='Passwords to login to the system',\n    )\n    parser.add_argument(\n        '--version',\n        action='store_true',\n        help='Print the version of this script'\n    )\n    parser.add_argument(\n        '-v', ", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n\n    # Allow the user to specify the name of the module they wish to load.\n    parser.add_argument('-m', '--module', help='The module to load.')\n\n    # Allow the user to specify the path to the module that wants to load.\n    parser.add_argument('-p', '--path', help='The path to the module that wants to load.')\n\n    # Allow the user to specify the name of the class they wish to initialize.\n    parser.add_argument('-c', '--class', help='The class to initialize the module with.')\n\n    # Allow the user to specify the name of the method that wants to initialize the module.\n    parser.add_argument('-m', '--method', help='The method to initialize the module with.')\n\n    # Allow the user to specify the name of the argument that wants to initialize the module.\n    parser.add_argument('-a', '--argument', help='The name of the argument that wants to initialize the modul", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-i', '--input-json', required=True, type=str,\n                        help='JSON file containing data for the data source.')\n    parser.add_argument('-o', '--output-csv', required=True, type=str,\n                        help='CSV file where to write the results.')\n    parser.add_argument('-v', '--version', action='version',\n                        version='%(prog)s'+ __version__)\n\n    return parser.parse_args(*arguments)\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-v', '--verbose', action='store_true',\n                        help='Show more output (overrides -v).')\n    parser.add_argument('-d', '--debug', action='store_true',\n                        help='Show debug output.')\n    parser.add_argument('-i', '--interactive', action='store_true',\n                        help='Interactive mode.')\n    parser.add_argument('-l', '--list', action='store_true',\n                        help='List the entries in the database.')\n    parser.add_argument('-o', '--output', type=str, help='Output file.')\n    return parser.parse_args(*arguments)\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-v', '--verbose', action='store_true',\n                        help='be more verbose')\n    parser.add_argument('-f', '--force', action='store_true',\n                        help='overwrite existing files')\n    parser.add_argument('-d', '--debug', action='store_true',\n                        help='enable debug logging')\n    parser.add_argument('-p', '--profile-dir', default=None,\n                        help='directory for profile information')\n    parser.add_argument('--profile-name', default=None,\n                        help='name for profile information')\n    parser.add_argument('--trace', action='store_true',\n                        help='trace errors')\n    parser.add_argument('--trace-exception', action='store_true',\n           ", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--version', action='version', version=__version__)\n    return parser.parse_args(arguments)\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for argument in arguments:\n        parser.add_argument(argument)\n    return parser\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--version', action='version', version=VERSION)\n    for argument in arguments:\n        parser.add_argument(*argument.split())\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-i', '--input', type=str, required=True)\n    parser.add_argument('-o', '--output', type=str, required=True)\n    parser.add_argument('-l', '--limit', type=int, default=100)\n    parser.add_argument('-v', '--verbose', action='store_true')\n    parser.add_argument('-a', '--attributes', type=str, nargs='+')\n    parser.add_argument('-t', '--template', type=str, default='{name} {age}')\n    parser.add_argument('-s', '--start-at', type=str, default='')\n    parser.add_argument('-t', '--end-at', type=str, default='')\n    parser.add_argument('-v', '--version', action='store_true')\n    parser.add_argument('-s', '--short', action='store_true')\n    parser.add_argument('-a', '--all', action='store_true')\n    return parser.parse_args(*arguments)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description='Check output of git commits under git.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    parser.add_argument(\n        '--rev', action='store', dest='rev', default=None,\n        help=(\n            'Commit revision to check out. If no rev is specified, '\n            'the latest commit is used.'\n        ),\n    )\n    parser.add_argument(\n        '--no-color', action='store_true',\n        help=(\n            'Don\\'t colorize output. Show output in color.'\n        ),\n    )\n    parser.add_argument(\n        '--show-changed', action='store_true',\n        help=(\n            'Show output in color. Show output in color.'\n        ),\n    )\n    parser.add_argument(\n        '--ignore-staged', action='store_true',", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description='Common User Password Authentication Tool'\n    )\n    parser.add_argument(\n        '-i', '--interactive',\n        action='store_true',\n        help='Interactive mode for user password auth'\n    )\n    parser.add_argument(\n        '-l', '--login-credentials',\n        nargs='+',\n        metavar='USERNAME',\n        type=str,\n        help='Usernames to login to the system',\n    )\n    parser.add_argument(\n        '-p', '--password',\n        nargs='+',\n        metavar='PASSWORD',\n        type=str,\n        help='Passwords to login to the system',\n    )\n    parser.add_argument(\n        '--version',\n        action='store_true',\n        help='Print the version of this script'\n    )\n    parser.add_argument(\n        '-v', ", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n\n    # Allow the user to specify the name of the module they wish to load.\n    parser.add_argument('-m', '--module', help='The module to load.')\n\n    # Allow the user to specify the path to the module that wants to load.\n    parser.add_argument('-p', '--path', help='The path to the module that wants to load.')\n\n    # Allow the user to specify the name of the class they wish to initialize.\n    parser.add_argument('-c', '--class', help='The class to initialize the module with.')\n\n    # Allow the user to specify the name of the method that wants to initialize the module.\n    parser.add_argument('-m', '--method', help='The method to initialize the module with.')\n\n    # Allow the user to specify the name of the argument that wants to initialize the module.\n    parser.add_argument('-a', '--argument', help='The name of the argument that wants to initialize the modul", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-i', '--input-json', required=True, type=str,\n                        help='JSON file containing data for the data source.')\n    parser.add_argument('-o', '--output-csv', required=True, type=str,\n                        help='CSV file where to write the results.')\n    parser.add_argument('-v', '--version', action='version',\n                        version='%(prog)s'+ __version__)\n\n    return parser.parse_args(*arguments)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-v', '--verbose', action='store_true',\n                        help='Show more output (overrides -v).')\n    parser.add_argument('-d', '--debug', action='store_true',\n                        help='Show debug output.')\n    parser.add_argument('-i', '--interactive', action='store_true',\n                        help='Interactive mode.')\n    parser.add_argument('-l', '--list', action='store_true',\n                        help='List the entries in the database.')\n    parser.add_argument('-o', '--output', type=str, help='Output file.')\n    return parser.parse_args(*arguments)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-v', '--verbose', action='store_true',\n                        help='be more verbose')\n    parser.add_argument('-f', '--force', action='store_true',\n                        help='overwrite existing files')\n    parser.add_argument('-d', '--debug', action='store_true',\n                        help='enable debug logging')\n    parser.add_argument('-p', '--profile-dir', default=None,\n                        help='directory for profile information')\n    parser.add_argument('--profile-name', default=None,\n                        help='name for profile information')\n    parser.add_argument('--trace', action='store_true',\n                        help='trace errors')\n    parser.add_argument('--trace-exception', action='store_true',\n           ", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--version', action='version', version=__version__)\n    return parser.parse_args(arguments)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    for argument in arguments:\n        parser.add_argument(argument)\n    return parser\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/completion.py", "project": "witten/atticmatic", "name": "parser_flags", "docstring": "Given an argparse.ArgumentParser instance, return its argument flags in a space-separated\nstring.", "ques_id": "62b45679d7d32e5b55cc83a9", "code": ["def parser_flags(parser):\n    return''.join(parser._flags)\n", "def parser_flags(parser):\n    flags = []\n    for arg in parser._actions:\n        if isinstance(arg, argparse.ArgumentParser):\n            flags.append('-' + arg.description)\n        else:\n            flags.append(arg)\n    return''.join(flags)\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if isinstance(arg, argparse.ArgumentParser):\n            flags +='' + arg.format_help()\n        else:\n            flags +='-' + arg\n    return flags\n", "def parser_flags(parser):\n    return''.join(\n        flag.short_flag for flag in parser._actions\n        if flag.is_flag\n    )\n", "def parser_flags(parser):\n    flags = []\n    for arg in parser._actions:\n        if isinstance(arg, argparse.ArgumentParser):\n            flags.append('-' + arg.default)\n        else:\n            flags.append(arg)\n    return''.join(flags)\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if isinstance(arg, argparse.ArgumentParser):\n            flags +='' + arg.format_help()\n        else:\n            flags +='' + arg\n    return flags\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        flags +='' + arg._long_flag()\n    return flags\n", "def parser_flags(parser):\n    return''.join(flag.name for flag in parser._get_args())\n", "def parser_flags(parser):\n    return''.join(list(map(str, parser.args)))\n", "def parser_flags(parser):\n    return''.join([str(flag) for flag in parser.flags])\n"], "level": "self_contained", "generate_results": [{"generate_code": "def parser_flags(parser):\n    return''.join(parser._flags)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = []\n    for arg in parser._actions:\n        if isinstance(arg, argparse.ArgumentParser):\n            flags.append('-' + arg.description)\n        else:\n            flags.append(arg)\n    return''.join(flags)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if isinstance(arg, argparse.ArgumentParser):\n            flags +='' + arg.format_help()\n        else:\n            flags +='-' + arg\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join(\n        flag.short_flag for flag in parser._actions\n        if flag.is_flag\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = []\n    for arg in parser._actions:\n        if isinstance(arg, argparse.ArgumentParser):\n            flags.append('-' + arg.default)\n        else:\n            flags.append(arg)\n    return''.join(flags)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if isinstance(arg, argparse.ArgumentParser):\n            flags +='' + arg.format_help()\n        else:\n            flags +='' + arg\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        flags +='' + arg._long_flag()\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join(flag.name for flag in parser._get_args())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join(list(map(str, parser.args)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join([str(flag) for flag in parser.flags])\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/arguments.py", "project": "witten/atticmatic", "name": "parse_arguments", "docstring": "Given command-line arguments with which this script was invoked, parse the arguments and return\nthem as a dict mapping from subparser name (or \"global\") to an argparse.Namespace instance.", "ques_id": "62b45665d7d32e5b55cc8365", "code": ["def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--config-file')\n    parser.add_argument('--debug', action='store_true')\n    parser.add_argument('--silent', action='store_true')\n    parser.add_argument('--quiet', action='store_true')\n    parser.add_argument('--version')\n    for unparsed_argument in unparsed_arguments:\n        parser.add_argument(*unparsed_argument.split('=', 1))\n\n    result = {}\n    for argument in parser.parse_args():\n        if argument.metavar is None:\n            name = argument.name\n        else:\n            name = argument.metavar\n        if argument.default is None:\n            default = None\n        else:\n            default = argument.default\n        if argument.required is False:\n            result[name] = Argument(name, default=default)\n        elif arg", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n    return vars(parser.parse_args())\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='subcommand')\n    for name, parser_name in _ARGUMENT_PARSERS:\n        subparser = subparsers.add_parser(name)\n        parser_args = parser.parse_known_args(unparsed_arguments + (subparser,))\n        yield parser_name, parser_args\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='subcommand')\n    for command_name in COMMAND_NAMES:\n        command_parser = subparsers.add_parser(command_name)\n        COMMAND_ARGS[command_name] = command_parser.parse_args()\n\n    for unparsed_argument in unparsed_arguments:\n        if isinstance(unparsed_argument, str):\n            COMMAND_ARGS[unparsed_argument]\n        else:\n            COMMAND_ARGS[unparsed_argument.name]\n    return COMMAND_ARGS\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser(\n        description=\"This script crawls a list of recent blogs and outputs \"\n        \"their titles and body text and links to each blog post on a given \"\n        \"site.\",\n    )\n    group = parser.add_mutually_exclusive_group()\n    group.add_argument(\n        \"-v\", \"--verbose\", action=\"store_true\", help=\"Print more output.\"\n    )\n    group.add_argument(\n        \"-d\", \"--debug\", action=\"store_true\", help=\"Print debug output.\"\n    )\n    group.add_argument(\n        \"-i\",\n        \"--interactive\",\n        action=\"store_true\",\n        help=\"Interactive mode (don't print anything to stdout).\",\n    )\n    group.add_argument(\n        \"-o\",\n        \"--output\",\n        metavar=\"FILE\",\n        help=\"Output file to write the titles and body text to.\",\n    )\n    group.add_argument(\n        \"-a\",\n        \"--account\",", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser(\n        description='A simple command-line tool that outputs to '\n                    'a log file on the console.')\n    parser.add_argument('-v', '--version', action='version',\n                        version='%(prog)s {}'.format(__version__))\n\n    for unparsed_argument in unparsed_arguments:\n        parser.add_argument(*unparsed_argument.args, **unparsed_argument.kwargs)\n\n    return vars(parser.parse_args())\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='subcommand')\n    for name, command in commands.items():\n        # Add the command to the subparsers\n        command_parser = subparsers.add_parser(name, help=command.__doc__)\n        command.add_arguments(command_parser)\n\n    for unparsed_argument in unparsed_arguments:\n        if not isinstance(unparsed_argument, str):\n            raise TypeError(\"Unexpected type for unparsed_argument %r\" % unparsed_argument)\n        parser.add_argument(*unparsed_argument.split(), **unparsed_argument_kwargs(unparsed_argument))\n\n    return vars(parser.parse_args())\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n\n    subparsers = parser.add_subparsers(dest=\"subcommand\")\n    for subcommand in _COMMANDS:\n        subcommand.add_to_parser(subparsers)\n\n    for unparsed_argument in unparsed_arguments:\n        subparser = subparsers.add_parser(unparsed_argument.name)\n        subparser.add_argument(\"--help\", action=\"store_true\")\n        subparser.add_argument(\"--version\", action=\"store_true\")\n        subparser.add_argument(\n            \"--config\",\n            help=\"The configuration file to use when running the \"\n            \"script. Default is the named config file in the \"\n            \"working directory of the script.\",\n        )\n        unparsed_argument.add_to_parser(subparser)\n\n    return vars(parser.parse_args(unparsed_arguments))\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest=\"subcommand\")\n\n    for name, command in COMMANDS.items():\n        subparser = subparsers.add_parser(name, help=command.__doc__)\n        command.add_to_subparser(subparser)\n        command.add_arguments(subparser)\n        for args in command.get_arguments(unparsed_arguments):\n            subparser.add_argument(*args)\n\n    return vars(parser.parse_args(unparsed_arguments))\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n                        help=\"be more verbose\")\n    parser.add_argument(\"-q\", \"--quiet\", action=\"store_true\",\n                        help=\"be less verbose\")\n    parser.add_argument(\"-d\", \"--debug\", action=\"store_true\",\n                        help=\"be more verbose\")\n    parser.add_argument(\"--version\", action=\"store_true\",\n                        help=\"Show the version number\")\n    parser.add_argument(\"--debug-modules\", action=\"store_true\",\n                        help=\"Show the debugger module names\")\n    parser.add_argument(\"--recursive\", action=\"store_true\",\n                        help=\"Show the recursive patterns\")\n    parser.add_argument(\"--no-colors\", action=\"store_true\",\n                        help=\"Don'"], "level": "file_runnable", "generate_results": [{"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--config-file')\n    parser.add_argument('--debug', action='store_true')\n    parser.add_argument('--silent', action='store_true')\n    parser.add_argument('--quiet', action='store_true')\n    parser.add_argument('--version')\n    for unparsed_argument in unparsed_arguments:\n        parser.add_argument(*unparsed_argument.split('=', 1))\n\n    result = {}\n    for argument in parser.parse_args():\n        if argument.metavar is None:\n            name = argument.name\n        else:\n            name = argument.metavar\n        if argument.default is None:\n            default = None\n        else:\n            default = argument.default\n        if argument.required is False:\n            result[name] = Argument(name, default=default)\n        elif arg", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n    return vars(parser.parse_args())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='subcommand')\n    for name, parser_name in _ARGUMENT_PARSERS:\n        subparser = subparsers.add_parser(name)\n        parser_args = parser.parse_known_args(unparsed_arguments + (subparser,))\n        yield parser_name, parser_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='subcommand')\n    for command_name in COMMAND_NAMES:\n        command_parser = subparsers.add_parser(command_name)\n        COMMAND_ARGS[command_name] = command_parser.parse_args()\n\n    for unparsed_argument in unparsed_arguments:\n        if isinstance(unparsed_argument, str):\n            COMMAND_ARGS[unparsed_argument]\n        else:\n            COMMAND_ARGS[unparsed_argument.name]\n    return COMMAND_ARGS\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser(\n        description=\"This script crawls a list of recent blogs and outputs \"\n        \"their titles and body text and links to each blog post on a given \"\n        \"site.\",\n    )\n    group = parser.add_mutually_exclusive_group()\n    group.add_argument(\n        \"-v\", \"--verbose\", action=\"store_true\", help=\"Print more output.\"\n    )\n    group.add_argument(\n        \"-d\", \"--debug\", action=\"store_true\", help=\"Print debug output.\"\n    )\n    group.add_argument(\n        \"-i\",\n        \"--interactive\",\n        action=\"store_true\",\n        help=\"Interactive mode (don't print anything to stdout).\",\n    )\n    group.add_argument(\n        \"-o\",\n        \"--output\",\n        metavar=\"FILE\",\n        help=\"Output file to write the titles and body text to.\",\n    )\n    group.add_argument(\n        \"-a\",\n        \"--account\",", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser(\n        description='A simple command-line tool that outputs to '\n                    'a log file on the console.')\n    parser.add_argument('-v', '--version', action='version',\n                        version='%(prog)s {}'.format(__version__))\n\n    for unparsed_argument in unparsed_arguments:\n        parser.add_argument(*unparsed_argument.args, **unparsed_argument.kwargs)\n\n    return vars(parser.parse_args())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='subcommand')\n    for name, command in commands.items():\n        # Add the command to the subparsers\n        command_parser = subparsers.add_parser(name, help=command.__doc__)\n        command.add_arguments(command_parser)\n\n    for unparsed_argument in unparsed_arguments:\n        if not isinstance(unparsed_argument, str):\n            raise TypeError(\"Unexpected type for unparsed_argument %r\" % unparsed_argument)\n        parser.add_argument(*unparsed_argument.split(), **unparsed_argument_kwargs(unparsed_argument))\n\n    return vars(parser.parse_args())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n\n    subparsers = parser.add_subparsers(dest=\"subcommand\")\n    for subcommand in _COMMANDS:\n        subcommand.add_to_parser(subparsers)\n\n    for unparsed_argument in unparsed_arguments:\n        subparser = subparsers.add_parser(unparsed_argument.name)\n        subparser.add_argument(\"--help\", action=\"store_true\")\n        subparser.add_argument(\"--version\", action=\"store_true\")\n        subparser.add_argument(\n            \"--config\",\n            help=\"The configuration file to use when running the \"\n            \"script. Default is the named config file in the \"\n            \"working directory of the script.\",\n        )\n        unparsed_argument.add_to_parser(subparser)\n\n    return vars(parser.parse_args(unparsed_arguments))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest=\"subcommand\")\n\n    for name, command in COMMANDS.items():\n        subparser = subparsers.add_parser(name, help=command.__doc__)\n        command.add_to_subparser(subparser)\n        command.add_arguments(subparser)\n        for args in command.get_arguments(unparsed_arguments):\n            subparser.add_argument(*args)\n\n    return vars(parser.parse_args(unparsed_arguments))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n                        help=\"be more verbose\")\n    parser.add_argument(\"-q\", \"--quiet\", action=\"store_true\",\n                        help=\"be less verbose\")\n    parser.add_argument(\"-d\", \"--debug\", action=\"store_true\",\n                        help=\"be more verbose\")\n    parser.add_argument(\"--version\", action=\"store_true\",\n                        help=\"Show the version number\")\n    parser.add_argument(\"--debug-modules\", action=\"store_true\",\n                        help=\"Show the debugger module names\")\n    parser.add_argument(\"--recursive\", action=\"store_true\",\n                        help=\"Show the recursive patterns\")\n    parser.add_argument(\"--no-colors\", action=\"store_true\",\n                        help=\"Don'", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/arguments.py", "project": "witten/atticmatic", "name": "parse_subparser_arguments", "docstring": "Given a sequence of arguments and a dict from subparser name to argparse.ArgumentParser\ninstance, give each requested action's subparser a shot at parsing all arguments. This allows\ncommon arguments like \"--repository\" to be shared across multiple subparsers.\n\nReturn the result as a tuple of (a dict mapping from subparser name to a parsed namespace of\narguments, a list of remaining arguments not claimed by any subparser).", "ques_id": "62b45665d7d32e5b55cc8364", "code": ["def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    not_parsed_arguments = []\n    for subparser_name in subparsers:\n        subparser = subparsers[subparser_name]\n        parsed_arguments[subparser_name] = subparser.parse_args(unparsed_arguments)\n        if subparser.debug:\n            not_parsed_arguments.append(subparser_name)\n    return parsed_arguments, not_parsed_arguments, len(not_parsed_arguments)\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    for subparser_name, subparser in six.iteritems(subparsers):\n        parsed_namespace = parsed_arguments.copy()\n        remaining_arguments.extend(subparser.parse_known_args(unparsed_arguments))\n        parsed_arguments.update(parsed_namespace)\n    return (parsed_arguments, remaining_arguments, remaining_arguments)\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    for name, parser in subparsers.items():\n        parser_arguments = parser.parse_known_args(unparsed_arguments)\n        parsed_arguments[name] = parser_arguments\n        remaining_arguments.extend(parser_arguments.args)\n    return parsed_arguments, remaining_arguments, remaining_arguments\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    not_parsed_arguments = []\n    for subparser_name in subparsers:\n        subparser = subparsers[subparser_name]\n        parsed_arguments.update(subparser.parse_known_args(unparsed_arguments))\n        not_parsed_arguments.append(subparser_name)\n    return parsed_arguments, not_parsed_arguments, not_parsed_arguments\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    for subparser in subparsers.values():\n        if subparser.name not in unparsed_arguments:\n            arguments.update(subparser.parse_known_args())\n        else:\n            remaining_arguments.append(subparser.name)\n    return (arguments, remaining_arguments, unparsed_arguments)\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments_to_parse = {}\n    remaining_arguments = []\n    for subparser_name in subparsers:\n        subparser = subparsers[subparser_name]\n        arguments_to_parse[subparser_name] = subparser.parse_args()\n        remaining_arguments.extend(subparser.required_args)\n    return (arguments_to_parse, remaining_arguments, unparsed_arguments)\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    unparsed_arguments = unparsed_arguments or []\n    for subparser_name in subparsers:\n        parser = subparsers[subparser_name]\n        arguments.update(parser.parse_known_args(unparsed_arguments))\n    remaining_arguments = arguments.copy()\n    remaining_arguments.difference_update(unparsed_arguments)\n    return (arguments, remaining_arguments, unparsed_arguments)\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    unparsed_args = []\n    remaining_arguments = []\n    for name, parser in subparsers.items():\n        if name not in unparsed_arguments:\n            parsed_arguments[name] = parser.parse_args(unparsed_arguments)\n            remaining_arguments.append(name)\n        else:\n            parsed_arguments[name] = unparsed_arguments[name]\n    return parsed_arguments, remaining_arguments, unparsed_args\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    for subparser_name in subparsers:\n        parsed_subparser_name = subparser_name.replace('-', '_')\n        parsed_arguments[parsed_subparser_name] = parsed_arguments.get(subparser_name, None)\n        remaining_arguments += [a for a in unparsed_arguments if a.name!= parsed_subparser_name]\n    return (parsed_arguments, remaining_arguments, remaining_arguments!= [])\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    unparsed_args = []\n    not_parsed = []\n    for subparser in subparsers.values():\n        try:\n            arguments.update(subparser.parse_args(unparsed_arguments))\n        except (SystemExit, KeyboardInterrupt):\n            not_parsed.append(subparser.name)\n        except Exception as e:\n            not_parsed.append(subparser.name)\n            raise e\n        else:\n            unparsed_args.append(subparser.name)\n\n    return (arguments, unparsed_args, not_parsed)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    not_parsed_arguments = []\n    for subparser_name in subparsers:\n        subparser = subparsers[subparser_name]\n        parsed_arguments[subparser_name] = subparser.parse_args(unparsed_arguments)\n        if subparser.debug:\n            not_parsed_arguments.append(subparser_name)\n    return parsed_arguments, not_parsed_arguments, len(not_parsed_arguments)\n", "is_pass": false, "return_code": 2}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    for subparser_name, subparser in six.iteritems(subparsers):\n        parsed_namespace = parsed_arguments.copy()\n        remaining_arguments.extend(subparser.parse_known_args(unparsed_arguments))\n        parsed_arguments.update(parsed_namespace)\n    return (parsed_arguments, remaining_arguments, remaining_arguments)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    for name, parser in subparsers.items():\n        parser_arguments = parser.parse_known_args(unparsed_arguments)\n        parsed_arguments[name] = parser_arguments\n        remaining_arguments.extend(parser_arguments.args)\n    return parsed_arguments, remaining_arguments, remaining_arguments\n", "is_pass": false, "return_code": 2}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    not_parsed_arguments = []\n    for subparser_name in subparsers:\n        subparser = subparsers[subparser_name]\n        parsed_arguments.update(subparser.parse_known_args(unparsed_arguments))\n        not_parsed_arguments.append(subparser_name)\n    return parsed_arguments, not_parsed_arguments, not_parsed_arguments\n", "is_pass": false, "return_code": 2}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    for subparser in subparsers.values():\n        if subparser.name not in unparsed_arguments:\n            arguments.update(subparser.parse_known_args())\n        else:\n            remaining_arguments.append(subparser.name)\n    return (arguments, remaining_arguments, unparsed_arguments)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments_to_parse = {}\n    remaining_arguments = []\n    for subparser_name in subparsers:\n        subparser = subparsers[subparser_name]\n        arguments_to_parse[subparser_name] = subparser.parse_args()\n        remaining_arguments.extend(subparser.required_args)\n    return (arguments_to_parse, remaining_arguments, unparsed_arguments)\n", "is_pass": false, "return_code": 2}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    unparsed_arguments = unparsed_arguments or []\n    for subparser_name in subparsers:\n        parser = subparsers[subparser_name]\n        arguments.update(parser.parse_known_args(unparsed_arguments))\n    remaining_arguments = arguments.copy()\n    remaining_arguments.difference_update(unparsed_arguments)\n    return (arguments, remaining_arguments, unparsed_arguments)\n", "is_pass": false, "return_code": 2}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    unparsed_args = []\n    remaining_arguments = []\n    for name, parser in subparsers.items():\n        if name not in unparsed_arguments:\n            parsed_arguments[name] = parser.parse_args(unparsed_arguments)\n            remaining_arguments.append(name)\n        else:\n            parsed_arguments[name] = unparsed_arguments[name]\n    return parsed_arguments, remaining_arguments, unparsed_args\n", "is_pass": false, "return_code": 2}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    for subparser_name in subparsers:\n        parsed_subparser_name = subparser_name.replace('-', '_')\n        parsed_arguments[parsed_subparser_name] = parsed_arguments.get(subparser_name, None)\n        remaining_arguments += [a for a in unparsed_arguments if a.name!= parsed_subparser_name]\n    return (parsed_arguments, remaining_arguments, remaining_arguments!= [])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    unparsed_args = []\n    not_parsed = []\n    for subparser in subparsers.values():\n        try:\n            arguments.update(subparser.parse_args(unparsed_arguments))\n        except (SystemExit, KeyboardInterrupt):\n            not_parsed.append(subparser.name)\n        except Exception as e:\n            not_parsed.append(subparser.name)\n            raise e\n        else:\n            unparsed_args.append(subparser.name)\n\n    return (arguments, unparsed_args, not_parsed)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/arguments.py", "project": "witten/atticmatic", "name": "make_parsers", "docstring": "Build a top-level parser and its subparsers and return them as a tuple.", "ques_id": "62b45665d7d32e5b55cc8363", "code": ["def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"Parse a series of commands from a given YAML file.\",\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n    )\n\n    subparser = parser.add_subparsers(\n        dest=\"command\", metavar=\"<command>\", required=False\n    )\n\n    for command in COMMANDS:\n        command_parser = subparser.add_parser(\n            command, help=\"Display information about a command.\"\n        )\n        command_parser.add_argument(\n            \"-l\", \"--long\", action=\"store_true\", help=\"Print a table of information.\"\n        )\n        command_parser.add_argument(\n            \"-v\", \"--verbose\", action=\"store_true\", help=\"Print a verbose output.\"\n        )\n        command_parser.add_argument(\n            \"-s\", \"--show-errors\", action=\"store_true\", help=\"Show errors.\"\n        )\n        command_parser.add_argument(\n           ", "def make_parsers():\n    parser = argparse.ArgumentParser(description=\"Test for LilyPond files.\")\n    subparsers = parser.add_subparsers(dest=\"subcommand\")\n    parser_foo = subparsers.add_parser(\"foo\")\n    parser_foo.add_argument(\"--bar\", action=\"store_true\")\n    parser_bar = subparsers.add_parser(\"bar\")\n    parser_bar.add_argument(\"--baz\", action=\"store_true\")\n    parser_baz = subparsers.add_parser(\"baz\")\n    parser_baz.add_argument(\"--qux\", action=\"store_true\")\n    parser_qux = subparsers.add_parser(\"qux\")\n    parser_qux.add_argument(\"--foobar\", action=\"store_true\")\n    parser_qux.add_argument(\"--fooqux\", action=\"store_true\")\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Summary of commands for demonstration purposes.'\n    )\n    subparsers = parser.add_subparsers(dest='command')\n\n    for command, help_text in COMMANDS.items():\n        subparser = subparsers.add_parser(command)\n        subparser.set_defaults(\n            func=getattr(subparsers, command).__call__,\n            help=help_text\n        )\n\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='command')\n\n    for command_name, command in commands.items():\n        command_parser = subparsers.add_parser(\n            command_name,\n            help=command.help,\n            description=command.description\n        )\n        command_parser.add_argument(\n            'command',\n            nargs='?',\n            default=None,\n            type=str,\n            metavar='COMMAND',\n            help='The command to run.'\n        )\n\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"Test that stash commands are recognized as stash commands\"\n    )\n    parser.add_argument(\n        \"-v\", \"--verbose\", action=\"store_true\", help=\"turn on verbosity\"\n    )\n    parser.add_argument(\n        \"-d\", \"--debug\", action=\"store_true\", help=\"turn off debugging\"\n    )\n    parser.add_argument(\n        \"--version\",\n        action=\"store_true\",\n        help=\"Show the version number and exit\",\n    )\n\n    subparsers = parser.add_subparsers(dest=\"stash_cmd\")\n    subparsers.required = True\n    subparsers.add_argument(\n        \"--stash-args\", metavar=\"ARGS\", nargs=\"*\", help=\"stash arguments\"\n    )\n    subparsers.add_argument(\n        \"--stash-failure\", action=\"store_true\", help=\"failure messages\"\n    )\n    subparsers.add_argument(\n        \"--stash-error\", action=\"store_true\", help=\"error mes", "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='command')\n    subparsers.required = True\n\n    create_parser = subparsers.add_parser('create')\n    create_parser.add_argument('-i', '--input-json', help='JSON file to be loaded.')\n    create_parser.add_argument('-o', '--output-json', help='JSON file to be written.')\n    create_parser.add_argument('-s', '--schema', help='JSON schema file.')\n    create_parser.add_argument('-f', '--force', action='store_true', help='Overwrite existing output file.')\n\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser(description=\"A simple CLI tool\")\n    parser.add_argument(\"-v\", \"--version\", action=\"store_true\",\n                        help=\"Show the version number\")\n    parser.add_argument(\"-q\", \"--quiet\", action=\"store_true\",\n                        help=\"Quiet mode, no output\")\n    parser.add_argument(\"--no-color\", action=\"store_true\",\n                        help=\"Disable coloring of output\")\n    return parser.parse_args()\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Test that importing a file works.'\n    )\n    subparsers = parser.add_subparsers(dest='subcommand')\n    subparsers.required = True\n\n    import_parser = subparsers.add_parser(\n        'import', help='Import a file.'\n    )\n    import_parser.add_argument(\n        'file', nargs=1, type=str, help='File to import.'\n    )\n\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='This is a simple example command.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    subparsers = parser.add_subparsers(dest='command')\n\n    add_config(subparsers)\n    add_status(subparsers)\n    add_report(subparsers)\n    add_run(subparsers)\n\n    return parser.parse_args()\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"A simple tool to parse and validate Materials output \"\n        \"from Material Report tool.\")\n\n    parser.add_argument(\n        \"-i\",\n        \"--input-file\",\n        type=str,\n        required=True,\n        help=\"Input file containing the data to process\",\n    )\n\n    parser.add_argument(\n        \"-o\",\n        \"--output-file\",\n        type=str,\n        required=True,\n        help=\"Output file for the validated data\",\n    )\n\n    return parser\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"Parse a series of commands from a given YAML file.\",\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n    )\n\n    subparser = parser.add_subparsers(\n        dest=\"command\", metavar=\"<command>\", required=False\n    )\n\n    for command in COMMANDS:\n        command_parser = subparser.add_parser(\n            command, help=\"Display information about a command.\"\n        )\n        command_parser.add_argument(\n            \"-l\", \"--long\", action=\"store_true\", help=\"Print a table of information.\"\n        )\n        command_parser.add_argument(\n            \"-v\", \"--verbose\", action=\"store_true\", help=\"Print a verbose output.\"\n        )\n        command_parser.add_argument(\n            \"-s\", \"--show-errors\", action=\"store_true\", help=\"Show errors.\"\n        )\n        command_parser.add_argument(\n           ", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(description=\"Test for LilyPond files.\")\n    subparsers = parser.add_subparsers(dest=\"subcommand\")\n    parser_foo = subparsers.add_parser(\"foo\")\n    parser_foo.add_argument(\"--bar\", action=\"store_true\")\n    parser_bar = subparsers.add_parser(\"bar\")\n    parser_bar.add_argument(\"--baz\", action=\"store_true\")\n    parser_baz = subparsers.add_parser(\"baz\")\n    parser_baz.add_argument(\"--qux\", action=\"store_true\")\n    parser_qux = subparsers.add_parser(\"qux\")\n    parser_qux.add_argument(\"--foobar\", action=\"store_true\")\n    parser_qux.add_argument(\"--fooqux\", action=\"store_true\")\n    return parser, subparsers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Summary of commands for demonstration purposes.'\n    )\n    subparsers = parser.add_subparsers(dest='command')\n\n    for command, help_text in COMMANDS.items():\n        subparser = subparsers.add_parser(command)\n        subparser.set_defaults(\n            func=getattr(subparsers, command).__call__,\n            help=help_text\n        )\n\n    return parser, subparsers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='command')\n\n    for command_name, command in commands.items():\n        command_parser = subparsers.add_parser(\n            command_name,\n            help=command.help,\n            description=command.description\n        )\n        command_parser.add_argument(\n            'command',\n            nargs='?',\n            default=None,\n            type=str,\n            metavar='COMMAND',\n            help='The command to run.'\n        )\n\n    return parser, subparsers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"Test that stash commands are recognized as stash commands\"\n    )\n    parser.add_argument(\n        \"-v\", \"--verbose\", action=\"store_true\", help=\"turn on verbosity\"\n    )\n    parser.add_argument(\n        \"-d\", \"--debug\", action=\"store_true\", help=\"turn off debugging\"\n    )\n    parser.add_argument(\n        \"--version\",\n        action=\"store_true\",\n        help=\"Show the version number and exit\",\n    )\n\n    subparsers = parser.add_subparsers(dest=\"stash_cmd\")\n    subparsers.required = True\n    subparsers.add_argument(\n        \"--stash-args\", metavar=\"ARGS\", nargs=\"*\", help=\"stash arguments\"\n    )\n    subparsers.add_argument(\n        \"--stash-failure\", action=\"store_true\", help=\"failure messages\"\n    )\n    subparsers.add_argument(\n        \"--stash-error\", action=\"store_true\", help=\"error mes", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='command')\n    subparsers.required = True\n\n    create_parser = subparsers.add_parser('create')\n    create_parser.add_argument('-i', '--input-json', help='JSON file to be loaded.')\n    create_parser.add_argument('-o', '--output-json', help='JSON file to be written.')\n    create_parser.add_argument('-s', '--schema', help='JSON schema file.')\n    create_parser.add_argument('-f', '--force', action='store_true', help='Overwrite existing output file.')\n\n    return parser, subparsers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(description=\"A simple CLI tool\")\n    parser.add_argument(\"-v\", \"--version\", action=\"store_true\",\n                        help=\"Show the version number\")\n    parser.add_argument(\"-q\", \"--quiet\", action=\"store_true\",\n                        help=\"Quiet mode, no output\")\n    parser.add_argument(\"--no-color\", action=\"store_true\",\n                        help=\"Disable coloring of output\")\n    return parser.parse_args()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Test that importing a file works.'\n    )\n    subparsers = parser.add_subparsers(dest='subcommand')\n    subparsers.required = True\n\n    import_parser = subparsers.add_parser(\n        'import', help='Import a file.'\n    )\n    import_parser.add_argument(\n        'file', nargs=1, type=str, help='File to import.'\n    )\n\n    return parser, subparsers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='This is a simple example command.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    subparsers = parser.add_subparsers(dest='command')\n\n    add_config(subparsers)\n    add_status(subparsers)\n    add_report(subparsers)\n    add_run(subparsers)\n\n    return parser.parse_args()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"A simple tool to parse and validate Materials output \"\n        \"from Material Report tool.\")\n\n    parser.add_argument(\n        \"-i\",\n        \"--input-file\",\n        type=str,\n        required=True,\n        help=\"Input file containing the data to process\",\n    )\n\n    parser.add_argument(\n        \"-o\",\n        \"--output-file\",\n        type=str,\n        required=True,\n        help=\"Output file for the validated data\",\n    )\n\n    return parser\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/config/load.py", "project": "witten/borgmatic", "name": "deep_merge_nodes", "docstring": "Given a nested borgmatic configuration data structure as a list of tuples in the form of:\n\n    (\n        ruamel.yaml.nodes.ScalarNode as a key,\n        ruamel.yaml.nodes.MappingNode or other Node as a value,\n    ),\n\n... deep merge any node values corresponding to duplicate keys and return the result. If\nthere are colliding keys with non-MappingNode values (e.g., integers or strings), the last\nof the values wins.\n\nFor instance, given node values of:\n\n    [\n        (\n            ScalarNode(tag='tag:yaml.org,2002:str', value='retention'),\n            MappingNode(tag='tag:yaml.org,2002:map', value=[\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_hourly'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='24')\n                ),\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_daily'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='7')\n                ),\n            ]),\n        ),\n        (\n            ScalarNode(tag='tag:yaml.org,2002:str', value='retention'),\n            MappingNode(tag='tag:yaml.org,2002:map', value=[\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_daily'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='5')\n                ),\n            ]),\n        ),\n    ]\n\n... the returned result would be:\n\n    [\n        (\n            ScalarNode(tag='tag:yaml.org,2002:str', value='retention'),\n            MappingNode(tag='tag:yaml.org,2002:map', value=[\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_hourly'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='24')\n                ),\n                (\n                    ScalarNode(tag='tag:yaml.org,2002:str', value='keep_daily'),\n                    ScalarNode(tag='tag:yaml.org,2002:int', value='5')\n                ),\n            ]),\n        ),\n    ]\n\nThe purpose of deep merging like this is to support, for instance, merging one borgmatic\nconfiguration file into another for reuse, such that a configuration section (\"retention\",\netc.) does not completely replace the corresponding section in a merged file.", "ques_id": "62b438ba66fea644fe22cca2", "code": ["def deep_merge_nodes(nodes):\n    result = []\n\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            new_node = node.copy()\n            for k, v in new_node.items():\n                new_node[k] = deep_merge_nodes(v)\n            node = new_node\n        elif isinstance(node, ScalarNode):\n            node = node.value\n        elif isinstance(node, list):\n            node = [item.value if isinstance(item, ScalarNode) else item for item in node]\n\n        result.append(node)\n\n    return result\n", "def deep_merge_nodes(nodes):\n    # type: (List[Tuple[Node, MappingNode, Any]]) -> List[Tuple[Node, MappingNode, Any]]\n    \"\"\"\n    Given a nested borgmatic configuration data structure as a list of tuples in the\n    form of:\n\n    :param nodes:\n        A list of tuples in the form of:\n\n            (\n                ruamel.yaml.nodes.ScalarNode as a key,\n                ruamel.yaml.nodes.MappingNode or other Node as a value,\n            )\n\n    :param deep:\n        A boolean indicating if the values should be collapsed into MappingNodes\n        and returned as a list of tuples with their own values.\n    \"\"\"\n    return [\n        (node, mapping_node) if isinstance(node, MappingNode) else node\n        for node, mapping_node in nodes\n        if not (isinstance(node, Node) or isinstance(node, MappingNode))\n    ] if deep els", "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node[0], MappingNode):\n            result.append(deep_merge_nodes(node[0].value))\n        else:\n            result.append(node)\n    return result\n", "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            result.append(deep_merge_nodes(node.value))\n        else:\n            result.append(node)\n    return result\n", "def deep_merge_nodes(nodes):\n    nodes = copy.deepcopy(nodes)\n    for k, v in nodes:\n        if isinstance(v, MappingNode):\n            nodes.append((k, deep_merge_nodes(v)))\n        else:\n            if k in nodes:\n                nodes[k] = [(nodes[k], v)]\n            else:\n                nodes[k] = v\n    return nodes\n", "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            value = node.value\n        else:\n            value = node\n        if value in result:\n            result[result.index(value)].append(node)\n        else:\n            result.append(value)\n    return result\n", "def deep_merge_nodes(nodes):\n    result = []\n\n    for node in nodes:\n        if isinstance(node[1], MappingNode):\n            node_val = node[1].value\n        elif isinstance(node[1], Node):\n            node_val = node[1].value\n        else:\n            node_val = node[1]\n        if node_val in result:\n            result[result.index(node_val)].append(node)\n        else:\n            result.append(node)\n    return result\n", "def deep_merge_nodes(nodes):\n\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            if node.value in result:\n                result[result.index(node.value)] = node.merge(result[result.index(node.value)])\n            else:\n                result.append(node)\n        else:\n            result.append(node)\n    return result\n", "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            if node.value not in result:\n                result.append(node.value)\n            else:\n                result[result.index(node.value)] = node.value\n        else:\n            if node not in result:\n                result.append(node)\n    return result\n", "def deep_merge_nodes(nodes):\n    result = []\n\n    for node in nodes:\n        if isinstance(node[0], MappingNode):\n            next_node = deep_merge_nodes(node[0].value)\n        else:\n            next_node = node[0]\n\n        if isinstance(next_node, MappingNode):\n            next_node.value = node[1]\n        else:\n            next_node.value = next_node\n\n        result.append(next_node)\n\n    return result\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def deep_merge_nodes(nodes):\n    result = []\n\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            new_node = node.copy()\n            for k, v in new_node.items():\n                new_node[k] = deep_merge_nodes(v)\n            node = new_node\n        elif isinstance(node, ScalarNode):\n            node = node.value\n        elif isinstance(node, list):\n            node = [item.value if isinstance(item, ScalarNode) else item for item in node]\n\n        result.append(node)\n\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    # type: (List[Tuple[Node, MappingNode, Any]]) -> List[Tuple[Node, MappingNode, Any]]\n    \"\"\"\n    Given a nested borgmatic configuration data structure as a list of tuples in the\n    form of:\n\n    :param nodes:\n        A list of tuples in the form of:\n\n            (\n                ruamel.yaml.nodes.ScalarNode as a key,\n                ruamel.yaml.nodes.MappingNode or other Node as a value,\n            )\n\n    :param deep:\n        A boolean indicating if the values should be collapsed into MappingNodes\n        and returned as a list of tuples with their own values.\n    \"\"\"\n    return [\n        (node, mapping_node) if isinstance(node, MappingNode) else node\n        for node, mapping_node in nodes\n        if not (isinstance(node, Node) or isinstance(node, MappingNode))\n    ] if deep els", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node[0], MappingNode):\n            result.append(deep_merge_nodes(node[0].value))\n        else:\n            result.append(node)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            result.append(deep_merge_nodes(node.value))\n        else:\n            result.append(node)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    nodes = copy.deepcopy(nodes)\n    for k, v in nodes:\n        if isinstance(v, MappingNode):\n            nodes.append((k, deep_merge_nodes(v)))\n        else:\n            if k in nodes:\n                nodes[k] = [(nodes[k], v)]\n            else:\n                nodes[k] = v\n    return nodes\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            value = node.value\n        else:\n            value = node\n        if value in result:\n            result[result.index(value)].append(node)\n        else:\n            result.append(value)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = []\n\n    for node in nodes:\n        if isinstance(node[1], MappingNode):\n            node_val = node[1].value\n        elif isinstance(node[1], Node):\n            node_val = node[1].value\n        else:\n            node_val = node[1]\n        if node_val in result:\n            result[result.index(node_val)].append(node)\n        else:\n            result.append(node)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            if node.value in result:\n                result[result.index(node.value)] = node.merge(result[result.index(node.value)])\n            else:\n                result.append(node)\n        else:\n            result.append(node)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = []\n    for node in nodes:\n        if isinstance(node, MappingNode):\n            if node.value not in result:\n                result.append(node.value)\n            else:\n                result[result.index(node.value)] = node.value\n        else:\n            if node not in result:\n                result.append(node)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def deep_merge_nodes(nodes):\n    result = []\n\n    for node in nodes:\n        if isinstance(node[0], MappingNode):\n            next_node = deep_merge_nodes(node[0].value)\n        else:\n            next_node = node[0]\n\n        if isinstance(next_node, MappingNode):\n            next_node.value = node[1]\n        else:\n            next_node.value = next_node\n\n        result.append(next_node)\n\n    return result\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/generate_config.py", "project": "witten/borgmatic", "name": "parse_arguments", "docstring": "Given command-line arguments with which this script was invoked, parse the arguments and return\nthem as an ArgumentParser instance.", "ques_id": "62b438b666fea644fe22cc78", "code": ["def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--config')\n    parser.add_argument('--s3-bucket')\n    parser.add_argument('--s3-key')\n    parser.add_argument('--s3-region')\n    parser.add_argument('--s3-endpoint')\n    parser.add_argument('--s3-version', action='store_true')\n    parser.add_argument('--s3-profile')\n    parser.add_argument('--s3-s3-endpoint-url')\n    parser.add_argument('--s3-s3-credentials', default=None)\n    parser.add_argument('--s3-s3-access-key', default=None)\n    parser.add_argument('--s3-s3-secret-key', default=None)\n    parser.add_argument('--s3-region', default=None)\n    parser.add_argument('--s3-endpoint-url-override')\n\n    return parser.parse_args(*arguments)\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-o', '--output-file', required=True,\n                        help='output csv file')\n    parser.add_argument('-d', '--delimiter', required=True,\n                        help='delimiter in csv file')\n    parser.add_argument('-v', '--version', action='version',\n                        version='%(prog)s {}'.format(__version__))\n\n    return parser.parse_args(arguments)\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--version', action='version', version=VERSION)\n    for argument in arguments:\n        parser.add_argument(argument)\n    return parser\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description='Generate a coverage report for the given code.'\n    )\n    parser.add_argument(\n        '--junit-xml',\n        '-x',\n        action='store_true',\n        help='Generate the xml report in junit format.'\n    )\n    parser.add_argument(\n        '--output-file',\n        default='coverage.xml',\n        help='The file to write the xml report to.'\n    )\n    parser.add_argument(\n        '--coverage-xml',\n        '-x',\n        action='store_true',\n        help='Generate the xml report in coverage format.'\n    )\n    parser.add_argument(\n        '--junit-file',\n        default='coverage.xml',\n        help='The file to write the xml report in junit format.'\n    )\n    parser.add_argument(\n        'code',\n        nargs='?'", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '--version',\n        action='store_true',\n        help='Show the version number and exit.'\n    )\n    parser.add_argument(\n        '--debug',\n        action='store_true',\n        help='Show debug messages.'\n    )\n    parser.add_argument(\n        '--config',\n        help='Configuration file to use.'\n    )\n    parser.add_argument(\n        '--config-file',\n        help='Configuration file to use.'\n    )\n    parser.add_argument(\n        '--json',\n        action='store_true',\n        help='Show JSON output instead of printing.'\n    )\n\n    return parser.parse_args(arguments)\n", "def parse_arguments(*arguments):\n\n    parser = argparse.ArgumentParser(\n        description='Test the installation of a repository.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    parser.add_argument(\n        '--repository', '-r',\n        required=False,\n        help='The path to the repository.'\n    )\n\n    parser.add_argument(\n        '--output', '-o',\n        required=False,\n        help='The path to the output file.'\n    )\n\n    return parser\n", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Test that the package was successfully installed\")\n    parser.add_argument(\n        \"-v\", \"--version\", action=\"store_true\",\n        help=\"Show the version number and exit.\")\n    parser.add_argument(\n        \"-d\", \"--debug\", action=\"store_true\",\n        help=\"Show debugging information.\")\n    parser.add_argument(\n        \"--install-dir\", default=\".\",\n        help=\"The directory to install the package from.\")\n    parser.add_argument(\n        \"--requirements-file\", default=\"requirements.txt\",\n        help=\"The file to store the requirements for.\")\n    parser.add_argument(\n        \"--skip-setuptools\", action=\"store_true\",\n        help=\"Skip setuptools installation step.\")\n    parser.add_argument(\n        \"--failure-message\",\n        help=\"A message to be displayed when the test fails.\")\n    parser.add_argument(\n        \"--long-description\",", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Just a Hello World demonstration.\"\n    )\n\n    parser.add_argument(\n        \"-v\",\n        \"--version\",\n        action=\"store_true\",\n        help=\"Show the version number and exit.\",\n    )\n\n    parser.add_argument(\n        \"-n\",\n        \"--name\",\n        action=\"store\",\n        help=\"Show the name of the user who created the comment.\",\n    )\n\n    parser.add_argument(\n        \"-a\",\n        \"--author\",\n        action=\"store\",\n        help=\"Show the author of the user who created the comment.\",\n    )\n\n    parser.add_argument(\n        \"-d\",\n        \"--description\",\n        action=\"store\",\n        help=\"Show the description of the user who created the comment.\",\n    )\n\n    parser.add_argument(\n        \"-i\",\n        \"--issue\",\n        action=\"store\",\n ", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description='Just a Field Tower test script.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    parser.add_argument(\n        '-v', '--version',\n        action='version',\n        version='%(prog)s {}'.format(__version__)\n    )\n\n    parser.add_argument(\n        '-t', '--test',\n        action='store_true',\n        help='Run the tests against the server.'\n    )\n\n    parser.add_argument(\n        '-n', '--name',\n        help='The name of the test being performed.'\n    )\n\n    parser.add_argument(\n        '-s', '--samples',\n        help='The number of samples to run.'\n    )\n\n    parser.add_argument(\n        '-tx', '--test-type',\n        help='The type of test to run.'\n    )\n\n    parser.add_argument(", "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description='Test the behaviour of Nginx which parses HTTP requests and returns responses.')\n    parser.add_argument(\n        '--host', '-h', default='127.0.0.1', type=str, help='HTTP server host address')\n    parser.add_argument(\n        '--port', '-p', default=80, type=int, help='HTTP server port')\n    parser.add_argument(\n        '--username', '-u', default=None, type=str, help='HTTP server username')\n    parser.add_argument(\n        '--password', '-p', default=None, type=str, help='HTTP server password')\n    parser.add_argument(\n        '--url', '-u', default=None, type=str, help='HTTP server url')\n\n    return parser.parse_args(arguments)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--config')\n    parser.add_argument('--s3-bucket')\n    parser.add_argument('--s3-key')\n    parser.add_argument('--s3-region')\n    parser.add_argument('--s3-endpoint')\n    parser.add_argument('--s3-version', action='store_true')\n    parser.add_argument('--s3-profile')\n    parser.add_argument('--s3-s3-endpoint-url')\n    parser.add_argument('--s3-s3-credentials', default=None)\n    parser.add_argument('--s3-s3-access-key', default=None)\n    parser.add_argument('--s3-s3-secret-key', default=None)\n    parser.add_argument('--s3-region', default=None)\n    parser.add_argument('--s3-endpoint-url-override')\n\n    return parser.parse_args(*arguments)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('-o', '--output-file', required=True,\n                        help='output csv file')\n    parser.add_argument('-d', '--delimiter', required=True,\n                        help='delimiter in csv file')\n    parser.add_argument('-v', '--version', action='version',\n                        version='%(prog)s {}'.format(__version__))\n\n    return parser.parse_args(arguments)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--version', action='version', version=VERSION)\n    for argument in arguments:\n        parser.add_argument(argument)\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description='Generate a coverage report for the given code.'\n    )\n    parser.add_argument(\n        '--junit-xml',\n        '-x',\n        action='store_true',\n        help='Generate the xml report in junit format.'\n    )\n    parser.add_argument(\n        '--output-file',\n        default='coverage.xml',\n        help='The file to write the xml report to.'\n    )\n    parser.add_argument(\n        '--coverage-xml',\n        '-x',\n        action='store_true',\n        help='Generate the xml report in coverage format.'\n    )\n    parser.add_argument(\n        '--junit-file',\n        default='coverage.xml',\n        help='The file to write the xml report in junit format.'\n    )\n    parser.add_argument(\n        'code',\n        nargs='?'", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '--version',\n        action='store_true',\n        help='Show the version number and exit.'\n    )\n    parser.add_argument(\n        '--debug',\n        action='store_true',\n        help='Show debug messages.'\n    )\n    parser.add_argument(\n        '--config',\n        help='Configuration file to use.'\n    )\n    parser.add_argument(\n        '--config-file',\n        help='Configuration file to use.'\n    )\n    parser.add_argument(\n        '--json',\n        action='store_true',\n        help='Show JSON output instead of printing.'\n    )\n\n    return parser.parse_args(arguments)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n\n    parser = argparse.ArgumentParser(\n        description='Test the installation of a repository.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    parser.add_argument(\n        '--repository', '-r',\n        required=False,\n        help='The path to the repository.'\n    )\n\n    parser.add_argument(\n        '--output', '-o',\n        required=False,\n        help='The path to the output file.'\n    )\n\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Test that the package was successfully installed\")\n    parser.add_argument(\n        \"-v\", \"--version\", action=\"store_true\",\n        help=\"Show the version number and exit.\")\n    parser.add_argument(\n        \"-d\", \"--debug\", action=\"store_true\",\n        help=\"Show debugging information.\")\n    parser.add_argument(\n        \"--install-dir\", default=\".\",\n        help=\"The directory to install the package from.\")\n    parser.add_argument(\n        \"--requirements-file\", default=\"requirements.txt\",\n        help=\"The file to store the requirements for.\")\n    parser.add_argument(\n        \"--skip-setuptools\", action=\"store_true\",\n        help=\"Skip setuptools installation step.\")\n    parser.add_argument(\n        \"--failure-message\",\n        help=\"A message to be displayed when the test fails.\")\n    parser.add_argument(\n        \"--long-description\",", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Just a Hello World demonstration.\"\n    )\n\n    parser.add_argument(\n        \"-v\",\n        \"--version\",\n        action=\"store_true\",\n        help=\"Show the version number and exit.\",\n    )\n\n    parser.add_argument(\n        \"-n\",\n        \"--name\",\n        action=\"store\",\n        help=\"Show the name of the user who created the comment.\",\n    )\n\n    parser.add_argument(\n        \"-a\",\n        \"--author\",\n        action=\"store\",\n        help=\"Show the author of the user who created the comment.\",\n    )\n\n    parser.add_argument(\n        \"-d\",\n        \"--description\",\n        action=\"store\",\n        help=\"Show the description of the user who created the comment.\",\n    )\n\n    parser.add_argument(\n        \"-i\",\n        \"--issue\",\n        action=\"store\",\n ", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description='Just a Field Tower test script.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    parser.add_argument(\n        '-v', '--version',\n        action='version',\n        version='%(prog)s {}'.format(__version__)\n    )\n\n    parser.add_argument(\n        '-t', '--test',\n        action='store_true',\n        help='Run the tests against the server.'\n    )\n\n    parser.add_argument(\n        '-n', '--name',\n        help='The name of the test being performed.'\n    )\n\n    parser.add_argument(\n        '-s', '--samples',\n        help='The number of samples to run.'\n    )\n\n    parser.add_argument(\n        '-tx', '--test-type',\n        help='The type of test to run.'\n    )\n\n    parser.add_argument(", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*arguments):\n    parser = argparse.ArgumentParser(\n        description='Test the behaviour of Nginx which parses HTTP requests and returns responses.')\n    parser.add_argument(\n        '--host', '-h', default='127.0.0.1', type=str, help='HTTP server host address')\n    parser.add_argument(\n        '--port', '-p', default=80, type=int, help='HTTP server port')\n    parser.add_argument(\n        '--username', '-u', default=None, type=str, help='HTTP server username')\n    parser.add_argument(\n        '--password', '-p', default=None, type=str, help='HTTP server password')\n    parser.add_argument(\n        '--url', '-u', default=None, type=str, help='HTTP server url')\n\n    return parser.parse_args(arguments)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/completion.py", "project": "witten/borgmatic", "name": "parser_flags", "docstring": "Given an argparse.ArgumentParser instance, return its argument flags in a space-separated\nstring.", "ques_id": "62b438b666fea644fe22cc72", "code": ["def parser_flags(parser):\n    return''.join(a.description for a in parser._actions)\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._get_args():\n        flags +='' + str(arg)\n    return flags\n", "def parser_flags(parser):\n    return''.join(str(flag) for flag in parser._flags)\n", "def parser_flags(parser):\n    return''.join([a.choices[0] for a in parser._actions])\n", "def parser_flags(parser):\n    return''.join([str(flag) for flag in parser.flags])\n", "def parser_flags(parser):\n    return''.join(['--{}'.format(k) for k in vars(parser).keys()])\n", "def parser_flags(parser):\n    return''.join('--{}'.format(flag) for flag in parser.flags)\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if isinstance(arg, argparse.ArgumentParser):\n            flags +='' + arg.format_help()\n        elif isinstance(arg, str):\n            flags +='' + arg\n    return flags\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if isinstance(arg, argparse.ArgumentParser):\n            flags +='' + arg.format_help().strip()\n        else:\n            flags +='' + arg\n    return flags\n", "def parser_flags(parser):\n    return''.join(str(flag) for flag in parser._flags)\n"], "level": "self_contained", "generate_results": [{"generate_code": "def parser_flags(parser):\n    return''.join(a.description for a in parser._actions)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._get_args():\n        flags +='' + str(arg)\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join(str(flag) for flag in parser._flags)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join([a.choices[0] for a in parser._actions])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join([str(flag) for flag in parser.flags])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join(['--{}'.format(k) for k in vars(parser).keys()])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join('--{}'.format(flag) for flag in parser.flags)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if isinstance(arg, argparse.ArgumentParser):\n            flags +='' + arg.format_help()\n        elif isinstance(arg, str):\n            flags +='' + arg\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if isinstance(arg, argparse.ArgumentParser):\n            flags +='' + arg.format_help().strip()\n        else:\n            flags +='' + arg\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join(str(flag) for flag in parser._flags)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/completion.py", "project": "witten/borgmatic", "name": "bash_completion", "docstring": "Return a bash completion script for the borgmatic command. Produce this by introspecting\nborgmatic's command-line argument parsers.", "ques_id": "62b438b566fea644fe22cc70", "code": ["def bash_completion():\n    return '''\\\n# Borgmatic command-line completion.\n# This file is auto-generated by the autopkglib package.\n__all__ = [\"cli\", \"bash\", \"bash-completion\", \"bash-completion-min\", \"bash-completion-no-quotes\"]\n'''\n", "def bash_completion():\n    bash_completion = []\n    for argument_name in sorted(_bash_completion.keys()):\n        bash_completion.append(\"--{}={}\".format(argument_name,\n                                                _bash_completion[argument_name]))\n    return bash_completion\n", "def bash_completion():\n    return '\\n'.join('  {} = {}'.format(k, v) for k, v in vars(argparse.ArgumentParser).items() if k.startswith('bash_'))\n", "def bash_completion():\n    return '\\n'.join('  %s %s' % (k.replace('_', '-'), v)\n                     for k, v in sorted(vars(argparse.ArgumentParser()).items()))\n", "def bash_completion():\n    return '''\\\n# Borgmatic CLI completion tool.\n# It produces the full description of what the tool does, and a\n# list of commands that can be used to complete it.\n# It also uses the ``-h`` option to show this help message and exits.\n\n%s\n\n''' % ('\\n'.join('  %s - %s' % (k, v) for k, v in vars(bash).items()),)\n", "def bash_completion():\n    return \"\\n\".join([\"  %s %s\" % (k, v) for k, v in sorted(globals().items())])\n", "def bash_completion():\n    bash_completion_dict = {}\n    for argument_name in sorted(bash_completion_arguments):\n        bash_completion_dict[argument_name] = getattr(bash_completion, argument_name)\n    return bash_completion_dict\n", "def bash_completion():\n    return '\\n'.join(_BASH_COMMANDS)\n", "def bash_completion():\n    return '\\n'.join(_BASH_COMMAND)\n", "def bash_completion():\n    bash_completion = \"\"\"\n        # Borgmatic CLI completion\n        export LIBCLOUD_BASHRC=/dev/null\n        export LIBCLOUD_BASH_COMMAND=$LIBCLOUD_BASHCOMMAND --bash\n        export LIBCLOUD_BASH_COMMAND_CALL_ARGS=$LIBCLOUD_BASHCOMMAND_CALL_ARGS --bash\n        export LIBCLOUD_BASH_COMMAND_EXIT=$LIBCLOUD_BASH_COMMAND_EXIT --bash\n        export LIBCLOUD_BASH_COMMAND_PROMPT=$LIBCLOUD_BASH_COMMAND_PROMPT --bash\n        export LIBCLOUD_BASH_COMMAND_CLEANUP=$LIBCLOUD_BASH_COMMAND_CLEANUP\n        export LIBCLOUD_BASH_COMMAND_EXIT_COMMAND=$LIBCLOUD_BASH_COMMAND_EXIT_COMMAND --bash\n        export LIBCLOUD_BASH_COMMAND_SUPPRESSION=$LIBCLOUD_BASH_COMMAND_SUPPRESSION --bash\n        export LIBCLOUD_BASH_COMMAND_EXIT_COMMAND_PROMPT=$LIBCLOUD_BASH_COMMAND_EXIT_COMMAND_PROMPT --bash\n        export LIBCLOUD_BASH_COMMAND_EXI"], "level": "file_runnable", "generate_results": [{"generate_code": "def bash_completion():\n    return '''\\\n# Borgmatic command-line completion.\n# This file is auto-generated by the autopkglib package.\n__all__ = [\"cli\", \"bash\", \"bash-completion\", \"bash-completion-min\", \"bash-completion-no-quotes\"]\n'''\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    bash_completion = []\n    for argument_name in sorted(_bash_completion.keys()):\n        bash_completion.append(\"--{}={}\".format(argument_name,\n                                                _bash_completion[argument_name]))\n    return bash_completion\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    return '\\n'.join('  {} = {}'.format(k, v) for k, v in vars(argparse.ArgumentParser).items() if k.startswith('bash_'))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    return '\\n'.join('  %s %s' % (k.replace('_', '-'), v)\n                     for k, v in sorted(vars(argparse.ArgumentParser()).items()))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    return '''\\\n# Borgmatic CLI completion tool.\n# It produces the full description of what the tool does, and a\n# list of commands that can be used to complete it.\n# It also uses the ``-h`` option to show this help message and exits.\n\n%s\n\n''' % ('\\n'.join('  %s - %s' % (k, v) for k, v in vars(bash).items()),)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    return \"\\n\".join([\"  %s %s\" % (k, v) for k, v in sorted(globals().items())])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    bash_completion_dict = {}\n    for argument_name in sorted(bash_completion_arguments):\n        bash_completion_dict[argument_name] = getattr(bash_completion, argument_name)\n    return bash_completion_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    return '\\n'.join(_BASH_COMMANDS)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    return '\\n'.join(_BASH_COMMAND)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def bash_completion():\n    bash_completion = \"\"\"\n        # Borgmatic CLI completion\n        export LIBCLOUD_BASHRC=/dev/null\n        export LIBCLOUD_BASH_COMMAND=$LIBCLOUD_BASHCOMMAND --bash\n        export LIBCLOUD_BASH_COMMAND_CALL_ARGS=$LIBCLOUD_BASHCOMMAND_CALL_ARGS --bash\n        export LIBCLOUD_BASH_COMMAND_EXIT=$LIBCLOUD_BASH_COMMAND_EXIT --bash\n        export LIBCLOUD_BASH_COMMAND_PROMPT=$LIBCLOUD_BASH_COMMAND_PROMPT --bash\n        export LIBCLOUD_BASH_COMMAND_CLEANUP=$LIBCLOUD_BASH_COMMAND_CLEANUP\n        export LIBCLOUD_BASH_COMMAND_EXIT_COMMAND=$LIBCLOUD_BASH_COMMAND_EXIT_COMMAND --bash\n        export LIBCLOUD_BASH_COMMAND_SUPPRESSION=$LIBCLOUD_BASH_COMMAND_SUPPRESSION --bash\n        export LIBCLOUD_BASH_COMMAND_EXIT_COMMAND_PROMPT=$LIBCLOUD_BASH_COMMAND_EXIT_COMMAND_PROMPT --bash\n        export LIBCLOUD_BASH_COMMAND_EXI", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/arguments.py", "project": "witten/borgmatic", "name": "parse_arguments", "docstring": "Given command-line arguments with which this script was invoked, parse the arguments and return\nthem as a dict mapping from subparser name (or \"global\") to an argparse.Namespace instance.", "ques_id": "62b438a266fea644fe22cc2e", "code": ["def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '--version',\n        action='version',\n        version='%(prog)s {}'.format(__version__),\n    )\n\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n\n    return vars(parser.parse_args())\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='subcommand')\n    for name, parser_name in PARSERS.items():\n        parser_class = PARSERS[parser_name]\n        parser = parser_class(unparsed_arguments, name=name)\n        subparser_name = 'global' if parser_name == 'global' else name\n        subparsers.add_parser(subparser_name, parser)\n    return vars(parser.parse_args())\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Test the command line tool.\",\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n    )\n\n    parser.add_argument(\n        \"--debug\",\n        action=\"store_true\",\n        help=\"Print debug messages to stderr (for testing purposes).\",\n    )\n\n    parser.add_argument(\n        \"--quiet\",\n        action=\"store_true\",\n        help=\"Print less informational messages to stderr (for testing purposes).\",\n    )\n\n    parser.add_argument(\n        \"-v\", \"--verbose\", action=\"store_true\", help=\"Print more verbose messages.\"\n    )\n\n    parser.add_argument(\n        \"--version\", action=\"store_true\", help=\"Print the version number.\"\n    )\n\n    unparsed_arguments = list(unparsed_arguments)\n\n    for argument in unparsed_arguments:\n        if not argument.startswith(\"--\"):\n            parser.add_argument(argument)\n\n    return vars(par", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.name.split('.'), **argument.options)\n    return vars(parser.parse_args())\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--version', action='version', version=VERSION)\n    parser.add_argument('-v', '--verbose', action='store_true',\n                        help='be more verbose')\n    parser.add_argument('--config-file', nargs='?', default=None,\n                        help='configuration file to use')\n\n    unparsed_arguments = list(unparsed_arguments)\n    unparsed_arguments.append('--config-file')\n\n    if len(unparsed_arguments) == 1:\n        parser.add_argument('--config', nargs='?', default=None)\n        return {}\n\n    parser.add_argument('--config', nargs='?', default=None)\n    return dict(parser.parse_known_args(unparsed_arguments))\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.names, **argument.values)\n    return vars(parser.parse_args())\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Test that the command line tool can parse out a set of \"\n        \"arguments correctly and return those which match the names given \"\n        \"in the subparser definition file.\",\n    )\n\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.names, **argument.values)\n\n    return vars(parser.parse_args(unparsed_arguments))\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Test that the --{} command correctly handles \"\n        \"git repos\".format(\"\".join(UNPARSED_ARGUMENTS)))\n    for unparsed_argument in unparsed_arguments:\n        parser.add_argument(*unparsed_argument.names, **unparsed_argument.kwargs)\n\n    return dict(parser.parse_args(unparsed_arguments))\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='subcommand')\n    for (name, parser) in _get_parsers_for_subcommands():\n        subparser = subparsers.add_parser(name)\n        parser.add_subparser(subparser)\n        parser.parse_known_args(unparsed_arguments)\n\n    return {\n        subcommand: parser.parse_known_args(unparsed_arguments)\n        for subcommand, parser in _get_parsers_for_subcommands()\n    }\n", "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='subcommand')\n    for parse_name in ('list', 'create', 'update', 'delete'):\n        parser_name = parse_name.replace('-', '_')\n        subparser_name = parser_name.replace('_', '-')\n        subparser = subparsers.add_parser(subparser_name, help=parse_name.title())\n        for arg in unparsed_arguments:\n            parse_method = getattr(parser, parse_name)\n            parse_method(arg, subparser)\n    return vars(parser.parse_args(unparsed_arguments))\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\n        '--version',\n        action='version',\n        version='%(prog)s {}'.format(__version__),\n    )\n\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.args, **argument.kwargs)\n\n    return vars(parser.parse_args())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='subcommand')\n    for name, parser_name in PARSERS.items():\n        parser_class = PARSERS[parser_name]\n        parser = parser_class(unparsed_arguments, name=name)\n        subparser_name = 'global' if parser_name == 'global' else name\n        subparsers.add_parser(subparser_name, parser)\n    return vars(parser.parse_args())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Test the command line tool.\",\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter,\n    )\n\n    parser.add_argument(\n        \"--debug\",\n        action=\"store_true\",\n        help=\"Print debug messages to stderr (for testing purposes).\",\n    )\n\n    parser.add_argument(\n        \"--quiet\",\n        action=\"store_true\",\n        help=\"Print less informational messages to stderr (for testing purposes).\",\n    )\n\n    parser.add_argument(\n        \"-v\", \"--verbose\", action=\"store_true\", help=\"Print more verbose messages.\"\n    )\n\n    parser.add_argument(\n        \"--version\", action=\"store_true\", help=\"Print the version number.\"\n    )\n\n    unparsed_arguments = list(unparsed_arguments)\n\n    for argument in unparsed_arguments:\n        if not argument.startswith(\"--\"):\n            parser.add_argument(argument)\n\n    return vars(par", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.name.split('.'), **argument.options)\n    return vars(parser.parse_args())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--version', action='version', version=VERSION)\n    parser.add_argument('-v', '--verbose', action='store_true',\n                        help='be more verbose')\n    parser.add_argument('--config-file', nargs='?', default=None,\n                        help='configuration file to use')\n\n    unparsed_arguments = list(unparsed_arguments)\n    unparsed_arguments.append('--config-file')\n\n    if len(unparsed_arguments) == 1:\n        parser.add_argument('--config', nargs='?', default=None)\n        return {}\n\n    parser.add_argument('--config', nargs='?', default=None)\n    return dict(parser.parse_known_args(unparsed_arguments))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.names, **argument.values)\n    return vars(parser.parse_args())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Test that the command line tool can parse out a set of \"\n        \"arguments correctly and return those which match the names given \"\n        \"in the subparser definition file.\",\n    )\n\n    for argument in unparsed_arguments:\n        parser.add_argument(*argument.names, **argument.values)\n\n    return vars(parser.parse_args(unparsed_arguments))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser(\n        description=\"Test that the --{} command correctly handles \"\n        \"git repos\".format(\"\".join(UNPARSED_ARGUMENTS)))\n    for unparsed_argument in unparsed_arguments:\n        parser.add_argument(*unparsed_argument.names, **unparsed_argument.kwargs)\n\n    return dict(parser.parse_args(unparsed_arguments))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='subcommand')\n    for (name, parser) in _get_parsers_for_subcommands():\n        subparser = subparsers.add_parser(name)\n        parser.add_subparser(subparser)\n        parser.parse_known_args(unparsed_arguments)\n\n    return {\n        subcommand: parser.parse_known_args(unparsed_arguments)\n        for subcommand, parser in _get_parsers_for_subcommands()\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_arguments(*unparsed_arguments):\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='subcommand')\n    for parse_name in ('list', 'create', 'update', 'delete'):\n        parser_name = parse_name.replace('-', '_')\n        subparser_name = parser_name.replace('_', '-')\n        subparser = subparsers.add_parser(subparser_name, help=parse_name.title())\n        for arg in unparsed_arguments:\n            parse_method = getattr(parser, parse_name)\n            parse_method(arg, subparser)\n    return vars(parser.parse_args(unparsed_arguments))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/arguments.py", "project": "witten/borgmatic", "name": "parse_subparser_arguments", "docstring": "Given a sequence of arguments and a dict from subparser name to argparse.ArgumentParser\ninstance, give each requested action's subparser a shot at parsing all arguments. This allows\ncommon arguments like \"--repository\" to be shared across multiple subparsers.\n\nReturn the result as a tuple of (a dict mapping from subparser name to a parsed namespace of\narguments, a list of remaining arguments not claimed by any subparser).", "ques_id": "62b438a266fea644fe22cc2d", "code": ["def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    for subparser in subparsers.values():\n        parsed_arguments.update(subparser.parse_known_args(unparsed_arguments))\n        remaining_arguments.extend(subparser.required_arguments)\n    return (parsed_arguments, remaining_arguments, parsed_arguments.get('--repository'))\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    unparsed_args = unparsed_arguments.copy()\n    remaining_arguments = []\n    for subparser in subparsers._subparserss:\n        if subparser.name not in unparsed_arguments:\n            parsed_arguments[subparser.name] = subparser.parse_args()\n            remaining_arguments.extend(subparser.required_args)\n        else:\n            parsed_arguments[subparser.name] = unparsed_arguments[subparser.name]\n    return (parsed_arguments, remaining_arguments, unparsed_args)\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    for subparser_name in subparsers:\n        subparser = subparsers[subparser_name]\n        parsed_arguments[subparser_name] = subparser.parse_args()\n        remaining_arguments.extend(subparser.required_arguments)\n    for subparser_name in unparsed_arguments:\n        parsed_arguments[subparser_name] = unparsed_arguments[subparser_name]\n    return parsed_arguments, remaining_arguments, remaining_arguments\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    unparsed_arguments = set(unparsed_arguments)\n\n    for parser_name, parser in six.iteritems(subparsers):\n        try:\n            arguments.update(parser.parse_args(unparsed_arguments))\n        except Exception as e:\n            e.args = (\"%s: %s\" % (parser_name, e.args[0]), )\n            raise\n        else:\n            unparsed_arguments.difference_update(arguments)\n            remaining_arguments.extend(arguments.keys())\n\n    # If no arguments were passed to parse, the parser wasn't required. We can\n    # safely return the unparsed arguments which were removed from the\n    # unparsed_arguments set and remaining_arguments.\n    if unparsed_arguments:\n        return (arguments, remaining_arguments, unparsed_arguments)\n    else:\n        return ({}, remaining_arguments, unparse", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    for subparser in subparsers:\n        parser_name = \"--{}\".format(subparser)\n        if parser_name in unparsed_arguments:\n            raise ValueError(\n                \"{} argument supplied to {} is unrecognized\".format(\n                    parser_name, subparser))\n        arguments[parser_name] = parser.parse_known_args(unparsed_arguments[parser_name])\n        remaining_arguments.append(arguments[parser_name])\n\n    return (arguments, remaining_arguments, unparsed_arguments)\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    for parser in subparsers.values():\n        parser_arguments = parser.parse_known_args(unparsed_arguments)\n        arguments.update(parser_arguments)\n        remaining_arguments = remaining_arguments + parser_arguments.args\n    return (arguments, remaining_arguments, unparsed_arguments)\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    for subparser_name in subparsers:\n        parser = subparsers[subparser_name]\n        parsed_arguments[subparser_name] = parser.parse_args(unparsed_arguments)\n        remaining_arguments.extend(parsed_arguments[subparser_name].args)\n    return (parsed_arguments, remaining_arguments, remaining_arguments!= [])\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    for parser in subparsers.values():\n        parser_arguments = parser.parse_known_args(unparsed_arguments)\n        arguments.update(parser_arguments)\n        remaining_arguments.extend(parser_arguments.keys())\n    return (arguments, remaining_arguments, unparsed_arguments)\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    not_claimed_arguments = []\n    for name, parser in subparsers.items():\n        if name not in unparsed_arguments:\n            not_claimed_arguments.append(name)\n            continue\n        args = unparsed_arguments[name]\n        args = parser.parse_known_args(args)\n        parsed_arguments[name] = args\n    return parsed_arguments, not_claimed_arguments, not_claimed_arguments\n", "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    unparsed_arguments = list(unparsed_arguments)\n\n    while unparsed_arguments:\n        name = unparsed_arguments.pop(0)\n        parser = subparsers.get(name, None)\n        if parser is None:\n            raise ValueError('Unknown subparser \"%s\"' % name)\n        parsed_arguments[name] = parser.parse_args()\n        remaining_arguments.extend(parsed_arguments[name].args)\n        unparsed_arguments = unparsed_arguments[\n            len(remaining_arguments):]\n\n    return parsed_arguments, remaining_arguments, unparsed_arguments\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    for subparser in subparsers.values():\n        parsed_arguments.update(subparser.parse_known_args(unparsed_arguments))\n        remaining_arguments.extend(subparser.required_arguments)\n    return (parsed_arguments, remaining_arguments, parsed_arguments.get('--repository'))\n", "is_pass": false, "return_code": 2}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    unparsed_args = unparsed_arguments.copy()\n    remaining_arguments = []\n    for subparser in subparsers._subparserss:\n        if subparser.name not in unparsed_arguments:\n            parsed_arguments[subparser.name] = subparser.parse_args()\n            remaining_arguments.extend(subparser.required_args)\n        else:\n            parsed_arguments[subparser.name] = unparsed_arguments[subparser.name]\n    return (parsed_arguments, remaining_arguments, unparsed_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    for subparser_name in subparsers:\n        subparser = subparsers[subparser_name]\n        parsed_arguments[subparser_name] = subparser.parse_args()\n        remaining_arguments.extend(subparser.required_arguments)\n    for subparser_name in unparsed_arguments:\n        parsed_arguments[subparser_name] = unparsed_arguments[subparser_name]\n    return parsed_arguments, remaining_arguments, remaining_arguments\n", "is_pass": false, "return_code": 2}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    unparsed_arguments = set(unparsed_arguments)\n\n    for parser_name, parser in six.iteritems(subparsers):\n        try:\n            arguments.update(parser.parse_args(unparsed_arguments))\n        except Exception as e:\n            e.args = (\"%s: %s\" % (parser_name, e.args[0]), )\n            raise\n        else:\n            unparsed_arguments.difference_update(arguments)\n            remaining_arguments.extend(arguments.keys())\n\n    # If no arguments were passed to parse, the parser wasn't required. We can\n    # safely return the unparsed arguments which were removed from the\n    # unparsed_arguments set and remaining_arguments.\n    if unparsed_arguments:\n        return (arguments, remaining_arguments, unparsed_arguments)\n    else:\n        return ({}, remaining_arguments, unparse", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    for subparser in subparsers:\n        parser_name = \"--{}\".format(subparser)\n        if parser_name in unparsed_arguments:\n            raise ValueError(\n                \"{} argument supplied to {} is unrecognized\".format(\n                    parser_name, subparser))\n        arguments[parser_name] = parser.parse_known_args(unparsed_arguments[parser_name])\n        remaining_arguments.append(arguments[parser_name])\n\n    return (arguments, remaining_arguments, unparsed_arguments)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    for parser in subparsers.values():\n        parser_arguments = parser.parse_known_args(unparsed_arguments)\n        arguments.update(parser_arguments)\n        remaining_arguments = remaining_arguments + parser_arguments.args\n    return (arguments, remaining_arguments, unparsed_arguments)\n", "is_pass": false, "return_code": 2}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    for subparser_name in subparsers:\n        parser = subparsers[subparser_name]\n        parsed_arguments[subparser_name] = parser.parse_args(unparsed_arguments)\n        remaining_arguments.extend(parsed_arguments[subparser_name].args)\n    return (parsed_arguments, remaining_arguments, remaining_arguments!= [])\n", "is_pass": false, "return_code": 2}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    arguments = {}\n    remaining_arguments = []\n    for parser in subparsers.values():\n        parser_arguments = parser.parse_known_args(unparsed_arguments)\n        arguments.update(parser_arguments)\n        remaining_arguments.extend(parser_arguments.keys())\n    return (arguments, remaining_arguments, unparsed_arguments)\n", "is_pass": false, "return_code": 2}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    not_claimed_arguments = []\n    for name, parser in subparsers.items():\n        if name not in unparsed_arguments:\n            not_claimed_arguments.append(name)\n            continue\n        args = unparsed_arguments[name]\n        args = parser.parse_known_args(args)\n        parsed_arguments[name] = args\n    return parsed_arguments, not_claimed_arguments, not_claimed_arguments\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_subparser_arguments(unparsed_arguments, subparsers):\n    parsed_arguments = {}\n    remaining_arguments = []\n    unparsed_arguments = list(unparsed_arguments)\n\n    while unparsed_arguments:\n        name = unparsed_arguments.pop(0)\n        parser = subparsers.get(name, None)\n        if parser is None:\n            raise ValueError('Unknown subparser \"%s\"' % name)\n        parsed_arguments[name] = parser.parse_args()\n        remaining_arguments.extend(parsed_arguments[name].args)\n        unparsed_arguments = unparsed_arguments[\n            len(remaining_arguments):]\n\n    return parsed_arguments, remaining_arguments, unparsed_arguments\n", "is_pass": false, "return_code": 1}]}
{"file_path": "borgmatic/commands/arguments.py", "project": "witten/borgmatic", "name": "make_parsers", "docstring": "Build a top-level parser and its subparsers and return them as a tuple.", "ques_id": "62b438a266fea644fe22cc2c", "code": ["def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Test command line tool for building cmakelists.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    subparser = parser.add_subparsers(dest='subcommand')\n    subparser.required = True\n    test_generator = parser.add_parser(\n        'test',\n        help='Test command line tool for building cmakelists.'\n    )\n    test_generator.set_defaults(func=test)\n    test_parser = parser.add_parser(\n        'test-all',\n        help='Test command line tool for building cmakelists.'\n    )\n    test_parser.set_defaults(func=test_all)\n    test_parser.add_argument(\n        '--force',\n        action='store_true',\n        help='Force the build of all CMakeLists even if the command fails.',\n    )\n    return parser, subparser\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='A simple command line tool.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    subparsers = parser.add_subparsers(dest='command')\n\n    for command, description in COMMANDS.items():\n        command_parser = subparsers.add_parser(command, help=description)\n        command_parser.add_argument(\n            '-o', '--output', action='store',\n            help='Output directory.'\n        )\n        command_parser.add_argument(\n            '--recursive', action='store_true',\n            help='Recursive output of the command.'\n        )\n        command_parser.set_defaults(func=command)\n\n    return (parser, subparsers)\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Test that commands are run in the background.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    subparsers = parser.add_subparsers(dest='command')\n\n    for cmd in ('test', 'debug', 'test-run'):\n        subparser = subparsers.add_parser(cmd)\n        subparser.add_argument('--version', action='version',\n                               version=cmd_version(cmd))\n        cmd_func = getattr(subparser, 'add_command')\n        cmd_func([cmd])\n\n    return parser.parse_args(), subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"Simple CLI for testing the command line tools.\")\n\n    subparser = parser.add_subparsers(dest=\"command\")\n    subparser.required = True\n    add_required_parser(subparser)\n    add_no_required_parser(subparser)\n    add_list_parser(subparser)\n    add_bash_parser(subparser)\n    add_zsh_parser(subparser)\n\n    return parser.parse_args()\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Simple command line tool to generate a simple text document')\n    subparser = parser.add_subparsers(dest='cmd')\n    subparser.required = True\n\n    build_parser = subparser.add_parser('build',\n                                       help='Build a text document')\n    build_parser.add_argument('input_file', help='The file to be processed.')\n    build_parser.add_argument('-o', '--output-file', required=False,\n                              help='The file to be saved.')\n    build_parser.add_argument('-p', '--pages', type=int, default=1,\n                              help='The number of pages to be shown.')\n\n    return (parser, subparser)\n", "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers()\n\n    for filename, content in FILES.items():\n        sample = subparsers.add_parser(filename)\n        sample.add_argument('-t', '--template', type=str, help='Template file to be substituted.')\n        sample.add_argument('-v', '--verbose', action='store_true', help='Print more verbose output.')\n        sample.add_argument('-n', '--no-colors', action='store_true', help='Don\\'t color output with colors.')\n        sample.add_argument('-o', '--output', type=str, default=filename.split('.')[0] + '.txt',\n                            help='Output file name.')\n\n        for line in content:\n            sample.add_argument('-e', '--editor', type=str, help='Editor command for executing the script.')\n            sample.add_argument('-l', '--line', typ", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Hello, world!',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    subparsers = parser.add_subparsers(dest='command')\n    subparsers.required = True\n    add_command(subparsers, 'test')\n    return parser.parse_args()\n", "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='command')\n\n    build_parser = subparsers.add_parser(\n        'build',\n        help='Build a single package'\n    )\n    build_parser.add_argument(\n        'package',\n        help='Package to build'\n    )\n\n    update_parser = subparsers.add_parser(\n        'update',\n        help='Update the package'\n    )\n    update_parser.add_argument(\n        'package',\n        help='Package to update'\n    )\n\n    remove_parser = subparsers.add_parser(\n       'remove',\n        help='Remove a package'\n    )\n    remove_parser.add_argument(\n        'package',\n        help='Package to remove'\n    )\n\n    return parser, subparsers\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Common User Password Manager for Google App Engine'\n    )\n    parser.add_argument(\n        '--version',\n        action='version',\n        version='%(prog)s {}'.format(__version__)\n    )\n    return parser\n", "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Program that parses files containing YAML files.')\n    parser.add_argument(\n        '-v', '--version',\n        action='version',\n        version='%(prog)s {}'.format(__version__))\n    parser.add_argument(\n        '-f', '--file',\n        metavar='FILE',\n        nargs='+',\n        help='YAML files to parse.')\n    return parser.parse_args()\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Test command line tool for building cmakelists.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    subparser = parser.add_subparsers(dest='subcommand')\n    subparser.required = True\n    test_generator = parser.add_parser(\n        'test',\n        help='Test command line tool for building cmakelists.'\n    )\n    test_generator.set_defaults(func=test)\n    test_parser = parser.add_parser(\n        'test-all',\n        help='Test command line tool for building cmakelists.'\n    )\n    test_parser.set_defaults(func=test_all)\n    test_parser.add_argument(\n        '--force',\n        action='store_true',\n        help='Force the build of all CMakeLists even if the command fails.',\n    )\n    return parser, subparser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='A simple command line tool.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n\n    subparsers = parser.add_subparsers(dest='command')\n\n    for command, description in COMMANDS.items():\n        command_parser = subparsers.add_parser(command, help=description)\n        command_parser.add_argument(\n            '-o', '--output', action='store',\n            help='Output directory.'\n        )\n        command_parser.add_argument(\n            '--recursive', action='store_true',\n            help='Recursive output of the command.'\n        )\n        command_parser.set_defaults(func=command)\n\n    return (parser, subparsers)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Test that commands are run in the background.',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    subparsers = parser.add_subparsers(dest='command')\n\n    for cmd in ('test', 'debug', 'test-run'):\n        subparser = subparsers.add_parser(cmd)\n        subparser.add_argument('--version', action='version',\n                               version=cmd_version(cmd))\n        cmd_func = getattr(subparser, 'add_command')\n        cmd_func([cmd])\n\n    return parser.parse_args(), subparsers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description=\"Simple CLI for testing the command line tools.\")\n\n    subparser = parser.add_subparsers(dest=\"command\")\n    subparser.required = True\n    add_required_parser(subparser)\n    add_no_required_parser(subparser)\n    add_list_parser(subparser)\n    add_bash_parser(subparser)\n    add_zsh_parser(subparser)\n\n    return parser.parse_args()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Simple command line tool to generate a simple text document')\n    subparser = parser.add_subparsers(dest='cmd')\n    subparser.required = True\n\n    build_parser = subparser.add_parser('build',\n                                       help='Build a text document')\n    build_parser.add_argument('input_file', help='The file to be processed.')\n    build_parser.add_argument('-o', '--output-file', required=False,\n                              help='The file to be saved.')\n    build_parser.add_argument('-p', '--pages', type=int, default=1,\n                              help='The number of pages to be shown.')\n\n    return (parser, subparser)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers()\n\n    for filename, content in FILES.items():\n        sample = subparsers.add_parser(filename)\n        sample.add_argument('-t', '--template', type=str, help='Template file to be substituted.')\n        sample.add_argument('-v', '--verbose', action='store_true', help='Print more verbose output.')\n        sample.add_argument('-n', '--no-colors', action='store_true', help='Don\\'t color output with colors.')\n        sample.add_argument('-o', '--output', type=str, default=filename.split('.')[0] + '.txt',\n                            help='Output file name.')\n\n        for line in content:\n            sample.add_argument('-e', '--editor', type=str, help='Editor command for executing the script.')\n            sample.add_argument('-l', '--line', typ", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Hello, world!',\n        formatter_class=argparse.ArgumentDefaultsHelpFormatter\n    )\n    subparsers = parser.add_subparsers(dest='command')\n    subparsers.required = True\n    add_command(subparsers, 'test')\n    return parser.parse_args()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser()\n    subparsers = parser.add_subparsers(dest='command')\n\n    build_parser = subparsers.add_parser(\n        'build',\n        help='Build a single package'\n    )\n    build_parser.add_argument(\n        'package',\n        help='Package to build'\n    )\n\n    update_parser = subparsers.add_parser(\n        'update',\n        help='Update the package'\n    )\n    update_parser.add_argument(\n        'package',\n        help='Package to update'\n    )\n\n    remove_parser = subparsers.add_parser(\n       'remove',\n        help='Remove a package'\n    )\n    remove_parser.add_argument(\n        'package',\n        help='Package to remove'\n    )\n\n    return parser, subparsers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Common User Password Manager for Google App Engine'\n    )\n    parser.add_argument(\n        '--version',\n        action='version',\n        version='%(prog)s {}'.format(__version__)\n    )\n    return parser\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_parsers():\n    parser = argparse.ArgumentParser(\n        description='Program that parses files containing YAML files.')\n    parser.add_argument(\n        '-v', '--version',\n        action='version',\n        version='%(prog)s {}'.format(__version__))\n    parser.add_argument(\n        '-f', '--file',\n        metavar='FILE',\n        nargs='+',\n        help='YAML files to parse.')\n    return parser.parse_args()\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_10.py", "name": "paging", "docstring": "Returns WAPI response page by page\n\nArgs:\n    response (list): WAPI response.\n    max_results (int): Maximum number of objects to be returned in one page.\nReturns:\n    Generator object with WAPI response split page by page.", "ques_id": "62ece4982e6aefcf4aabbd5f", "code": ["def paging(response, max_results):\n    offset = 0\n    while offset < max_results:\n        for item in response:\n            yield item\n        offset += max_results\n", "def paging(response, max_results):\n    offset = 0\n    page_size = len(response)\n\n    while offset < max_results:\n        for i, result in enumerate(response):\n            result_page = result['results']['value']\n            if i < page_size - 1:\n                yield result_page\n            else:\n                break\n        offset += page_size\n", "def paging(response, max_results):\n    if len(response) > max_results:\n        response = response[:max_results]\n    for item in response:\n        yield item\n", "def paging(response, max_results):\n\n    for item in response:\n        if len(item) < max_results:\n            yield item\n", "def paging(response, max_results):\n    offset = 0\n    page_size = int(response['meta']['pagination']['pageSize'])\n\n    while offset < max_results:\n        for item in response['data']:\n            yield item\n\n        offset += page_size\n", "def paging(response, max_results):\n    return (response[i:i + max_results] for i in range(0, len(response), max_results))\n", "def paging(response, max_results):\n\n    for i in range(0, max_results):\n        yield response[i:i + 1]\n", "def paging(response, max_results):\n    if not response:\n        return\n\n    for page in range(0, max_results):\n        yield response[page * 100:(page + 1) * 100]\n", "def paging(response, max_results):\n    page = 1\n    while True:\n        if len(response) <= max_results:\n            yield response[page - 1]\n            if page == 1:\n                break\n            page += 1\n        response = response[page:]\n", "def paging(response, max_results):\n    if not response:\n        raise ValueError(\"Response list is empty\")\n\n    if len(response) > max_results:\n        response = response[:max_results]\n\n    for item in response:\n        yield item\n"], "level": "self_contained", "generate_results": [{"generate_code": "def paging(response, max_results):\n    offset = 0\n    while offset < max_results:\n        for item in response:\n            yield item\n        offset += max_results\n", "is_pass": false, "return_code": 1}, {"generate_code": "def paging(response, max_results):\n    offset = 0\n    page_size = len(response)\n\n    while offset < max_results:\n        for i, result in enumerate(response):\n            result_page = result['results']['value']\n            if i < page_size - 1:\n                yield result_page\n            else:\n                break\n        offset += page_size\n", "is_pass": false, "return_code": 1}, {"generate_code": "def paging(response, max_results):\n    if len(response) > max_results:\n        response = response[:max_results]\n    for item in response:\n        yield item\n", "is_pass": false, "return_code": 1}, {"generate_code": "def paging(response, max_results):\n\n    for item in response:\n        if len(item) < max_results:\n            yield item\n", "is_pass": false, "return_code": 1}, {"generate_code": "def paging(response, max_results):\n    offset = 0\n    page_size = int(response['meta']['pagination']['pageSize'])\n\n    while offset < max_results:\n        for item in response['data']:\n            yield item\n\n        offset += page_size\n", "is_pass": false, "return_code": 1}, {"generate_code": "def paging(response, max_results):\n    return (response[i:i + max_results] for i in range(0, len(response), max_results))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def paging(response, max_results):\n\n    for i in range(0, max_results):\n        yield response[i:i + 1]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def paging(response, max_results):\n    if not response:\n        return\n\n    for page in range(0, max_results):\n        yield response[page * 100:(page + 1) * 100]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def paging(response, max_results):\n    page = 1\n    while True:\n        if len(response) <= max_results:\n            yield response[page - 1]\n            if page == 1:\n                break\n            page += 1\n        response = response[page:]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def paging(response, max_results):\n    if not response:\n        raise ValueError(\"Response list is empty\")\n\n    if len(response) > max_results:\n        response = response[:max_results]\n\n    for item in response:\n        yield item\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_20.py", "name": "size_to_bytes", "docstring": "Convert human readable file size to bytes.\n\nResulting value is an approximation as input value is in most case rounded.\n\nArgs:\n    size: A string representing a human readable file size (eg: '500K')\n\nReturns:\n    A decimal representation of file size\n\n    Examples::\n\n        >>> size_to_bytes(\"500\")\n        500\n        >>> size_to_bytes(\"1K\")\n        1000", "ques_id": "62ece4982e6aefcf4aabbd60", "code": ["def size_to_bytes(size: str) -> int:\n    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]:\n        if abs(int(size)) < 1024:\n            return int(size)\n        size /= 1024\n    return int(round(size))\n", "def size_to_bytes(size: str) -> int:\n    for factor, precision in FACTORS:\n        if size.endswith(factor):\n            break\n\n    # Assume 8 bytes for a single factor\n    num = float(size[:-1])\n    suffixes = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\"]\n    i = int(math.floor(math.log(num, 1024)))\n    p = math.pow(1024, i)\n    s = round(num / p, precision)\n    return int(s.to_bytes(size[-1:], \"big\"))\n", "def size_to_bytes(size: str) -> int:\n    value = float(size)\n    for x in ['B', 'KB', 'MB', 'GB', 'TB']:\n        if value < 1024:\n            return value\n        value /= 1024.0\n    return value\n", "def size_to_bytes(size: str) -> int:\n    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\"]:\n        if unit in size:\n            return int(size.rstrip(unit))\n    raise ValueError(\"Unknown unit {}\".format(unit))\n", "def size_to_bytes(size: str) -> int:\n    value, unit = _get_unit(size)\n    if unit == \"B\":\n        return value\n    elif unit == \"KiB\":\n        return value // 1024\n    elif unit == \"MiB\":\n        return value // 1024 // 1024\n    elif unit == \"GiB\":\n        return value // 1024 // 1024 // 1024\n    elif unit == \"TiB\":\n        return value // 1024 // 1024 // 1024 // 1024\n    elif unit == \"PiB\":\n        return value // 1024 // 1024 // 1024 // 1024\n    elif unit == \"EiB\":\n        return value // 1024 // 1024 // 1024 // 1024 // 1024\n    elif unit == \"ZiB\":\n        return value // 1024 // 1024 // 1024 // 1024 // 1024\n    elif unit == \"YiB\":\n        return value // 1024 // 1024 // 1024 // 1024 // 1024\n   ", "def size_to_bytes(size: str) -> int:\n    multiplier = 1024\n    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n        if unit in size:\n            return int(size.split(unit)[0]) * multiplier\n    return 0\n", "def size_to_bytes(size: str) -> int:\n    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n        if size.endswith(unit):\n            size = size[:-len(unit)]\n            return int(size)\n\n    # No result, default to bytes\n    return int(size)\n", "def size_to_bytes(size: str) -> int:\n    for factor, unit in SZ_UNITS:\n        if size.endswith(factor):\n            size = size[:-len(factor)]\n            break\n    else:\n        raise ValueError(\"Unknown size format: %s\" % size)\n    num, unit = float(size.replace('B', '')), 'B'\n    if 'K' in size:\n        num /= 1024.0\n    if 'M' in size:\n        num /= 1024.0 * 1024.0\n    if 'G' in size:\n        num /= 1024.0 * 1024\n    if 'T' in size:\n        num /= 1024\n    if 'P' in size:\n        num /= 1024 * 1024\n    return round(num, 2) if unit == 'B' else num\n", "def size_to_bytes(size: str) -> int:\n    if not size:\n        return 0\n    return int(float(size) / 1024)\n", "def size_to_bytes(size: str) -> int:\n    value = Decimal(size.replace(\"M\", \"\"))\n    value /= Decimal(1024 ** 2)\n    value = int(round(value))\n    return value\n"], "level": "self_contained", "generate_results": [{"generate_code": "def size_to_bytes(size: str) -> int:\n    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\"]:\n        if abs(int(size)) < 1024:\n            return int(size)\n        size /= 1024\n    return int(round(size))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    for factor, precision in FACTORS:\n        if size.endswith(factor):\n            break\n\n    # Assume 8 bytes for a single factor\n    num = float(size[:-1])\n    suffixes = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\"]\n    i = int(math.floor(math.log(num, 1024)))\n    p = math.pow(1024, i)\n    s = round(num / p, precision)\n    return int(s.to_bytes(size[-1:], \"big\"))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    value = float(size)\n    for x in ['B', 'KB', 'MB', 'GB', 'TB']:\n        if value < 1024:\n            return value\n        value /= 1024.0\n    return value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    for unit in [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\"]:\n        if unit in size:\n            return int(size.rstrip(unit))\n    raise ValueError(\"Unknown unit {}\".format(unit))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    value, unit = _get_unit(size)\n    if unit == \"B\":\n        return value\n    elif unit == \"KiB\":\n        return value // 1024\n    elif unit == \"MiB\":\n        return value // 1024 // 1024\n    elif unit == \"GiB\":\n        return value // 1024 // 1024 // 1024\n    elif unit == \"TiB\":\n        return value // 1024 // 1024 // 1024 // 1024\n    elif unit == \"PiB\":\n        return value // 1024 // 1024 // 1024 // 1024\n    elif unit == \"EiB\":\n        return value // 1024 // 1024 // 1024 // 1024 // 1024\n    elif unit == \"ZiB\":\n        return value // 1024 // 1024 // 1024 // 1024 // 1024\n    elif unit == \"YiB\":\n        return value // 1024 // 1024 // 1024 // 1024 // 1024\n   ", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    multiplier = 1024\n    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n        if unit in size:\n            return int(size.split(unit)[0]) * multiplier\n    return 0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n        if size.endswith(unit):\n            size = size[:-len(unit)]\n            return int(size)\n\n    # No result, default to bytes\n    return int(size)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    for factor, unit in SZ_UNITS:\n        if size.endswith(factor):\n            size = size[:-len(factor)]\n            break\n    else:\n        raise ValueError(\"Unknown size format: %s\" % size)\n    num, unit = float(size.replace('B', '')), 'B'\n    if 'K' in size:\n        num /= 1024.0\n    if 'M' in size:\n        num /= 1024.0 * 1024.0\n    if 'G' in size:\n        num /= 1024.0 * 1024\n    if 'T' in size:\n        num /= 1024\n    if 'P' in size:\n        num /= 1024 * 1024\n    return round(num, 2) if unit == 'B' else num\n", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    if not size:\n        return 0\n    return int(float(size) / 1024)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def size_to_bytes(size: str) -> int:\n    value = Decimal(size.replace(\"M\", \"\"))\n    value /= Decimal(1024 ** 2)\n    value = int(round(value))\n    return value\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_14.py", "name": "_dictsum", "docstring": "Combine values of the dictionaries supplied by iterable dicts.\n\n>>> _dictsum([{'a': 1, 'b': 2}, {'a': 5, 'b': 0}])\n{'a': 6, 'b': 2}", "ques_id": "62ece4982e6aefcf4aabbd61", "code": ["def _dictsum(dicts):\n    return dict(sum(d.items(), ()) for d in dicts)\n", "def _dictsum(dicts):\n    return dict(reduce(operator.add, map(dict.items, dicts)))\n", "def _dictsum(dicts):\n    return dict(sum(d.items(), ()) for d in dicts)\n", "def _dictsum(dicts):\n    return dict(reduce(operator.add, map(dict.items, dicts)))\n", "def _dictsum(dicts):\n    return dict(reduce(operator.add, map(dict.items, dicts)))\n", "def _dictsum(dicts):\n    return dict(reduce(operator.add, map(dict.items, dicts)))\n", "def _dictsum(dicts):\n    return dict(itertools.chain.from_iterable(dicts))\n", "def _dictsum(dicts):\n    return dict(sum(d.items(), ()) for d in dicts)\n", "def _dictsum(dicts):\n    return dict(sum(d.items(), ()) for d in dicts)\n", "def _dictsum(dicts):\n    return dict(sum(dicts, {}))\n"], "level": "self_contained", "generate_results": [{"generate_code": "def _dictsum(dicts):\n    return dict(sum(d.items(), ()) for d in dicts)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dictsum(dicts):\n    return dict(reduce(operator.add, map(dict.items, dicts)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dictsum(dicts):\n    return dict(sum(d.items(), ()) for d in dicts)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dictsum(dicts):\n    return dict(reduce(operator.add, map(dict.items, dicts)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dictsum(dicts):\n    return dict(reduce(operator.add, map(dict.items, dicts)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dictsum(dicts):\n    return dict(reduce(operator.add, map(dict.items, dicts)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dictsum(dicts):\n    return dict(itertools.chain.from_iterable(dicts))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dictsum(dicts):\n    return dict(sum(d.items(), ()) for d in dicts)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dictsum(dicts):\n    return dict(sum(d.items(), ()) for d in dicts)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dictsum(dicts):\n    return dict(sum(dicts, {}))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_15.py", "name": "_replace_url_args", "docstring": "Replace any custom string URL items with values in args", "ques_id": "62ece4982e6aefcf4aabbd62", "code": ["def _replace_url_args(url, url_args):\n    new_url = []\n    for item in url:\n        if item in url_args:\n            new_url.append(url_args[item])\n        else:\n            new_url.append(item)\n    return ''.join(new_url)\n", "def _replace_url_args(url, url_args):\n    return url.format(**url_args)\n", "def _replace_url_args(url, url_args):\n    for key, value in url_args.items():\n        url = re.sub('{{{}}}'.format(key), value, url)\n    return url\n", "def _replace_url_args(url, url_args):\n    for key, value in url_args.items():\n        url = url.replace('{{' + key + '}}', value)\n    return url\n", "def _replace_url_args(url, url_args):\n    return url.format(**url_args)\n", "def _replace_url_args(url, url_args):\n    for key, value in url_args.items():\n        url.query[key] = value\n    return url\n", "def _replace_url_args(url, url_args):\n    return url.format(**url_args)\n", "def _replace_url_args(url, url_args):\n    for key, value in url_args.items():\n        url.query.setdefault(key, value)\n    return url\n", "def _replace_url_args(url, url_args):\n    for key, value in url_args.items():\n        url = re.sub(r'{{{0}}}'.format(key), value, url)\n    return url\n", "def _replace_url_args(url, url_args):\n    return url.replace('%s', urlencode(url_args))\n"], "level": "self_contained", "generate_results": [{"generate_code": "def _replace_url_args(url, url_args):\n    new_url = []\n    for item in url:\n        if item in url_args:\n            new_url.append(url_args[item])\n        else:\n            new_url.append(item)\n    return ''.join(new_url)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    return url.format(**url_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    for key, value in url_args.items():\n        url = re.sub('{{{}}}'.format(key), value, url)\n    return url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    for key, value in url_args.items():\n        url = url.replace('{{' + key + '}}', value)\n    return url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    return url.format(**url_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    for key, value in url_args.items():\n        url.query[key] = value\n    return url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    return url.format(**url_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    for key, value in url_args.items():\n        url.query.setdefault(key, value)\n    return url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    for key, value in url_args.items():\n        url = re.sub(r'{{{0}}}'.format(key), value, url)\n    return url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_url_args(url, url_args):\n    return url.replace('%s', urlencode(url_args))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_5.py", "name": "is_none_string", "docstring": "Check if a string represents a None value.", "ques_id": "62ece4982e6aefcf4aabbd63", "code": ["def is_none_string(val: str) -> bool:\n    return val == 'None' or val is None\n", "def is_none_string(val: str) -> bool:\n    return val is None or val == ''\n", "def is_none_string(val: str) -> bool:\n    return val is None or val == ''\n", "def is_none_string(val: Any) -> bool:\n    return val is None or isinstance(val, str) and val == ''\n", "def is_none_string(val: str) -> bool:\n    return val is None or val == ''\n", "def is_none_string(val: Any) -> bool:\n    return val is None or isinstance(val, str) and val == ''\n", "def is_none_string(val: str) -> bool:\n    return val is None or val == ''\n", "def is_none_string(val: Any) -> bool:\n    return val is None or type(val) is str and val == ''\n", "def is_none_string(val: str) -> bool:\n    return val is None or val == \"\"\n", "def is_none_string(val: str) -> bool:\n    return val is None or val == ''\n"], "level": "self_contained", "generate_results": [{"generate_code": "def is_none_string(val: str) -> bool:\n    return val == 'None' or val is None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_none_string(val: str) -> bool:\n    return val is None or val == ''\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_none_string(val: str) -> bool:\n    return val is None or val == ''\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_none_string(val: Any) -> bool:\n    return val is None or isinstance(val, str) and val == ''\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_none_string(val: str) -> bool:\n    return val is None or val == ''\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_none_string(val: Any) -> bool:\n    return val is None or isinstance(val, str) and val == ''\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_none_string(val: str) -> bool:\n    return val is None or val == ''\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_none_string(val: Any) -> bool:\n    return val is None or type(val) is str and val == ''\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_none_string(val: str) -> bool:\n    return val is None or val == \"\"\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_none_string(val: str) -> bool:\n    return val is None or val == ''\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_1.py", "name": "strip_root", "docstring": "Remove root from path, throw exception on failure.", "ques_id": "62ece4982e6aefcf4aabbd64", "code": ["def strip_root(path, root):\n    if root:\n        if path.startswith(root):\n            path = path[len(root):]\n        else:\n            raise BlobException(\n                \"Path {path} does not start with root {root}\".format(\n                    path=path, root=root))\n    return path\n", "def strip_root(path, root):\n    if path == root:\n        return path\n    elif path.startswith(root + '/'):\n        return path[len(root):]\n    else:\n        raise RuntimeError(\"Not root of path: '%s' and '%s'\" % (path, root))\n", "def strip_root(path, root):\n    if path == root:\n        return path\n    if path[-1]!= '/':\n        raise Exception(\n            'Cannot remove root from path: {}, '\n            'path does not end with \"/\".'.format(path)\n        )\n    return path[:-1]\n", "def strip_root(path, root):\n    if root:\n        path = '/'.join([p.lstrip('/') for p in path.split('/')])\n        path = '/'.join([p.rstrip('/') for p in path.split('/')])\n        path = '/'.join([p.lstrip(root) for p in path.split('/')])\n        path = '/'.join([p.rstrip(root) for p in path.split('/')])\n    return path\n", "def strip_root(path, root):\n    if root == '/':\n        return path\n    if path == '/':\n        path = root\n    return path\n", "def strip_root(path, root):\n    if path.startswith(root):\n        path = path[len(root):]\n    return path\n", "def strip_root(path, root):\n    if path == root:\n        return path\n    if path[:len(root)] == root:\n        return path[len(root):]\n    return ''\n", "def strip_root(path, root):\n    if path == '':\n        return root\n\n    if path[0] == root:\n        return path[1:]\n\n    return path\n", "def strip_root(path, root):\n    if root == '/':\n        return path\n    elif path[:len(root)] == root:\n        return path[len(root):]\n    else:\n        raise ValueError('Invalid path {}'.format(path))\n", "def strip_root(path, root):\n    if not path:\n        raise Exception('Invalid path')\n    if path[0] == root:\n        path = path[1:]\n    return path\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def strip_root(path, root):\n    if root:\n        if path.startswith(root):\n            path = path[len(root):]\n        else:\n            raise BlobException(\n                \"Path {path} does not start with root {root}\".format(\n                    path=path, root=root))\n    return path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n    if path == root:\n        return path\n    elif path.startswith(root + '/'):\n        return path[len(root):]\n    else:\n        raise RuntimeError(\"Not root of path: '%s' and '%s'\" % (path, root))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n    if path == root:\n        return path\n    if path[-1]!= '/':\n        raise Exception(\n            'Cannot remove root from path: {}, '\n            'path does not end with \"/\".'.format(path)\n        )\n    return path[:-1]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n    if root:\n        path = '/'.join([p.lstrip('/') for p in path.split('/')])\n        path = '/'.join([p.rstrip('/') for p in path.split('/')])\n        path = '/'.join([p.lstrip(root) for p in path.split('/')])\n        path = '/'.join([p.rstrip(root) for p in path.split('/')])\n    return path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n    if root == '/':\n        return path\n    if path == '/':\n        path = root\n    return path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n    if path.startswith(root):\n        path = path[len(root):]\n    return path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n    if path == root:\n        return path\n    if path[:len(root)] == root:\n        return path[len(root):]\n    return ''\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n    if path == '':\n        return root\n\n    if path[0] == root:\n        return path[1:]\n\n    return path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n    if root == '/':\n        return path\n    elif path[:len(root)] == root:\n        return path[len(root):]\n    else:\n        raise ValueError('Invalid path {}'.format(path))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def strip_root(path, root):\n    if not path:\n        raise Exception('Invalid path')\n    if path[0] == root:\n        path = path[1:]\n    return path\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_8.py", "name": "parser_flags", "docstring": "Given an argparse.ArgumentParser instance, return its argument flags in a space-separated\nstring.", "ques_id": "62ece4982e6aefcf4aabbd65", "code": ["def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.dest is None:\n            flags +='' + arg._flag_name\n        else:\n            flags +='' + arg._flag_name +'' + arg.dest\n    return flags\n", "def parser_flags(parser):\n    return''.join(p.action for p in parser._option_groups)\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.nargs == argparse.OPTIONAL:\n            flags +=''\n        elif arg.nargs == argparse.ZERO_OR_MORE:\n            flags +='-'\n        elif arg.nargs == argparse.ZERO_OR_MORE:\n            flags +=''\n        elif arg.nargs == argparse.ZERO_OR_MORE:\n            flags +=''\n        elif arg.nargs == argparse.ONE_OR_MORE:\n            flags +=''\n        elif arg.nargs == argparse.ZERO_OR_MORE:\n            flags +=''\n        elif arg.nargs == argparse.ONE_OR_MORE:\n            flags +=''\n        elif arg.nargs == argparse.ZERO_OR_MORE:\n            flags +=''\n        e", "def parser_flags(parser):\n    flags = []\n    for argument_group in parser._action_groups:\n        for action in argument_group._group_actions:\n            if action.dest == 'flags':\n                flags.extend(action._flags)\n    return''.join(flags)\n", "def parser_flags(parser):\n    flags = ''\n    for argument_group in parser._action_groups:\n        for action in argument_group._group_actions:\n            if action.dest == 'flags':\n                flags +='' + action._option_strings[0]\n                for flag in action._option_strings[1:]:\n                    flags +='' + flag\n    return flags\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.nargs == argparse.ZERO_OR_MORE:\n            flags +=''\n        else:\n            flags += '-' * arg.default\n    return flags\n", "def parser_flags(parser):\n    return''.join(a.argparse_args()[0] for a in parser._actions)\n", "def parser_flags(parser):\n    return''.join(flag.name for flag in parser._option_classes)\n", "def parser_flags(parser):\n    return''.join(flag.name for flag in parser._option_classes)\n", "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.dest!= 'args':\n            flags +='' + arg._flag_str()\n    return flags\n"], "level": "self_contained", "generate_results": [{"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.dest is None:\n            flags +='' + arg._flag_name\n        else:\n            flags +='' + arg._flag_name +'' + arg.dest\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join(p.action for p in parser._option_groups)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.nargs == argparse.OPTIONAL:\n            flags +=''\n        elif arg.nargs == argparse.ZERO_OR_MORE:\n            flags +='-'\n        elif arg.nargs == argparse.ZERO_OR_MORE:\n            flags +=''\n        elif arg.nargs == argparse.ZERO_OR_MORE:\n            flags +=''\n        elif arg.nargs == argparse.ONE_OR_MORE:\n            flags +=''\n        elif arg.nargs == argparse.ZERO_OR_MORE:\n            flags +=''\n        elif arg.nargs == argparse.ONE_OR_MORE:\n            flags +=''\n        elif arg.nargs == argparse.ZERO_OR_MORE:\n            flags +=''\n        e", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = []\n    for argument_group in parser._action_groups:\n        for action in argument_group._group_actions:\n            if action.dest == 'flags':\n                flags.extend(action._flags)\n    return''.join(flags)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for argument_group in parser._action_groups:\n        for action in argument_group._group_actions:\n            if action.dest == 'flags':\n                flags +='' + action._option_strings[0]\n                for flag in action._option_strings[1:]:\n                    flags +='' + flag\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.nargs == argparse.ZERO_OR_MORE:\n            flags +=''\n        else:\n            flags += '-' * arg.default\n    return flags\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join(a.argparse_args()[0] for a in parser._actions)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join(flag.name for flag in parser._option_classes)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    return''.join(flag.name for flag in parser._option_classes)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parser_flags(parser):\n    flags = ''\n    for arg in parser._actions:\n        if arg.dest!= 'args':\n            flags +='' + arg._flag_str()\n    return flags\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_19.py", "name": "was_processed", "docstring": "Check if a file or directory has already been processed.\n\nTo prevent recursion, expand the path name to an absolution path\ncall this function with a set that will store all the entries and\nthe entry to test. If the entry is already in the set, report the issue\nand return ``True``. Otherwise, add the entry to the set and return\n``False`` to allow the path to be processed.\n\nArgs:\n    processed: Set to store processed pathnames\n    path_name: Path to a directory or file\n    verbose: True if verbose output is requested\n\nReturns:\n    True if it's already in the set. False if not.", "ques_id": "62ece4982e6aefcf4aabbd66", "code": ["def was_processed(processed, path_name, verbose):\n\n    # Get the list of files in the path.\n    files = os.listdir(path_name)\n\n    # If the entry is already in the set, return false.\n    if path_name in processed:\n        return False\n\n    # If the entry is not in the set, add it.\n    elif path_name not in files:\n        processed.add(path_name)\n        if verbose:\n            print(\"Adding {} to processed set\".format(path_name))\n\n    # If the entry is not in the set, return true.\n    else:\n        return True\n", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print('Issue processing path {0} already processed.'.format(path_name))\n        return True\n    else:\n        processed.add(path_name)\n        if verbose:\n            print('Added {0} to processed set.'.format(path_name))\n        return False\n", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"Recursion detected: {}\".format(path_name))\n        return False\n    else:\n        processed.add(path_name)\n    return True\n", "def was_processed(processed, path_name, verbose):\n\n    if path_name in processed:\n        if verbose:\n            print(\"Refusing to process directory {} as it already processed it.\"\n                 .format(path_name))\n        return False\n    else:\n        processed.add(path_name)\n        return True\n", "def was_processed(processed, path_name, verbose):\n\n    if path_name in processed:\n        if verbose:\n            print(\"Issue processing path {0}\".format(path_name))\n        return True\n    else:\n        processed.add(path_name)\n        if verbose:\n            print(\"Adding {0} to processed set\".format(path_name))\n        return False\n", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"Issue processing {0}\".format(path_name))\n        return True\n    else:\n        processed.add(path_name)\n        if verbose:\n            print(\"Adding {0} to processed\".format(path_name))\n        return False\n", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"Skipping {0} because it already exists\".format(path_name))\n        return True\n    else:\n        processed.add(path_name)\n        if verbose:\n            print(\"Adding {0} to the set\".format(path_name))\n        return False\n", "def was_processed(processed, path_name, verbose):\n\n    if path_name in processed:\n        if verbose:\n            print(\"Issue processing {} with {}\".format(path_name, processed[path_name]))\n        return True\n    else:\n        processed.add(path_name)\n        return False\n", "def was_processed(processed, path_name, verbose):\n\n    if path_name in processed:\n        if verbose:\n            print(\"Issue when processing {}\".format(path_name))\n        return True\n    else:\n        processed.add(path_name)\n\n    return False\n", "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"File:\", path_name, \"already processed.\")\n        return False\n    else:\n        processed.add(path_name)\n    return True\n"], "level": "self_contained", "generate_results": [{"generate_code": "def was_processed(processed, path_name, verbose):\n\n    # Get the list of files in the path.\n    files = os.listdir(path_name)\n\n    # If the entry is already in the set, return false.\n    if path_name in processed:\n        return False\n\n    # If the entry is not in the set, add it.\n    elif path_name not in files:\n        processed.add(path_name)\n        if verbose:\n            print(\"Adding {} to processed set\".format(path_name))\n\n    # If the entry is not in the set, return true.\n    else:\n        return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print('Issue processing path {0} already processed.'.format(path_name))\n        return True\n    else:\n        processed.add(path_name)\n        if verbose:\n            print('Added {0} to processed set.'.format(path_name))\n        return False\n", "is_pass": true, "return_code": 0}, {"generate_code": "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"Recursion detected: {}\".format(path_name))\n        return False\n    else:\n        processed.add(path_name)\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def was_processed(processed, path_name, verbose):\n\n    if path_name in processed:\n        if verbose:\n            print(\"Refusing to process directory {} as it already processed it.\"\n                 .format(path_name))\n        return False\n    else:\n        processed.add(path_name)\n        return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def was_processed(processed, path_name, verbose):\n\n    if path_name in processed:\n        if verbose:\n            print(\"Issue processing path {0}\".format(path_name))\n        return True\n    else:\n        processed.add(path_name)\n        if verbose:\n            print(\"Adding {0} to processed set\".format(path_name))\n        return False\n", "is_pass": true, "return_code": 0}, {"generate_code": "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"Issue processing {0}\".format(path_name))\n        return True\n    else:\n        processed.add(path_name)\n        if verbose:\n            print(\"Adding {0} to processed\".format(path_name))\n        return False\n", "is_pass": true, "return_code": 0}, {"generate_code": "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"Skipping {0} because it already exists\".format(path_name))\n        return True\n    else:\n        processed.add(path_name)\n        if verbose:\n            print(\"Adding {0} to the set\".format(path_name))\n        return False\n", "is_pass": true, "return_code": 0}, {"generate_code": "def was_processed(processed, path_name, verbose):\n\n    if path_name in processed:\n        if verbose:\n            print(\"Issue processing {} with {}\".format(path_name, processed[path_name]))\n        return True\n    else:\n        processed.add(path_name)\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def was_processed(processed, path_name, verbose):\n\n    if path_name in processed:\n        if verbose:\n            print(\"Issue when processing {}\".format(path_name))\n        return True\n    else:\n        processed.add(path_name)\n\n    return False\n", "is_pass": true, "return_code": 0}, {"generate_code": "def was_processed(processed, path_name, verbose):\n    if path_name in processed:\n        if verbose:\n            print(\"File:\", path_name, \"already processed.\")\n        return False\n    else:\n        processed.add(path_name)\n    return True\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_9.py", "name": "vertex3tuple", "docstring": "return 3 points for each vertex of the polygon. This will include the vertex and the 2 points on both sides of the vertex::\n\npolygon with vertices ABCD\nWill return\nDAB, ABC, BCD, CDA -> returns 3tuples\n#A    B    C    D  -> of vertices", "ques_id": "62ece4982e6aefcf4aabbd67", "code": ["def vertex3tuple(vertices):\n\n    if len(vertices) < 3:\n        raise ValueError(\"vertices list must have at least 3 elements\")\n\n    A, B, C, D = vertices\n\n    return tuple([A, B, C, D, A, B, C, D])\n", "def vertex3tuple(vertices):\n    return tuple((vertices[i], vertices[(i + 1) % 4], vertices[(i + 2) % 4])\n                 for i in range(0, 3))\n", "def vertex3tuple(vertices):\n\n    (x1, y1, z1) = vertices\n\n    return ((x1, y1, z1),\n            (x1, y1, -z1),\n            (x1, -y1, z1),\n            (x1, -y1, -z1),\n            (x1, y1, +z1),\n            (-x1, -y1, z1),\n            (-x1, -y1, -z1))\n", "def vertex3tuple(vertices):\n\n    return tuple([vertices[0], vertices[1], vertices[2]])\n", "def vertex3tuple(vertices):\n\n    A = vertices[0::3]\n    B = vertices[1::3]\n    C = vertices[2::3]\n\n    ABCD = [(A[0]+B[0],A[1]+B[1],A[2]+B[2])]\n\n    return ABCD + [(C[0]+A[0],C[1]+A[1],C[2]+A[2])]\n", "def vertex3tuple(vertices):\n\n    return tuple((vertices[0], vertices[1], vertices[2]))\n", "def vertex3tuple(vertices):\n\n    A, B, C, D = vertices\n\n    return tuple([A, B, C, D])\n", "def vertex3tuple(vertices):\n    return tuple([vertices[0], vertices[1], vertices[2]])\n", "def vertex3tuple(vertices):\n\n    if len(vertices) < 3:\n        return None\n\n    a = vertices[0]\n    b = vertices[1]\n    c = vertices[2]\n\n    dab = (a[0] - b[0]) * (b[1] - c[1]) - (a[1] - b[1]) * (c[0] - b[0])\n    dbc = (b[0] - c[0]) * (c[1] - a[1]) - (b[1] - c[1]) * (a[0] - c[0])\n    dbd = (c[0] - a[0]) * (a[1] - b[1]) - (c[1] - b[1]) * (b[0] - a[0])\n\n    return (dab, dbc, dbd)\n", "def vertex3tuple(vertices):\n    a, b, c = vertices\n    return ((a, b, c), (b, a, c), (c, b, a))\n"], "level": "self_contained", "generate_results": [{"generate_code": "def vertex3tuple(vertices):\n\n    if len(vertices) < 3:\n        raise ValueError(\"vertices list must have at least 3 elements\")\n\n    A, B, C, D = vertices\n\n    return tuple([A, B, C, D, A, B, C, D])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n    return tuple((vertices[i], vertices[(i + 1) % 4], vertices[(i + 2) % 4])\n                 for i in range(0, 3))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n\n    (x1, y1, z1) = vertices\n\n    return ((x1, y1, z1),\n            (x1, y1, -z1),\n            (x1, -y1, z1),\n            (x1, -y1, -z1),\n            (x1, y1, +z1),\n            (-x1, -y1, z1),\n            (-x1, -y1, -z1))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n\n    return tuple([vertices[0], vertices[1], vertices[2]])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n\n    A = vertices[0::3]\n    B = vertices[1::3]\n    C = vertices[2::3]\n\n    ABCD = [(A[0]+B[0],A[1]+B[1],A[2]+B[2])]\n\n    return ABCD + [(C[0]+A[0],C[1]+A[1],C[2]+A[2])]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n\n    return tuple((vertices[0], vertices[1], vertices[2]))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n\n    A, B, C, D = vertices\n\n    return tuple([A, B, C, D])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n    return tuple([vertices[0], vertices[1], vertices[2]])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n\n    if len(vertices) < 3:\n        return None\n\n    a = vertices[0]\n    b = vertices[1]\n    c = vertices[2]\n\n    dab = (a[0] - b[0]) * (b[1] - c[1]) - (a[1] - b[1]) * (c[0] - b[0])\n    dbc = (b[0] - c[0]) * (c[1] - a[1]) - (b[1] - c[1]) * (a[0] - c[0])\n    dbd = (c[0] - a[0]) * (a[1] - b[1]) - (c[1] - b[1]) * (b[0] - a[0])\n\n    return (dab, dbc, dbd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def vertex3tuple(vertices):\n    a, b, c = vertices\n    return ((a, b, c), (b, a, c), (c, b, a))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_6.py", "name": "int_to_string", "docstring": "Convert a number to a string, using the given alphabet.\n\nThe output has the most significant digit first.", "ques_id": "62ece4982e6aefcf4aabbd68", "code": ["def int_to_string(number: int, alphabet: str) -> str:\n    s = ''\n    while number > 0:\n        s = alphabet[number % len(alphabet)] + s\n        number //= len(alphabet)\n    return s\n", "def int_to_string(number: int, alphabet: List[str]) -> str:\n    if number < 0:\n        raise ValueError('Can not convert negative numbers.')\n\n    output = ''\n    base = len(alphabet)\n\n    while number > 0:\n        output = alphabet[number % base] + output\n        number //= base\n\n    return output\n", "def int_to_string(number: int, alphabet: Optional[str] = None) -> str:\n    if alphabet is None:\n        alphabet = string.digits\n    if number == 0:\n        return '0'\n    if not alphabet:\n        return str(number)\n    if number < 0:\n        raise ValueError('number must be non-negative')\n    if number >= len(alphabet):\n        raise ValueError('number out of range')\n    result = []\n    while number:\n        number, mod = divmod(number, len(alphabet))\n        result.append(alphabet[mod])\n    return ''.join(reversed(result))\n", "def int_to_string(number: int, alphabet: List[str]) -> str:\n    if number == 0:\n        return '0'\n    arr = []\n    base = len(alphabet)\n    while number:\n        number, remainder = divmod(number, base)\n        arr.append(alphabet[remainder])\n    arr.reverse()\n    return ''.join(arr)\n", "def int_to_string(number: int, alphabet: str) -> str:\n    base = len(alphabet)\n    str_number = \"{:0\" + str(base) + \"d}\"\n    return str_number.format(number)\n", "def int_to_string(number: int, alphabet: str) -> str:\n    if number == 0:\n        return '0'\n    arr = []\n    base = len(alphabet)\n    while number:\n        number, remainder = divmod(number, base)\n        arr.append(alphabet[remainder])\n    arr.reverse()\n    return ''.join(arr)\n", "def int_to_string(number: int, alphabet: str) -> str:\n    if number == 0:\n        return '0'\n    arr = []\n    base = len(alphabet)\n    while number:\n        number, remainder = divmod(number, base)\n        arr.append(alphabet[remainder])\n    arr.reverse()\n    return ''.join(arr)\n", "def int_to_string(number: int, alphabet: List[str]) -> str:\n    if number < 0:\n        raise ValueError(\"Number must be non-negative.\")\n    if len(alphabet) == 0:\n        raise ValueError(\"Alphabet must contain at least one character.\")\n    if number == 0:\n        return alphabet[0]\n    arr = []\n    while number:\n        number, mod = divmod(number, len(alphabet))\n        arr.append(alphabet[mod])\n    arr.reverse()\n    return ''.join(arr)\n", "def int_to_string(number: int, alphabet: str) -> str:\n    base = len(alphabet)\n    str_number = ''\n    power = 1\n    while number > 0:\n        number, remainder = divmod(number, base)\n        str_number = alphabet[remainder] + str_number\n    return str_number\n", "def int_to_string(number: int, alphabet: Optional[str] = None) -> str:\n    if alphabet is None:\n        alphabet = _alphabet\n    if number == 0:\n        return \"0\"\n    if number == 1:\n        return alphabet[0]\n    digits = []\n    while number > 0:\n        number, remainder = divmod(number, len(alphabet))\n        digits.append(alphabet[remainder])\n    return \"\".join(reversed(digits))\n"], "level": "self_contained", "generate_results": [{"generate_code": "def int_to_string(number: int, alphabet: str) -> str:\n    s = ''\n    while number > 0:\n        s = alphabet[number % len(alphabet)] + s\n        number //= len(alphabet)\n    return s\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: List[str]) -> str:\n    if number < 0:\n        raise ValueError('Can not convert negative numbers.')\n\n    output = ''\n    base = len(alphabet)\n\n    while number > 0:\n        output = alphabet[number % base] + output\n        number //= base\n\n    return output\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: Optional[str] = None) -> str:\n    if alphabet is None:\n        alphabet = string.digits\n    if number == 0:\n        return '0'\n    if not alphabet:\n        return str(number)\n    if number < 0:\n        raise ValueError('number must be non-negative')\n    if number >= len(alphabet):\n        raise ValueError('number out of range')\n    result = []\n    while number:\n        number, mod = divmod(number, len(alphabet))\n        result.append(alphabet[mod])\n    return ''.join(reversed(result))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: List[str]) -> str:\n    if number == 0:\n        return '0'\n    arr = []\n    base = len(alphabet)\n    while number:\n        number, remainder = divmod(number, base)\n        arr.append(alphabet[remainder])\n    arr.reverse()\n    return ''.join(arr)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: str) -> str:\n    base = len(alphabet)\n    str_number = \"{:0\" + str(base) + \"d}\"\n    return str_number.format(number)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: str) -> str:\n    if number == 0:\n        return '0'\n    arr = []\n    base = len(alphabet)\n    while number:\n        number, remainder = divmod(number, base)\n        arr.append(alphabet[remainder])\n    arr.reverse()\n    return ''.join(arr)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: str) -> str:\n    if number == 0:\n        return '0'\n    arr = []\n    base = len(alphabet)\n    while number:\n        number, remainder = divmod(number, base)\n        arr.append(alphabet[remainder])\n    arr.reverse()\n    return ''.join(arr)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: List[str]) -> str:\n    if number < 0:\n        raise ValueError(\"Number must be non-negative.\")\n    if len(alphabet) == 0:\n        raise ValueError(\"Alphabet must contain at least one character.\")\n    if number == 0:\n        return alphabet[0]\n    arr = []\n    while number:\n        number, mod = divmod(number, len(alphabet))\n        arr.append(alphabet[mod])\n    arr.reverse()\n    return ''.join(arr)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: str) -> str:\n    base = len(alphabet)\n    str_number = ''\n    power = 1\n    while number > 0:\n        number, remainder = divmod(number, base)\n        str_number = alphabet[remainder] + str_number\n    return str_number\n", "is_pass": false, "return_code": 1}, {"generate_code": "def int_to_string(number: int, alphabet: Optional[str] = None) -> str:\n    if alphabet is None:\n        alphabet = _alphabet\n    if number == 0:\n        return \"0\"\n    if number == 1:\n        return alphabet[0]\n    digits = []\n    while number > 0:\n        number, remainder = divmod(number, len(alphabet))\n        digits.append(alphabet[remainder])\n    return \"\".join(reversed(digits))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_12.py", "name": "_replace_register", "docstring": "Replace value from flows to given register number\n\n'register_value' key in dictionary will be replaced by register number\ngiven by 'register_number'\n\n:param flow_params: Dictionary containing defined flows\n:param register_number: The number of register where value will be stored\n:param register_value: Key to be replaced by register number", "ques_id": "62ece4982e6aefcf4aabbd69", "code": ["def _replace_register(flow_params, register_number, register_value):\n    if flow_params.get('registers', {}).get(register_number):\n        flow_params['registers'][register_number] = flow_params['registers'][register_number].replace(\n            '{} {}'.format(register_value, flow_params['registers'][register_number]),\n            flow_params['registers'][register_number])\n        del flow_params['registers'][register_number]\n", "def _replace_register(flow_params, register_number, register_value):\n    for k, v in flow_params.items():\n        if k == \"idle\":\n            flow_params[k] = {\"idle\": v}\n        elif k == \"baudrate\":\n            flow_params[k][\"baudrate\"] = v\n        elif k == \"bytesize\":\n            flow_params[k][\"bytesize\"] = v\n        elif k == \"parity\":\n            flow_params[k][\"parity\"] = v\n        elif k == \"stopbits\":\n            flow_params[k][\"stopbits\"] = v\n        elif k == \"timeout\":\n            flow_params[k][\"timeout\"] = v\n        elif k == \"xonxoff\":\n            flow_params[k][\"xonxoff\"] = v\n        elif k == \"rtscts\":\n            flow_params[k][\"rtscts\"] = v\n        elif k == \"xonoticenable", "def _replace_register(flow_params, register_number, register_value):\n    if register_value in flow_params['registers'][register_number]:\n        flow_params['registers'][register_number] = flow_params['registers'][register_number].replace(\n            register_value, '')\n", "def _replace_register(flow_params, register_number, register_value):\n    for key in flow_params:\n        if register_number in flow_params[key]:\n            flow_params[key][register_number] = flow_params[key][register_number]\n", "def _replace_register(flow_params, register_number, register_value):\n    if flow_params.get(\"registers\"):\n        if flow_params.get(\"registers\").get(register_number):\n            flow_params[\"registers\"][register_number] = flow_params[\"registers\"][register_number].replace(\n                \"{{register_value}}\", str(register_value))\n        else:\n            flow_params[\"registers\"][register_number] = str(register_value)\n    else:\n        flow_params[\"registers\"] = {register_number: str(register_value)}\n", "def _replace_register(flow_params, register_number, register_value):\n    for param_name, param_value in flow_params.items():\n        if param_name =='src':\n            flow_params[param_name] = flow_params['dst'][register_number]\n        elif param_name == 'dst':\n            flow_params[param_name] = flow_params['src'][register_number]\n        elif param_name == 'dst_mask':\n            flow_params[param_name] = flow_params['dst'][register_number] & flow_params['dst_mask'][register_number]\n        elif param_name =='src_mask':\n            flow_params[param_name] = flow_params['src'][register_number] & flow_params['src_mask'][register_number]\n        elif param_name == 'tcp':\n            flow_params[param_name] = flow_params['dst'][register_number] & flow_params['src_mask'][register_number]\n        elif param_name == 'tcp_mask':\n         ", "def _replace_register(flow_params, register_number, register_value):\n    if \"registers\" in flow_params:\n        flow_params[\"registers\"][register_number] = flow_params[\"registers\"][register_value]\n    else:\n        flow_params[\"registers\"] = {register_number: flow_params[\"registers\"][register_value]}\n", "def _replace_register(flow_params, register_number, register_value):\n    if'register_value' in flow_params.keys():\n        flow_params['register_value'][register_number] = flow_params['register_value'][register_number]\n    else:\n        flow_params['register_value'] = {register_number: flow_params['register_value'][register_number]}\n", "def _replace_register(flow_params, register_number, register_value):\n    for key, value in flow_params.items():\n        if key == \"input\":\n            value[\"input\"][register_number] = register_value\n        else:\n            value[\"output\"][register_number] = register_value\n", "def _replace_register(flow_params, register_number, register_value):\n    if'registers' in flow_params:\n        if register_number in flow_params['registers']:\n            flow_params['registers'][register_number] = flow_params['registers'][register_number].replace('$', register_value)\n    else:\n        flow_params['registers'] = {register_number: register_value}\n"], "level": "self_contained", "generate_results": [{"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    if flow_params.get('registers', {}).get(register_number):\n        flow_params['registers'][register_number] = flow_params['registers'][register_number].replace(\n            '{} {}'.format(register_value, flow_params['registers'][register_number]),\n            flow_params['registers'][register_number])\n        del flow_params['registers'][register_number]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    for k, v in flow_params.items():\n        if k == \"idle\":\n            flow_params[k] = {\"idle\": v}\n        elif k == \"baudrate\":\n            flow_params[k][\"baudrate\"] = v\n        elif k == \"bytesize\":\n            flow_params[k][\"bytesize\"] = v\n        elif k == \"parity\":\n            flow_params[k][\"parity\"] = v\n        elif k == \"stopbits\":\n            flow_params[k][\"stopbits\"] = v\n        elif k == \"timeout\":\n            flow_params[k][\"timeout\"] = v\n        elif k == \"xonxoff\":\n            flow_params[k][\"xonxoff\"] = v\n        elif k == \"rtscts\":\n            flow_params[k][\"rtscts\"] = v\n        elif k == \"xonoticenable", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    if register_value in flow_params['registers'][register_number]:\n        flow_params['registers'][register_number] = flow_params['registers'][register_number].replace(\n            register_value, '')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    for key in flow_params:\n        if register_number in flow_params[key]:\n            flow_params[key][register_number] = flow_params[key][register_number]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    if flow_params.get(\"registers\"):\n        if flow_params.get(\"registers\").get(register_number):\n            flow_params[\"registers\"][register_number] = flow_params[\"registers\"][register_number].replace(\n                \"{{register_value}}\", str(register_value))\n        else:\n            flow_params[\"registers\"][register_number] = str(register_value)\n    else:\n        flow_params[\"registers\"] = {register_number: str(register_value)}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    for param_name, param_value in flow_params.items():\n        if param_name =='src':\n            flow_params[param_name] = flow_params['dst'][register_number]\n        elif param_name == 'dst':\n            flow_params[param_name] = flow_params['src'][register_number]\n        elif param_name == 'dst_mask':\n            flow_params[param_name] = flow_params['dst'][register_number] & flow_params['dst_mask'][register_number]\n        elif param_name =='src_mask':\n            flow_params[param_name] = flow_params['src'][register_number] & flow_params['src_mask'][register_number]\n        elif param_name == 'tcp':\n            flow_params[param_name] = flow_params['dst'][register_number] & flow_params['src_mask'][register_number]\n        elif param_name == 'tcp_mask':\n         ", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    if \"registers\" in flow_params:\n        flow_params[\"registers\"][register_number] = flow_params[\"registers\"][register_value]\n    else:\n        flow_params[\"registers\"] = {register_number: flow_params[\"registers\"][register_value]}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    if'register_value' in flow_params.keys():\n        flow_params['register_value'][register_number] = flow_params['register_value'][register_number]\n    else:\n        flow_params['register_value'] = {register_number: flow_params['register_value'][register_number]}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    for key, value in flow_params.items():\n        if key == \"input\":\n            value[\"input\"][register_number] = register_value\n        else:\n            value[\"output\"][register_number] = register_value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _replace_register(flow_params, register_number, register_value):\n    if'registers' in flow_params:\n        if register_number in flow_params['registers']:\n            flow_params['registers'][register_number] = flow_params['registers'][register_number].replace('$', register_value)\n    else:\n        flow_params['registers'] = {register_number: register_value}\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_2.py", "name": "replace_dots", "docstring": "Replaces all values of '.' to arg from the given string", "ques_id": "62ece4982e6aefcf4aabbd6a", "code": ["def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace(\".\", arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "def replace_dots(value, arg):\n    return value.replace(\".\", arg)\n", "def replace_dots(value, arg):\n    return value.replace('.', arg)\n"], "level": "self_contained", "generate_results": [{"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace(\".\", arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace(\".\", arg)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def replace_dots(value, arg):\n    return value.replace('.', arg)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "self_contained/test_3.py", "name": "subclasses", "docstring": "Return all subclasses of a class, recursively", "ques_id": "62ece4982e6aefcf4aabbd6b", "code": ["def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield subclass\n        yield from subclass.subclasses()\n", "def subclasses(cls):\n    return [subcls for subcls in cls.__subclasses__() if issubclass(subcls, cls)]\n", "def subclasses(cls):\n    return cls.__subclasses__() + [g for s in cls.__subclasses__() for g in subclasses(s)]\n", "def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield subclass\n        yield from subclass.subclasses()\n", "def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield subclass\n        yield from subclasses(subclass)\n", "def subclasses(cls):\n    return cls.__subclasses__() + [g for s in cls.__subclasses__()\n                                   for g in subclasses(s)]\n", "def subclasses(cls):\n    return cls.__subclasses__() + [g for s in cls.__subclasses__() for g in subclasses(s)]\n", "def subclasses(cls):\n    return [\n        g for g in cls.__subclasses__()\n        if issubclass(cls, g)\n    ] + [cls]\n", "def subclasses(cls):\n    return cls.__subclasses__() + [g for s in cls.__subclasses__()\n                                  for g in subclasses(s)]\n", "def subclasses(cls):\n    return [c for c in cls.__subclasses__() if c is not cls]\n"], "level": "self_contained", "generate_results": [{"generate_code": "def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield subclass\n        yield from subclass.subclasses()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    return [subcls for subcls in cls.__subclasses__() if issubclass(subcls, cls)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    return cls.__subclasses__() + [g for s in cls.__subclasses__() for g in subclasses(s)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield subclass\n        yield from subclass.subclasses()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    for subclass in cls.__subclasses__():\n        yield subclass\n        yield from subclasses(subclass)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    return cls.__subclasses__() + [g for s in cls.__subclasses__()\n                                   for g in subclasses(s)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    return cls.__subclasses__() + [g for s in cls.__subclasses__() for g in subclasses(s)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    return [\n        g for g in cls.__subclasses__()\n        if issubclass(cls, g)\n    ] + [cls]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    return cls.__subclasses__() + [g for s in cls.__subclasses__()\n                                  for g in subclasses(s)]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subclasses(cls):\n    return [c for c in cls.__subclasses__() if c is not cls]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "self_contained/test_7.py", "name": "string_to_int", "docstring": "Convert a string to a number, using the given alphabet.\n\nThe input is assumed to have the most significant digit first.", "ques_id": "62ece4982e6aefcf4aabbd6d", "code": ["def string_to_int(string: str, alphabet: str = '0123456789') -> int:\n    base = len(alphabet)\n    str_len = len(string)\n    num = 0\n\n    for idx, char in enumerate(string):\n        num += alphabet.index(char) * (base ** str_len - idx)\n    return num\n", "def string_to_int(string: str, alphabet: str) -> int:\n    # Hint: the following line, `number = alphabet.index(string[-1]) + 1`\n    # will give you the index of the last digit in the alphabet.\n    number = 0\n    for letter in string:\n        number = number * len(alphabet) + alphabet.index(letter)\n    return number\n", "def string_to_int(string: str, alphabet: List[str]) -> int:\n    result = 0\n    for c in string:\n        result *= len(alphabet)\n        result += alphabet.index(c)\n    return result\n", "def string_to_int(string: str, alphabet: str) -> int:\n    num = 0\n    for c in string:\n        num = num * len(alphabet) + alphabet.index(c)\n    return num\n", "def string_to_int(string: str, alphabet: str) -> int:\n    if not alphabet:\n        raise ValueError(\"Alphabet must contain at least one character.\")\n    if len(alphabet) < len(string):\n        raise ValueError(\"Alphabet must contain at most %d characters.\" % len(string))\n\n    string = string.upper()\n    out = 0\n    for c in string:\n        out *= len(alphabet)\n        out += alphabet.index(c)\n    return out\n", "def string_to_int(string: str, alphabet: str) -> int:\n    result = 0\n    for c in string:\n        result = result * len(alphabet) + alphabet.index(c)\n    return result\n", "def string_to_int(string: str, alphabet: str = '0123456789') -> int:\n    # Handle up to base 36 alphabet characters\n    base = len(alphabet)\n    str_len = len(string)\n    num = 0\n\n    for idx, char in enumerate(string):\n        power = (str_len - (idx + 1))\n        num += alphabet.index(char) * (base ** power)\n\n    return num\n", "def string_to_int(string: str, alphabet: str) -> int:\n    result = 0\n    for c in string:\n        result = result * len(alphabet) + alphabet.index(c)\n    return result\n", "def string_to_int(string: str, alphabet: str) -> int:\n    result = 0\n    for c in string:\n        result = result * len(alphabet) + alphabet.index(c)\n    return result\n", "def string_to_int(string: str, alphabet: str) -> int:\n    base = len(alphabet)\n    str_len = len(string)\n    num = 0\n\n    for idx, c in enumerate(string):\n        num += alphabet.index(c) * (base ** str_len - idx)\n    return num\n"], "level": "self_contained", "generate_results": [{"generate_code": "def string_to_int(string: str, alphabet: str = '0123456789') -> int:\n    base = len(alphabet)\n    str_len = len(string)\n    num = 0\n\n    for idx, char in enumerate(string):\n        num += alphabet.index(char) * (base ** str_len - idx)\n    return num\n", "is_pass": false, "return_code": 1}, {"generate_code": "def string_to_int(string: str, alphabet: str) -> int:\n    # Hint: the following line, `number = alphabet.index(string[-1]) + 1`\n    # will give you the index of the last digit in the alphabet.\n    number = 0\n    for letter in string:\n        number = number * len(alphabet) + alphabet.index(letter)\n    return number\n", "is_pass": true, "return_code": 0}, {"generate_code": "def string_to_int(string: str, alphabet: List[str]) -> int:\n    result = 0\n    for c in string:\n        result *= len(alphabet)\n        result += alphabet.index(c)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def string_to_int(string: str, alphabet: str) -> int:\n    num = 0\n    for c in string:\n        num = num * len(alphabet) + alphabet.index(c)\n    return num\n", "is_pass": true, "return_code": 0}, {"generate_code": "def string_to_int(string: str, alphabet: str) -> int:\n    if not alphabet:\n        raise ValueError(\"Alphabet must contain at least one character.\")\n    if len(alphabet) < len(string):\n        raise ValueError(\"Alphabet must contain at most %d characters.\" % len(string))\n\n    string = string.upper()\n    out = 0\n    for c in string:\n        out *= len(alphabet)\n        out += alphabet.index(c)\n    return out\n", "is_pass": false, "return_code": 1}, {"generate_code": "def string_to_int(string: str, alphabet: str) -> int:\n    result = 0\n    for c in string:\n        result = result * len(alphabet) + alphabet.index(c)\n    return result\n", "is_pass": true, "return_code": 0}, {"generate_code": "def string_to_int(string: str, alphabet: str = '0123456789') -> int:\n    # Handle up to base 36 alphabet characters\n    base = len(alphabet)\n    str_len = len(string)\n    num = 0\n\n    for idx, char in enumerate(string):\n        power = (str_len - (idx + 1))\n        num += alphabet.index(char) * (base ** power)\n\n    return num\n", "is_pass": true, "return_code": 0}, {"generate_code": "def string_to_int(string: str, alphabet: str) -> int:\n    result = 0\n    for c in string:\n        result = result * len(alphabet) + alphabet.index(c)\n    return result\n", "is_pass": true, "return_code": 0}, {"generate_code": "def string_to_int(string: str, alphabet: str) -> int:\n    result = 0\n    for c in string:\n        result = result * len(alphabet) + alphabet.index(c)\n    return result\n", "is_pass": true, "return_code": 0}, {"generate_code": "def string_to_int(string: str, alphabet: str) -> int:\n    base = len(alphabet)\n    str_len = len(string)\n    num = 0\n\n    for idx, c in enumerate(string):\n        num += alphabet.index(c) * (base ** str_len - idx)\n    return num\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_24.py", "name": "get_repo_archive", "docstring": "Given an url and a destination path, retrieve and extract .tar.gz archive\nwhich contains 'desc' file for each package.\nEach .tar.gz archive corresponds to an Arch Linux repo ('core', 'extra', 'community').\n\nArgs:\n    url: url of the .tar.gz archive to download\n    destination_path: the path on disk where to extract archive\n\nReturns:\n    a directory Path where the archive has been extracted to.", "ques_id": "62ece4982e6aefcf4aabbd6f", "code": ["def get_repo_archive(url: str, destination_path: Path) -> Path:\n    archive_name = url.split(\"/\")[-1]\n    archive_path = destination_path / archive_name\n\n    if not archive_path.exists():\n        urlretrieve(url, archive_path)\n\n    return archive_path\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    archive_path = destination_path / Path(url.split(\"/\")[-1])\n\n    if not archive_path.exists():\n        urlretrieve(url, archive_path)\n\n    return archive_path\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    result = _extract_tar_gz_from_url(url, destination_path)\n\n    if result.exit_code!= 0:\n        raise RepoDownloadError(result.stderr.decode())\n\n    return destination_path\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    archive_path = destination_path / \"desc\"\n    if not archive_path.exists():\n        logger.info(\"Downloading package descriptions from %s to %s...\", url, archive_path)\n        with urlopen(url) as response:\n            with archive_path.open(\"wb\") as target:\n                shutil.copyfileobj(response, target)\n    return archive_path\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    # check if the given url is a valid URL\n    if not url.startswith(\"http://\") and not url.startswith(\"https://\"):\n        raise InvalidURL(f\"{url!r} is not a valid URL\")\n\n    # extract the package archive to the given directory\n    tar_archive_name = url.split(\"/\")[-1]\n    tar_archive_path = destination_path / tar_archive_name\n    if not tar_archive_path.exists():\n        log.info(\"extracting {!r} to {!r}\", url, str(destination_path))\n        with tarfile.open(tar_archive_path, \"w:gz\") as tar:\n            tar.extractall(str(destination_path))\n    else:\n        log.info(\"{!r} is already extracted to {!r}\", url, str(destination_path))\n\n    return destination_path\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    # remove.tar.gz from the end of the path\n    archive_path = destination_path.with_suffix(\".tar.gz\")\n\n    # download the file\n    try:\n        response = urlopen(url)\n        with archive_path.open(\"wb\") as f:\n            f.write(response.read())\n    except Exception:\n        raise ValueError(\"URL {} could not be retrieved\".format(url))\n\n    # extract the archive to the given directory\n    try:\n        extract_archive(str(archive_path), destination_path)\n    except Exception as e:\n        raise ArchiveAccessError(\"Error extracting archive {}: {}\".format(archive_path, e))\n\n    # cleanup the temporary directory\n    try:\n        shutil.rmtree(str(destination_path))\n    except OSError as e:\n        raise ArchiveAccessError(\"Error removing temporary directory {}: {}\".format(destination_path, e))\n\n    return destination_path\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    archive_name = url.split('/')[-1]\n    tar_archive_path = destination_path / archive_name\n    if not tar_archive_path.exists():\n        with tarfile.open(tar_archive_path, 'r:gz') as tar:\n            tar.extractall(destination_path)\n    return tar_archive_path\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    if not destination_path.exists():\n        destination_path.mkdir()\n\n    tar = tarfile.open(str(destination_path / 'desc'))\n    tar.extractall(str(destination_path))\n    tar.close()\n\n    return destination_path\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    archive_name = url.split('/')[-1]\n    destination_path = destination_path.joinpath(archive_name)\n\n    # Download the tar file to the given path.\n    response = requests.get(url, stream=True)\n    with destination_path.open('wb') as target:\n        for chunk in response.iter_content(chunk_size=1024):\n            if chunk:  # filter out keep-alive new chunks\n                target.write(chunk)\n\n    return destination_path\n", "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    try:\n        response = requests.get(url, stream=True)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise RepoDownloaderException(e)\n\n    for i in range(1, 10):\n        archive_name = f\"core{i}.tar.gz\"\n        archive_path = destination_path / archive_name\n        if not archive_path.exists():\n            extract_tar_gz_from_url(url, archive_path)\n\n    return destination_path\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    archive_name = url.split(\"/\")[-1]\n    archive_path = destination_path / archive_name\n\n    if not archive_path.exists():\n        urlretrieve(url, archive_path)\n\n    return archive_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    archive_path = destination_path / Path(url.split(\"/\")[-1])\n\n    if not archive_path.exists():\n        urlretrieve(url, archive_path)\n\n    return archive_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    result = _extract_tar_gz_from_url(url, destination_path)\n\n    if result.exit_code!= 0:\n        raise RepoDownloadError(result.stderr.decode())\n\n    return destination_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    archive_path = destination_path / \"desc\"\n    if not archive_path.exists():\n        logger.info(\"Downloading package descriptions from %s to %s...\", url, archive_path)\n        with urlopen(url) as response:\n            with archive_path.open(\"wb\") as target:\n                shutil.copyfileobj(response, target)\n    return archive_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    # check if the given url is a valid URL\n    if not url.startswith(\"http://\") and not url.startswith(\"https://\"):\n        raise InvalidURL(f\"{url!r} is not a valid URL\")\n\n    # extract the package archive to the given directory\n    tar_archive_name = url.split(\"/\")[-1]\n    tar_archive_path = destination_path / tar_archive_name\n    if not tar_archive_path.exists():\n        log.info(\"extracting {!r} to {!r}\", url, str(destination_path))\n        with tarfile.open(tar_archive_path, \"w:gz\") as tar:\n            tar.extractall(str(destination_path))\n    else:\n        log.info(\"{!r} is already extracted to {!r}\", url, str(destination_path))\n\n    return destination_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    # remove.tar.gz from the end of the path\n    archive_path = destination_path.with_suffix(\".tar.gz\")\n\n    # download the file\n    try:\n        response = urlopen(url)\n        with archive_path.open(\"wb\") as f:\n            f.write(response.read())\n    except Exception:\n        raise ValueError(\"URL {} could not be retrieved\".format(url))\n\n    # extract the archive to the given directory\n    try:\n        extract_archive(str(archive_path), destination_path)\n    except Exception as e:\n        raise ArchiveAccessError(\"Error extracting archive {}: {}\".format(archive_path, e))\n\n    # cleanup the temporary directory\n    try:\n        shutil.rmtree(str(destination_path))\n    except OSError as e:\n        raise ArchiveAccessError(\"Error removing temporary directory {}: {}\".format(destination_path, e))\n\n    return destination_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    archive_name = url.split('/')[-1]\n    tar_archive_path = destination_path / archive_name\n    if not tar_archive_path.exists():\n        with tarfile.open(tar_archive_path, 'r:gz') as tar:\n            tar.extractall(destination_path)\n    return tar_archive_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    if not destination_path.exists():\n        destination_path.mkdir()\n\n    tar = tarfile.open(str(destination_path / 'desc'))\n    tar.extractall(str(destination_path))\n    tar.close()\n\n    return destination_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    archive_name = url.split('/')[-1]\n    destination_path = destination_path.joinpath(archive_name)\n\n    # Download the tar file to the given path.\n    response = requests.get(url, stream=True)\n    with destination_path.open('wb') as target:\n        for chunk in response.iter_content(chunk_size=1024):\n            if chunk:  # filter out keep-alive new chunks\n                target.write(chunk)\n\n    return destination_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_repo_archive(url: str, destination_path: Path) -> Path:\n    try:\n        response = requests.get(url, stream=True)\n        response.raise_for_status()\n    except requests.exceptions.RequestException as e:\n        raise RepoDownloaderException(e)\n\n    for i in range(1, 10):\n        archive_name = f\"core{i}.tar.gz\"\n        archive_path = destination_path / archive_name\n        if not archive_path.exists():\n            extract_tar_gz_from_url(url, archive_path)\n\n    return destination_path\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_20.py", "name": "os_is_mac", "docstring": "Checks if the os is macOS\n\n:return: True is macOS\n:rtype: bool", "ques_id": "62ece4982e6aefcf4aabbd70", "code": ["def os_is_mac():\n    return platform.system() == \"Darwin\"\n", "def os_is_mac():\n    return sys.platform.startswith('darwin')\n", "def os_is_mac():\n    return sys.platform.startswith('darwin')\n", "def os_is_mac():\n    return sys.platform.startswith(\"darwin\")\n", "def os_is_mac():\n    return sys.platform.startswith('darwin')\n", "def os_is_mac():\n    return sys.platform.startswith('darwin')\n", "def os_is_mac():\n\n    return sys.platform.startswith('darwin')\n", "def os_is_mac():\n\n    return sys.platform.startswith('darwin')\n", "def os_is_mac():\n    return sys.platform.startswith('darwin')\n", "def os_is_mac():\n    return sys.platform.startswith('darwin')\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def os_is_mac():\n    return platform.system() == \"Darwin\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def os_is_mac():\n    return sys.platform.startswith('darwin')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def os_is_mac():\n    return sys.platform.startswith('darwin')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def os_is_mac():\n    return sys.platform.startswith(\"darwin\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def os_is_mac():\n    return sys.platform.startswith('darwin')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def os_is_mac():\n    return sys.platform.startswith('darwin')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def os_is_mac():\n\n    return sys.platform.startswith('darwin')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def os_is_mac():\n\n    return sys.platform.startswith('darwin')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def os_is_mac():\n    return sys.platform.startswith('darwin')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def os_is_mac():\n    return sys.platform.startswith('darwin')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_14.py", "name": "regex_dict", "docstring": "Convert *.cpp keys to regex keys\n\nGiven a dict where the keys are all filenames with wildcards, convert only\nthe keys into equivalent regexes and leave the values intact.\n\nExample:\n\nrules = {\n    '*.cpp':\n        {'a': 'arf', 'b': 'bark', 'c': 'coo'},\n    '*.h':\n        {'h': 'help'}\n}\nregex_keys = regex_dict(rules)\n\nArgs:\n    item: dict to convert\nReturns:\n    dict with keys converted to regexes", "ques_id": "62ece4982e6aefcf4aabbd71", "code": ["def regex_dict(item):\n    return {re.sub(r'\\.cpp$', '', key): value for key, value in item.items()}\n", "def regex_dict(item):\n    return {re.sub(r'\\.cpp$', '', key): value for key, value in item.items()}\n", "def regex_dict(item):\n    return {k: re.compile(v) for k, v in item.items()}\n", "def regex_dict(item):\n    return {k: re.compile(v) for k, v in item.items()}\n", "def regex_dict(item):\n    return {k.replace('.', '\\\\.'): v for k, v in item.items()}\n", "def regex_dict(item):\n    return {re.sub(r'\\.cpp$', '', key): value for key, value in item.items()}\n", "def regex_dict(item):\n    return {key: re.compile(value) for key, value in item.items()}\n", "def regex_dict(item):\n    return {\n        wildcard: re.compile(regex)\n        for wildcard, regex in item.items()\n    }\n", "def regex_dict(item):\n    return {k: re.compile(v) for k, v in item.items()}\n", "def regex_dict(item):\n    return dict((key, re.compile(value)) for (key, value) in item.items())\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def regex_dict(item):\n    return {re.sub(r'\\.cpp$', '', key): value for key, value in item.items()}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    return {re.sub(r'\\.cpp$', '', key): value for key, value in item.items()}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    return {k: re.compile(v) for k, v in item.items()}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    return {k: re.compile(v) for k, v in item.items()}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    return {k.replace('.', '\\\\.'): v for k, v in item.items()}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    return {re.sub(r'\\.cpp$', '', key): value for key, value in item.items()}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    return {key: re.compile(value) for key, value in item.items()}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    return {\n        wildcard: re.compile(regex)\n        for wildcard, regex in item.items()\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    return {k: re.compile(v) for k, v in item.items()}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def regex_dict(item):\n    return dict((key, re.compile(value)) for (key, value) in item.items())\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_4.py", "name": "unquote", "docstring": "Remove quote from the given name.", "ques_id": "62ece4982e6aefcf4aabbd72", "code": ["def unquote(name):\n    if name[0] in '\"\\'':\n        name = name[1:-1]\n    return name.replace('\\\\\"', '')\n", "def unquote(name):\n    if name[0] == name[-1] == '\"':\n        name = name[1:-1]\n    return name\n", "def unquote(name):\n    if name[0] in '\"\\'':\n        name = name[1:-1]\n    return name\n", "def unquote(name):\n    if name[0] == name[-1] == '\"':\n        name = name[1:-1]\n    return name\n", "def unquote(name):\n    if name[0] == name[-1] == '\"':\n        name = name[1:-1]\n    return name\n", "def unquote(name):\n    if name[0] == name[-1] == '\"':\n        name = name[1:-1]\n    return name.replace('\\\\\"', '')\n", "def unquote(name):\n    if name[0] in \"!@#$%^&*()+=[]\":\n        name = name[1:]\n    if name[-1] in \"!#$&*()+=[]\":\n        name = name[:-1]\n    return name\n", "def unquote(name):\n    if name[0] in '\"\\'':\n        name = name[1:-1]\n    return name\n", "def unquote(name):\n    if name[0] == name[-1] == '\"':\n        name = name[1:-1]\n    return name\n", "def unquote(name):\n    if name[0] in ('\"', \"'\") and name[-1] == name[0]:\n        name = name[1:-1]\n    return name\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def unquote(name):\n    if name[0] in '\"\\'':\n        name = name[1:-1]\n    return name.replace('\\\\\"', '')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if name[0] == name[-1] == '\"':\n        name = name[1:-1]\n    return name\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if name[0] in '\"\\'':\n        name = name[1:-1]\n    return name\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if name[0] == name[-1] == '\"':\n        name = name[1:-1]\n    return name\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if name[0] == name[-1] == '\"':\n        name = name[1:-1]\n    return name\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if name[0] == name[-1] == '\"':\n        name = name[1:-1]\n    return name.replace('\\\\\"', '')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if name[0] in \"!@#$%^&*()+=[]\":\n        name = name[1:]\n    if name[-1] in \"!#$&*()+=[]\":\n        name = name[:-1]\n    return name\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if name[0] in '\"\\'':\n        name = name[1:-1]\n    return name\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if name[0] == name[-1] == '\"':\n        name = name[1:-1]\n    return name\n", "is_pass": false, "return_code": 1}, {"generate_code": "def unquote(name):\n    if name[0] in ('\"', \"'\") and name[-1] == name[0]:\n        name = name[1:-1]\n    return name\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_21.py", "name": "split", "docstring": "Multi-platform variant of shlex.split() for command-line splitting.\nFor use with subprocess, for argv injection etc. Using fast REGEX.\n\nplatform: 'this' = auto from current platform;\n          1 = POSIX;\n          0 = Windows/CMD\n          (other values reserved)", "ques_id": "62ece4982e6aefcf4aabbd73", "code": ["def split(s, platform='this'):\n    if platform == 'c':\n        return shlex.split(s)\n    else:\n        return re.split(r'\\W', s)\n", "def split(s, platform='this'):\n\n    if platform == 'c':\n        return shlex.split(s)\n    else:\n        return re.split(r'\\W', s)\n", "def split(s, platform='this'):\n\n    if platform == 'this':\n        platform = os.name\n\n    if platform == 'posix':\n        pattern = r'\\A[^\\W\\d]*\\Z'\n    elif platform == 'cmd':\n        pattern = r'[^\\W\\d]*'\n    else:\n        raise ValueError('unknown platform: %r' % platform)\n\n    return re.split(pattern, s)\n", "def split(s, platform='this'):\n    if platform == 'this':\n        platform = os.name\n    if platform == 'posix':\n        match = re.match(r'^(\\\\w+)(?:-\\\\w+)?$', s)\n        if match:\n            if match.group(1) == '-W':\n                return []\n            else:\n                return [match.group(1), match.group(2)]\n        else:\n            if s.startswith('-W'):\n                return []\n            else:\n                return s.split(' ')\n    elif platform == 'windows':\n        if ':' in s:\n            return [s]\n        else:\n            return s.split(':')\n    else:\n        return shlex.split(s)\n", "def split(s, platform='this'):\n    pattern = r'(?!%s).*' % platform\n    return re.split(pattern, s)\n", "def split(s, platform='this'):\n\n    # POSIX variant: shlex.split() always returns a list\n    # shlex.split() handles escaped special chars properly\n    # (see https://github.com/shlib/shlex/issues/4236)\n    if platform == 'posix':\n        flags = re.UNICODE | re.MULTILINE | re.UNICODE_SPLIT\n    elif platform == 'cmd':\n        flags = re.UNICODE\n    else:\n        raise ValueError(\"invalid platform: %r\" % platform)\n\n    if isinstance(s, bytes):\n        s = s.decode(getattr(sys.stdin, 'encoding', 'ascii'))\n    split = shlex.split(s, posix=not sys.platform.startswith('win'),\n                       flags=flags)\n    return [x for x in split if x!= '']\n", "def split(s, platform='this'):\n    if platform == 'this':\n        platform = os.name\n    if platform == 'posix':\n        split = re.split(r'(\\\\(?!c)|(?<!c))', s)\n    elif platform == 'windows':\n        split = re.split(r'(?<![\\\\\\/])', s)\n    else:\n        raise ValueError('unknown platform {}'.format(platform))\n    return split\n", "def split(s, platform='this'):\n\n    if platform == 'c':\n        return shlex.split(s)\n    else:\n        return re.split('(\\\\w+)', s)\n", "def split(s, platform='this'):\n\n    if platform == 'c':\n        return shlex.split(s)\n\n    if platform == 'posix':\n        import posix\n        return posix.split(s)\n\n    if platform == 'cmd':\n        import shlex\n        return shlex.split(s)\n\n    raise ValueError('invalid platform {!r}'.format(platform))\n", "def split(s, platform='this'):\n    if platform == 'this':\n        platform = os.name\n    if platform == 'posix':\n        match = REGEX.match(s)\n        if match:\n            # split on colon\n            return match.group(1).split(':')\n        else:\n            return [s]\n    elif platform == 'windows':\n        match = REGEX.match(s)\n        if match:\n            # split on colon\n            return [match.group(1)]\n        else:\n            return [s]\n    else:\n        raise ValueError('unknown platform: %r' % platform)\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def split(s, platform='this'):\n    if platform == 'c':\n        return shlex.split(s)\n    else:\n        return re.split(r'\\W', s)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n\n    if platform == 'c':\n        return shlex.split(s)\n    else:\n        return re.split(r'\\W', s)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n\n    if platform == 'this':\n        platform = os.name\n\n    if platform == 'posix':\n        pattern = r'\\A[^\\W\\d]*\\Z'\n    elif platform == 'cmd':\n        pattern = r'[^\\W\\d]*'\n    else:\n        raise ValueError('unknown platform: %r' % platform)\n\n    return re.split(pattern, s)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n    if platform == 'this':\n        platform = os.name\n    if platform == 'posix':\n        match = re.match(r'^(\\\\w+)(?:-\\\\w+)?$', s)\n        if match:\n            if match.group(1) == '-W':\n                return []\n            else:\n                return [match.group(1), match.group(2)]\n        else:\n            if s.startswith('-W'):\n                return []\n            else:\n                return s.split(' ')\n    elif platform == 'windows':\n        if ':' in s:\n            return [s]\n        else:\n            return s.split(':')\n    else:\n        return shlex.split(s)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n    pattern = r'(?!%s).*' % platform\n    return re.split(pattern, s)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n\n    # POSIX variant: shlex.split() always returns a list\n    # shlex.split() handles escaped special chars properly\n    # (see https://github.com/shlib/shlex/issues/4236)\n    if platform == 'posix':\n        flags = re.UNICODE | re.MULTILINE | re.UNICODE_SPLIT\n    elif platform == 'cmd':\n        flags = re.UNICODE\n    else:\n        raise ValueError(\"invalid platform: %r\" % platform)\n\n    if isinstance(s, bytes):\n        s = s.decode(getattr(sys.stdin, 'encoding', 'ascii'))\n    split = shlex.split(s, posix=not sys.platform.startswith('win'),\n                       flags=flags)\n    return [x for x in split if x!= '']\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n    if platform == 'this':\n        platform = os.name\n    if platform == 'posix':\n        split = re.split(r'(\\\\(?!c)|(?<!c))', s)\n    elif platform == 'windows':\n        split = re.split(r'(?<![\\\\\\/])', s)\n    else:\n        raise ValueError('unknown platform {}'.format(platform))\n    return split\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n\n    if platform == 'c':\n        return shlex.split(s)\n    else:\n        return re.split('(\\\\w+)', s)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n\n    if platform == 'c':\n        return shlex.split(s)\n\n    if platform == 'posix':\n        import posix\n        return posix.split(s)\n\n    if platform == 'cmd':\n        import shlex\n        return shlex.split(s)\n\n    raise ValueError('invalid platform {!r}'.format(platform))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def split(s, platform='this'):\n    if platform == 'this':\n        platform = os.name\n    if platform == 'posix':\n        match = REGEX.match(s)\n        if match:\n            # split on colon\n            return match.group(1).split(':')\n        else:\n            return [s]\n    elif platform == 'windows':\n        match = REGEX.match(s)\n        if match:\n            # split on colon\n            return [match.group(1)]\n        else:\n            return [s]\n    else:\n        raise ValueError('unknown platform: %r' % platform)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_15.py", "name": "prepare_repository_from_archive", "docstring": "Given an existing archive_path, uncompress it.\nReturns a file repo url which can be used as origin url.\n\nThis does not deal with the case where the archive passed along does not exist.", "ques_id": "62ece4982e6aefcf4aabbd74", "code": ["def prepare_repository_from_archive(\n    archive_path: Path, *, branch: str = \"master\"\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it. Returns a file repo url\n    which can be used as origin url.\n\n    This does not deal with the case where the archive passed along does\n    not exist. This does not deal with the case where the archive was\n    already saved and the archive does not have to be created.\n    \"\"\"\n    if not archive_path.exists():\n        raise ValueError(\"No such archive: {}\".format(str(archive_path)))\n    if not archive_path.is_file():\n        raise ValueError(\"Archive is not a file: {}\".format(str(archive_path)))\n\n    # Remove the extension if present\n    archive_path = archive_path.with_suffix(\".tar.gz\")\n\n    # Try to untar the archive\n    try:\n        archive_tar = tarfile.open(archive_path)\n        archive_tar.extractall(str(archive_path))\n        archive_tar.close()\n    except tarfile.TarError", "def prepare_repository_from_archive(\n    archive_path: pathlib.Path,\n    directory: pathlib.Path,\n    private: bool = False,\n) -> str:\n    \"\"\"Given an existing archive_path, uncompress it.\n    Returns a file repo url which can be used as origin url.\n    This does not deal with the case where the archive passed along\n    does not exist.\n    \"\"\"\n    # TODO: Should we just use `shutil.copy2` here? If the archive\n    #       does not exist, a `OSError` will be raised and this method\n    #       should be ignored.\n    archive = zipfile.ZipFile(archive_path, 'r')\n    archive.extractall(directory)\n    archive.close()\n    repo_url = pathlib.Path(archive_path).with_suffix('')\n    if private:\n        repo_url.name = archive_path.name\n    return repo_url\n", "def prepare_repository_from_archive(\n    archive_path: Path, allow_bare: bool = False, allow_overwrite: bool = False\n) -> str:\n    \"\"\"Given an existing archive_path, uncompress it. Returns a file repo\n    url which can be used as origin url. This does not deal with the case\n    where the archive passed along does not exist.\n    \"\"\"\n    # TODO: test that the archive exists and is a zipfile\n    # TODO: test that the archive passes the allow_bare and allow_overwrite\n    # TODO: test that the archive does not have a.git directory\n    return prepare_repository(\n        archive_path, allow_bare=allow_bare, allow_overwrite=allow_overwrite\n    )\n", "def prepare_repository_from_archive(\n    archive_path: Path, repository: Repository, build_path: Path\n) -> RepositoryUrl:\n    \"\"\"\n    Given an existing archive_path, uncompress it. Returns a file repo url\n    which can be used as origin url.\n\n    This does not deal with the case where the archive passed along does not\n    exist.  This does not deal with the case where the archive did not exist.\n    \"\"\"\n    # TODO: refactor this to use RepositoryUrl\n    repository_dir = repository.working_dir\n    archive_dir = archive_path.parent\n    return RepositoryUrl(\n        repository_url=repository.url,\n        repository_dir=repository_dir,\n        archive_dir=archive_dir,\n        build_path=build_path,\n        commit_sha=archive_path.commit_sha,\n        branch_name=archive_path.branch,\n    )\n", "def prepare_repository_from_archive(\n    archive_path: pathlib.Path,\n    compression: str = \"bzip2\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it. Returns a file repo url\n    which can be used as origin url. This does not deal with the case where\n    the archive passed along does not exist.\n    \"\"\"\n    if not archive_path.is_file():\n        raise ValueError(\"archive path does not exist\")\n\n    with archive_path.open(\"rb\") as f:\n        contents = f.read()\n\n    return contents_to_repo_url(contents, compression=compression)\n", "def prepare_repository_from_archive(\n    archive_path: Path, repository: Repository, version: Optional[str]\n) -> Optional[str]:\n    \"\"\"Given an existing archive_path, uncompress it. Returns a file repo url\n    which can be used as origin url. This does not deal with the case where the\n    archive passed along does not exist. \"\"\"\n    repo_url = None\n    if archive_path.exists():\n        archive_contents = archive_path.read_text(encoding=\"utf-8\")\n        repo_url = archive_contents.replace(\n            \"repository-url\", \"https://raw.githubusercontent.com/{}/v{}/archive/{}\".format(\n                repository.name, version, archive_path.name\n            )\n        )\n    return repo_url\n", "def prepare_repository_from_archive(\n    archive_path: Path, allow_missing_files: bool = False\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it. Returns a file repo url\n    which can be used as origin url.\n\n    This does not deal with the case where the archive passed along does not\n    exist. This does not deal with the case where the archive didn't exist.\n    \"\"\"\n    # TODO: We may want to ensure that the archive exists before we do anything\n    #       else.\n    repo_url = archive_path.with_suffix(\".tar.gz\")\n    repo_url.unlink()\n    if not allow_missing_files:\n        repo_url.unlink()\n    return repo_url\n", "def prepare_repository_from_archive(\n    archive_path: Path, prefix: str, allow_missing: bool = False\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it.\n\n    Returns a file repo url which can be used as origin url.\n\n    This does not deal with the case where the archive passed along\n    does not exist.\n    \"\"\"\n    archive_path = archive_path.with_suffix(\".tar.gz\")\n    archive_path.unlink()\n\n    # Extract the archive into a temporary directory and extract it into the\n    # repo root.\n    with tarfile.open(str(archive_path)) as tar:\n        tar.extractall(str(prefix))\n\n    # Convert the archive into a temporary directory and return the url\n    return prefix + archive_path.with_suffix(\".tar.gz\").name\n", "def prepare_repository_from_archive(\n    archive_path: Path, allow_missing: bool = False\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it. Returns a file repo url\n    which can be used as origin url.\n\n    This does not deal with the case where the archive passed along does not\n    exist. This does not deal with the case where the archive passed along\n    does not exist.\n    \"\"\"\n    # TODO: need to support multiple archives at the same time\n    archive = archive_path.with_suffix(\".zip\")\n    if not allow_missing:\n        archive.unlink()\n\n    with archive.open(\"rt\") as f:\n        repo_url = f.read()\n\n    return repo_url\n", "def prepare_repository_from_archive(\n    archive_path: Path,\n    contents_path: Path,\n    compression: CompressionOptions = CompressionOptions.NONE,\n    compression_algorithm: CompressionAlgorithm = CompressionAlgorithm.NONE,\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it.\n\n    Returns a file repo url which can be used as origin url. This does not deal\n    with the case where the archive passed along does not exist.\n    \"\"\"\n    try:\n        with archive_path.open(\"rb\") as archive_file:\n            contents = archive_file.read()\n    except (OSError, IOError):\n        raise ArchiveUnreadableException(archive_path)\n\n    return prepare_repository(\n        contents=contents,\n        contents_path=contents_path,\n        compression=compression,\n        compression_algorithm=compression_algorithm,\n    )\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def prepare_repository_from_archive(\n    archive_path: Path, *, branch: str = \"master\"\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it. Returns a file repo url\n    which can be used as origin url.\n\n    This does not deal with the case where the archive passed along does\n    not exist. This does not deal with the case where the archive was\n    already saved and the archive does not have to be created.\n    \"\"\"\n    if not archive_path.exists():\n        raise ValueError(\"No such archive: {}\".format(str(archive_path)))\n    if not archive_path.is_file():\n        raise ValueError(\"Archive is not a file: {}\".format(str(archive_path)))\n\n    # Remove the extension if present\n    archive_path = archive_path.with_suffix(\".tar.gz\")\n\n    # Try to untar the archive\n    try:\n        archive_tar = tarfile.open(archive_path)\n        archive_tar.extractall(str(archive_path))\n        archive_tar.close()\n    except tarfile.TarError", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: pathlib.Path,\n    directory: pathlib.Path,\n    private: bool = False,\n) -> str:\n    \"\"\"Given an existing archive_path, uncompress it.\n    Returns a file repo url which can be used as origin url.\n    This does not deal with the case where the archive passed along\n    does not exist.\n    \"\"\"\n    # TODO: Should we just use `shutil.copy2` here? If the archive\n    #       does not exist, a `OSError` will be raised and this method\n    #       should be ignored.\n    archive = zipfile.ZipFile(archive_path, 'r')\n    archive.extractall(directory)\n    archive.close()\n    repo_url = pathlib.Path(archive_path).with_suffix('')\n    if private:\n        repo_url.name = archive_path.name\n    return repo_url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: Path, allow_bare: bool = False, allow_overwrite: bool = False\n) -> str:\n    \"\"\"Given an existing archive_path, uncompress it. Returns a file repo\n    url which can be used as origin url. This does not deal with the case\n    where the archive passed along does not exist.\n    \"\"\"\n    # TODO: test that the archive exists and is a zipfile\n    # TODO: test that the archive passes the allow_bare and allow_overwrite\n    # TODO: test that the archive does not have a.git directory\n    return prepare_repository(\n        archive_path, allow_bare=allow_bare, allow_overwrite=allow_overwrite\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: Path, repository: Repository, build_path: Path\n) -> RepositoryUrl:\n    \"\"\"\n    Given an existing archive_path, uncompress it. Returns a file repo url\n    which can be used as origin url.\n\n    This does not deal with the case where the archive passed along does not\n    exist.  This does not deal with the case where the archive did not exist.\n    \"\"\"\n    # TODO: refactor this to use RepositoryUrl\n    repository_dir = repository.working_dir\n    archive_dir = archive_path.parent\n    return RepositoryUrl(\n        repository_url=repository.url,\n        repository_dir=repository_dir,\n        archive_dir=archive_dir,\n        build_path=build_path,\n        commit_sha=archive_path.commit_sha,\n        branch_name=archive_path.branch,\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: pathlib.Path,\n    compression: str = \"bzip2\",\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it. Returns a file repo url\n    which can be used as origin url. This does not deal with the case where\n    the archive passed along does not exist.\n    \"\"\"\n    if not archive_path.is_file():\n        raise ValueError(\"archive path does not exist\")\n\n    with archive_path.open(\"rb\") as f:\n        contents = f.read()\n\n    return contents_to_repo_url(contents, compression=compression)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: Path, repository: Repository, version: Optional[str]\n) -> Optional[str]:\n    \"\"\"Given an existing archive_path, uncompress it. Returns a file repo url\n    which can be used as origin url. This does not deal with the case where the\n    archive passed along does not exist. \"\"\"\n    repo_url = None\n    if archive_path.exists():\n        archive_contents = archive_path.read_text(encoding=\"utf-8\")\n        repo_url = archive_contents.replace(\n            \"repository-url\", \"https://raw.githubusercontent.com/{}/v{}/archive/{}\".format(\n                repository.name, version, archive_path.name\n            )\n        )\n    return repo_url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: Path, allow_missing_files: bool = False\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it. Returns a file repo url\n    which can be used as origin url.\n\n    This does not deal with the case where the archive passed along does not\n    exist. This does not deal with the case where the archive didn't exist.\n    \"\"\"\n    # TODO: We may want to ensure that the archive exists before we do anything\n    #       else.\n    repo_url = archive_path.with_suffix(\".tar.gz\")\n    repo_url.unlink()\n    if not allow_missing_files:\n        repo_url.unlink()\n    return repo_url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: Path, prefix: str, allow_missing: bool = False\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it.\n\n    Returns a file repo url which can be used as origin url.\n\n    This does not deal with the case where the archive passed along\n    does not exist.\n    \"\"\"\n    archive_path = archive_path.with_suffix(\".tar.gz\")\n    archive_path.unlink()\n\n    # Extract the archive into a temporary directory and extract it into the\n    # repo root.\n    with tarfile.open(str(archive_path)) as tar:\n        tar.extractall(str(prefix))\n\n    # Convert the archive into a temporary directory and return the url\n    return prefix + archive_path.with_suffix(\".tar.gz\").name\n", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: Path, allow_missing: bool = False\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it. Returns a file repo url\n    which can be used as origin url.\n\n    This does not deal with the case where the archive passed along does not\n    exist. This does not deal with the case where the archive passed along\n    does not exist.\n    \"\"\"\n    # TODO: need to support multiple archives at the same time\n    archive = archive_path.with_suffix(\".zip\")\n    if not allow_missing:\n        archive.unlink()\n\n    with archive.open(\"rt\") as f:\n        repo_url = f.read()\n\n    return repo_url\n", "is_pass": false, "return_code": 1}, {"generate_code": "def prepare_repository_from_archive(\n    archive_path: Path,\n    contents_path: Path,\n    compression: CompressionOptions = CompressionOptions.NONE,\n    compression_algorithm: CompressionAlgorithm = CompressionAlgorithm.NONE,\n) -> str:\n    \"\"\"\n    Given an existing archive_path, uncompress it.\n\n    Returns a file repo url which can be used as origin url. This does not deal\n    with the case where the archive passed along does not exist.\n    \"\"\"\n    try:\n        with archive_path.open(\"rb\") as archive_file:\n            contents = archive_file.read()\n    except (OSError, IOError):\n        raise ArchiveUnreadableException(archive_path)\n\n    return prepare_repository(\n        contents=contents,\n        contents_path=contents_path,\n        compression=compression,\n        compression_algorithm=compression_algorithm,\n    )\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_5.py", "name": "addignored", "docstring": "Use the git command to obtain the file names, turn it into a list, sort the list for only ignored files, return those files as a single string with each filename separated by a comma.", "ques_id": "62ece4982e6aefcf4aabbd75", "code": ["def addignored(ignored):\n    ignored = git._iterate_gitignore(ignored)\n    ignored = [filename.decoded_path for filename in ignored]\n    ignored = ','.join(ignored)\n    return ignored\n", "def addignored(ignored):\n    files = []\n    for filename in ignored:\n        if not filename.startswith('.'):\n            files.append(filename)\n    files.sort()\n    return ','.join(files)\n", "def addignored(ignored):\n    filenames = []\n    for filename in ignored:\n        if filename.endswith(\".py\") or filename.endswith(\".pyc\"):\n            pass\n        else:\n            filenames.append(filename)\n    filenames.sort()\n    return ', '.join(filenames)\n", "def addignored(ignored):\n    ignored = [f for f in ignored if not f.startswith(\".\" + os.sep)]\n    ignored.sort()\n    return \", \".join(ignored)\n", "def addignored(ignored):\n    ignored = git._iter_log_oneline(ignored)\n    ignored = [f for f in ignored if not f.startswith('ignore')]\n    ignored.sort()\n    return ','.join(ignored)\n", "def addignored(ignored):\n    ignored = git.cmd.GitCommand('ls-files').split()\n    ignored.sort()\n    return ', '.join(ignored)\n", "def addignored(ignored):\n    file_list = []\n    for f in ignored:\n        f = f.replace('/', '\\\\')\n        if not f.startswith('.'):\n            file_list.append(f)\n    return ', '.join(file_list)\n", "def addignored(ignored):\n    ignore_files = []\n    for filename in ignored:\n        if os.path.basename(filename) in IGNORED_FILES:\n            ignore_files.append(filename)\n    ignore_files.sort()\n    return ', '.join(ignore_files)\n", "def addignored(ignored):\n    ignored = ignored.decode(\"utf-8\")\n    ignored = ignored.split(\",\")\n    ignored = filter(bool, ignored)\n    ignored = \",\".join(ignored)\n    return ignored\n", "def addignored(ignored):\n    ignored = git.git_cmd(['ls-files', '-z'], ignore_err=True)\n    ignored = ignored.split('\\0')\n    ignored.sort()\n    return ignored\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def addignored(ignored):\n    ignored = git._iterate_gitignore(ignored)\n    ignored = [filename.decoded_path for filename in ignored]\n    ignored = ','.join(ignored)\n    return ignored\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    files = []\n    for filename in ignored:\n        if not filename.startswith('.'):\n            files.append(filename)\n    files.sort()\n    return ','.join(files)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    filenames = []\n    for filename in ignored:\n        if filename.endswith(\".py\") or filename.endswith(\".pyc\"):\n            pass\n        else:\n            filenames.append(filename)\n    filenames.sort()\n    return ', '.join(filenames)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    ignored = [f for f in ignored if not f.startswith(\".\" + os.sep)]\n    ignored.sort()\n    return \", \".join(ignored)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    ignored = git._iter_log_oneline(ignored)\n    ignored = [f for f in ignored if not f.startswith('ignore')]\n    ignored.sort()\n    return ','.join(ignored)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    ignored = git.cmd.GitCommand('ls-files').split()\n    ignored.sort()\n    return ', '.join(ignored)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    file_list = []\n    for f in ignored:\n        f = f.replace('/', '\\\\')\n        if not f.startswith('.'):\n            file_list.append(f)\n    return ', '.join(file_list)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    ignore_files = []\n    for filename in ignored:\n        if os.path.basename(filename) in IGNORED_FILES:\n            ignore_files.append(filename)\n    ignore_files.sort()\n    return ', '.join(ignore_files)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    ignored = ignored.decode(\"utf-8\")\n    ignored = ignored.split(\",\")\n    ignored = filter(bool, ignored)\n    ignored = \",\".join(ignored)\n    return ignored\n", "is_pass": false, "return_code": 1}, {"generate_code": "def addignored(ignored):\n    ignored = git.git_cmd(['ls-files', '-z'], ignore_err=True)\n    ignored = ignored.split('\\0')\n    ignored.sort()\n    return ignored\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_11.py", "name": "match", "docstring": "Check if the filename is a type that this module supports\n\nArgs:\n    filename: Filename to match\nReturns:\n    False if not a match, True if supported", "ques_id": "62ece4982e6aefcf4aabbd76", "code": ["def match(filename):\n    return (\n        filename.endswith(\".bz2\")\n        or filename.endswith(\".gz\")\n        or filename.endswith(\".zip\")\n        or filename.endswith(\".lzma\")\n    )\n", "def match(filename):\n    return (\n        not filename.endswith(\".xml\")\n        and filename.endswith(\"metadata.xml\")\n        and not filename.endswith(\"playlist.xml\")\n    )\n", "def match(filename):\n    return (\n        filename.endswith(\".svg\") or\n        filename.endswith(\".svgz\") or\n        filename.endswith(\".png\") or\n        filename.endswith(\".jpg\")\n    )\n", "def match(filename):\n    return (\n        filename.endswith(\".xml\")\n        or filename.endswith(\".xsd\")\n        or filename.endswith(\".xml.bz2\")\n        or filename.endswith(\".xsd.bz2\")\n    )\n", "def match(filename):\n    return (\n        filename.endswith('.xml') or\n        filename.endswith('.xml.gz') or\n        filename.endswith('.xml.bz2') or\n        filename.endswith('.zip')\n    )\n", "def match(filename):\n    return (\n        not filename.startswith(\"http://\")\n        and not filename.startswith(\"https://\")\n        and filename.endswith(\".txt\")\n        and filename.endswith(\".csv\")\n    )\n", "def match(filename):\n    return filename.lower().endswith((\".doc\", \".docx\", \".odt\", \".pdf\"))\n", "def match(filename):\n    return filename.lower().endswith((\n        '.yml',\n        '.yaml',\n        '.json',\n    ))\n", "def match(filename):\n    return (\n        filename.endswith(\".xml\")\n        or filename.endswith(\".yaml\")\n        or filename.endswith(\".json\")\n        or filename.endswith(\".pkl\")\n    )\n", "def match(filename):\n    return (\n        not filename.startswith(\"s3a://\")\n        and filename.endswith(\".tar.gz\")\n        and filename.endswith(\".tgz\")\n        and filename[4:-4].lower() in SUPPORTED_EXTENSIONS\n    )\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def match(filename):\n    return (\n        filename.endswith(\".bz2\")\n        or filename.endswith(\".gz\")\n        or filename.endswith(\".zip\")\n        or filename.endswith(\".lzma\")\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return (\n        not filename.endswith(\".xml\")\n        and filename.endswith(\"metadata.xml\")\n        and not filename.endswith(\"playlist.xml\")\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return (\n        filename.endswith(\".svg\") or\n        filename.endswith(\".svgz\") or\n        filename.endswith(\".png\") or\n        filename.endswith(\".jpg\")\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return (\n        filename.endswith(\".xml\")\n        or filename.endswith(\".xsd\")\n        or filename.endswith(\".xml.bz2\")\n        or filename.endswith(\".xsd.bz2\")\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return (\n        filename.endswith('.xml') or\n        filename.endswith('.xml.gz') or\n        filename.endswith('.xml.bz2') or\n        filename.endswith('.zip')\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return (\n        not filename.startswith(\"http://\")\n        and not filename.startswith(\"https://\")\n        and filename.endswith(\".txt\")\n        and filename.endswith(\".csv\")\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return filename.lower().endswith((\".doc\", \".docx\", \".odt\", \".pdf\"))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return filename.lower().endswith((\n        '.yml',\n        '.yaml',\n        '.json',\n    ))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return (\n        filename.endswith(\".xml\")\n        or filename.endswith(\".yaml\")\n        or filename.endswith(\".json\")\n        or filename.endswith(\".pkl\")\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def match(filename):\n    return (\n        not filename.startswith(\"s3a://\")\n        and filename.endswith(\".tar.gz\")\n        and filename.endswith(\".tgz\")\n        and filename[4:-4].lower() in SUPPORTED_EXTENSIONS\n    )\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_1.py", "name": "parse_frequency", "docstring": "Given a frequency string with a number and a unit of time, return a corresponding\ndatetime.timedelta instance or None if the frequency is None or \"always\".\n\nFor instance, given \"3 weeks\", return datetime.timedelta(weeks=3)\n\nRaise ValueError if the given frequency cannot be parsed.", "ques_id": "62ece4982e6aefcf4aabbd77", "code": ["def parse_frequency(frequency):\n    if frequency is None or frequency == 'always':\n        return timedelta(weeks=1)\n    else:\n        frequency = frequency.upper()\n        if frequency == 'WEEKLY':\n            return timedelta(weeks=52)\n        elif frequency == 'MONTHLY':\n            return timedelta(weeks=52 * 4)\n        elif frequency == 'DAILY':\n            return timedelta(weeks=52 * 30)\n        elif frequency == 'YEARLY':\n            return timedelta(weeks=53)\n        elif frequency == 'THURSDAY':\n            return timedelta(weeks=53 * 28)\n        elif frequency == 'TUESDAY':\n            return timedelta(weeks=53 * 29)\n        elif frequency == 'WEEKLY 30 DAYS':\n            return timedelta(weeks=53 * 30 * 24)\n        elif frequency == 'MONTHLY 30 DAYS':\n            return timedelta(weeks=53 * 30", "def parse_frequency(frequency):\n    if frequency is None or frequency.lower() not in _FREQ_VALS:\n        raise ValueError(\"frequency must be one of %s\" % _FREQ_VALS)\n\n    weeks = int(frequency)\n    return datetime.timedelta(weeks=weeks)\n", "def parse_frequency(frequency):\n    if frequency is None or frequency == 'always':\n        return None\n    elif frequency == 'weekly':\n        return timedelta(weeks=7)\n    elif frequency == 'daily':\n        return timedelta(days=1)\n    elif frequency =='monthly':\n        return timedelta(months=12)\n    elif frequency == 'yearly':\n        return timedelta(years=1)\n    else:\n        raise ValueError('Frequency \"{}\" is not supported.'.format(frequency))\n", "def parse_frequency(frequency):\n    if frequency is None or frequency.lower() not in [\"always\", \"weeks\", \"days\"]:\n        return None\n    return timedelta(days=int(frequency[:-1]))\n", "def parse_frequency(frequency):\n    frequency = frequency.lower()\n    if frequency not in _FREQ_MAP:\n        raise ValueError(\"Frequency must be one of {0!r}\".format(_FREQ_MAP))\n    return _FREQ_MAP[frequency]\n", "def parse_frequency(frequency):\n    frequency = frequency.lower()\n    if frequency not in _FREQ_PARAMS:\n        raise ValueError(\"Frequency '%s' is not a recognised frequency\" % frequency)\n    return _FREQ_PARAMS[frequency]\n", "def parse_frequency(frequency):\n    frequency = frequency.strip()\n    if frequency in ('always', 'never'):\n        return None\n\n    match = _FREQ_REGEX.match(frequency)\n    if match is None:\n        raise ValueError('Frequency \"{0}\" is not valid.'.format(frequency))\n\n    num_part, unit_part = match.groups()\n    num = int(num_part)\n    unit = _UNITS.get(unit_part.lower())\n    if unit is None:\n        raise ValueError('Unknown frequency \"{0}\".'.format(unit_part))\n\n    return timedelta(\n        **{\n            'num': num,\n            'unit': unit\n        }\n    )\n", "def parse_frequency(frequency):\n    try:\n        num, unit = frequency.split(\" \")\n    except ValueError:\n        raise ValueError(\"frequency must be in the form 'weeks'\")\n\n    try:\n        num = int(num)\n    except ValueError:\n        raise ValueError(\"frequency must be an integer\")\n\n    if unit not in [\"weeks\", \"days\"]:\n        raise ValueError(\"frequency must be 'weeks' or 'days'\")\n\n    if num < 1:\n        raise ValueError(\"frequency must be a positive integer\")\n\n    return timedelta(weeks=num)\n", "def parse_frequency(frequency):\n    if frequency in ('always', 'never'):\n        return None\n\n    frequency = frequency.lower()\n    if frequency in ('weeks', 'week'):\n        return timedelta(weeks=1)\n    elif frequency in ('days', 'day'):\n        return timedelta(days=1)\n    elif frequency in ('hours', 'hour'):\n        return timedelta(hours=1)\n    elif frequency in ('minutes','minute'):\n        return timedelta(minutes=1)\n    elif frequency in ('seconds','second'):\n        return timedelta(seconds=1)\n    elif frequency in ('weekdays', 'weekday', 'weekday_start', 'weekday_end'):\n        return timedelta(days=1, weeks=1)\n    elif frequency in ('months','month'):\n        return timedelta(days=1, months=1)\n    elif frequency in ('quarters', 'quarter'):\n        return timedelta(days=4, quarters=1)\n    elif frequency in ('daily', 'd'):\n        return timedelta(days=365)\n    elif", "def parse_frequency(frequency):\n    if frequency in (None, 'always'):\n        return None\n\n    frequency = frequency.upper()\n\n    if frequency in ('1day', '7day', '30day', '90day'):\n        return timedelta(days=1)\n\n    raise ValueError('Unrecognized frequency \"%s\"' % frequency)\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def parse_frequency(frequency):\n    if frequency is None or frequency == 'always':\n        return timedelta(weeks=1)\n    else:\n        frequency = frequency.upper()\n        if frequency == 'WEEKLY':\n            return timedelta(weeks=52)\n        elif frequency == 'MONTHLY':\n            return timedelta(weeks=52 * 4)\n        elif frequency == 'DAILY':\n            return timedelta(weeks=52 * 30)\n        elif frequency == 'YEARLY':\n            return timedelta(weeks=53)\n        elif frequency == 'THURSDAY':\n            return timedelta(weeks=53 * 28)\n        elif frequency == 'TUESDAY':\n            return timedelta(weeks=53 * 29)\n        elif frequency == 'WEEKLY 30 DAYS':\n            return timedelta(weeks=53 * 30 * 24)\n        elif frequency == 'MONTHLY 30 DAYS':\n            return timedelta(weeks=53 * 30", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    if frequency is None or frequency.lower() not in _FREQ_VALS:\n        raise ValueError(\"frequency must be one of %s\" % _FREQ_VALS)\n\n    weeks = int(frequency)\n    return datetime.timedelta(weeks=weeks)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    if frequency is None or frequency == 'always':\n        return None\n    elif frequency == 'weekly':\n        return timedelta(weeks=7)\n    elif frequency == 'daily':\n        return timedelta(days=1)\n    elif frequency =='monthly':\n        return timedelta(months=12)\n    elif frequency == 'yearly':\n        return timedelta(years=1)\n    else:\n        raise ValueError('Frequency \"{}\" is not supported.'.format(frequency))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    if frequency is None or frequency.lower() not in [\"always\", \"weeks\", \"days\"]:\n        return None\n    return timedelta(days=int(frequency[:-1]))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    frequency = frequency.lower()\n    if frequency not in _FREQ_MAP:\n        raise ValueError(\"Frequency must be one of {0!r}\".format(_FREQ_MAP))\n    return _FREQ_MAP[frequency]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    frequency = frequency.lower()\n    if frequency not in _FREQ_PARAMS:\n        raise ValueError(\"Frequency '%s' is not a recognised frequency\" % frequency)\n    return _FREQ_PARAMS[frequency]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    frequency = frequency.strip()\n    if frequency in ('always', 'never'):\n        return None\n\n    match = _FREQ_REGEX.match(frequency)\n    if match is None:\n        raise ValueError('Frequency \"{0}\" is not valid.'.format(frequency))\n\n    num_part, unit_part = match.groups()\n    num = int(num_part)\n    unit = _UNITS.get(unit_part.lower())\n    if unit is None:\n        raise ValueError('Unknown frequency \"{0}\".'.format(unit_part))\n\n    return timedelta(\n        **{\n            'num': num,\n            'unit': unit\n        }\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    try:\n        num, unit = frequency.split(\" \")\n    except ValueError:\n        raise ValueError(\"frequency must be in the form 'weeks'\")\n\n    try:\n        num = int(num)\n    except ValueError:\n        raise ValueError(\"frequency must be an integer\")\n\n    if unit not in [\"weeks\", \"days\"]:\n        raise ValueError(\"frequency must be 'weeks' or 'days'\")\n\n    if num < 1:\n        raise ValueError(\"frequency must be a positive integer\")\n\n    return timedelta(weeks=num)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    if frequency in ('always', 'never'):\n        return None\n\n    frequency = frequency.lower()\n    if frequency in ('weeks', 'week'):\n        return timedelta(weeks=1)\n    elif frequency in ('days', 'day'):\n        return timedelta(days=1)\n    elif frequency in ('hours', 'hour'):\n        return timedelta(hours=1)\n    elif frequency in ('minutes','minute'):\n        return timedelta(minutes=1)\n    elif frequency in ('seconds','second'):\n        return timedelta(seconds=1)\n    elif frequency in ('weekdays', 'weekday', 'weekday_start', 'weekday_end'):\n        return timedelta(days=1, weeks=1)\n    elif frequency in ('months','month'):\n        return timedelta(days=1, months=1)\n    elif frequency in ('quarters', 'quarter'):\n        return timedelta(days=4, quarters=1)\n    elif frequency in ('daily', 'd'):\n        return timedelta(days=365)\n    elif", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_frequency(frequency):\n    if frequency in (None, 'always'):\n        return None\n\n    frequency = frequency.upper()\n\n    if frequency in ('1day', '7day', '30day', '90day'):\n        return timedelta(days=1)\n\n    raise ValueError('Unrecognized frequency \"%s\"' % frequency)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_18.py", "name": "is_local", "docstring": "Checks if the host is the localhost\n\n:param host: The hostname or ip\n:return: True if the host is the localhost", "ques_id": "62ece4992e6aefcf4aabbd78", "code": ["def is_local(host):\n    return host == '127.0.0.1'\n", "def is_local(host):\n    return host == '127.0.0.1'\n", "def is_local(host):\n    return host == '127.0.0.1'\n", "def is_local(host):\n    return host.startswith('127.0.0.1')\n", "def is_local(host):\n    if not isinstance(host, string_types):\n        return False\n\n    return host.startswith('127.0.0.1')\n", "def is_local(host):\n    return host.startswith('localhost')\n", "def is_local(host):\n    return host.startswith('127.0.0.1')\n", "def is_local(host):\n    return host == '127.0.0.1'\n", "def is_local(host):\n    return host == '127.0.0.1'\n", "def is_local(host):\n    return host == '127.0.0.1'\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def is_local(host):\n    return host == '127.0.0.1'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    return host == '127.0.0.1'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    return host == '127.0.0.1'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    return host.startswith('127.0.0.1')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    if not isinstance(host, string_types):\n        return False\n\n    return host.startswith('127.0.0.1')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    return host.startswith('localhost')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    return host.startswith('127.0.0.1')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    return host == '127.0.0.1'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    return host == '127.0.0.1'\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_local(host):\n    return host == '127.0.0.1'\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_8.py", "name": "make_find_paths", "docstring": "Given a sequence of path fragments or patterns as passed to `--find`, transform all path\nfragments into glob patterns. Pass through existing patterns untouched.\n\nFor example, given find_paths of:\n\n  ['foo.txt', 'pp:root/somedir']\n\n... transform that into:\n\n  ['sh:**/*foo.txt*/**', 'pp:root/somedir']", "ques_id": "62ece4992e6aefcf4aabbd79", "code": ["def make_find_paths(find_paths):\n    return [f'sh:**/*{path}*/**' for path in find_paths]\n", "def make_find_paths(find_paths):\n    return [f\"sh:**/*{f}*/**\" for f in find_paths]\n", "def make_find_paths(find_paths):\n    return [f\"sh:**/*{f}*/**\" for f in find_paths]\n", "def make_find_paths(find_paths):\n    return [f\"sh:**/*{p}*/**\" for p in find_paths]\n", "def make_find_paths(find_paths):\n    return [f\"sh:**/*{p}*/**\" for p in find_paths]\n", "def make_find_paths(find_paths):\n    return [f'sh:**/*{p}*/**' for p in find_paths]\n", "def make_find_paths(find_paths):\n    return [f\"sh:**/*{p}*/**\" for p in find_paths]\n", "def make_find_paths(find_paths):\n    return [f\"sh:**/*{p}*/**\" for p in find_paths]\n", "def make_find_paths(find_paths):\n    return [f'sh:**/*{p}*/**' for p in find_paths]\n", "def make_find_paths(find_paths):\n    return [f'sh:**/*{p}*/**' for p in find_paths]\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def make_find_paths(find_paths):\n    return [f'sh:**/*{path}*/**' for path in find_paths]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    return [f\"sh:**/*{f}*/**\" for f in find_paths]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    return [f\"sh:**/*{f}*/**\" for f in find_paths]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    return [f\"sh:**/*{p}*/**\" for p in find_paths]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    return [f\"sh:**/*{p}*/**\" for p in find_paths]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    return [f'sh:**/*{p}*/**' for p in find_paths]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    return [f\"sh:**/*{p}*/**\" for p in find_paths]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    return [f\"sh:**/*{p}*/**\" for p in find_paths]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    return [f'sh:**/*{p}*/**' for p in find_paths]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_find_paths(find_paths):\n    return [f'sh:**/*{p}*/**' for p in find_paths]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_19.py", "name": "is_gitbash", "docstring": "returns True if you run in a Windows gitbash\n\n:return: True if gitbash", "ques_id": "62ece4992e6aefcf4aabbd7a", "code": ["def is_gitbash():\n    try:\n        subprocess.check_output(['git', '--help'])\n        return True\n    except Exception:\n        return False\n", "def is_gitbash():\n    return os.name == 'nt'\n", "def is_gitbash():\n    return os.name == \"nt\"\n", "def is_gitbash():\n    try:\n        subprocess.check_output(['git', 'config', '--get','remote.origin.url'])\n        return True\n    except subprocess.CalledProcessError:\n        return False\n", "def is_gitbash():\n    # type: () -> bool\n    \"\"\"returns True if you run in a Windows gitbash\n\n    :return: True if gitbash\n    \"\"\"\n    return os.name == \"nt\"\n", "def is_gitbash():\n    return os.name == \"nt\"\n", "def is_gitbash():\n    return os.name == 'nt'\n", "def is_gitbash():\n    return os.name == 'nt'\n", "def is_gitbash():\n    return os.name == 'nt'\n", "def is_gitbash():\n    return os.name == \"nt\"\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def is_gitbash():\n    try:\n        subprocess.check_output(['git', '--help'])\n        return True\n    except Exception:\n        return False\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_gitbash():\n    return os.name == 'nt'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_gitbash():\n    return os.name == \"nt\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_gitbash():\n    try:\n        subprocess.check_output(['git', 'config', '--get','remote.origin.url'])\n        return True\n    except subprocess.CalledProcessError:\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_gitbash():\n    # type: () -> bool\n    \"\"\"returns True if you run in a Windows gitbash\n\n    :return: True if gitbash\n    \"\"\"\n    return os.name == \"nt\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_gitbash():\n    return os.name == \"nt\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_gitbash():\n    return os.name == 'nt'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_gitbash():\n    return os.name == 'nt'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_gitbash():\n    return os.name == 'nt'\n", "is_pass": true, "return_code": 0}, {"generate_code": "def is_gitbash():\n    return os.name == \"nt\"\n", "is_pass": true, "return_code": 0}]}
{"file_path": "slib_runnable/test_9.py", "name": "write_configuration", "docstring": "Given a target config filename and rendered config YAML, write it out to file. Create any\ncontaining directories as needed. But if the file already exists and overwrite is False,\nabort before writing anything.", "ques_id": "62ece4992e6aefcf4aabbd7b", "code": ["def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.isfile(config_filename):\n        print('Configuration file \"{}\" already exists. Aborting.'.format(config_filename))\n        sys.exit()\n\n    # If the directories don't exist, make them and write them out as needed.\n    if not overwrite and not os.path.isdir(os.path.dirname(config_filename)):\n        os.makedirs(os.path.dirname(config_filename))\n\n    with open(config_filename, mode) as f:\n        yaml.dump(rendered_config, f, default_flow_style=False)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n\n    dirname = os.path.dirname(config_filename)\n    if not overwrite and os.path.exists(dirname):\n        print(\"Configuration file already exists: %s\" % dirname)\n        sys.exit(1)\n\n    try:\n        os.makedirs(dirname)\n    except OSError as exc:\n        if exc.errno!= errno.EEXIST:\n            raise\n\n    with open(config_filename, 'w') as configfile:\n        configfile.write(rendered_config)\n\n    os.chmod(config_filename, mode)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    directory = os.path.dirname(config_filename)\n    if not overwrite and os.path.isdir(directory):\n        sys.exit(\n            \"Error: Configuration file {0} already exists. Overwrite is False.\".format(config_filename)\n        )\n    if not overwrite and not os.path.isdir(directory):\n        os.makedirs(directory)\n    with open(config_filename, \"w\") as configfile:\n        configfile.write(rendered_config)\n    os.chmod(config_filename, mode)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    directory = os.path.dirname(config_filename)\n    if not overwrite and os.path.exists(config_filename):\n        print('Configuration file already exists at {}. Overwrite?'.format(config_filename))\n        return\n\n    os.makedirs(directory, mode)\n    with open(config_filename, 'w') as f:\n        f.write(rendered_config)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    directory = os.path.dirname(config_filename)\n    if not overwrite and os.path.exists(config_filename):\n        print('Configuration file already exists at {0}. Aborting.'.format(config_filename))\n        return\n\n    print('Writing configuration file at {0}.'.format(config_filename))\n    try:\n        with open(config_filename, mode) as outfile:\n            outfile.write(rendered_config)\n    except IOError as e:\n        print('Could not write to file {0}: {1}'.format(config_filename, e))\n        sys.exit(1)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    directory = os.path.dirname(config_filename)\n\n    if not overwrite and os.path.exists(config_filename):\n        print(\"File %s already exists, skipping\" % config_filename)\n        return\n\n    # Make sure the directory is clean\n    if not overwrite and directory and not os.path.isdir(directory):\n        os.makedirs(directory)\n\n    with open(config_filename, mode) as outfile:\n        outfile.write(yaml.dump(rendered_config, default_flow_style=False))\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.exists(config_filename):\n        abort(\"Config file {} already exists. Aborting.\".format(config_filename))\n\n    dirname = os.path.dirname(config_filename)\n    if dirname:\n        if not overwrite and os.path.exists(dirname):\n            abort(\"Directory {} already exists.\".format(dirname))\n\n        os.makedirs(dirname)\n\n    with open(config_filename, mode) as outfile:\n        outfile.write(rendered_config)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    # if the filename doesn't exist, make it\n    if not os.path.isfile(config_filename):\n        os.makedirs(os.path.dirname(config_filename), exist_ok=True)\n\n    with open(config_filename, mode) as configfile:\n        configfile.write(rendered_config)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    directory = os.path.dirname(config_filename)\n    if not overwrite and os.path.exists(config_filename):\n        print(\"{0} exists. Overwrite it?\".format(config_filename))\n        return\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    with open(config_filename, mode) as f:\n        f.write(rendered_config)\n", "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    directory = os.path.dirname(config_filename)\n    if not overwrite and os.path.exists(config_filename):\n        print(\"\\t\\t\\tWARNING: config file already exists: {}\".format(config_filename))\n        return\n\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    with open(config_filename, mode) as outfile:\n        outfile.write(yaml.dump(rendered_config, default_flow_style=False))\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.isfile(config_filename):\n        print('Configuration file \"{}\" already exists. Aborting.'.format(config_filename))\n        sys.exit()\n\n    # If the directories don't exist, make them and write them out as needed.\n    if not overwrite and not os.path.isdir(os.path.dirname(config_filename)):\n        os.makedirs(os.path.dirname(config_filename))\n\n    with open(config_filename, mode) as f:\n        yaml.dump(rendered_config, f, default_flow_style=False)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n\n    dirname = os.path.dirname(config_filename)\n    if not overwrite and os.path.exists(dirname):\n        print(\"Configuration file already exists: %s\" % dirname)\n        sys.exit(1)\n\n    try:\n        os.makedirs(dirname)\n    except OSError as exc:\n        if exc.errno!= errno.EEXIST:\n            raise\n\n    with open(config_filename, 'w') as configfile:\n        configfile.write(rendered_config)\n\n    os.chmod(config_filename, mode)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    directory = os.path.dirname(config_filename)\n    if not overwrite and os.path.isdir(directory):\n        sys.exit(\n            \"Error: Configuration file {0} already exists. Overwrite is False.\".format(config_filename)\n        )\n    if not overwrite and not os.path.isdir(directory):\n        os.makedirs(directory)\n    with open(config_filename, \"w\") as configfile:\n        configfile.write(rendered_config)\n    os.chmod(config_filename, mode)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    directory = os.path.dirname(config_filename)\n    if not overwrite and os.path.exists(config_filename):\n        print('Configuration file already exists at {}. Overwrite?'.format(config_filename))\n        return\n\n    os.makedirs(directory, mode)\n    with open(config_filename, 'w') as f:\n        f.write(rendered_config)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    directory = os.path.dirname(config_filename)\n    if not overwrite and os.path.exists(config_filename):\n        print('Configuration file already exists at {0}. Aborting.'.format(config_filename))\n        return\n\n    print('Writing configuration file at {0}.'.format(config_filename))\n    try:\n        with open(config_filename, mode) as outfile:\n            outfile.write(rendered_config)\n    except IOError as e:\n        print('Could not write to file {0}: {1}'.format(config_filename, e))\n        sys.exit(1)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    directory = os.path.dirname(config_filename)\n\n    if not overwrite and os.path.exists(config_filename):\n        print(\"File %s already exists, skipping\" % config_filename)\n        return\n\n    # Make sure the directory is clean\n    if not overwrite and directory and not os.path.isdir(directory):\n        os.makedirs(directory)\n\n    with open(config_filename, mode) as outfile:\n        outfile.write(yaml.dump(rendered_config, default_flow_style=False))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    if not overwrite and os.path.exists(config_filename):\n        abort(\"Config file {} already exists. Aborting.\".format(config_filename))\n\n    dirname = os.path.dirname(config_filename)\n    if dirname:\n        if not overwrite and os.path.exists(dirname):\n            abort(\"Directory {} already exists.\".format(dirname))\n\n        os.makedirs(dirname)\n\n    with open(config_filename, mode) as outfile:\n        outfile.write(rendered_config)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    # if the filename doesn't exist, make it\n    if not os.path.isfile(config_filename):\n        os.makedirs(os.path.dirname(config_filename), exist_ok=True)\n\n    with open(config_filename, mode) as configfile:\n        configfile.write(rendered_config)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    directory = os.path.dirname(config_filename)\n    if not overwrite and os.path.exists(config_filename):\n        print(\"{0} exists. Overwrite it?\".format(config_filename))\n        return\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n    with open(config_filename, mode) as f:\n        f.write(rendered_config)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def write_configuration(config_filename, rendered_config, mode=0o600, overwrite=False):\n    directory = os.path.dirname(config_filename)\n    if not overwrite and os.path.exists(config_filename):\n        print(\"\\t\\t\\tWARNING: config file already exists: {}\".format(config_filename))\n        return\n\n    if not os.path.exists(directory):\n        os.makedirs(directory)\n\n    with open(config_filename, mode) as outfile:\n        outfile.write(yaml.dump(rendered_config, default_flow_style=False))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_22.py", "name": "oneline", "docstring": "converts a script to one line command.\nTHis is useful to run a single ssh command and pass a one line script.\n\n:param script:\n:return:", "ques_id": "62ece4992e6aefcf4aabbd7c", "code": ["def oneline(script, seperator=\" && \"):\n    return seperator.join([\"ssh -o '%s'\" % s for s in script.split(\"\\n\")])\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join([\"echo '%s'\" % line for line in script.split(\"\\n\")])\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join([line for line in script.split(\"\\n\") if line])\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join([line for line in script.split(\"\\n\") if line])\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join([\"echo '%s'\" % line for line in script.split(\"\\n\")])\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.splitlines())\n", "def oneline(script, seperator=\" && \"):\n    return \"{}{}\".format(seperator, script)\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join([shlex.quote(s) for s in script.split(\"\\n\")])\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(seperator))\n", "def oneline(script, seperator=\" && \"):\n    return seperator.join([line for line in script.splitlines()])\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join([\"ssh -o '%s'\" % s for s in script.split(\"\\n\")])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join([\"echo '%s'\" % line for line in script.split(\"\\n\")])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join([line for line in script.split(\"\\n\") if line])\n", "is_pass": true, "return_code": 0}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join([line for line in script.split(\"\\n\") if line])\n", "is_pass": true, "return_code": 0}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join([\"echo '%s'\" % line for line in script.split(\"\\n\")])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.splitlines())\n", "is_pass": true, "return_code": 0}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return \"{}{}\".format(seperator, script)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join([shlex.quote(s) for s in script.split(\"\\n\")])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join(script.split(seperator))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def oneline(script, seperator=\" && \"):\n    return seperator.join([line for line in script.splitlines()])\n", "is_pass": true, "return_code": 0}]}
{"file_path": "slib_runnable/test_16.py", "name": "subprocess_run_helper", "docstring": "Run a function in a sub-process.\n\nParameters\n----------\nfunc : function\n    The function to be run.  It must be in a module that is importable.\n*args : str\n    Any additional command line arguments to be passed in\n    the first argument to ``subprocess.run``.\nextra_env : dict[str, str]\n    Any additional environment variables to be set for the subprocess.", "ques_id": "62ece4992e6aefcf4aabbd7d", "code": ["def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    with tempfile.NamedTemporaryFile(suffix='.py') as tmp:\n        tmp.write('__init__.py\\n')\n        tmp.write('__version__ = \"{}\"\\n'.format(__version__))\n        tmp.flush()\n        proc = subprocess.Popen(\n            [tmp.name, '-c', 'import sys; sys.path=[\"{}\"]'.format(sys.path)],\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            env=extra_env or os.environ.copy(),\n        )\n        proc.communicate(input=func(tmp.name, *args))\n        return proc.wait(), tmp.read()\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    env.update(extra_env or {})\n    proc = subprocess.Popen(\n        args,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        env=env,\n        timeout=timeout,\n    )\n    out, err = proc.communicate()\n    return proc.returncode, out, err\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env:\n        env.update(extra_env)\n    proc = subprocess.Popen(\n        [sys.executable, '-c', 'import time; time.sleep(%s)' % timeout] +\n        list(args),\n        env=env\n    )\n    proc.wait(timeout)\n    return proc.returncode\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env:\n        env.update(extra_env)\n    p = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n                         env=env)\n    p.communicate(timeout)\n    return p.returncode, p.stdout, p.stderr\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env:\n        env.update(extra_env)\n    with open(os.devnull, 'wb') as devnull:\n        p = subprocess.Popen(\n            [sys.executable, func.__module__] + list(args),\n            stdout=subprocess.PIPE,\n            stderr=devnull,\n            env=env,\n        )\n        p.communicate()\n        return p.returncode == 0\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = {}\n    if extra_env:\n        env.update(extra_env)\n    env['PGPASSWORD'] = 'test'\n    proc = subprocess.Popen(args, stdout=subprocess.PIPE,\n                            stderr=subprocess.PIPE, env=env)\n    proc.wait(timeout)\n    output = proc.communicate()[0].decode()\n    if proc.returncode:\n        raise Exception(\"Failed to run {}\".format(func))\n    return output\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env:\n        env.update(extra_env)\n    p = subprocess.Popen(\n        [sys.executable, '-m', func] + list(args),\n        env=env,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        timeout=timeout)\n    return p.communicate()\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    env.update(extra_env or {})\n    with open(os.devnull, 'w') as devnull:\n        proc = subprocess.Popen(\n            [sys.executable, func.__module__] + list(args),\n            stdout=devnull,\n            stderr=devnull,\n            env=env,\n            timeout=timeout)\n        return proc.wait()\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    if extra_env is None:\n        extra_env = {}\n    env = os.environ.copy()\n    env.update(extra_env)\n    try:\n        proc = subprocess.Popen(\n            args, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n            env=env)\n    except OSError:\n        proc = subprocess.Popen(\n            args, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n            env=env, close_fds=True)\n    output, errors = proc.communicate(timeout=timeout)\n    if proc.returncode:\n        raise OSError('{}: {}'.format(proc.returncode, errors))\n    return output.decode('utf-8')\n", "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env:\n        env.update(extra_env)\n    with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:\n        f.write('{} {}'.format(args, timeout))\n        f.flush()\n        cmd = [sys.executable, f.name]\n        cmd.append('--timeout={}s'.format(timeout))\n        cmd.append('--verbose')\n        cmd.append(func.__name__)\n        cmd.append('--shell={}'.format(os.environ.get('SHELL', '/bin/bash')))\n        cmd.extend(args)\n        cmd.append('--stdout-only')\n        cmd.append('--no-eval')\n        print('Running command: {}'.format(' '.join(cmd)))\n        subprocess.run(cmd, check=True, env=env)\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    with tempfile.NamedTemporaryFile(suffix='.py') as tmp:\n        tmp.write('__init__.py\\n')\n        tmp.write('__version__ = \"{}\"\\n'.format(__version__))\n        tmp.flush()\n        proc = subprocess.Popen(\n            [tmp.name, '-c', 'import sys; sys.path=[\"{}\"]'.format(sys.path)],\n            stdin=subprocess.PIPE,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            env=extra_env or os.environ.copy(),\n        )\n        proc.communicate(input=func(tmp.name, *args))\n        return proc.wait(), tmp.read()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    env.update(extra_env or {})\n    proc = subprocess.Popen(\n        args,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        env=env,\n        timeout=timeout,\n    )\n    out, err = proc.communicate()\n    return proc.returncode, out, err\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env:\n        env.update(extra_env)\n    proc = subprocess.Popen(\n        [sys.executable, '-c', 'import time; time.sleep(%s)' % timeout] +\n        list(args),\n        env=env\n    )\n    proc.wait(timeout)\n    return proc.returncode\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env:\n        env.update(extra_env)\n    p = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n                         env=env)\n    p.communicate(timeout)\n    return p.returncode, p.stdout, p.stderr\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env:\n        env.update(extra_env)\n    with open(os.devnull, 'wb') as devnull:\n        p = subprocess.Popen(\n            [sys.executable, func.__module__] + list(args),\n            stdout=subprocess.PIPE,\n            stderr=devnull,\n            env=env,\n        )\n        p.communicate()\n        return p.returncode == 0\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = {}\n    if extra_env:\n        env.update(extra_env)\n    env['PGPASSWORD'] = 'test'\n    proc = subprocess.Popen(args, stdout=subprocess.PIPE,\n                            stderr=subprocess.PIPE, env=env)\n    proc.wait(timeout)\n    output = proc.communicate()[0].decode()\n    if proc.returncode:\n        raise Exception(\"Failed to run {}\".format(func))\n    return output\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env:\n        env.update(extra_env)\n    p = subprocess.Popen(\n        [sys.executable, '-m', func] + list(args),\n        env=env,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        timeout=timeout)\n    return p.communicate()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    env.update(extra_env or {})\n    with open(os.devnull, 'w') as devnull:\n        proc = subprocess.Popen(\n            [sys.executable, func.__module__] + list(args),\n            stdout=devnull,\n            stderr=devnull,\n            env=env,\n            timeout=timeout)\n        return proc.wait()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    if extra_env is None:\n        extra_env = {}\n    env = os.environ.copy()\n    env.update(extra_env)\n    try:\n        proc = subprocess.Popen(\n            args, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n            env=env)\n    except OSError:\n        proc = subprocess.Popen(\n            args, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n            env=env, close_fds=True)\n    output, errors = proc.communicate(timeout=timeout)\n    if proc.returncode:\n        raise OSError('{}: {}'.format(proc.returncode, errors))\n    return output.decode('utf-8')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def subprocess_run_helper(func, *args, timeout, extra_env=None):\n    env = os.environ.copy()\n    if extra_env:\n        env.update(extra_env)\n    with tempfile.NamedTemporaryFile(mode='w', delete=False) as f:\n        f.write('{} {}'.format(args, timeout))\n        f.flush()\n        cmd = [sys.executable, f.name]\n        cmd.append('--timeout={}s'.format(timeout))\n        cmd.append('--verbose')\n        cmd.append(func.__name__)\n        cmd.append('--shell={}'.format(os.environ.get('SHELL', '/bin/bash')))\n        cmd.extend(args)\n        cmd.append('--stdout-only')\n        cmd.append('--no-eval')\n        print('Running command: {}'.format(' '.join(cmd)))\n        subprocess.run(cmd, check=True, env=env)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_6.py", "name": "_resolve_string", "docstring": "Get the value from environment given a matcher containing a name and an optional default value.\nIf the variable is not defined in environment and no default value is provided, an Error is raised.", "ques_id": "62ece4992e6aefcf4aabbd7e", "code": ["def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = matcher.group(2) or ''\n    try:\n        return os.environ[name]\n    except KeyError:\n        error = 'Environment variable \"{}\" not found.'\n        raise Error(error.format(name))\n    except TypeError:\n        # Python 2\n        error = 'Type {} cannot be converted to string.'\n        raise Error(error.format(type(name)))\n", "def _resolve_string(matcher):\n    name, default = matcher.group(1, 2)\n    if default is None:\n        default = os.environ.get(name)\n    else:\n        default = str(default)\n\n    return os.environ.get(name, default)\n", "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = matcher.group(2) if matcher.group(2) else None\n    return os.environ.get(name, default)\n", "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = None\n    value = os.environ.get(name)\n\n    if value is None:\n        raise Error('Environment variable \"{}\" is not defined'.format(name))\n\n    if value == 'True':\n        default = True\n    elif value == 'False':\n        default = False\n\n    return value, default\n", "def _resolve_string(matcher):\n    name, default = matcher.group(1, 2)\n\n    if default is None:\n        raise Error(\"Environment variable %s is not defined\" % name)\n    else:\n        return os.environ.get(name, default)\n", "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = None\n    value = os.environ.get(name)\n    if value:\n        if value == 'True':\n            default = True\n        elif value == 'False':\n            default = False\n        else:\n            try:\n                value = int(value)\n            except ValueError:\n                try:\n                    value = float(value)\n                except ValueError:\n                    if value == '':\n                        value = default\n                if value is not None:\n                    raise Error('Cannot convert value \"{}\" to int'.format(value))\n    return name, default\n", "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = None\n\n    try:\n        return os.environ[name]\n    except KeyError:\n        pass\n\n    try:\n        return os.environ['DEFAULT']\n    except KeyError:\n        pass\n\n    if default is not None:\n        return default\n\n    raise Error('Variable {} is not defined.'.format(name))\n", "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = None\n    if matcher.group(2):\n        try:\n            return os.environ[name]\n        except KeyError:\n            raise Error(\n                \"Environment variable '{}' was not found\".format(name)\n            )\n    elif matcher.group(3):\n        try:\n            return os.environ[name] == matcher.group(3)\n        except KeyError:\n            raise Error(\n                \"Environment variable '{}' was not found\".format(name)\n            )\n    else:\n        try:\n            return os.environ[name]\n        except KeyError:\n            return default\n", "def _resolve_string(matcher):\n    name, default = matcher.group(1), matcher.group(2)\n    if default is None:\n        raise EnvironmentError('{0} not defined'.format(name))\n    elif default == '':\n        raise EnvironmentError('{0} is required'.format(name))\n    return os.environ.get(name, default)\n", "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = matcher.group(2)\n    try:\n        return os.environ[name]\n    except KeyError:\n        if default is None:\n            raise Error(\"Environment variable '{}' does not exist\".format(name))\n        return default\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = matcher.group(2) or ''\n    try:\n        return os.environ[name]\n    except KeyError:\n        error = 'Environment variable \"{}\" not found.'\n        raise Error(error.format(name))\n    except TypeError:\n        # Python 2\n        error = 'Type {} cannot be converted to string.'\n        raise Error(error.format(type(name)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    name, default = matcher.group(1, 2)\n    if default is None:\n        default = os.environ.get(name)\n    else:\n        default = str(default)\n\n    return os.environ.get(name, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = matcher.group(2) if matcher.group(2) else None\n    return os.environ.get(name, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = None\n    value = os.environ.get(name)\n\n    if value is None:\n        raise Error('Environment variable \"{}\" is not defined'.format(name))\n\n    if value == 'True':\n        default = True\n    elif value == 'False':\n        default = False\n\n    return value, default\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    name, default = matcher.group(1, 2)\n\n    if default is None:\n        raise Error(\"Environment variable %s is not defined\" % name)\n    else:\n        return os.environ.get(name, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = None\n    value = os.environ.get(name)\n    if value:\n        if value == 'True':\n            default = True\n        elif value == 'False':\n            default = False\n        else:\n            try:\n                value = int(value)\n            except ValueError:\n                try:\n                    value = float(value)\n                except ValueError:\n                    if value == '':\n                        value = default\n                if value is not None:\n                    raise Error('Cannot convert value \"{}\" to int'.format(value))\n    return name, default\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = None\n\n    try:\n        return os.environ[name]\n    except KeyError:\n        pass\n\n    try:\n        return os.environ['DEFAULT']\n    except KeyError:\n        pass\n\n    if default is not None:\n        return default\n\n    raise Error('Variable {} is not defined.'.format(name))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = None\n    if matcher.group(2):\n        try:\n            return os.environ[name]\n        except KeyError:\n            raise Error(\n                \"Environment variable '{}' was not found\".format(name)\n            )\n    elif matcher.group(3):\n        try:\n            return os.environ[name] == matcher.group(3)\n        except KeyError:\n            raise Error(\n                \"Environment variable '{}' was not found\".format(name)\n            )\n    else:\n        try:\n            return os.environ[name]\n        except KeyError:\n            return default\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    name, default = matcher.group(1), matcher.group(2)\n    if default is None:\n        raise EnvironmentError('{0} not defined'.format(name))\n    elif default == '':\n        raise EnvironmentError('{0} is required'.format(name))\n    return os.environ.get(name, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _resolve_string(matcher):\n    name = matcher.group(1)\n    default = matcher.group(2)\n    try:\n        return os.environ[name]\n    except KeyError:\n        if default is None:\n            raise Error(\"Environment variable '{}' does not exist\".format(name))\n        return default\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_2.py", "name": "_parse_image_ref", "docstring": "Parse an image href into composite parts.\n\n:param image_href: href of an image\n:returns: a tuple of the form (image_id, netloc, use_ssl)\n:raises ValueError:", "ques_id": "62ece4992e6aefcf4aabbd7f", "code": ["def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    parsed = urlparse(image_href)\n\n    if parsed.netloc.find(':') < 0:\n        raise ValueError('Invalid image reference:'+ image_href)\n\n    netloc = parsed.netloc.split(':')[0]\n    use_ssl = False\n    if parsed.scheme == 'https':\n        use_ssl = True\n\n    image_id = parsed.path.split('/')[-1]\n    return image_id, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    if image_href.startswith('/'):\n        raise ValueError('Image href should not start with a path')\n    image_id = image_href.split('/')[-1]\n    netloc = urlparse(image_href).netloc\n    use_ssl = False\n    if ':' in image_href:\n        use_ssl, image_href = image_href.split(':')\n    return image_id, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    m = re.match(r'(.*?)/([^/]+)(?:#.*)?', image_href)\n    if m is None:\n        raise ValueError('Invalid image href: %s' % image_href)\n    image_id = m.group(1)\n    netloc = m.group(2)\n    use_ssl = (m.group(3) == 'on')\n\n    return image_id, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> tuple:\n    if not image_href.startswith(IMAGE_PREFIX):\n        raise ValueError('image_href must start with {}'.format(IMAGE_PREFIX))\n\n    image_href = image_href[len(IMAGE_PREFIX):]\n    netloc = None\n    use_ssl = False\n\n    if ':' in image_href:\n        image_href, netloc = image_href.split(':', 1)\n        use_ssl = True\n\n    image_id = image_href.strip('/')\n\n    return image_id, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    parsed = urlparse(image_href)\n    try:\n        netloc = parsed.netloc.split(':')[0]\n    except Exception:\n        raise ValueError('Invalid image href {}'.format(image_href))\n\n    image_id = parsed.path.lstrip('/')\n    use_ssl = False if ':' in parsed.path else True\n\n    return image_id, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    m = re.match(r\"(.+?)://(.+)\", image_href)\n    if not m:\n        raise ValueError(\"Invalid image reference: {}\".format(image_href))\n    netloc = m.group(1)\n    use_ssl = m.group(2) == \"on\"\n\n    return m.group(1), netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    if not image_href:\n        raise ValueError('Image href cannot be empty')\n\n    image_id = image_href.split('/')[-1]\n    netloc = image_href.split('/')[:-1]\n    use_ssl = False\n\n    return image_id, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    url_components = urlparse(image_href)\n    if not url_components.netloc:\n        raise ValueError('Invalid image reference: {}'.format(image_href))\n    image_id = url_components.path.split('/')[-1]\n    netloc = url_components.netloc\n    use_ssl = False\n    if url_components.scheme == 'https':\n        use_ssl = True\n    return image_id, netloc, use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    parsed = urlparse(image_href)\n    if not parsed.netloc:\n        raise ValueError('Invalid image href: {}'.format(image_href))\n    return parsed.path.split('/')[-1], parsed.netloc, parsed.use_ssl\n", "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    image_href = image_href.lstrip('/')\n    parsed = urlparse(image_href)\n\n    if '//' in image_href:\n        netloc = parsed.netloc.rsplit(':', 1)[0]\n        use_ssl = True\n    else:\n        netloc = parsed.netloc\n        use_ssl = False\n\n    image_id = parsed.path.lstrip('/')\n    return image_id, netloc, use_ssl\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    parsed = urlparse(image_href)\n\n    if parsed.netloc.find(':') < 0:\n        raise ValueError('Invalid image reference:'+ image_href)\n\n    netloc = parsed.netloc.split(':')[0]\n    use_ssl = False\n    if parsed.scheme == 'https':\n        use_ssl = True\n\n    image_id = parsed.path.split('/')[-1]\n    return image_id, netloc, use_ssl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    if image_href.startswith('/'):\n        raise ValueError('Image href should not start with a path')\n    image_id = image_href.split('/')[-1]\n    netloc = urlparse(image_href).netloc\n    use_ssl = False\n    if ':' in image_href:\n        use_ssl, image_href = image_href.split(':')\n    return image_id, netloc, use_ssl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    m = re.match(r'(.*?)/([^/]+)(?:#.*)?', image_href)\n    if m is None:\n        raise ValueError('Invalid image href: %s' % image_href)\n    image_id = m.group(1)\n    netloc = m.group(2)\n    use_ssl = (m.group(3) == 'on')\n\n    return image_id, netloc, use_ssl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> tuple:\n    if not image_href.startswith(IMAGE_PREFIX):\n        raise ValueError('image_href must start with {}'.format(IMAGE_PREFIX))\n\n    image_href = image_href[len(IMAGE_PREFIX):]\n    netloc = None\n    use_ssl = False\n\n    if ':' in image_href:\n        image_href, netloc = image_href.split(':', 1)\n        use_ssl = True\n\n    image_id = image_href.strip('/')\n\n    return image_id, netloc, use_ssl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    parsed = urlparse(image_href)\n    try:\n        netloc = parsed.netloc.split(':')[0]\n    except Exception:\n        raise ValueError('Invalid image href {}'.format(image_href))\n\n    image_id = parsed.path.lstrip('/')\n    use_ssl = False if ':' in parsed.path else True\n\n    return image_id, netloc, use_ssl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    m = re.match(r\"(.+?)://(.+)\", image_href)\n    if not m:\n        raise ValueError(\"Invalid image reference: {}\".format(image_href))\n    netloc = m.group(1)\n    use_ssl = m.group(2) == \"on\"\n\n    return m.group(1), netloc, use_ssl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    if not image_href:\n        raise ValueError('Image href cannot be empty')\n\n    image_id = image_href.split('/')[-1]\n    netloc = image_href.split('/')[:-1]\n    use_ssl = False\n\n    return image_id, netloc, use_ssl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    url_components = urlparse(image_href)\n    if not url_components.netloc:\n        raise ValueError('Invalid image reference: {}'.format(image_href))\n    image_id = url_components.path.split('/')[-1]\n    netloc = url_components.netloc\n    use_ssl = False\n    if url_components.scheme == 'https':\n        use_ssl = True\n    return image_id, netloc, use_ssl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    parsed = urlparse(image_href)\n    if not parsed.netloc:\n        raise ValueError('Invalid image href: {}'.format(image_href))\n    return parsed.path.split('/')[-1], parsed.netloc, parsed.use_ssl\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _parse_image_ref(image_href: str) -> Tuple[str, str, bool]:\n    image_href = image_href.lstrip('/')\n    parsed = urlparse(image_href)\n\n    if '//' in image_href:\n        netloc = parsed.netloc.rsplit(':', 1)[0]\n        use_ssl = True\n    else:\n        netloc = parsed.netloc\n        use_ssl = False\n\n    image_id = parsed.path.lstrip('/')\n    return image_id, netloc, use_ssl\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_13.py", "name": "remove_ending_os_sep", "docstring": "Iterate over a string list and remove trailing os seperator characters.\n\nEach string is tested if its length is greater than one and if the last\ncharacter is the pathname seperator. If so, the pathname seperator character\nis removed.\n\nArgs:\n    input_list: list of strings\n\nReturns:\n    Processed list of strings\n\nRaises:\n    TypeError", "ques_id": "62ece4992e6aefcf4aabbd80", "code": ["def remove_ending_os_sep(input_list):\n    # Test if list is not a string\n    if not isinstance(input_list, str):\n        raise TypeError(\"input_list must be a string\")\n\n    # Test if input_list has at least one item\n    if len(input_list) <= 1:\n        raise TypeError(\"input_list must have at least one item\")\n\n    # Test if input_list has a seperator character\n    if input_list[-1] == '/':\n        return input_list[0:-1]\n    else:\n        return input_list\n", "def remove_ending_os_sep(input_list):\n    if not isinstance(input_list, list):\n        raise TypeError('input_list must be a list')\n    if len(input_list) <= 1:\n        raise TypeError('input_list must have at least one element')\n\n    processed_list = []\n    for item in input_list:\n        if isinstance(item, str) and item!= os.sep:\n            processed_list.append(item)\n        elif isinstance(item, list):\n            processed_list.append(remove_ending_os_sep(item))\n\n    return processed_list\n", "def remove_ending_os_sep(input_list):\n    if not isinstance(input_list, list):\n        raise TypeError(\"input_list must be a list\")\n    if len(input_list) > 1:\n        for item in input_list:\n            if item[-1:] == os.sep:\n                item = item[:-1]\n            yield item\n    for item in input_list:\n        if item[-1:]!= os.sep:\n            yield item\n", "def remove_ending_os_sep(input_list):\n    if not isinstance(input_list, list):\n        raise TypeError(\"Input list must be of type list\")\n\n    if len(input_list) <= 1:\n        return input_list\n\n    if input_list[-1]!= os.sep:\n        input_list.pop()\n\n    return input_list\n", "def remove_ending_os_sep(input_list):\n    if len(input_list) <= 1:\n        return input_list\n\n    if input_list[-1]!= os.sep:\n        return input_list\n\n    return input_list[0:len(input_list) - 1]\n", "def remove_ending_os_sep(input_list):\n    if not isinstance(input_list, list):\n        raise TypeError('input_list must be of type list')\n\n    if len(input_list) <= 1:\n        return input_list\n\n    if input_list[-1] == os.sep:\n        return input_list[:-1]\n\n    return input_list\n", "def remove_ending_os_sep(input_list):\n    if len(input_list) > 1:\n        for i, val in enumerate(input_list):\n            if len(val) > 1 and val[-1] == os.sep:\n                input_list[i] = val[:-1]\n        return input_list\n    else:\n        raise TypeError(\"Input list must have at least one string\")\n", "def remove_ending_os_sep(input_list):\n    if len(input_list) > 1:\n        for i in range(len(input_list)):\n            if len(input_list[i]) > 1 and input_list[i][-1:] == os.sep:\n                input_list[i] = input_list[i][:-1]\n    return input_list\n", "def remove_ending_os_sep(input_list):\n    if not isinstance(input_list, list):\n        raise TypeError('input_list must be a list')\n\n    if len(input_list) == 0:\n        return input_list\n\n    if len(input_list) == 1:\n        return input_list\n\n    last_char = input_list[-1]\n    if len(last_char) > 1 and last_char.endswith(os.sep):\n        return input_list[:-1]\n\n    return input_list\n", "def remove_ending_os_sep(input_list):\n    if not isinstance(input_list, list):\n        raise TypeError('Input must be a list')\n\n    if len(input_list) == 0:\n        return input_list\n\n    processed_list = []\n    for item in input_list:\n        if len(item) > 1 and item[-1]!= os.sep:\n            processed_list.append(item[:-1])\n        else:\n            processed_list.append(item)\n\n    return processed_list\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def remove_ending_os_sep(input_list):\n    # Test if list is not a string\n    if not isinstance(input_list, str):\n        raise TypeError(\"input_list must be a string\")\n\n    # Test if input_list has at least one item\n    if len(input_list) <= 1:\n        raise TypeError(\"input_list must have at least one item\")\n\n    # Test if input_list has a seperator character\n    if input_list[-1] == '/':\n        return input_list[0:-1]\n    else:\n        return input_list\n", "is_pass": false, "return_code": 1}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if not isinstance(input_list, list):\n        raise TypeError('input_list must be a list')\n    if len(input_list) <= 1:\n        raise TypeError('input_list must have at least one element')\n\n    processed_list = []\n    for item in input_list:\n        if isinstance(item, str) and item!= os.sep:\n            processed_list.append(item)\n        elif isinstance(item, list):\n            processed_list.append(remove_ending_os_sep(item))\n\n    return processed_list\n", "is_pass": false, "return_code": 1}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if not isinstance(input_list, list):\n        raise TypeError(\"input_list must be a list\")\n    if len(input_list) > 1:\n        for item in input_list:\n            if item[-1:] == os.sep:\n                item = item[:-1]\n            yield item\n    for item in input_list:\n        if item[-1:]!= os.sep:\n            yield item\n", "is_pass": false, "return_code": 1}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if not isinstance(input_list, list):\n        raise TypeError(\"Input list must be of type list\")\n\n    if len(input_list) <= 1:\n        return input_list\n\n    if input_list[-1]!= os.sep:\n        input_list.pop()\n\n    return input_list\n", "is_pass": false, "return_code": 1}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if len(input_list) <= 1:\n        return input_list\n\n    if input_list[-1]!= os.sep:\n        return input_list\n\n    return input_list[0:len(input_list) - 1]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if not isinstance(input_list, list):\n        raise TypeError('input_list must be of type list')\n\n    if len(input_list) <= 1:\n        return input_list\n\n    if input_list[-1] == os.sep:\n        return input_list[:-1]\n\n    return input_list\n", "is_pass": false, "return_code": 1}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if len(input_list) > 1:\n        for i, val in enumerate(input_list):\n            if len(val) > 1 and val[-1] == os.sep:\n                input_list[i] = val[:-1]\n        return input_list\n    else:\n        raise TypeError(\"Input list must have at least one string\")\n", "is_pass": true, "return_code": 0}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if len(input_list) > 1:\n        for i in range(len(input_list)):\n            if len(input_list[i]) > 1 and input_list[i][-1:] == os.sep:\n                input_list[i] = input_list[i][:-1]\n    return input_list\n", "is_pass": true, "return_code": 0}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if not isinstance(input_list, list):\n        raise TypeError('input_list must be a list')\n\n    if len(input_list) == 0:\n        return input_list\n\n    if len(input_list) == 1:\n        return input_list\n\n    last_char = input_list[-1]\n    if len(last_char) > 1 and last_char.endswith(os.sep):\n        return input_list[:-1]\n\n    return input_list\n", "is_pass": false, "return_code": 1}, {"generate_code": "def remove_ending_os_sep(input_list):\n    if not isinstance(input_list, list):\n        raise TypeError('Input must be a list')\n\n    if len(input_list) == 0:\n        return input_list\n\n    processed_list = []\n    for item in input_list:\n        if len(item) > 1 and item[-1]!= os.sep:\n            processed_list.append(item[:-1])\n        else:\n            processed_list.append(item)\n\n    return processed_list\n", "is_pass": false, "return_code": 1}]}
{"file_path": "slib_runnable/test_17.py", "name": "get_pattern", "docstring": "This method converts the given string to regex pattern", "ques_id": "62ece4992e6aefcf4aabbd82", "code": ["def get_pattern(pattern, strip=True):\n    regex_pattern = re.compile(pattern, re.I | re.S)\n    if strip:\n        regex_pattern = regex_pattern.strip()\n    return regex_pattern\n", "def get_pattern(pattern, strip=True):\n    return re.compile(''.join([\n        (r'(?P<(?:{pattern})\\s*)' if strip else r'(?:{pattern})')\n       .format(pattern=pattern)\n    ]))\n", "def get_pattern(pattern, strip=True):\n    if strip:\n        pattern = pattern.strip()\n    return re.compile(pattern)\n", "def get_pattern(pattern, strip=True):\n    if not isinstance(pattern, str):\n        raise TypeError(\"pattern must be a string\")\n\n    if strip:\n        pattern = pattern.strip()\n\n    pattern = re.compile(pattern)\n\n    return pattern\n", "def get_pattern(pattern, strip=True):\n    if type(pattern) is str:\n        pattern = pattern.strip()\n        pattern = re.compile(pattern)\n    elif type(pattern) is list:\n        pattern = pattern[0].strip()\n        pattern = re.compile(pattern)\n    elif type(pattern) is dict:\n        pattern = pattern['pattern'].strip()\n        pattern = re.compile(pattern)\n    elif type(pattern) is tuple:\n        pattern = pattern[0].strip()\n        pattern = re.compile(pattern[0])\n    elif type(pattern) is set:\n        pattern = pattern[0].strip()\n        pattern = re.compile(pattern[0])\n    elif type(pattern) is dict_keys:\n        pattern = pattern[1].strip()\n        pattern = re.compile(pattern[1])\n    elif type(pattern) is list_keys:\n        pattern = pattern[0].strip()\n        pattern = re.compile(pattern[0])\n    elif type(pattern) is str:\n        pattern = pattern[0].stri", "def get_pattern(pattern, strip=True):\n\n    if strip:\n        pattern = re.sub(r'\\s+', '\\\\s+', pattern)\n    pattern = re.sub(r'\\W', '\\\\W', pattern)\n    pattern = re.sub(r'\\d+', '\\\\d+', pattern)\n    pattern = re.sub(r'\\[(.+?)\\]', r'\\1', pattern)\n    pattern = re.sub(r'\\[(.+?)\\]', r'\\1', pattern)\n    pattern = re.sub(r'\\((.+?)\\)', r'\\1', pattern)\n    pattern = re.sub(r'\\s+', '\\\\s+', pattern)\n\n    return pattern\n", "def get_pattern(pattern, strip=True):\n    if strip:\n        pattern = re.compile(pattern.strip())\n    else:\n        pattern = re.compile(pattern)\n    return pattern\n", "def get_pattern(pattern, strip=True):\n    return re.compile(\"^\" + pattern.replace(\"*\", \"\\\\*\") + \"$\", re.UNICODE | re.MULTILINE | re.DOTALL) if strip else re.compile(pattern.replace(\"*\", \"\\\\*\") + \"$\", re.UNICODE | re.MULTILINE | re.DOTALL)\n", "def get_pattern(pattern, strip=True):\n    return re.compile(pattern, re.UNICODE | re.VERBOSE) if strip else re.compile(pattern)\n", "def get_pattern(pattern, strip=True):\n    return re.compile(pattern.replace('\\n', '\\\\n')) if strip else re.compile(pattern)\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def get_pattern(pattern, strip=True):\n    regex_pattern = re.compile(pattern, re.I | re.S)\n    if strip:\n        regex_pattern = regex_pattern.strip()\n    return regex_pattern\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_pattern(pattern, strip=True):\n    return re.compile(''.join([\n        (r'(?P<(?:{pattern})\\s*)' if strip else r'(?:{pattern})')\n       .format(pattern=pattern)\n    ]))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_pattern(pattern, strip=True):\n    if strip:\n        pattern = pattern.strip()\n    return re.compile(pattern)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def get_pattern(pattern, strip=True):\n    if not isinstance(pattern, str):\n        raise TypeError(\"pattern must be a string\")\n\n    if strip:\n        pattern = pattern.strip()\n\n    pattern = re.compile(pattern)\n\n    return pattern\n", "is_pass": true, "return_code": 0}, {"generate_code": "def get_pattern(pattern, strip=True):\n    if type(pattern) is str:\n        pattern = pattern.strip()\n        pattern = re.compile(pattern)\n    elif type(pattern) is list:\n        pattern = pattern[0].strip()\n        pattern = re.compile(pattern)\n    elif type(pattern) is dict:\n        pattern = pattern['pattern'].strip()\n        pattern = re.compile(pattern)\n    elif type(pattern) is tuple:\n        pattern = pattern[0].strip()\n        pattern = re.compile(pattern[0])\n    elif type(pattern) is set:\n        pattern = pattern[0].strip()\n        pattern = re.compile(pattern[0])\n    elif type(pattern) is dict_keys:\n        pattern = pattern[1].strip()\n        pattern = re.compile(pattern[1])\n    elif type(pattern) is list_keys:\n        pattern = pattern[0].strip()\n        pattern = re.compile(pattern[0])\n    elif type(pattern) is str:\n        pattern = pattern[0].stri", "is_pass": false, "return_code": 1}, {"generate_code": "def get_pattern(pattern, strip=True):\n\n    if strip:\n        pattern = re.sub(r'\\s+', '\\\\s+', pattern)\n    pattern = re.sub(r'\\W', '\\\\W', pattern)\n    pattern = re.sub(r'\\d+', '\\\\d+', pattern)\n    pattern = re.sub(r'\\[(.+?)\\]', r'\\1', pattern)\n    pattern = re.sub(r'\\[(.+?)\\]', r'\\1', pattern)\n    pattern = re.sub(r'\\((.+?)\\)', r'\\1', pattern)\n    pattern = re.sub(r'\\s+', '\\\\s+', pattern)\n\n    return pattern\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_pattern(pattern, strip=True):\n    if strip:\n        pattern = re.compile(pattern.strip())\n    else:\n        pattern = re.compile(pattern)\n    return pattern\n", "is_pass": true, "return_code": 0}, {"generate_code": "def get_pattern(pattern, strip=True):\n    return re.compile(\"^\" + pattern.replace(\"*\", \"\\\\*\") + \"$\", re.UNICODE | re.MULTILINE | re.DOTALL) if strip else re.compile(pattern.replace(\"*\", \"\\\\*\") + \"$\", re.UNICODE | re.MULTILINE | re.DOTALL)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_pattern(pattern, strip=True):\n    return re.compile(pattern, re.UNICODE | re.VERBOSE) if strip else re.compile(pattern)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_pattern(pattern, strip=True):\n    return re.compile(pattern.replace('\\n', '\\\\n')) if strip else re.compile(pattern)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "slib_runnable/test_7.py", "name": "run_command", "docstring": "Call the given command(s).", "ques_id": "62ece4992e6aefcf4aabbd83", "code": ["def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n"], "level": "slib_runnable", "generate_results": [{"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def run_command(commands, args, cwd=None, verbose=False, hide_stderr=False, env=None):\n    assert isinstance(commands, list)\n    p = None\n    for c in commands:\n        try:\n            dispcmd = str([c] + args)\n            # remember shell=False, so use git.cmd on windows, not just git\n            p = subprocess.Popen([c] + args, cwd=cwd, env=env,\n                                 stdout=subprocess.PIPE,\n                                 stderr=(subprocess.PIPE if hide_stderr\n                                         else None))\n            break\n        except EnvironmentError:\n            e = sys.exc_info()[1]\n            if e.errno == errno.ENOENT:\n                continue\n            if verbose:\n                print(\"unable to run %s\" % dispcmd)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "plib_runnable/test_4.py", "name": "is_ipv4", "docstring": "Test if IPv4 address or not\n    ", "ques_id": "62ece4992e6aefcf4aabbd84", "code": ["def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def is_ipv4(target):\n    try:\n        socket.inet_aton(target)\n    except socket.error:\n        return False\n    return True\n", "is_pass": false, "return_code": 1}]}
{"file_path": "plib_runnable/test_11.py", "name": "find_roots", "docstring": "Find the roots in some sort of transitive hierarchy.\n\nfind_roots(graph, rdflib.RDFS.subClassOf)\nwill return a set of all roots of the sub-class hierarchy\n\nAssumes triple of the form (child, prop, parent), i.e. the direction of\nRDFS.subClassOf or SKOS.broader", "ques_id": "62ece4992e6aefcf4aabbd85", "code": ["def find_roots(\n    graph: Graph,\n    rdflib_sub_class: str,\n    rdflib_sub_class_property: str\n) -> Set[str]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of\n    the sub-class hierarchy\n\n    Assumes triple of the form\n\n    (child, prop, parent), i.e. the direction of RDFS.subClassOf or SKOS.broader\n    \"\"\"\n    triple_tree = nx.node_link_graph(graph)\n\n    for (child, prop, parent) in triple_tree.nodes(data=True):\n        # skip the root of the triple hierarchy\n        if prop == rdflib_sub_class_property:\n            continue\n\n        if prop == SKOS.broader:\n            if parent in triple_tree[child]:\n                yield child\n        elif prop == rdflib_sub_class:\n            if parent in triple_tree[child]:\n                yield child,", "def find_roots(\n    graph: Graph,\n    subclass: Union[\n        Class, type, Tuple[Union[Class, type], Union[Class, type]]\n    ],\n) -> Set[BaseEntity]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction\n    of RDFS.subClassOf or SKOS.broader\n    \"\"\"\n    # TODO: make this more robust in the future\n    for triple in graph.triples((subclass, None, None)):\n        if triple[0] is None:\n            continue\n        if isinstance(triple[0], Class):\n            continue\n        yield triple[0]\n", "def find_roots(\n    graph: Graph,\n    rdflib_sub_class: str,\n    rdflib_sub_prop: str,\n    triple: Tuple[Tuple[str, str, str], Tuple[str, str, str], Tuple[str, str]],\n) -> Set[str]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form\n\n    (child, prop, parent), i.e. the direction of RDFS.subClassOf or\n    SKOS.broader\n    \"\"\"\n    nodes = triple[0]\n    props = triple[1]\n    parents = triple[2]\n    for prop in graph.subjects(rdflib_sub_prop, nodes):\n        if prop in graph:\n            for parent in graph[prop]:\n                if parent in graph:\n                    yield nodes[0]\n                    yield nodes[1]\n                    yield nodes", "def find_roots(\n    graph: Graph,\n    rdflib_subclass: Union[str, URIRef]\n) -> Set[URIRef]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of\n    the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of\n    RDFS.subClassOf or SKOS.broader\n    \"\"\"\n    # build a list of all the roots of the subclass hierarchy\n    roots = set()\n    for triple in graph.triples((rdflib_subclass, None, None)):\n        roots.add(triple[2])\n    return roots\n", "def find_roots(\n    graph: Graph, subclass_of: Set[Tuple[str, str, str]]\n) -> Set[Tuple[str, str, str]]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of\n    the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of\n    RDFS.subClassOf or SKOS.broader\n    \"\"\"\n    roots = set()\n    for p, o, c in graph.triples((None, DCTERMS.subClassOf, None)):\n        if c not in subclass_of and c not in roots:\n            roots.add(c)\n            roots.add(o)\n    return roots\n", "def find_roots(\n    graph: Graph,\n    subclasses: Tuple[Tuple[str, str, str],...],\n    rdflib_subclasses: Tuple[Tuple[str, str, str],...],\n) -> Set[str]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy. find_roots(graph, rdflib.RDFS.subClassOf) will return a set of\n    all roots of the sub-class hierarchy\n\n    Assumes triple of the form\n\n    (child, prop, parent), i.e. the direction of RDFS.subClassOf or SKOS.broader\n    \"\"\"\n\n    roots = set()\n\n    for (child, prop, parent) in subclasses:\n        if graph.has_node((child, prop, parent)):\n            if graph.has_edge((child, prop, parent), (parent, prop, child)):\n                roots.add((child, prop, parent))\n\n    for (prop, parent) in rdflib_subclasses:\n        if graph.has_node((prop, parent)):\n            if graph.has_edge((prop, parent, parent), (parent, prop, prop)):\n                roots.add((prop", "def find_roots(\n    graph: Graph,\n    triple: Tuple[\n        (URIRef, RDFlib.RDF.type, URIRef),\n        (URIRef, SKOS.broader),\n        (URIRef, SKOS.notation),\n        (URIRef, SKOS.dc, SKOS.dc),\n    ],\n    prop: LiteralProperty,\n    parent: URIRef,\n) -> Set[URIRef]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form\n\n    (child, prop, parent), i.e. the direction of RDFS.subClassOf\n    or SKOS.broader\n\n    \"\"\"\n    roots = set()\n    for triple_el in triple:\n        for triple_sub in graph.objects(triple_el[0], prop):\n            for triple_sub_prop in graph.objects(triple_sub, prop):\n                roots.add(triple_el[1] + '.' + triple_sub_prop[1])\n    return roots\n", "def find_roots(\n    graph: Graph,\n    rdflib_subclass: Union[\n        Literal, URIRef, Comment, URIRef, URIRef, URIRef, URIRef, URIRef\n    ],\n) -> Set[URIRef]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of\n    the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of\n    RDFS.subClassOf or SKOS.broader\n    \"\"\"\n    if isinstance(graph, Graph):\n        graph = graph.graph\n\n    for triple in graph.triples((graph.skos(), RDF.type, SKOS.Class)):\n        if triple[0] == rdflib_subclass or triple[1] == rdflib_subclass:\n            yield triple[2]\n", "def find_roots(\n    graph: Graph,\n    rdflib_subclass: RDFClass,\n    rdflib_property: RDFProperty,\n    triple: Tuple[(URIRef, RDFClass, URIRef),...],\n    *,\n    max_depth: Optional[int] = None,\n    max_instances: Optional[int] = None,\n) -> Set[URIRef]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form\n    (child, prop, parent), i.e. the direction of RDFS.subClassOf or\n    SKOS.broader\n\n    \"\"\"\n    if max_depth is None:\n        max_depth = max(1, len(triple))\n    if max_instances is None:\n        max_instances = max(1, len(triple) * 2)\n    roots = set()\n\n    for triple in triple:\n        roots.update(\n            graph.triple_to_root(triple, max_depth=max_depth, max_instances=max_instances)\n        ", "def find_roots(\n    graph: Graph,\n    rdflib_subclass: Literal,\n    rdflib_subclass_prop: Literal,\n    rdflib_subclass_is_super_of: bool = False,\n    ) -> Set[Tuple[Literal, str, str]]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of the\n    sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of RDFS.subClassOf\n    or SKOS.broader\n\n    \"\"\"\n    roots = set()\n    for subclass in graph.subjects(rdflib_subclass, rdflib_subclass_prop):\n        for prop in graph.predicate_objects(subclass, RDFS.subClassOf):\n            if rdflib_subclass_is_super_of and \\\n                    prop == rdflib_subclass:\n                continue\n            if prop == rdflib_subclass_prop:\n                continue\n            if graph.predicat"], "level": "plib_runnable", "generate_results": [{"generate_code": "def find_roots(\n    graph: Graph,\n    rdflib_sub_class: str,\n    rdflib_sub_class_property: str\n) -> Set[str]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of\n    the sub-class hierarchy\n\n    Assumes triple of the form\n\n    (child, prop, parent), i.e. the direction of RDFS.subClassOf or SKOS.broader\n    \"\"\"\n    triple_tree = nx.node_link_graph(graph)\n\n    for (child, prop, parent) in triple_tree.nodes(data=True):\n        # skip the root of the triple hierarchy\n        if prop == rdflib_sub_class_property:\n            continue\n\n        if prop == SKOS.broader:\n            if parent in triple_tree[child]:\n                yield child\n        elif prop == rdflib_sub_class:\n            if parent in triple_tree[child]:\n                yield child,", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: Graph,\n    subclass: Union[\n        Class, type, Tuple[Union[Class, type], Union[Class, type]]\n    ],\n) -> Set[BaseEntity]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction\n    of RDFS.subClassOf or SKOS.broader\n    \"\"\"\n    # TODO: make this more robust in the future\n    for triple in graph.triples((subclass, None, None)):\n        if triple[0] is None:\n            continue\n        if isinstance(triple[0], Class):\n            continue\n        yield triple[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: Graph,\n    rdflib_sub_class: str,\n    rdflib_sub_prop: str,\n    triple: Tuple[Tuple[str, str, str], Tuple[str, str, str], Tuple[str, str]],\n) -> Set[str]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form\n\n    (child, prop, parent), i.e. the direction of RDFS.subClassOf or\n    SKOS.broader\n    \"\"\"\n    nodes = triple[0]\n    props = triple[1]\n    parents = triple[2]\n    for prop in graph.subjects(rdflib_sub_prop, nodes):\n        if prop in graph:\n            for parent in graph[prop]:\n                if parent in graph:\n                    yield nodes[0]\n                    yield nodes[1]\n                    yield nodes", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: Graph,\n    rdflib_subclass: Union[str, URIRef]\n) -> Set[URIRef]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of\n    the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of\n    RDFS.subClassOf or SKOS.broader\n    \"\"\"\n    # build a list of all the roots of the subclass hierarchy\n    roots = set()\n    for triple in graph.triples((rdflib_subclass, None, None)):\n        roots.add(triple[2])\n    return roots\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: Graph, subclass_of: Set[Tuple[str, str, str]]\n) -> Set[Tuple[str, str, str]]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of\n    the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of\n    RDFS.subClassOf or SKOS.broader\n    \"\"\"\n    roots = set()\n    for p, o, c in graph.triples((None, DCTERMS.subClassOf, None)):\n        if c not in subclass_of and c not in roots:\n            roots.add(c)\n            roots.add(o)\n    return roots\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: Graph,\n    subclasses: Tuple[Tuple[str, str, str],...],\n    rdflib_subclasses: Tuple[Tuple[str, str, str],...],\n) -> Set[str]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy. find_roots(graph, rdflib.RDFS.subClassOf) will return a set of\n    all roots of the sub-class hierarchy\n\n    Assumes triple of the form\n\n    (child, prop, parent), i.e. the direction of RDFS.subClassOf or SKOS.broader\n    \"\"\"\n\n    roots = set()\n\n    for (child, prop, parent) in subclasses:\n        if graph.has_node((child, prop, parent)):\n            if graph.has_edge((child, prop, parent), (parent, prop, child)):\n                roots.add((child, prop, parent))\n\n    for (prop, parent) in rdflib_subclasses:\n        if graph.has_node((prop, parent)):\n            if graph.has_edge((prop, parent, parent), (parent, prop, prop)):\n                roots.add((prop", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: Graph,\n    triple: Tuple[\n        (URIRef, RDFlib.RDF.type, URIRef),\n        (URIRef, SKOS.broader),\n        (URIRef, SKOS.notation),\n        (URIRef, SKOS.dc, SKOS.dc),\n    ],\n    prop: LiteralProperty,\n    parent: URIRef,\n) -> Set[URIRef]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form\n\n    (child, prop, parent), i.e. the direction of RDFS.subClassOf\n    or SKOS.broader\n\n    \"\"\"\n    roots = set()\n    for triple_el in triple:\n        for triple_sub in graph.objects(triple_el[0], prop):\n            for triple_sub_prop in graph.objects(triple_sub, prop):\n                roots.add(triple_el[1] + '.' + triple_sub_prop[1])\n    return roots\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: Graph,\n    rdflib_subclass: Union[\n        Literal, URIRef, Comment, URIRef, URIRef, URIRef, URIRef, URIRef\n    ],\n) -> Set[URIRef]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of\n    the sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of\n    RDFS.subClassOf or SKOS.broader\n    \"\"\"\n    if isinstance(graph, Graph):\n        graph = graph.graph\n\n    for triple in graph.triples((graph.skos(), RDF.type, SKOS.Class)):\n        if triple[0] == rdflib_subclass or triple[1] == rdflib_subclass:\n            yield triple[2]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: Graph,\n    rdflib_subclass: RDFClass,\n    rdflib_property: RDFProperty,\n    triple: Tuple[(URIRef, RDFClass, URIRef),...],\n    *,\n    max_depth: Optional[int] = None,\n    max_instances: Optional[int] = None,\n) -> Set[URIRef]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots\n    of the sub-class hierarchy\n\n    Assumes triple of the form\n    (child, prop, parent), i.e. the direction of RDFS.subClassOf or\n    SKOS.broader\n\n    \"\"\"\n    if max_depth is None:\n        max_depth = max(1, len(triple))\n    if max_instances is None:\n        max_instances = max(1, len(triple) * 2)\n    roots = set()\n\n    for triple in triple:\n        roots.update(\n            graph.triple_to_root(triple, max_depth=max_depth, max_instances=max_instances)\n        ", "is_pass": false, "return_code": 1}, {"generate_code": "def find_roots(\n    graph: Graph,\n    rdflib_subclass: Literal,\n    rdflib_subclass_prop: Literal,\n    rdflib_subclass_is_super_of: bool = False,\n    ) -> Set[Tuple[Literal, str, str]]:\n    \"\"\"\n    Find the roots in some sort of transitive hierarchy.\n    find_roots(graph, rdflib.RDFS.subClassOf) will return a set of all roots of the\n    sub-class hierarchy\n\n    Assumes triple of the form (child, prop, parent), i.e. the direction of RDFS.subClassOf\n    or SKOS.broader\n\n    \"\"\"\n    roots = set()\n    for subclass in graph.subjects(rdflib_subclass, rdflib_subclass_prop):\n        for prop in graph.predicate_objects(subclass, RDFS.subClassOf):\n            if rdflib_subclass_is_super_of and \\\n                    prop == rdflib_subclass:\n                continue\n            if prop == rdflib_subclass_prop:\n                continue\n            if graph.predicat", "is_pass": false, "return_code": 1}]}
{"file_path": "plib_runnable/test_1.py", "name": "_dump_string", "docstring": "Dump to a py2-unicode or py3-string", "ques_id": "62ece4992e6aefcf4aabbd86", "code": ["def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = Dumper\n\n    if isinstance(obj, string_types):\n        return dumper.represent_scalar(u'!str', obj)\n    elif isinstance(obj, bytes):\n        return dumper.represent_str(obj)\n    else:\n        raise TypeError(\"Type %r not serializable\" % type(obj))\n", "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = yaml.SafeDumper\n    if isinstance(obj, str):\n        return dumper.represent_scalar(u'tag:yaml.org,2002:str', obj,\n                                      flow_style=False)\n    elif isinstance(obj, bytes):\n        return dumper.represent_scalar(u'tag:yaml.org,2002:bytes', obj,\n                                      flow_style=False)\n    else:\n        raise TypeError('Object of type %s is not serializable' % type(obj))\n", "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = Dumper()\n\n    if isinstance(obj, bytes):\n        return dumper.represent_bytes(obj)\n    elif isinstance(obj, unicode):\n        return dumper.represent_unicode(obj)\n    else:\n        raise TypeError(\"Unsupported type %r\" % type(obj))\n", "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = Dumper()\n    return dumper.represent_scalar(u'tag:yaml.org,2002:str', obj)\n", "def _dump_string(obj, dumper=None):\n    if not isinstance(obj, six.binary_type):\n        obj = obj.encode('utf-8')\n    if dumper is None:\n        return obj\n    return dumper.represent_scalar(u'tag:yaml.org,2002:str', obj)\n", "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = yaml.SafeDumper\n    if isinstance(obj, yaml.SafeData):\n        return dumper.represent_scalar(u'tag:yaml.org,2002:str', obj)\n    elif isinstance(obj, bytes):\n        return dumper.represent_scalar(u'tag:python.org,2002:str', obj)\n    else:\n        return dumper.represent_scalar(u'tag:python.org,2002:str', unicode(obj))\n", "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = Dumper()\n\n    if isinstance(obj, unicode):\n        return dumper.represent_unicode(obj)\n    elif isinstance(obj, str):\n        return dumper.represent_str(obj)\n    elif isinstance(obj, bytes):\n        return dumper.represent_bytes(obj)\n    else:\n        raise TypeError(\"Cannot represent object of type %s\" % type(obj))\n", "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = yaml.SafeDumper\n    if isinstance(obj, bytes):\n        dumper = dumpers.BytesDumper\n    return dumper.dump(obj, default_flow_style=False)\n", "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = Dumper\n    return dumper.dump(obj)\n", "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = Dumper\n\n    if isinstance(obj, bytes):\n        return dumper.dump(obj)\n    elif isinstance(obj, unicode):\n        return dumper.represent_unicode(obj)\n    else:\n        raise TypeError(\"Object %r is not a unicode or bytes instance\" % obj)\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = Dumper\n\n    if isinstance(obj, string_types):\n        return dumper.represent_scalar(u'!str', obj)\n    elif isinstance(obj, bytes):\n        return dumper.represent_str(obj)\n    else:\n        raise TypeError(\"Type %r not serializable\" % type(obj))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = yaml.SafeDumper\n    if isinstance(obj, str):\n        return dumper.represent_scalar(u'tag:yaml.org,2002:str', obj,\n                                      flow_style=False)\n    elif isinstance(obj, bytes):\n        return dumper.represent_scalar(u'tag:yaml.org,2002:bytes', obj,\n                                      flow_style=False)\n    else:\n        raise TypeError('Object of type %s is not serializable' % type(obj))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = Dumper()\n\n    if isinstance(obj, bytes):\n        return dumper.represent_bytes(obj)\n    elif isinstance(obj, unicode):\n        return dumper.represent_unicode(obj)\n    else:\n        raise TypeError(\"Unsupported type %r\" % type(obj))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = Dumper()\n    return dumper.represent_scalar(u'tag:yaml.org,2002:str', obj)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dump_string(obj, dumper=None):\n    if not isinstance(obj, six.binary_type):\n        obj = obj.encode('utf-8')\n    if dumper is None:\n        return obj\n    return dumper.represent_scalar(u'tag:yaml.org,2002:str', obj)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = yaml.SafeDumper\n    if isinstance(obj, yaml.SafeData):\n        return dumper.represent_scalar(u'tag:yaml.org,2002:str', obj)\n    elif isinstance(obj, bytes):\n        return dumper.represent_scalar(u'tag:python.org,2002:str', obj)\n    else:\n        return dumper.represent_scalar(u'tag:python.org,2002:str', unicode(obj))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = Dumper()\n\n    if isinstance(obj, unicode):\n        return dumper.represent_unicode(obj)\n    elif isinstance(obj, str):\n        return dumper.represent_str(obj)\n    elif isinstance(obj, bytes):\n        return dumper.represent_bytes(obj)\n    else:\n        raise TypeError(\"Cannot represent object of type %s\" % type(obj))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = yaml.SafeDumper\n    if isinstance(obj, bytes):\n        dumper = dumpers.BytesDumper\n    return dumper.dump(obj, default_flow_style=False)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = Dumper\n    return dumper.dump(obj)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _dump_string(obj, dumper=None):\n    if dumper is None:\n        dumper = Dumper\n\n    if isinstance(obj, bytes):\n        return dumper.dump(obj)\n    elif isinstance(obj, unicode):\n        return dumper.represent_unicode(obj)\n    else:\n        raise TypeError(\"Object %r is not a unicode or bytes instance\" % obj)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "plib_runnable/test_8.py", "name": "build_app_logger", "docstring": "General purpose application logger. Useful mainly for debugging", "ques_id": "62ece4992e6aefcf4aabbd87", "code": ["def build_app_logger(name='app', logfile='app.log', debug=True):\n    log_formatter = logging.Formatter(\n        '[%(levelname)s] %(asctime)s %(name)s: %(message)s')\n    app_logger = logging.getLogger(name)\n    app_logger.setLevel(logging.INFO)\n\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.INFO)\n\n    formatter = logging.Formatter(\n        '%(asctime)s %(name)s: %(levelname)s: %(message)s')\n    handler.setFormatter(formatter)\n\n    app_logger.addHandler(handler)\n    if debug:\n        app_logger.setLevel(logging.DEBUG)\n\n    return app_logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    app_logger = logging.getLogger(name)\n    app_logger.setLevel(logging.INFO)\n\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.INFO)\n\n    formatter = logging.Formatter(\n        '%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n        '%Y-%m-%d %H:%M:%S')\n\n    handler.setFormatter(formatter)\n\n    app_logger.addHandler(handler)\n    if debug:\n        app_logger.debug('Debug mode enabled')\n    else:\n        app_logger.info('Debug mode enabled')\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.DEBUG)\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.DEBUG)\n\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    handler.setFormatter(formatter)\n\n    if debug:\n        logger.addHandler(handler)\n    else:\n        logger.addHandler(None)\n\n    return logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.DEBUG)\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n    if debug:\n        logger.setLevel(logging.DEBUG)\n    return logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    handler = logging.StreamHandler()\n    handler.setFormatter(logging.Formatter('%(levelname)s - %(message)s'))\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n    logger.addHandler(handler)\n    if debug:\n        logger.addHandler(logging.StreamHandler())\n        logger.setLevel(logging.DEBUG)\n        logger.debug('Adding debug handler to logger: %s', name)\n    return logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    # Create logger\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n\n    # Configure file handler\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.INFO)\n\n    # Configure formatter\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n    # Add formatter to handler\n    handler.setFormatter(formatter)\n\n    # Add handler to logger\n    logger.addHandler(handler)\n\n    if debug:\n        logger.debug('Debug mode enabled')\n    else:\n        logger.info('Debug mode disabled')\n\n    return logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    log = logging.getLogger(name)\n    log.setLevel(logging.DEBUG if debug else logging.INFO)\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.DEBUG if debug else logging.INFO)\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    handler.setFormatter(formatter)\n    log.addHandler(handler)\n    return log\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    if debug:\n        handler = logging.StreamHandler()\n        formatter = logging.Formatter(\n            '%(asctime)s %(levelname)s %(name)s %(message)s')\n        handler.setFormatter(formatter)\n        logger.addHandler(handler)\n        logger.setLevel(logging.DEBUG)\n    else:\n        handler = logging.StreamHandler()\n        formatter = logging.Formatter(\n            '%(asctime)s %(levelname)s %(name)s %(message)s')\n        handler.setFormatter(formatter)\n        logger.addHandler(handler)\n        logger.setLevel(logging.INFO)\n    logger.propagate = False\n    return logger\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    log = logging.getLogger(name)\n    log.setLevel(logging.INFO)\n\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.INFO)\n\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n    handler.setFormatter(formatter)\n\n    log.addHandler(handler)\n\n    if debug:\n        log.setLevel(logging.DEBUG)\n\n    return log\n", "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.INFO)\n\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    )\n    handler.setFormatter(formatter)\n\n    logger.addHandler(handler)\n\n    if debug:\n        logger.setLevel(logging.DEBUG)\n        logger.debug('Debug mode enabled')\n\n    return logger\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    log_formatter = logging.Formatter(\n        '[%(levelname)s] %(asctime)s %(name)s: %(message)s')\n    app_logger = logging.getLogger(name)\n    app_logger.setLevel(logging.INFO)\n\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.INFO)\n\n    formatter = logging.Formatter(\n        '%(asctime)s %(name)s: %(levelname)s: %(message)s')\n    handler.setFormatter(formatter)\n\n    app_logger.addHandler(handler)\n    if debug:\n        app_logger.setLevel(logging.DEBUG)\n\n    return app_logger\n", "is_pass": false, "return_code": 1}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    app_logger = logging.getLogger(name)\n    app_logger.setLevel(logging.INFO)\n\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.INFO)\n\n    formatter = logging.Formatter(\n        '%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n        '%Y-%m-%d %H:%M:%S')\n\n    handler.setFormatter(formatter)\n\n    app_logger.addHandler(handler)\n    if debug:\n        app_logger.debug('Debug mode enabled')\n    else:\n        app_logger.info('Debug mode enabled')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.DEBUG)\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.DEBUG)\n\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    handler.setFormatter(formatter)\n\n    if debug:\n        logger.addHandler(handler)\n    else:\n        logger.addHandler(None)\n\n    return logger\n", "is_pass": false, "return_code": 1}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.DEBUG)\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n    if debug:\n        logger.setLevel(logging.DEBUG)\n    return logger\n", "is_pass": false, "return_code": 1}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    handler = logging.StreamHandler()\n    handler.setFormatter(logging.Formatter('%(levelname)s - %(message)s'))\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n    logger.addHandler(handler)\n    if debug:\n        logger.addHandler(logging.StreamHandler())\n        logger.setLevel(logging.DEBUG)\n        logger.debug('Adding debug handler to logger: %s', name)\n    return logger\n", "is_pass": false, "return_code": 1}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    # Create logger\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n\n    # Configure file handler\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.INFO)\n\n    # Configure formatter\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n    # Add formatter to handler\n    handler.setFormatter(formatter)\n\n    # Add handler to logger\n    logger.addHandler(handler)\n\n    if debug:\n        logger.debug('Debug mode enabled')\n    else:\n        logger.info('Debug mode disabled')\n\n    return logger\n", "is_pass": true, "return_code": 0}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    log = logging.getLogger(name)\n    log.setLevel(logging.DEBUG if debug else logging.INFO)\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.DEBUG if debug else logging.INFO)\n    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n    handler.setFormatter(formatter)\n    log.addHandler(handler)\n    return log\n", "is_pass": false, "return_code": 1}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    if debug:\n        handler = logging.StreamHandler()\n        formatter = logging.Formatter(\n            '%(asctime)s %(levelname)s %(name)s %(message)s')\n        handler.setFormatter(formatter)\n        logger.addHandler(handler)\n        logger.setLevel(logging.DEBUG)\n    else:\n        handler = logging.StreamHandler()\n        formatter = logging.Formatter(\n            '%(asctime)s %(levelname)s %(name)s %(message)s')\n        handler.setFormatter(formatter)\n        logger.addHandler(handler)\n        logger.setLevel(logging.INFO)\n    logger.propagate = False\n    return logger\n", "is_pass": false, "return_code": 1}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    log = logging.getLogger(name)\n    log.setLevel(logging.INFO)\n\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.INFO)\n\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n\n    handler.setFormatter(formatter)\n\n    log.addHandler(handler)\n\n    if debug:\n        log.setLevel(logging.DEBUG)\n\n    return log\n", "is_pass": false, "return_code": 1}, {"generate_code": "def build_app_logger(name='app', logfile='app.log', debug=True):\n    logger = logging.getLogger(name)\n    logger.setLevel(logging.INFO)\n\n    handler = logging.FileHandler(logfile)\n    handler.setLevel(logging.INFO)\n\n    formatter = logging.Formatter(\n        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n    )\n    handler.setFormatter(formatter)\n\n    logger.addHandler(handler)\n\n    if debug:\n        logger.setLevel(logging.DEBUG)\n        logger.debug('Debug mode enabled')\n\n    return logger\n", "is_pass": false, "return_code": 1}]}
{"file_path": "plib_runnable/test_6.py", "name": "make_array", "docstring": "Function to create an array with shape and dtype.\n\nParameters\n----------\nshape : tuple\n    shape of the array to create\ndtype : `numpy.dtype`\n    data-type of the array to create", "ques_id": "62ece4992e6aefcf4aabbd88", "code": ["def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.ones(shape, dtype) * np.nan\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype=dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype)\n", "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype=dtype)\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.ones(shape, dtype) * np.nan\n", "is_pass": false, "return_code": 1}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype=dtype)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def make_array(shape, dtype=np.dtype(\"float32\")):\n    return np.zeros(shape, dtype=dtype)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "plib_runnable/test_2.py", "name": "gaussian", "docstring": "Gaussian centered around 0.2 with a sigma of 0.1.", "ques_id": "62ece4992e6aefcf4aabbd89", "code": ["def gaussian(x):\n    return np.exp(-(x - 0.2)**2/(2*0.1**2))\n", "def gaussian(x):\n    return 0.2*np.exp(-(x-0.2)**2/(2*0.1**2))\n", "def gaussian(x):\n    return 0.2 * np.exp(-(x - 0.2)**2/(2*0.1**2))\n", "def gaussian(x):\n    return np.exp(-(x - 0.2)**2/(2*0.1**2))\n", "def gaussian(x):\n    return np.exp(-(x - 0.2)**2/(2*0.1**2))\n", "def gaussian(x):\n    return np.exp(-(x-0.2)**2/(2*0.1**2))\n", "def gaussian(x):\n    return np.exp(-(x**2) / (2*0.1**2))\n", "def gaussian(x):\n    return np.exp(-(x - 0.2)**2 / (2*0.1**2))\n", "def gaussian(x):\n    return np.exp(-(x-0.2)**2/(2*0.1**2))\n", "def gaussian(x):\n    return 0.2 * np.exp(-(x-0.2)**2/(2*0.1**2))\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def gaussian(x):\n    return np.exp(-(x - 0.2)**2/(2*0.1**2))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def gaussian(x):\n    return 0.2*np.exp(-(x-0.2)**2/(2*0.1**2))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def gaussian(x):\n    return 0.2 * np.exp(-(x - 0.2)**2/(2*0.1**2))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def gaussian(x):\n    return np.exp(-(x - 0.2)**2/(2*0.1**2))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def gaussian(x):\n    return np.exp(-(x - 0.2)**2/(2*0.1**2))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def gaussian(x):\n    return np.exp(-(x-0.2)**2/(2*0.1**2))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def gaussian(x):\n    return np.exp(-(x**2) / (2*0.1**2))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def gaussian(x):\n    return np.exp(-(x - 0.2)**2 / (2*0.1**2))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def gaussian(x):\n    return np.exp(-(x-0.2)**2/(2*0.1**2))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def gaussian(x):\n    return 0.2 * np.exp(-(x-0.2)**2/(2*0.1**2))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "plib_runnable/test_13.py", "name": "load_configurations", "docstring": "Given a sequence of configuration filenames, load and validate each configuration file. Return\nthe results as a tuple of: dict of configuration filename to corresponding parsed configuration,\nand sequence of logging.LogRecord instances containing any parse errors.", "ques_id": "62ece4992e6aefcf4aabbd8a", "code": ["def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = {}\n    errors = []\n\n    for config_filename in config_filenames:\n        try:\n            parser = config.get_parser(config_filename)\n            configs[config_filename] = parser.parse_known_args()\n        except Exception as e:\n            errors.append(e)\n            continue\n\n        if overrides:\n            configs.update(overrides)\n\n    if errors:\n        raise ConfigurationError(\n            '\\n'.join(str(e) for e in errors)\n        )\n\n    return configs, errors\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = {}\n    errors = []\n    for filename in config_filenames:\n        try:\n            with open(filename, \"rt\") as config_file:\n                configs[filename] = load_configuration(\n                    config_file, overrides, resolve_env=resolve_env\n                )\n        except IOError as e:\n            errors.append(e)\n            continue\n        except Exception as e:\n            errors.append(e)\n            continue\n        else:\n            break\n    else:\n        # No errors were found. Consider ignoring the file and returning the\n        # whole configuration sequence without errors.\n        return configs, []\n\n    return configs, errors\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = {}\n    errors = []\n    for filename in config_filenames:\n        try:\n            config = load_configuration(filename, overrides, resolve_env)\n        except ConfigurationError as error:\n            errors.append(error)\n            configs[filename] = Configuration(filename)\n        else:\n            if config is not None:\n                if not isinstance(config, Configuration):\n                    raise ConfigurationError(\"Configuration for {!r} not a \"\n                                             \"Configuration instance\".format(filename))\n                configs[filename] = config\n            else:\n                if overrides and filename in overrides:\n                    configs[filename] = overrides[filename]\n                else:\n                    configs[filename] = Co", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = {}\n    errors = []\n\n    for filename in config_filenames:\n        try:\n            config = load_configuration(filename, resolve_env=resolve_env)\n        except IOError as e:\n            errors.append(e)\n            continue\n        except Exception as e:\n            e.filename = filename\n            errors.append(e)\n            continue\n        configs[filename] = config\n\n    if overrides:\n        configs.update(overrides)\n\n    # We want to log all the parsing errors and return the sequence of errors\n    # which should be raised as a tuple of (parse_error, logging.LogRecord).\n    # We can also return the errors which could be raised by logging.StreamHandler.error().\n    return configs, errors\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    return [\n        load_config(fn, overrides, resolve_env)\n        for fn in config_filenames\n    ]\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    config_filenames = [\n        os.path.expanduser(f) for f in config_filenames\n    ]\n    configs = {}\n    errors = []\n    for config_filename in config_filenames:\n        try:\n            with open(config_filename) as f:\n                configs[config_filename] = yaml.safe_load(f)\n        except IOError:\n            errors.append(\n                'Unable to load configuration file {0}. Please make sure '\n                'the configuration file is a valid YAML file.'.format(\n                    config_filename))\n            continue\n        except yaml.YAMLError as e:\n            e.filename = config_filename\n            errors.append(str(e))\n        else:\n            if not overrides:\n                pass\n            elif overrides == {}:\n             ", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = {}\n    errors = []\n\n    for config_filename in config_filenames:\n        try:\n            parsed_config = _load_config_from_file(config_filename,\n                                                 overrides=overrides,\n                                                 resolve_env=resolve_env)\n        except ConfigFileParseException as e:\n            errors.append(e)\n            configs[config_filename] = ConfigSequence()\n            continue\n\n        configs[config_filename] = parsed_config\n\n    if errors:\n        raise ConfigFileParseException(errors)\n\n    return (configs, errors)\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = {}\n    errors = []\n    for config_filename in config_filenames:\n        try:\n            configs[config_filename] = load_config(\n                config_filename, overrides=overrides,\n                resolve_env=resolve_env)\n        except ConfigError as e:\n            errors.append(e)\n            continue\n        except Exception as e:\n            errors.append(e)\n            continue\n\n        if not configs[config_filename].validate():\n            errors.append(configs[config_filename].error())\n            continue\n\n        return configs[config_filename], configs[config_filename].sequence, errors\n\n    raise ConfigError('\\n'.join(errors))\n", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    # type: (Sequence[Text], Optional[Mapping[Text, Text]], bool) -> Tuple[Mapping[Text, Configuration], Sequence[logging.LogRecord]]\n    \"\"\"\n    Given a sequence of configuration filenames, load and validate each configuration file.\n\n    Return the results as a tuple of:\n    dict of configuration filename to corresponding parsed configuration, and sequence of logging.LogRecord\n    instances containing any parse errors.\n    \"\"\"\n    # The values that are missing from the file, will be set to the empty sequence if there are no\n    # files in the sequence.\n    missing_configs = set(config_filenames) - set(_load_config_files(config_filenames, resolve_env=resolve_env))\n    missing_filenames = [fname for fname in missing_configs if not os.path.exists(fname)]\n\n    if missing_filenames:\n        raise MissingConfigError(missing_filenames)\n\n    configs = {}\n    logging.getLogger(\"requests\").setLevel(logging.WARNING)\n    for fname in config_filenames:\n        parsed_confi", "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    validator = Validator(config_filenames, overrides, resolve_env)\n    return validator.validate()\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = {}\n    errors = []\n\n    for config_filename in config_filenames:\n        try:\n            parser = config.get_parser(config_filename)\n            configs[config_filename] = parser.parse_known_args()\n        except Exception as e:\n            errors.append(e)\n            continue\n\n        if overrides:\n            configs.update(overrides)\n\n    if errors:\n        raise ConfigurationError(\n            '\\n'.join(str(e) for e in errors)\n        )\n\n    return configs, errors\n", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = {}\n    errors = []\n    for filename in config_filenames:\n        try:\n            with open(filename, \"rt\") as config_file:\n                configs[filename] = load_configuration(\n                    config_file, overrides, resolve_env=resolve_env\n                )\n        except IOError as e:\n            errors.append(e)\n            continue\n        except Exception as e:\n            errors.append(e)\n            continue\n        else:\n            break\n    else:\n        # No errors were found. Consider ignoring the file and returning the\n        # whole configuration sequence without errors.\n        return configs, []\n\n    return configs, errors\n", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = {}\n    errors = []\n    for filename in config_filenames:\n        try:\n            config = load_configuration(filename, overrides, resolve_env)\n        except ConfigurationError as error:\n            errors.append(error)\n            configs[filename] = Configuration(filename)\n        else:\n            if config is not None:\n                if not isinstance(config, Configuration):\n                    raise ConfigurationError(\"Configuration for {!r} not a \"\n                                             \"Configuration instance\".format(filename))\n                configs[filename] = config\n            else:\n                if overrides and filename in overrides:\n                    configs[filename] = overrides[filename]\n                else:\n                    configs[filename] = Co", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = {}\n    errors = []\n\n    for filename in config_filenames:\n        try:\n            config = load_configuration(filename, resolve_env=resolve_env)\n        except IOError as e:\n            errors.append(e)\n            continue\n        except Exception as e:\n            e.filename = filename\n            errors.append(e)\n            continue\n        configs[filename] = config\n\n    if overrides:\n        configs.update(overrides)\n\n    # We want to log all the parsing errors and return the sequence of errors\n    # which should be raised as a tuple of (parse_error, logging.LogRecord).\n    # We can also return the errors which could be raised by logging.StreamHandler.error().\n    return configs, errors\n", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    return [\n        load_config(fn, overrides, resolve_env)\n        for fn in config_filenames\n    ]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    config_filenames = [\n        os.path.expanduser(f) for f in config_filenames\n    ]\n    configs = {}\n    errors = []\n    for config_filename in config_filenames:\n        try:\n            with open(config_filename) as f:\n                configs[config_filename] = yaml.safe_load(f)\n        except IOError:\n            errors.append(\n                'Unable to load configuration file {0}. Please make sure '\n                'the configuration file is a valid YAML file.'.format(\n                    config_filename))\n            continue\n        except yaml.YAMLError as e:\n            e.filename = config_filename\n            errors.append(str(e))\n        else:\n            if not overrides:\n                pass\n            elif overrides == {}:\n             ", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = {}\n    errors = []\n\n    for config_filename in config_filenames:\n        try:\n            parsed_config = _load_config_from_file(config_filename,\n                                                 overrides=overrides,\n                                                 resolve_env=resolve_env)\n        except ConfigFileParseException as e:\n            errors.append(e)\n            configs[config_filename] = ConfigSequence()\n            continue\n\n        configs[config_filename] = parsed_config\n\n    if errors:\n        raise ConfigFileParseException(errors)\n\n    return (configs, errors)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    configs = {}\n    errors = []\n    for config_filename in config_filenames:\n        try:\n            configs[config_filename] = load_config(\n                config_filename, overrides=overrides,\n                resolve_env=resolve_env)\n        except ConfigError as e:\n            errors.append(e)\n            continue\n        except Exception as e:\n            errors.append(e)\n            continue\n\n        if not configs[config_filename].validate():\n            errors.append(configs[config_filename].error())\n            continue\n\n        return configs[config_filename], configs[config_filename].sequence, errors\n\n    raise ConfigError('\\n'.join(errors))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    # type: (Sequence[Text], Optional[Mapping[Text, Text]], bool) -> Tuple[Mapping[Text, Configuration], Sequence[logging.LogRecord]]\n    \"\"\"\n    Given a sequence of configuration filenames, load and validate each configuration file.\n\n    Return the results as a tuple of:\n    dict of configuration filename to corresponding parsed configuration, and sequence of logging.LogRecord\n    instances containing any parse errors.\n    \"\"\"\n    # The values that are missing from the file, will be set to the empty sequence if there are no\n    # files in the sequence.\n    missing_configs = set(config_filenames) - set(_load_config_files(config_filenames, resolve_env=resolve_env))\n    missing_filenames = [fname for fname in missing_configs if not os.path.exists(fname)]\n\n    if missing_filenames:\n        raise MissingConfigError(missing_filenames)\n\n    configs = {}\n    logging.getLogger(\"requests\").setLevel(logging.WARNING)\n    for fname in config_filenames:\n        parsed_confi", "is_pass": false, "return_code": 1}, {"generate_code": "def load_configurations(config_filenames, overrides=None, resolve_env=True):\n    validator = Validator(config_filenames, overrides, resolve_env)\n    return validator.validate()\n", "is_pass": false, "return_code": 1}]}
{"file_path": "plib_runnable/test_3.py", "name": "force_string", "docstring": "This function returns the bytes object corresponding to ``obj``\nin case it is a string using UTF-8. ", "ques_id": "62ece4992e6aefcf4aabbd8b", "code": ["def force_string(obj):\n    if isinstance(obj, str):\n        return obj.encode(\"utf-8\")\n    return obj\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj\n    elif isinstance(obj, str):\n        return obj.encode(\"utf-8\")\n    else:\n        raise TypeError(\"force_string must take either bytes or str \"\n                        \"arguments (got %r)\" % type(obj))\n", "def force_string(obj):\n    if isinstance(obj, str):\n        return obj.encode('utf-8')\n    return obj\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj\n    elif isinstance(obj, unicode):\n        return obj.encode('utf-8')\n    else:\n        raise TypeError('force_string must be called with a string or bytes object')\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj\n    elif isinstance(obj, str):\n        return obj.encode('utf-8')\n    else:\n        raise TypeError(\"force_string expects bytes or str, \"\n                        \"got %s\" % type(obj).__name__)\n", "def force_string(obj):\n    return obj.encode('utf-8') if isinstance(obj, str) else obj\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj\n    elif isinstance(obj, unicode):\n        return obj.encode('utf-8')\n    else:\n        raise TypeError(\"force_string expects bytes or unicode string as input\")\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj\n    elif isinstance(obj, bytearray):\n        return bytes(obj)\n    elif isinstance(obj, memoryview):\n        return obj.tobytes()\n    elif isinstance(obj, unicode):\n        raise TypeError('unicode strings are not supported, please encode to bytes: {!r}'.format(obj))\n    else:\n        # Assume the object is some kind of object.\n        return obj\n", "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj\n    elif isinstance(obj, str):\n        return obj.encode('utf-8')\n    else:\n        raise TypeError('force_string received an unexpected type of %r' % type(obj))\n", "def force_string(obj):\n    return obj.encode(\"utf-8\") if isinstance(obj, str) else obj\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def force_string(obj):\n    if isinstance(obj, str):\n        return obj.encode(\"utf-8\")\n    return obj\n", "is_pass": false, "return_code": 1}, {"generate_code": "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj\n    elif isinstance(obj, str):\n        return obj.encode(\"utf-8\")\n    else:\n        raise TypeError(\"force_string must take either bytes or str \"\n                        \"arguments (got %r)\" % type(obj))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def force_string(obj):\n    if isinstance(obj, str):\n        return obj.encode('utf-8')\n    return obj\n", "is_pass": false, "return_code": 1}, {"generate_code": "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj\n    elif isinstance(obj, unicode):\n        return obj.encode('utf-8')\n    else:\n        raise TypeError('force_string must be called with a string or bytes object')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj\n    elif isinstance(obj, str):\n        return obj.encode('utf-8')\n    else:\n        raise TypeError(\"force_string expects bytes or str, \"\n                        \"got %s\" % type(obj).__name__)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def force_string(obj):\n    return obj.encode('utf-8') if isinstance(obj, str) else obj\n", "is_pass": false, "return_code": 1}, {"generate_code": "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj\n    elif isinstance(obj, unicode):\n        return obj.encode('utf-8')\n    else:\n        raise TypeError(\"force_string expects bytes or unicode string as input\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj\n    elif isinstance(obj, bytearray):\n        return bytes(obj)\n    elif isinstance(obj, memoryview):\n        return obj.tobytes()\n    elif isinstance(obj, unicode):\n        raise TypeError('unicode strings are not supported, please encode to bytes: {!r}'.format(obj))\n    else:\n        # Assume the object is some kind of object.\n        return obj\n", "is_pass": false, "return_code": 1}, {"generate_code": "def force_string(obj):\n    if isinstance(obj, bytes):\n        return obj\n    elif isinstance(obj, str):\n        return obj.encode('utf-8')\n    else:\n        raise TypeError('force_string received an unexpected type of %r' % type(obj))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def force_string(obj):\n    return obj.encode(\"utf-8\") if isinstance(obj, str) else obj\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/time/__init__.py", "project": "neo4j/neo4j-python-driver", "name": "from_ticks", "docstring": "Create a time from ticks (nanoseconds since midnight).\n\n:param ticks: nanoseconds since midnight\n:type ticks: int\n:param tz: optional timezone\n:type tz: datetime.tzinfo\n\n:rtype: Time\n\n:raises ValueError: if ticks is out of bounds\n    (0 <= ticks < 86400000000000)", "ques_id": "62e60723d76274f8a4026b76", "code": ["def from_ticks(cls, ticks, tz=None):\n    if ticks < 0:\n        raise ValueError('Time ticks must be greater than 0 ns')\n\n    if tz is None:\n        return cls(*time.gmtime(ticks)[:6])\n    else:\n        return cls(*time.gmtime(ticks)[:6], tz=tz)\n", "def from_ticks(cls, ticks, tz=None):\n    if ticks < 0:\n        raise ValueError(\"ticks must be >= 0, got %s\" % repr(ticks))\n\n    if tz is None:\n        return Time(0, 0, ticks, tz=UTC)\n    else:\n        return tz.fromutc(ticks)\n", "def from_ticks(cls, ticks, tz=None):\n    if ticks < 0:\n        raise ValueError(\"Time.from_ticks(%s) : ticks must be non-negative\" % ticks)\n\n    if tz is None:\n        return cls.from_seconds(ticks / 1000000000, ticks_ns=True)\n    else:\n        return tz.fromutc(cls.from_seconds(ticks / 1000000000, ticks_ns=True))\n", "def from_ticks(cls, ticks, tz=None):\n    if ticks > cls.MAX_TICKS:\n        raise ValueError(\"Time ticks out of range (%d)\" % cls.MAX_TICKS)\n\n    if tz is None:\n        return cls(*time.gmtime(ticks)[:6])\n\n    return cls(*time.gmtime(ticks)[:6], tz=tz)\n", "def from_ticks(cls, ticks, tz=None):\n    if not 0 <= ticks < 86400000000:\n        raise ValueError(\"ticks must be in range 0 <= ticks < 86400000000\")\n\n    if tz is None:\n        return cls.from_seconds(ticks)\n\n    return cls.from_datetime(tz.localize(ticks))\n", "def from_ticks(cls, ticks, tz=None):\n    if ticks < 0:\n        raise ValueError('ticks must be greater than zero')\n\n    if tz is None:\n        return cls.from_seconds(ticks // (2 ** 32) * (2 ** 32))\n    else:\n        if not isinstance(tz, datetime.tzinfo):\n            raise TypeError('tz must be a datetime.tzinfo')\n\n    return tz.fromutc(datetime.timedelta(seconds=ticks))\n", "def from_ticks(cls, ticks, tz=None):\n    if ticks > _MAX_TICKS:\n        raise ValueError(\"Time ticks out of range (%d)\" % _MAX_TICKS)\n\n    if tz is not None and ticks > (tz.utcoffset(None).total_seconds() / 1000000000):\n        raise ValueError(\"Time ticks out of range (%d)\" % (ticks / 1000000000))\n\n    return cls.from_datetime(datetime.utcfromtimestamp(ticks), tz)\n", "def from_ticks(cls, ticks, tz=None):\n    if ticks < 0:\n        raise ValueError('ticks must be >= 0, got {0}'.format(ticks))\n\n    if tz is None:\n        return Time(0, 0, ticks)\n\n    return Time(tz=tz, hour=ticks // 3600, minute=(ticks % 3600) // 60,\n                second=ticks % 60)\n", "def from_ticks(cls, ticks, tz=None):\n    if ticks < 0:\n        raise ValueError(\"ticks must be >= 0, got %s\" % ticks)\n\n    if tz is None:\n        tz = _UTC\n\n    return cls(ticks * 1e9, tz=tz)\n", "def from_ticks(cls, ticks, tz=None):\n    if ticks > cls.MAX_TICKS:\n        raise ValueError('ticks out of bounds: {0!r}'.format(ticks))\n\n    if not (0 <= ticks < cls.MAX_TICKS):\n        raise ValueError('ticks out of bounds: {0!r}'.format(ticks))\n\n    if tz is None:\n        tz = _get_timezone()\n\n    return cls(ticks, tz)\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def from_ticks(cls, ticks, tz=None):\n    if ticks < 0:\n        raise ValueError('Time ticks must be greater than 0 ns')\n\n    if tz is None:\n        return cls(*time.gmtime(ticks)[:6])\n    else:\n        return cls(*time.gmtime(ticks)[:6], tz=tz)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    if ticks < 0:\n        raise ValueError(\"ticks must be >= 0, got %s\" % repr(ticks))\n\n    if tz is None:\n        return Time(0, 0, ticks, tz=UTC)\n    else:\n        return tz.fromutc(ticks)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    if ticks < 0:\n        raise ValueError(\"Time.from_ticks(%s) : ticks must be non-negative\" % ticks)\n\n    if tz is None:\n        return cls.from_seconds(ticks / 1000000000, ticks_ns=True)\n    else:\n        return tz.fromutc(cls.from_seconds(ticks / 1000000000, ticks_ns=True))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    if ticks > cls.MAX_TICKS:\n        raise ValueError(\"Time ticks out of range (%d)\" % cls.MAX_TICKS)\n\n    if tz is None:\n        return cls(*time.gmtime(ticks)[:6])\n\n    return cls(*time.gmtime(ticks)[:6], tz=tz)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    if not 0 <= ticks < 86400000000:\n        raise ValueError(\"ticks must be in range 0 <= ticks < 86400000000\")\n\n    if tz is None:\n        return cls.from_seconds(ticks)\n\n    return cls.from_datetime(tz.localize(ticks))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    if ticks < 0:\n        raise ValueError('ticks must be greater than zero')\n\n    if tz is None:\n        return cls.from_seconds(ticks // (2 ** 32) * (2 ** 32))\n    else:\n        if not isinstance(tz, datetime.tzinfo):\n            raise TypeError('tz must be a datetime.tzinfo')\n\n    return tz.fromutc(datetime.timedelta(seconds=ticks))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    if ticks > _MAX_TICKS:\n        raise ValueError(\"Time ticks out of range (%d)\" % _MAX_TICKS)\n\n    if tz is not None and ticks > (tz.utcoffset(None).total_seconds() / 1000000000):\n        raise ValueError(\"Time ticks out of range (%d)\" % (ticks / 1000000000))\n\n    return cls.from_datetime(datetime.utcfromtimestamp(ticks), tz)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    if ticks < 0:\n        raise ValueError('ticks must be >= 0, got {0}'.format(ticks))\n\n    if tz is None:\n        return Time(0, 0, ticks)\n\n    return Time(tz=tz, hour=ticks // 3600, minute=(ticks % 3600) // 60,\n                second=ticks % 60)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    if ticks < 0:\n        raise ValueError(\"ticks must be >= 0, got %s\" % ticks)\n\n    if tz is None:\n        tz = _UTC\n\n    return cls(ticks * 1e9, tz=tz)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_ticks(cls, ticks, tz=None):\n    if ticks > cls.MAX_TICKS:\n        raise ValueError('ticks out of bounds: {0!r}'.format(ticks))\n\n    if not (0 <= ticks < cls.MAX_TICKS):\n        raise ValueError('ticks out of bounds: {0!r}'.format(ticks))\n\n    if tz is None:\n        tz = _get_timezone()\n\n    return cls(ticks, tz)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "neo4j/_async/io/_bolt.py", "project": "neo4j/neo4j-python-driver", "name": "protocol_handlers", "docstring": "Return a dictionary of available Bolt protocol handlers,\nkeyed by version tuple. If an explicit protocol version is\nprovided, the dictionary will contain either zero or one items,\ndepending on whether that version is supported. If no protocol\nversion is provided, all available versions will be returned.\n\n:param protocol_version: tuple identifying a specific protocol\n    version (e.g. (3, 5)) or None\n:return: dictionary of version tuple to handler class for all\n    relevant and supported protocol versions\n:raise TypeError: if protocol version is not passed in a tuple", "ques_id": "62e60873d76274f8a4026bd8", "code": ["def protocol_handlers(cls, protocol_version=None):\n    version_tuples = {\n        (3, 5): _BoltHandler3,\n        (5, 7): _BoltHandler5,\n        (6, 9): _BoltHandler6,\n        (9, 0): _BoltHandler9,\n    }\n\n    if protocol_version is not None:\n        if len(protocol_version) == 3:\n            return version_tuples.get(protocol_version, {})\n        else:\n            raise TypeError('protocol_version must be a tuple with 3 elements')\n\n    return version_tuples\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n\n    return cls._protocol_handlers.get(protocol_version, {})\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is not None:\n        return cls._protocol_handlers.get(protocol_version, {})\n    else:\n        return cls._protocol_handlers\n", "def protocol_handlers(cls, protocol_version=None):\n    version_tuple = protocol_version or tuple(VERSION_CLASSES)\n    return {version_tuple[0]: version_tuple[1]}\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n\n    return cls._protocol_handlers.get(protocol_version, {})\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n\n    return cls._protocol_handlers.get(protocol_version, {})\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is not None:\n        if len(protocol_version) == 2:\n            return cls._protocol_handlers_v2[protocol_version[0]](protocol_version[1])\n        else:\n            raise TypeError('Explicit protocol version must be passed in a tuple of two elements')\n    else:\n        return cls._protocol_handlers\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n    else:\n        return cls._protocol_handlers.get(protocol_version, {})\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is not None:\n        supported = [version for version in cls.SUPPORTED_VERSIONS if version[0] <= protocol_version[0]]\n        if len(supported) > 0:\n            return supported\n        else:\n            raise TypeError(\"Protocol version %s not supported\" % protocol_version)\n\n    return {version: cls.SUPPORTED_HANDLERS[version] for version in cls.SUPPORTED_VERSIONS}\n", "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n    else:\n        return cls._protocol_handlers.get(protocol_version, {})\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    version_tuples = {\n        (3, 5): _BoltHandler3,\n        (5, 7): _BoltHandler5,\n        (6, 9): _BoltHandler6,\n        (9, 0): _BoltHandler9,\n    }\n\n    if protocol_version is not None:\n        if len(protocol_version) == 3:\n            return version_tuples.get(protocol_version, {})\n        else:\n            raise TypeError('protocol_version must be a tuple with 3 elements')\n\n    return version_tuples\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n\n    return cls._protocol_handlers.get(protocol_version, {})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is not None:\n        return cls._protocol_handlers.get(protocol_version, {})\n    else:\n        return cls._protocol_handlers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    version_tuple = protocol_version or tuple(VERSION_CLASSES)\n    return {version_tuple[0]: version_tuple[1]}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n\n    return cls._protocol_handlers.get(protocol_version, {})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n\n    return cls._protocol_handlers.get(protocol_version, {})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is not None:\n        if len(protocol_version) == 2:\n            return cls._protocol_handlers_v2[protocol_version[0]](protocol_version[1])\n        else:\n            raise TypeError('Explicit protocol version must be passed in a tuple of two elements')\n    else:\n        return cls._protocol_handlers\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n    else:\n        return cls._protocol_handlers.get(protocol_version, {})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is not None:\n        supported = [version for version in cls.SUPPORTED_VERSIONS if version[0] <= protocol_version[0]]\n        if len(supported) > 0:\n            return supported\n        else:\n            raise TypeError(\"Protocol version %s not supported\" % protocol_version)\n\n    return {version: cls.SUPPORTED_HANDLERS[version] for version in cls.SUPPORTED_VERSIONS}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def protocol_handlers(cls, protocol_version=None):\n    if protocol_version is None:\n        return cls._protocol_handlers\n    else:\n        return cls._protocol_handlers.get(protocol_version, {})\n", "is_pass": false, "return_code": 1}]}
{"file_path": "neo4j/api.py", "project": "neo4j/neo4j-python-driver", "name": "from_raw_values", "docstring": "Create a Bookmarks object from a list of raw bookmark string values.\n\nYou should not need to use this method unless you want to deserialize\nbookmarks.\n\n:param values: ASCII string values (raw bookmarks)\n:type values: Iterable[str]", "ques_id": "62e60e3bd76274f8a4026d1a", "code": ["def from_raw_values(cls, values):\n    return cls(values)\n", "def from_raw_values(cls, values):\n    return cls(values)\n", "def from_raw_values(cls, values):\n    return cls(values)\n", "def from_raw_values(cls, values):\n    return cls(values)\n", "def from_raw_values(cls, values):\n    return cls(values)\n", "def from_raw_values(cls, values):\n    return cls(values)\n", "def from_raw_values(cls, values):\n    return cls(values)\n", "def from_raw_values(cls, values):\n    return cls(values)\n", "def from_raw_values(cls, values):\n    return cls(values)\n", "def from_raw_values(cls, values):\n    return cls(values)\n"], "level": "self_contained", "generate_results": [{"generate_code": "def from_raw_values(cls, values):\n    return cls(values)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls(values)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls(values)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls(values)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls(values)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls(values)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls(values)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls(values)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls(values)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def from_raw_values(cls, values):\n    return cls(values)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "lena/core/split.py", "project": "ynikitenko/lena", "name": "_get_seq_with_type", "docstring": "Return a (sequence, type) pair.\nSequence is derived from *seq*\n(or is *seq*, if that is of a sequence type).", "ques_id": "62b87b199a0c4fa8b80b354c", "code": ["def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            return seq._get_seq_with_type()\n        else:\n            return _get_seq_with_type(seq._iterable, bufsize)\n    else:\n        return (seq, type(seq))\n", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = seq._bufsize\n        seq = seq._get_seq_with_type(bufsize)\n    elif not isinstance(seq, Sequence):\n        raise TypeError(\"seq must be a Sequence instance\")\n    return seq, seq._type\n", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is not None:\n            return seq, type(seq)\n        else:\n            return seq, type(seq)\n    else:\n        return seq, type(seq)\n", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            return seq, type(seq)\n        else:\n            return seq, Sequence(bufsize, seq.__class__)\n    else:\n        return seq, type(seq)\n", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = seq._bufsize\n        return seq, Sequence\n    else:\n        return seq, type(seq)\n", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = sys.getsizeof(seq)\n        return (seq._get_seq_with_type(bufsize), seq.__class__)\n    return (seq, type(seq))\n", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = sys.getrefcount(seq)\n        seq = seq.__iter__()\n    elif isinstance(seq, SequenceType):\n        if bufsize is None:\n            bufsize = 0\n        seq = seq.__iter__(bufsize)\n    else:\n        raise TypeError(\"seq must be a Sequence or SequenceType\")\n    return seq, type(seq)\n", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = seq._bufsize\n        return seq._get_seq_with_type(bufsize), seq._type\n    else:\n        return seq, seq._type\n", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            return seq._get_seq_with_type()\n        else:\n            return seq, type(seq)\n    else:\n        # assume seq is a string\n        return seq, type(seq)\n", "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = seq._bufsize\n        return seq._get_seq_with_type(bufsize)\n    else:\n        return (seq, type(seq))\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            return seq._get_seq_with_type()\n        else:\n            return _get_seq_with_type(seq._iterable, bufsize)\n    else:\n        return (seq, type(seq))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = seq._bufsize\n        seq = seq._get_seq_with_type(bufsize)\n    elif not isinstance(seq, Sequence):\n        raise TypeError(\"seq must be a Sequence instance\")\n    return seq, seq._type\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is not None:\n            return seq, type(seq)\n        else:\n            return seq, type(seq)\n    else:\n        return seq, type(seq)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            return seq, type(seq)\n        else:\n            return seq, Sequence(bufsize, seq.__class__)\n    else:\n        return seq, type(seq)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = seq._bufsize\n        return seq, Sequence\n    else:\n        return seq, type(seq)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = sys.getsizeof(seq)\n        return (seq._get_seq_with_type(bufsize), seq.__class__)\n    return (seq, type(seq))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = sys.getrefcount(seq)\n        seq = seq.__iter__()\n    elif isinstance(seq, SequenceType):\n        if bufsize is None:\n            bufsize = 0\n        seq = seq.__iter__(bufsize)\n    else:\n        raise TypeError(\"seq must be a Sequence or SequenceType\")\n    return seq, type(seq)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = seq._bufsize\n        return seq._get_seq_with_type(bufsize), seq._type\n    else:\n        return seq, seq._type\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            return seq._get_seq_with_type()\n        else:\n            return seq, type(seq)\n    else:\n        # assume seq is a string\n        return seq, type(seq)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_seq_with_type(seq, bufsize=None):\n    if isinstance(seq, Sequence):\n        if bufsize is None:\n            bufsize = seq._bufsize\n        return seq._get_seq_with_type(bufsize)\n    else:\n        return (seq, type(seq))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/structures/histogram.py", "project": "ynikitenko/lena", "name": "scale", "docstring": "Compute or set scale (integral of the histogram).\n\nIf *other* is ``None``, return scale of this histogram.\nIf its scale was not computed before,\nit is computed and stored for subsequent use\n(unless explicitly asked to *recompute*).\nNote that after changing (filling) the histogram\none must explicitly recompute the scale\nif it was computed before.\n\nIf a float *other* is provided, rescale self to *other*.\n\nHistograms with scale equal to zero can't be rescaled.\n:exc:`.LenaValueError` is raised if one tries to do that.", "ques_id": "62b87b4f9a0c4fa8b80b3581", "code": ["def scale(self, other=None, recompute=False):\n\n    if other is None:\n        try:\n            return self._scale\n        except AttributeError:\n            pass\n    else:\n        if recompute:\n            self._scale = other\n        else:\n            try:\n                self._scale = float(other)\n            except ValueError:\n                raise LenaValueError('scale cannot be computed when hist '\n                                     'is already scaled')\n", "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        if not recompute:\n            raise LenaValueError(\"scale() of uninitialized histogram\")\n        return self._scale\n    else:\n        if recompute:\n            self._scale = other\n        else:\n            return other\n", "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        # compute scale of the histogram\n        return scale_hist(self)\n    else:\n        # otherwise, set scale to the provided value\n        if recompute:\n            # compute scale of the histogram\n            return scale_hist(other)\n        else:\n            # otherwise, set scale to the provided value\n            other.scale = 1.0 * other.max / other.sum()\n", "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        if self._scale is None:\n            if recompute:\n                self._scale = 0\n                self._histo.scale = 0\n            else:\n                raise LenaValueError(\"scale cannot be computed before recompute\")\n        else:\n            self._scale = other\n    else:\n        self._scale = other\n", "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        if self.scale is not None:\n            return self.scale\n\n        if recompute:\n            self.scale = 0\n            return self.scale\n\n    else:\n        if not isinstance(other, float):\n            raise LenaValueError(\"scale must be a float\")\n\n        self.scale = other\n        return self.scale\n", "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        if self._scale is not None:\n            return self._scale\n\n        if recompute:\n            self._scale = 0\n            return self._scale\n\n        raise LenaValueError('scale() cannot be computed before setting scale')\n\n    if self._hist is None:\n        raise LenaError('histogram has to be computed before setting scale')\n\n    self._scale = np.sum(np.abs(self._hist - other)) / self._hist.size\n", "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        return float(self[3])\n\n    if recompute:\n        if self._scale is None:\n            raise LenaValueError(\"scale not computed before\")\n        else:\n            other = float(other)\n            if other == 0:\n                pass\n            elif other == 1:\n                self._scale = 0\n            else:\n                self._scale *= float(other)\n\n    else:\n        if self._scale is None:\n            self._scale = other\n        else:\n            raise LenaValueError(\"scale was already computed before\")\n", "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        return self._scale\n\n    if recompute and self._scale is None:\n        raise LenaValueError('scale not computed yet')\n\n    self._scale = numpy.sum([h.scale * h.count for h in self])\n", "def scale(self, other=None, recompute=False):\n\n    # check if scale was not computed before\n    if other is None:\n        if self._scale is None:\n            raise LenaValueError(\"scale not computed yet\")\n        else:\n            return self._scale\n\n    # otherwise, compute and store scale\n    else:\n        if recompute:\n            self._scale = other.scale()\n        else:\n            old_scale = self.scale()\n            self._scale = 0 if old_scale is None else old_scale * other.scale()\n        return self._scale\n", "def scale(self, other=None, recompute=False):\n\n    if recompute or (other is not None):\n        if (other is None):\n            try:\n                return self._scale\n            except LenaException:\n                pass\n        else:\n            self._scale = other._scale\n            try:\n                self._scale *= self._bins\n            except TypeError:\n                pass\n\n    return self._scale\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        try:\n            return self._scale\n        except AttributeError:\n            pass\n    else:\n        if recompute:\n            self._scale = other\n        else:\n            try:\n                self._scale = float(other)\n            except ValueError:\n                raise LenaValueError('scale cannot be computed when hist '\n                                     'is already scaled')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        if not recompute:\n            raise LenaValueError(\"scale() of uninitialized histogram\")\n        return self._scale\n    else:\n        if recompute:\n            self._scale = other\n        else:\n            return other\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        # compute scale of the histogram\n        return scale_hist(self)\n    else:\n        # otherwise, set scale to the provided value\n        if recompute:\n            # compute scale of the histogram\n            return scale_hist(other)\n        else:\n            # otherwise, set scale to the provided value\n            other.scale = 1.0 * other.max / other.sum()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        if self._scale is None:\n            if recompute:\n                self._scale = 0\n                self._histo.scale = 0\n            else:\n                raise LenaValueError(\"scale cannot be computed before recompute\")\n        else:\n            self._scale = other\n    else:\n        self._scale = other\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        if self.scale is not None:\n            return self.scale\n\n        if recompute:\n            self.scale = 0\n            return self.scale\n\n    else:\n        if not isinstance(other, float):\n            raise LenaValueError(\"scale must be a float\")\n\n        self.scale = other\n        return self.scale\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        if self._scale is not None:\n            return self._scale\n\n        if recompute:\n            self._scale = 0\n            return self._scale\n\n        raise LenaValueError('scale() cannot be computed before setting scale')\n\n    if self._hist is None:\n        raise LenaError('histogram has to be computed before setting scale')\n\n    self._scale = np.sum(np.abs(self._hist - other)) / self._hist.size\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        return float(self[3])\n\n    if recompute:\n        if self._scale is None:\n            raise LenaValueError(\"scale not computed before\")\n        else:\n            other = float(other)\n            if other == 0:\n                pass\n            elif other == 1:\n                self._scale = 0\n            else:\n                self._scale *= float(other)\n\n    else:\n        if self._scale is None:\n            self._scale = other\n        else:\n            raise LenaValueError(\"scale was already computed before\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    if other is None:\n        return self._scale\n\n    if recompute and self._scale is None:\n        raise LenaValueError('scale not computed yet')\n\n    self._scale = numpy.sum([h.scale * h.count for h in self])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    # check if scale was not computed before\n    if other is None:\n        if self._scale is None:\n            raise LenaValueError(\"scale not computed yet\")\n        else:\n            return self._scale\n\n    # otherwise, compute and store scale\n    else:\n        if recompute:\n            self._scale = other.scale()\n        else:\n            old_scale = self.scale()\n            self._scale = 0 if old_scale is None else old_scale * other.scale()\n        return self._scale\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None, recompute=False):\n\n    if recompute or (other is not None):\n        if (other is None):\n            try:\n                return self._scale\n            except LenaException:\n                pass\n        else:\n            self._scale = other._scale\n            try:\n                self._scale *= self._bins\n            except TypeError:\n                pass\n\n    return self._scale\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/structures/graph.py", "project": "ynikitenko/lena", "name": "scale", "docstring": "Get or set the scale of the graph.\n\nIf *other* is ``None``, return the scale of this graph.\n\nIf a numeric *other* is provided, rescale to that value.\nIf the graph has unknown or zero scale,\nrescaling that will raise :exc:`~.LenaValueError`.\n\nTo get meaningful results, graph's fields are used.\nOnly the last coordinate is rescaled.\nFor example, if the graph has *x* and *y* coordinates,\nthen *y* will be rescaled, and for a 3-dimensional graph\n*z* will be rescaled.\nAll errors are rescaled together with their coordinate.", "ques_id": "62b87b519a0c4fa8b80b3583", "code": ["def scale(self, other=None):\n    if other is None:\n        return self._scale\n    else:\n        if isinstance(other, (int, float)):\n            self._scale = other\n        else:\n            raise TypeError(\"Unknown scale type: %s\" % type(other))\n", "def scale(self, other=None):\n    if other is not None:\n        if other!= 0:\n            raise LenaError(\"graph has unknown or zero scale\")\n        scale = other\n    else:\n        return self._scale\n", "def scale(self, other=None):\n    if other is not None:\n        if not isinstance(other, Lena):\n            raise TypeError(\"only scaling other Lena objects can be scaled\")\n        other.rescale()\n    self._scale = other\n", "def scale(self, other=None):\n    if other is not None:\n        if not isinstance(other, Lena):\n            raise TypeError(\"other must be a Lena instance\")\n        other._rescale()\n        self._scale = other._scale\n    else:\n        return self._scale\n", "def scale(self, other=None):\n    if other:\n        try:\n            return Graph._scales[self, other]\n        except KeyError:\n            raise LenaValueError(\"Graph has no field with name %s\" % other)\n    else:\n        return Graph._scales[self]\n", "def scale(self, other=None):\n    if other is None:\n        return self._scale\n    else:\n        self._scale = other\n", "def scale(self, other=None):\n    if other is not None:\n        other = float(other)\n        if other!= 0:\n            raise LenaValueError('graph scale cannot be rescaled to other coordinates')\n    return self._scale\n", "def scale(self, other=None):\n    if other is not None:\n        if not isinstance(other, (int, float)):\n            raise TypeError(\"scale can only be set to an int or float\")\n        if other <= 0:\n            raise ValueError(\"scale must be greater than 0\")\n        if other == 1:\n            self.rescale(self, other)\n            return\n        if self._graph.scale is not None:\n            raise LenaValueError(\"graph has already scaled\")\n        self._graph.scale = other\n    else:\n        return self._graph.scale\n", "def scale(self, other=None):\n    if other is not None:\n        if other.shape!= self._shape:\n            raise ValueError('Requested scale for %s but reshape shape for %s given' % (other, self))\n        else:\n            return other.copy()\n    return self._scale\n", "def scale(self, other=None):\n    if other:\n        if not isinstance(other, (tuple, list)):\n            other = [other]\n        for i in range(len(self._data)):\n            self._data[i] = (self._data[i][0], self._data[i][1], other[i])\n    return self._scale\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def scale(self, other=None):\n    if other is None:\n        return self._scale\n    else:\n        if isinstance(other, (int, float)):\n            self._scale = other\n        else:\n            raise TypeError(\"Unknown scale type: %s\" % type(other))\n", "is_pass": true, "return_code": 0}, {"generate_code": "def scale(self, other=None):\n    if other is not None:\n        if other!= 0:\n            raise LenaError(\"graph has unknown or zero scale\")\n        scale = other\n    else:\n        return self._scale\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None):\n    if other is not None:\n        if not isinstance(other, Lena):\n            raise TypeError(\"only scaling other Lena objects can be scaled\")\n        other.rescale()\n    self._scale = other\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None):\n    if other is not None:\n        if not isinstance(other, Lena):\n            raise TypeError(\"other must be a Lena instance\")\n        other._rescale()\n        self._scale = other._scale\n    else:\n        return self._scale\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None):\n    if other:\n        try:\n            return Graph._scales[self, other]\n        except KeyError:\n            raise LenaValueError(\"Graph has no field with name %s\" % other)\n    else:\n        return Graph._scales[self]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None):\n    if other is None:\n        return self._scale\n    else:\n        self._scale = other\n", "is_pass": true, "return_code": 0}, {"generate_code": "def scale(self, other=None):\n    if other is not None:\n        other = float(other)\n        if other!= 0:\n            raise LenaValueError('graph scale cannot be rescaled to other coordinates')\n    return self._scale\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None):\n    if other is not None:\n        if not isinstance(other, (int, float)):\n            raise TypeError(\"scale can only be set to an int or float\")\n        if other <= 0:\n            raise ValueError(\"scale must be greater than 0\")\n        if other == 1:\n            self.rescale(self, other)\n            return\n        if self._graph.scale is not None:\n            raise LenaValueError(\"graph has already scaled\")\n        self._graph.scale = other\n    else:\n        return self._graph.scale\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None):\n    if other is not None:\n        if other.shape!= self._shape:\n            raise ValueError('Requested scale for %s but reshape shape for %s given' % (other, self))\n        else:\n            return other.copy()\n    return self._scale\n", "is_pass": false, "return_code": 1}, {"generate_code": "def scale(self, other=None):\n    if other:\n        if not isinstance(other, (tuple, list)):\n            other = [other]\n        for i in range(len(self._data)):\n            self._data[i] = (self._data[i][0], self._data[i][1], other[i])\n    return self._scale\n", "is_pass": false, "return_code": 1}]}
{"file_path": "lena/structures/hist_functions.py", "project": "ynikitenko/lena", "name": "hist_to_graph", "docstring": "Convert a :class:`.histogram` to a :class:`.graph`.\n\n*make_value* is a function to set the value of a graph's point.\nBy default it is bin content.\n*make_value* accepts a single value (bin content) without context.\n\nThis option could be used to create graph's error bars.\nFor example, to create a graph with errors\nfrom a histogram where bins contain\na named tuple with fields *mean*, *mean_error* and a context\none could use\n\n>>> make_value = lambda bin_: (bin_.mean, bin_.mean_error)\n\n*get_coordinate* defines what the coordinate\nof a graph point created from a histogram bin will be.\nIt can be \"left\" (default), \"right\" and \"middle\".\n\n*field_names* set field names of the graph. Their number\nmust be the same as the dimension of the result.\nFor a *make_value* above they would be\n*(\"x\", \"y_mean\", \"y_mean_error\")*.\n\n*scale* becomes the graph's scale (unknown by default).\nIf it is ``True``, it uses the histogram scale.\n\n*hist* must contain only numeric bins (without context)\nor *make_value* must remove context when creating a numeric graph.\n\nReturn the resulting graph.", "ques_id": "62b87b869a0c4fa8b80b35e1", "code": ["def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For a\n    *make_value* above that would be ``left``, it would be \"right\" and\n    \"middle\".  If it is ``True``, it uses the histogram scale.\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate* make_value\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    >>> make_value = lambda bin_: True\n    >>> scale = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    >>> hist_to_graph(make_value, make_value, field_names=field_names, scale=scale)\n\n    The resulting graph is the same as the histogram.\n    \"\"\"\n    g = his", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For a\n    *make_value* above that would be use the histogram scale.\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    defines what the coordinate of a graph point created from a histogram\n    bin will be. It can be \"left\" (default), \"right\" and \"middle\".\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    defines what the coordinate of a graph point created from a histogram\n    bin will be. It can be \"left\" (default), \"right\" and \"middle\".\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    defines what the coordinate of a", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For a *make_value*\n    above that would be *(\"x\", \"y_mean\", \"y_mean_error\")*. If it is ``True``, it\n    uses the histogram scale. If it is ``False``, it uses the histogram scale.\n\n    *field_names* set field names of the graph. The number must be the same as\n    the dimension of the result. For a *make_value* above that would be\n    *(\"x\", \"y_mean\", \"y_mean_error\")*.         \n\n    \"\"\"\n    if scale is None:\n        scale = get_coordinate(hist, \"scale\")\n    return make_graph(hist, make_value, get_coordinate, field_names, scale)\n", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For a\n    *make_value* above that would be *(\"x\", \"y_mean\", \"y_mean_error\")*.\n\n    If it is ``True``, it uses the histogram scale.  This can be used\n    to create a graph with errors from a histogram bin will be set.\n\n    For a *make_value* above that would be *(\"x\", \"y_mean\", \"y_mean_error\")*.\n\n    *field_names* set field names of the graph.\n\n    However, if it is ``True``, it uses the histogram scale.  This\n    can be used to create a graph with errors without context when\n    creating a numeric graph.\n\n    \"\"\"\n    return HistToGraph(hist, make_value, get_coordinate, field_names, scale)\n", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For a\n    ``make_value` above that would be ``left``, we use the histogram\n    scale. If it is ``True``, it uses the histogram scale. If it is\n    ``False``, it uses the histogram zero point.\n\n    *field_names* set field names of the graph. Everything must be the\n    same as the dimension of the result. For a ``make_value` above\n    that would be ``left``, we use the histogram scale. If it is ``False``\n    we use the histogram zero point.\n\n    Return the resulting graph.\n    \"\"\"\n    return _hist_to_graph(hist, make_value, get_coordinate, field_names, scale)\n", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n    Bydefault it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For a\n    *make_value* above that would be use the histogram scale.\n\n    For a *field_names* set field names of the graph. The number must be\n    the same as the dimension of the result. For a *make_value* who\n    would be ``True`` will use the histogram scale.\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * make_value\n    >>> scale = lambda bin_: (bin_.mean - bin_.mean ** 2, bin_.mean - bin_.mean ** 3)\n    >>> hist_to_graph(make_value, make_value, field_names=field_names,\n   ...       ", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars.\n\n    For a *make_value* above that would be use the histogram scale.\n\n    For a *field_names* set field names of the graph. The number must be\n    the same as the dimension of the result.  This can be \"left\"\n    (default), \"right\" and \"middle\".  If it is ``True``, it uses\n    the histogram scale.  This can be use the histogram scale.\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    >>> make_value = lambda bin_: True\n\n    >>> field_names = (\"mean\", \"mean_error\")\n    >", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For a\n    ``make_value` above that would be ``left``, it can be \"right\" and\n    \"middle\".\n\n    For a *make_value* above that would be ``True`` would be the graph's scale\n    (unknown by default).\n\n    *field_names* set field names of the graph. The number must be the same\n    as the dimension of the result. For a *make_value* above that would\n    be ``True`` would be the graph's scale.\n\n    Return the resulting graph.\n    \"\"\"\n    if scale is None:\n        scale = hist.get_scale()\n\n    return hist.make_graph(make_value=make_value, get_coordinate=get_coordinate,\n                           field_names=field_names,", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For a \n    *make_value* above that would be use the histogram scale.\n\n    For a *field_names* set field names of the graph. The number must be\n    the same as the dimension of the result. For a *make_value* \n    above that would be *(\"x\", \"y_mean\", \"y_mean_error\")*.          \n\n    This can be used to create a graph with errors from a histogram\n    where bins contain a named tuple with fields *mean*, *mean_error`,\n    and a context one would be \"left\" (default), \"right\" and \"middle\".\n\n    If it is ``True``, it uses the histogram scale.\n\n    This can be used to create a graph with errors from a make_value*\n", "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n    This option could be used to create graph's error bars.\n\n    For a *make_value* above that would be use the histogram scale.\n\n    Would be set the graph's scale (unknown by default). If it is ``True``,\n    it uses the histogram scale.\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    >>> make_value = lambda bin_: (\"left\", \"right\", \"middle\")\n    >>> make_value = lambda bin_: (\"x\", \"y\", \"z\")\n    >>> field_names = (\"x\", \"y\", \"z\")\n    >>> scale = lambda bin_: bin_.mean_error\n\n    >>> graph = hist_to_graph(hist, make_value, get_coordinate, field_names,\n   ...                   "], "level": "project_runnable", "generate_results": [{"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For a\n    *make_value* above that would be ``left``, it would be \"right\" and\n    \"middle\".  If it is ``True``, it uses the histogram scale.\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate* make_value\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    >>> make_value = lambda bin_: True\n    >>> scale = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    >>> hist_to_graph(make_value, make_value, field_names=field_names, scale=scale)\n\n    The resulting graph is the same as the histogram.\n    \"\"\"\n    g = his", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For a\n    *make_value* above that would be use the histogram scale.\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    defines what the coordinate of a graph point created from a histogram\n    bin will be. It can be \"left\" (default), \"right\" and \"middle\".\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    defines what the coordinate of a graph point created from a histogram\n    bin will be. It can be \"left\" (default), \"right\" and \"middle\".\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    defines what the coordinate of a", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For a *make_value*\n    above that would be *(\"x\", \"y_mean\", \"y_mean_error\")*. If it is ``True``, it\n    uses the histogram scale. If it is ``False``, it uses the histogram scale.\n\n    *field_names* set field names of the graph. The number must be the same as\n    the dimension of the result. For a *make_value* above that would be\n    *(\"x\", \"y_mean\", \"y_mean_error\")*.         \n\n    \"\"\"\n    if scale is None:\n        scale = get_coordinate(hist, \"scale\")\n    return make_graph(hist, make_value, get_coordinate, field_names, scale)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For a\n    *make_value* above that would be *(\"x\", \"y_mean\", \"y_mean_error\")*.\n\n    If it is ``True``, it uses the histogram scale.  This can be used\n    to create a graph with errors from a histogram bin will be set.\n\n    For a *make_value* above that would be *(\"x\", \"y_mean\", \"y_mean_error\")*.\n\n    *field_names* set field names of the graph.\n\n    However, if it is ``True``, it uses the histogram scale.  This\n    can be used to create a graph with errors without context when\n    creating a numeric graph.\n\n    \"\"\"\n    return HistToGraph(hist, make_value, get_coordinate, field_names, scale)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For a\n    ``make_value` above that would be ``left``, we use the histogram\n    scale. If it is ``True``, it uses the histogram scale. If it is\n    ``False``, it uses the histogram zero point.\n\n    *field_names* set field names of the graph. Everything must be the\n    same as the dimension of the result. For a ``make_value` above\n    that would be ``left``, we use the histogram scale. If it is ``False``\n    we use the histogram zero point.\n\n    Return the resulting graph.\n    \"\"\"\n    return _hist_to_graph(hist, make_value, get_coordinate, field_names, scale)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n    Bydefault it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For a\n    *make_value* above that would be use the histogram scale.\n\n    For a *field_names* set field names of the graph. The number must be\n    the same as the dimension of the result. For a *make_value* who\n    would be ``True`` will use the histogram scale.\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * make_value\n    >>> scale = lambda bin_: (bin_.mean - bin_.mean ** 2, bin_.mean - bin_.mean ** 3)\n    >>> hist_to_graph(make_value, make_value, field_names=field_names,\n   ...       ", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars.\n\n    For a *make_value* above that would be use the histogram scale.\n\n    For a *field_names* set field names of the graph. The number must be\n    the same as the dimension of the result.  This can be \"left\"\n    (default), \"right\" and \"middle\".  If it is ``True``, it uses\n    the histogram scale.  This can be use the histogram scale.\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    >>> make_value = lambda bin_: True\n\n    >>> field_names = (\"mean\", \"mean_error\")\n    >", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For a\n    ``make_value` above that would be ``left``, it can be \"right\" and\n    \"middle\".\n\n    For a *make_value* above that would be ``True`` would be the graph's scale\n    (unknown by default).\n\n    *field_names* set field names of the graph. The number must be the same\n    as the dimension of the result. For a *make_value* above that would\n    be ``True`` would be the graph's scale.\n\n    Return the resulting graph.\n    \"\"\"\n    if scale is None:\n        scale = hist.get_scale()\n\n    return hist.make_graph(make_value=make_value, get_coordinate=get_coordinate,\n                           field_names=field_names,", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n\n    This option could be used to create graph's error bars. For a \n    *make_value* above that would be use the histogram scale.\n\n    For a *field_names* set field names of the graph. The number must be\n    the same as the dimension of the result. For a *make_value* \n    above that would be *(\"x\", \"y_mean\", \"y_mean_error\")*.          \n\n    This can be used to create a graph with errors from a histogram\n    where bins contain a named tuple with fields *mean*, *mean_error`,\n    and a context one would be \"left\" (default), \"right\" and \"middle\".\n\n    If it is ``True``, it uses the histogram scale.\n\n    This can be used to create a graph with errors from a make_value*\n", "is_pass": false, "return_code": 1}, {"generate_code": "def hist_to_graph(hist, make_value=None, get_coordinate=\"left\",\n                  field_names=(\"x\", \"y\"), scale=None):\n    \"\"\"\n    Convert a :class:`.histogram` to a :class:`.graph`.\n\n    *make_value* is a function to set the value of a graph's point.\n\n    By default it is bin content.\n\n    *make_value* accepts a single value (bin content) without context.\n    This option could be used to create graph's error bars.\n\n    For a *make_value* above that would be use the histogram scale.\n\n    Would be set the graph's scale (unknown by default). If it is ``True``,\n    it uses the histogram scale.\n\n    >>> make_value = lambda bin_: (bin_.mean, bin_.mean_error) * get_coordinate\n    >>> make_value = lambda bin_: (\"left\", \"right\", \"middle\")\n    >>> make_value = lambda bin_: (\"x\", \"y\", \"z\")\n    >>> field_names = (\"x\", \"y\", \"z\")\n    >>> scale = lambda bin_: bin_.mean_error\n\n    >>> graph = hist_to_graph(hist, make_value, get_coordinate, field_names,\n   ...                   ", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/verify.py", "project": "pexip/os-zope", "name": "_verify", "docstring": "Verify that *candidate* might correctly provide *iface*.\n\nThis involves:\n\n- Making sure the candidate claims that it provides the\n  interface using ``iface.providedBy`` (unless *tentative* is `True`,\n  in which case this step is skipped). This means that the candidate's class\n  declares that it `implements <zope.interface.implementer>` the interface,\n  or the candidate itself declares that it `provides <zope.interface.provider>`\n  the interface\n\n- Making sure the candidate defines all the necessary methods\n\n- Making sure the methods have the correct signature (to the\n  extent possible)\n\n- Making sure the candidate defines all the necessary attributes\n\n:return bool: Returns a true value if everything that could be\n   checked passed.\n:raises zope.interface.Invalid: If any of the previous\n   conditions does not hold.\n\n.. versionchanged:: 5.0\n    If multiple methods or attributes are invalid, all such errors\n    are collected and reported. Previously, only the first error was reported.\n    As a special case, if only one such error is present, it is raised\n    alone, like before.", "ques_id": "62b8b4baeb7e40a82d2d1136", "code": ["def _verify(iface, candidate, tentative=False, vtype=None):\n    if vtype is None:\n        vtype = iface.providedBy(candidate)\n\n    if not vtype:\n        # Candidate does not define the interface, or candidate defines the\n        # interface but isn't provided by the current interface.\n        raise zope.interface.Invalid(\n            \"Candidate does not define the interface (%s)\" % candidate)\n\n    if not iface.providedBy(candidate):\n        # Candidate is not provided by the current interface.\n        raise zope.interface.Invalid(\n            \"Candidate is not provided by the current interface (%s)\" % candidate)\n\n    if not tentative:\n        # Candidate is not part of the current interface.\n        if candidate not in iface.__provided__:\n            # Candidate does not provide the interface (it may be provided\n            # by another interface than the current one).\n            raise zope.interface.Invalid(\n              ", "def _verify(iface, candidate, tentative=False, vtype=None):\n    if vtype is not None:\n        verifyObject(IContent, candidate)\n        verifyObject(IBrowserRequest, candidate.request)\n        verifyObject(IContentType, candidate.context)\n        verifyObject(ITransport, candidate.request.transport)\n\n        verifyClass(IHasTransport, candidate.request.transport)\n\n        verifyObject(IContent, candidate)\n        verifyObject(IBrowserRequest, candidate.request)\n        verifyObject(IHasTransport, candidate.request.transport)\n\n    if hasattr(candidate, '__parent__') and candidate.__parent__ is not None:\n        verifyObject(IContent, candidate.__parent__)\n        verifyObject(IBrowserRequest, candidate.__parent__)\n        verifyObject(IHasTransport, candidate.__parent__.request.transport)\n\n    if hasattr(candidate, '__name__') and candidate.__name__ is not None:\n        verifyObject(IHasTransport, candidate.__name__)\n        verifyObject(IContent, candidate.__name__)\n\n        verifyObject(IContentType", "def _verify(iface, candidate, tentative=False, vtype=None):\n    if iface.providedBy(candidate):\n        return True\n    if vtype is None:\n        vtype = get_vtype(candidate)\n    if not vtype.isConstructionAllowed():\n        raise zope.interface.Invalid(\n            'Candidate must be a Construction class')\n    if not vtype.isConstructionAllowed(candidate):\n        raise zope.interface.Invalid(\n            'Candidate must be a Construction class or instance')\n    if not hasattr(candidate, '__call__'):\n        raise zope.interface.Invalid(\n            'Candidate must be a Construction class or instance')\n    if not callable(candidate) and not tentative:\n        raise zope.interface.Invalid(\n            'Candidate must be callable or not tentative')\n    return True\n", "def _verify(iface, candidate, tentative=False, vtype=None):\n    if not iface.providedBy(candidate):\n        return False\n\n    if not hasattr(candidate, '__call__'):\n        # Candidate is not a callable object.\n        return False\n\n    if not hasattr(candidate, '__call__'):\n        # Candidate is not an object implementing the interface.\n        return False\n\n    # Candidate is not meant to be an ICalendar.\n    if not ICalendar.providedBy(candidate):\n        return False\n\n    # Candidate is not meant to be an object implementing the IContent.\n    if not IContent.providedBy(candidate):\n        return False\n\n    # Candidate implements the interface.\n    if not ICalendar.providedBy(candidate.context):\n        return False\n\n    # Candidate implements the content.\n    if not ICalendar.providedBy(candidate.context.__parent__):\n        return False\n\n    if not candidate.__parent__.providedBy(iface):\n        return False\n\n    # Candi", "def _verify(iface, candidate, tentative=False, vtype=None):\n    if vtype is not None:\n        verifyObject(IContent, candidate)\n\n    # Make sure the candidate claims that it provides the interface.\n    providedBy(candidate, iface)\n\n    # Make sure the candidate defines the interface and its methods.\n    if not iface.providedBy(candidate):\n        raise Invalid(\n            \"Candidate '%s' does not provide '%s'\" % (candidate, iface))\n\n    # Ensure the candidate defines the extension that it provides.\n    if not iface.providedBy(candidate.__ext__):\n        raise Invalid(\n            \"Candidate '%s' does not provide '%s'\" % (candidate, iface))\n\n    # Make sure the candidate defines the interface attributes.\n    if not hasattr(candidate, '__ac_local_roles__'):\n        raise Invalid(\n            \"Candidate '%s' does not provide '__ac_local_roles__'\" %\n            candidate)\n\n    # Make sure the candidate defin", "def _verify(iface, candidate, tentative=False, vtype=None):\n    if not iface.providedBy(candidate):\n        raise zope.interface.Invalid(\n            \"Candidate doesn't provide %r (%s)\" % (iface.__name__, candidate))\n    elif not iface.providedBy(candidate) and not tentative:\n        raise zope.interface.Invalid(\n            \"Candidate %r doesn't provide %r (%s)\" % (candidate, iface.__name__, iface))\n    return True\n", "def _verify(iface, candidate, tentative=False, vtype=None):\n    if vtype is None:\n        vtype = iface.providedBy(candidate)\n\n    if not vtype:\n        raise zope.interface.Invalid(\n            \"Candidate must provide the %s interface for %s\"\n            % (iface.__name__, candidate))\n\n    # If we actually got an IConcept but we didn't know what to do with it,\n    # let the caller handle it correctly.\n    if not candidate.providedBy(iface):\n        raise zope.interface.Invalid(\n            \"Candidate doesn't provide %s interface\" % iface.__name__)\n\n    # Check the candidate's interface declaration\n    if not iface.provides(candidate):\n        raise zope.interface.Invalid(\n            \"Candidate %s does not provide %s interface\" % (\n                candidate, iface.__name__))\n\n    # Check the candidate's implementation declaration\n    if not iface.provides(candidate, iface.context):\n        raise zope", "def _verify(iface, candidate, tentative=False, vtype=None):\n    # If the candidate has an implementation that provides the interface, we\n    # know we need to inspect it.\n    if vtype is not None and candidate.providedBy(vtype):\n        return True\n    if not iface.providedBy(candidate):\n        return False\n    if not candidate.isConcrete():\n        return False\n    # Make sure the candidate claims that it provides the interface.\n    if not iface.provides(candidate):\n        raise zope.interface.Invalid(\"Candidate claims that it doesn't provide \"\n                                     \"the interface\")\n    # Make sure the candidate defines all the necessary methods.\n    for name in ('get','set', 'del'):\n        if not hasattr(candidate, name):\n            raise zope.interface.Invalid(\n                \"Candidate doesn't define %s\" % name)\n    # Make sure the candidate defines all the required attributes.\n  ", "def _verify(iface, candidate, tentative=False, vtype=None):\n    if vtype is None:\n        vtype = iface.providedBy\n\n    if not issubclass(vtype, InterfaceClass):\n        return False\n\n    if not hasattr(candidate, '__providedBy__'):\n        return False\n\n    if not tentative:\n        # If the candidate didn't provide the interface, it means that\n        # the candidate could not be implemented by the iface.  We don't\n        # want to check anything that doesn't provide the interface, just\n        # check the candidate itself.\n        try:\n            provided = vtype.provides(candidate)\n        except TypeError:\n            return False\n\n        if not provided:\n            # Candidate didn't provide the interface, but it could\n            # provide it, so we don't want to check anything that\n            # doesn't provide it.\n            return False\n\n    return Tru", "def _verify(iface, candidate, tentative=False, vtype=None):\n    if iface.providedBy(candidate):\n        return True\n    if not tentative and not hasattr(candidate, 'providedBy'):\n        return False\n    if not hasattr(candidate, 'provides'):\n        # Candidate is not a configurable interface.\n        return False\n    if vtype is not None:\n        if not candidate.provides(vtype):\n            raise zope.interface.Invalid(\n                \"Candidate %s does not provide %s (%s)\" % (\n                    candidate, vtype, vtype.__name__))\n        return False\n    return True\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if vtype is None:\n        vtype = iface.providedBy(candidate)\n\n    if not vtype:\n        # Candidate does not define the interface, or candidate defines the\n        # interface but isn't provided by the current interface.\n        raise zope.interface.Invalid(\n            \"Candidate does not define the interface (%s)\" % candidate)\n\n    if not iface.providedBy(candidate):\n        # Candidate is not provided by the current interface.\n        raise zope.interface.Invalid(\n            \"Candidate is not provided by the current interface (%s)\" % candidate)\n\n    if not tentative:\n        # Candidate is not part of the current interface.\n        if candidate not in iface.__provided__:\n            # Candidate does not provide the interface (it may be provided\n            # by another interface than the current one).\n            raise zope.interface.Invalid(\n              ", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if vtype is not None:\n        verifyObject(IContent, candidate)\n        verifyObject(IBrowserRequest, candidate.request)\n        verifyObject(IContentType, candidate.context)\n        verifyObject(ITransport, candidate.request.transport)\n\n        verifyClass(IHasTransport, candidate.request.transport)\n\n        verifyObject(IContent, candidate)\n        verifyObject(IBrowserRequest, candidate.request)\n        verifyObject(IHasTransport, candidate.request.transport)\n\n    if hasattr(candidate, '__parent__') and candidate.__parent__ is not None:\n        verifyObject(IContent, candidate.__parent__)\n        verifyObject(IBrowserRequest, candidate.__parent__)\n        verifyObject(IHasTransport, candidate.__parent__.request.transport)\n\n    if hasattr(candidate, '__name__') and candidate.__name__ is not None:\n        verifyObject(IHasTransport, candidate.__name__)\n        verifyObject(IContent, candidate.__name__)\n\n        verifyObject(IContentType", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if iface.providedBy(candidate):\n        return True\n    if vtype is None:\n        vtype = get_vtype(candidate)\n    if not vtype.isConstructionAllowed():\n        raise zope.interface.Invalid(\n            'Candidate must be a Construction class')\n    if not vtype.isConstructionAllowed(candidate):\n        raise zope.interface.Invalid(\n            'Candidate must be a Construction class or instance')\n    if not hasattr(candidate, '__call__'):\n        raise zope.interface.Invalid(\n            'Candidate must be a Construction class or instance')\n    if not callable(candidate) and not tentative:\n        raise zope.interface.Invalid(\n            'Candidate must be callable or not tentative')\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if not iface.providedBy(candidate):\n        return False\n\n    if not hasattr(candidate, '__call__'):\n        # Candidate is not a callable object.\n        return False\n\n    if not hasattr(candidate, '__call__'):\n        # Candidate is not an object implementing the interface.\n        return False\n\n    # Candidate is not meant to be an ICalendar.\n    if not ICalendar.providedBy(candidate):\n        return False\n\n    # Candidate is not meant to be an object implementing the IContent.\n    if not IContent.providedBy(candidate):\n        return False\n\n    # Candidate implements the interface.\n    if not ICalendar.providedBy(candidate.context):\n        return False\n\n    # Candidate implements the content.\n    if not ICalendar.providedBy(candidate.context.__parent__):\n        return False\n\n    if not candidate.__parent__.providedBy(iface):\n        return False\n\n    # Candi", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if vtype is not None:\n        verifyObject(IContent, candidate)\n\n    # Make sure the candidate claims that it provides the interface.\n    providedBy(candidate, iface)\n\n    # Make sure the candidate defines the interface and its methods.\n    if not iface.providedBy(candidate):\n        raise Invalid(\n            \"Candidate '%s' does not provide '%s'\" % (candidate, iface))\n\n    # Ensure the candidate defines the extension that it provides.\n    if not iface.providedBy(candidate.__ext__):\n        raise Invalid(\n            \"Candidate '%s' does not provide '%s'\" % (candidate, iface))\n\n    # Make sure the candidate defines the interface attributes.\n    if not hasattr(candidate, '__ac_local_roles__'):\n        raise Invalid(\n            \"Candidate '%s' does not provide '__ac_local_roles__'\" %\n            candidate)\n\n    # Make sure the candidate defin", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if not iface.providedBy(candidate):\n        raise zope.interface.Invalid(\n            \"Candidate doesn't provide %r (%s)\" % (iface.__name__, candidate))\n    elif not iface.providedBy(candidate) and not tentative:\n        raise zope.interface.Invalid(\n            \"Candidate %r doesn't provide %r (%s)\" % (candidate, iface.__name__, iface))\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if vtype is None:\n        vtype = iface.providedBy(candidate)\n\n    if not vtype:\n        raise zope.interface.Invalid(\n            \"Candidate must provide the %s interface for %s\"\n            % (iface.__name__, candidate))\n\n    # If we actually got an IConcept but we didn't know what to do with it,\n    # let the caller handle it correctly.\n    if not candidate.providedBy(iface):\n        raise zope.interface.Invalid(\n            \"Candidate doesn't provide %s interface\" % iface.__name__)\n\n    # Check the candidate's interface declaration\n    if not iface.provides(candidate):\n        raise zope.interface.Invalid(\n            \"Candidate %s does not provide %s interface\" % (\n                candidate, iface.__name__))\n\n    # Check the candidate's implementation declaration\n    if not iface.provides(candidate, iface.context):\n        raise zope", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    # If the candidate has an implementation that provides the interface, we\n    # know we need to inspect it.\n    if vtype is not None and candidate.providedBy(vtype):\n        return True\n    if not iface.providedBy(candidate):\n        return False\n    if not candidate.isConcrete():\n        return False\n    # Make sure the candidate claims that it provides the interface.\n    if not iface.provides(candidate):\n        raise zope.interface.Invalid(\"Candidate claims that it doesn't provide \"\n                                     \"the interface\")\n    # Make sure the candidate defines all the necessary methods.\n    for name in ('get','set', 'del'):\n        if not hasattr(candidate, name):\n            raise zope.interface.Invalid(\n                \"Candidate doesn't define %s\" % name)\n    # Make sure the candidate defines all the required attributes.\n  ", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if vtype is None:\n        vtype = iface.providedBy\n\n    if not issubclass(vtype, InterfaceClass):\n        return False\n\n    if not hasattr(candidate, '__providedBy__'):\n        return False\n\n    if not tentative:\n        # If the candidate didn't provide the interface, it means that\n        # the candidate could not be implemented by the iface.  We don't\n        # want to check anything that doesn't provide the interface, just\n        # check the candidate itself.\n        try:\n            provided = vtype.provides(candidate)\n        except TypeError:\n            return False\n\n        if not provided:\n            # Candidate didn't provide the interface, but it could\n            # provide it, so we don't want to check anything that\n            # doesn't provide it.\n            return False\n\n    return Tru", "is_pass": false, "return_code": 1}, {"generate_code": "def _verify(iface, candidate, tentative=False, vtype=None):\n    if iface.providedBy(candidate):\n        return True\n    if not tentative and not hasattr(candidate, 'providedBy'):\n        return False\n    if not hasattr(candidate, 'provides'):\n        # Candidate is not a configurable interface.\n        return False\n    if vtype is not None:\n        if not candidate.provides(vtype):\n            raise zope.interface.Invalid(\n                \"Candidate %s does not provide %s (%s)\" % (\n                    candidate, vtype, vtype.__name__))\n        return False\n    return True\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/verify.py", "project": "pexip/os-zope", "name": "verifyObject", "docstring": "Verify that *candidate* might correctly provide *iface*.\n\nThis involves:\n\n- Making sure the candidate claims that it provides the\n  interface using ``iface.providedBy`` (unless *tentative* is `True`,\n  in which case this step is skipped). This means that the candidate's class\n  declares that it `implements <zope.interface.implementer>` the interface,\n  or the candidate itself declares that it `provides <zope.interface.provider>`\n  the interface\n\n- Making sure the candidate defines all the necessary methods\n\n- Making sure the methods have the correct signature (to the\n  extent possible)\n\n- Making sure the candidate defines all the necessary attributes\n\n:return bool: Returns a true value if everything that could be\n   checked passed.\n:raises zope.interface.Invalid: If any of the previous\n   conditions does not hold.\n\n.. versionchanged:: 5.0\n    If multiple methods or attributes are invalid, all such errors\n    are collected and reported. Previously, only the first error was reported.\n    As a special case, if only one such error is present, it is raised\n    alone, like before.", "ques_id": "62b8b4baeb7e40a82d2d1137", "code": ["def verifyObject(iface, candidate, tentative=False):\n    try:\n        providedBy = iface.providedBy\n    except AttributeError:\n        if not tentative:\n            raise\n        return False\n\n    verifyObjectInvariants(iface, candidate, tentative)\n    return verifyCandidateProperties(iface, candidate)\n", "def verifyObject(iface, candidate, tentative=False):\n    try:\n        verifyObject(iface, candidate)\n    except Invalid as e:\n        if e.args[0]!= zope.interface.Invalid:\n            raise\n        if not tentative:\n            raise\n    return True\n", "def verifyObject(iface, candidate, tentative=False):\n    try:\n        return iface.providedBy(candidate)\n    except KeyError:\n        pass\n    if not tentative:\n        try:\n            verifyClass(iface, candidate)\n        except KeyError:\n            raise\n        except Invalid as e:\n            if hasattr(candidate, '__name__') and candidate.__name__!= iface.__name__:\n                raise\n            try:\n                # At this point we are not yet in the context of a candidate\n                # class, so we should not expect further errors.\n                delattr(candidate, iface.__name__)\n            except KeyError:\n                pass\n    return True\n", "def verifyObject(iface, candidate, tentative=False):\n    if not isinstance(candidate, Candidate):\n        raise TypeError(\n            \"Candidate must be of type {0}, not {1}\".format(Candidate, candidate))\n\n    if not isinstance(iface, Interface):\n        raise TypeError(\n            \"Interface must be of type {0}, not {1}\".format(Interface, iface))\n\n    if not hasattr(candidate, 'providedBy'):\n        # Check to make sure the candidate is actually a candidate (i.e. not\n        # an interface).\n        if not isclass(candidate):\n            raise TypeError(\"Candidate must be a class, not a class instance\")\n\n        return False\n\n    if not ismethod(iface.providedBy):\n        # Check to make sure the candidate is actually a method.\n        if not ismethod(candidate):\n            raise TypeError(\"Candidate must be a method, not a method instance\")\n\n        return False\n\n    # All checks passed.\n", "def verifyObject(iface, candidate, tentative=False):\n    if iface.providedBy(candidate):\n        return True\n    if not hasattr(candidate, '__parent__'):\n        raise Invalid(\n            \"Candidate %s doesn't provide an '__parent__' attribute\" % candidate)\n    if not hasattr(candidate, '__name__'):\n        raise Invalid(\n            \"Candidate %s doesn't provide an '__name__' attribute\" % candidate)\n\n    # Check the '__providedBy__' attribute\n    if not hasattr(candidate, '__provides__'):\n        # Candidate has no '__provides__' attribute; assume it's a valid interface\n        return True\n    if candidate.__provides__ is None:\n        # Candidate has no '__provides__' attribute; assume it's an instance\n        return True\n    # Check the '__provides__' attribute for a valid interface\n    if not hasattr(candidate, '__provides__') or \\\n    ", "def verifyObject(iface, candidate, tentative=False):\n    if not candidate.providedBy(iface):\n        msg = \"%s does not provide %s\" % (iface, candidate)\n        raise zope.interface.Invalid(msg, candidate)\n    if not hasattr(iface, 'providedBy'):\n        # For Zope 2 compatibility reasons, providedBy is a method on\n        # Candidate, not an instance method. In this case, we want to\n        # catch that case.\n        msg = \"%s does not define providedBy\" % iface\n        raise zope.interface.Invalid(msg, candidate)\n    if not iface.providedBy(candidate):\n        if tentative:\n            raise zope.interface.Invalid(\n                \"Candidate %s is not provided by %s\" % (candidate, iface)\n            )\n        else:\n            msg = \"%s has not provided %s\" % (iface, candidate)\n            raise zope.interface.Invalid(msg, candidate)\n   ", "def verifyObject(iface, candidate, tentative=False):\n    if not isInterface(candidate):\n        raise zope.interface.Invalid(\n            \"Object %s is not an interface\" % (candidate,))\n    if not hasattr(candidate, 'providedBy'):\n        raise zope.interface.Invalid(\n            \"Object %s has no 'providedBy' attribute\" % (candidate,))\n    if not hasattr(candidate, '__providedBy__'):\n        raise zope.interface.Invalid(\n            \"Object %s has no '__providedBy__' attribute\" % (candidate,))\n    if tentative:\n        return True\n    # Make sure the candidate claims that it provides the interface\n    # directly.\n    if not iface.providedBy(candidate):\n        raise zope.interface.Invalid(\n            \"Object %s is not an interface but %r\" % (candidate, iface))\n", "def verifyObject(iface, candidate, tentative=False):\n    if not IInterface.providedBy(candidate):\n        return False\n    if not verifyObject(iface, candidate, tentative=True):\n        return False\n    if not verifyObject(iface, candidate, tentative=False):\n        return False\n    return True\n", "def verifyObject(iface, candidate, tentative=False):\n    if iface.providedBy(candidate) and not tentative:\n        return True\n\n    # The candidate claims that it *cannot* provide the interface.  We\n    # do this here instead of in ``providedBy`` to avoid dependency on\n    # ``zope.interface`` when we need to.\n    try:\n        providedBy(candidate)\n    except CannotProvide:\n        if not tentative:\n            raise\n\n        return False\n\n    # The candidate claims that it *cannot* provide the interface.  We\n    # do this here instead of in ``providedBy`` to avoid dependency on\n    # ``zope.interface`` when we need to.\n    try:\n        providedBy(candidate, iface)\n    except CannotProvide:\n        if not tentative:\n            raise\n\n        return False\n\n    return True\n", "def verifyObject(iface, candidate, tentative=False):\n    if not iface.providedBy(candidate):\n        raise zope.interface.Invalid(\n            \"Object {0} does not provide {1}\".format(\n                candidate, iface.__name__))\n\n    if not hasattr(candidate, '__call__'):\n        raise zope.interface.Invalid(\n            \"Object {0} does not call {1}\".format(\n                candidate, iface.__name__))\n\n    # Check for declared methods\n    if not hasattr(candidate, '__call__'):\n        try:\n            candidate(None, None)\n        except zope.interface.Invalid:\n            pass\n        else:\n            return True\n\n    # Check for declared attributes\n    if tentative:\n        for name in iface.__dict__.keys():\n            if not hasattr(candidate, name):\n                raise zope.interface.Invalid(\n           "], "level": "file_runnable", "generate_results": [{"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    try:\n        providedBy = iface.providedBy\n    except AttributeError:\n        if not tentative:\n            raise\n        return False\n\n    verifyObjectInvariants(iface, candidate, tentative)\n    return verifyCandidateProperties(iface, candidate)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    try:\n        verifyObject(iface, candidate)\n    except Invalid as e:\n        if e.args[0]!= zope.interface.Invalid:\n            raise\n        if not tentative:\n            raise\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    try:\n        return iface.providedBy(candidate)\n    except KeyError:\n        pass\n    if not tentative:\n        try:\n            verifyClass(iface, candidate)\n        except KeyError:\n            raise\n        except Invalid as e:\n            if hasattr(candidate, '__name__') and candidate.__name__!= iface.__name__:\n                raise\n            try:\n                # At this point we are not yet in the context of a candidate\n                # class, so we should not expect further errors.\n                delattr(candidate, iface.__name__)\n            except KeyError:\n                pass\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    if not isinstance(candidate, Candidate):\n        raise TypeError(\n            \"Candidate must be of type {0}, not {1}\".format(Candidate, candidate))\n\n    if not isinstance(iface, Interface):\n        raise TypeError(\n            \"Interface must be of type {0}, not {1}\".format(Interface, iface))\n\n    if not hasattr(candidate, 'providedBy'):\n        # Check to make sure the candidate is actually a candidate (i.e. not\n        # an interface).\n        if not isclass(candidate):\n            raise TypeError(\"Candidate must be a class, not a class instance\")\n\n        return False\n\n    if not ismethod(iface.providedBy):\n        # Check to make sure the candidate is actually a method.\n        if not ismethod(candidate):\n            raise TypeError(\"Candidate must be a method, not a method instance\")\n\n        return False\n\n    # All checks passed.\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    if iface.providedBy(candidate):\n        return True\n    if not hasattr(candidate, '__parent__'):\n        raise Invalid(\n            \"Candidate %s doesn't provide an '__parent__' attribute\" % candidate)\n    if not hasattr(candidate, '__name__'):\n        raise Invalid(\n            \"Candidate %s doesn't provide an '__name__' attribute\" % candidate)\n\n    # Check the '__providedBy__' attribute\n    if not hasattr(candidate, '__provides__'):\n        # Candidate has no '__provides__' attribute; assume it's a valid interface\n        return True\n    if candidate.__provides__ is None:\n        # Candidate has no '__provides__' attribute; assume it's an instance\n        return True\n    # Check the '__provides__' attribute for a valid interface\n    if not hasattr(candidate, '__provides__') or \\\n    ", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    if not candidate.providedBy(iface):\n        msg = \"%s does not provide %s\" % (iface, candidate)\n        raise zope.interface.Invalid(msg, candidate)\n    if not hasattr(iface, 'providedBy'):\n        # For Zope 2 compatibility reasons, providedBy is a method on\n        # Candidate, not an instance method. In this case, we want to\n        # catch that case.\n        msg = \"%s does not define providedBy\" % iface\n        raise zope.interface.Invalid(msg, candidate)\n    if not iface.providedBy(candidate):\n        if tentative:\n            raise zope.interface.Invalid(\n                \"Candidate %s is not provided by %s\" % (candidate, iface)\n            )\n        else:\n            msg = \"%s has not provided %s\" % (iface, candidate)\n            raise zope.interface.Invalid(msg, candidate)\n   ", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    if not isInterface(candidate):\n        raise zope.interface.Invalid(\n            \"Object %s is not an interface\" % (candidate,))\n    if not hasattr(candidate, 'providedBy'):\n        raise zope.interface.Invalid(\n            \"Object %s has no 'providedBy' attribute\" % (candidate,))\n    if not hasattr(candidate, '__providedBy__'):\n        raise zope.interface.Invalid(\n            \"Object %s has no '__providedBy__' attribute\" % (candidate,))\n    if tentative:\n        return True\n    # Make sure the candidate claims that it provides the interface\n    # directly.\n    if not iface.providedBy(candidate):\n        raise zope.interface.Invalid(\n            \"Object %s is not an interface but %r\" % (candidate, iface))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    if not IInterface.providedBy(candidate):\n        return False\n    if not verifyObject(iface, candidate, tentative=True):\n        return False\n    if not verifyObject(iface, candidate, tentative=False):\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    if iface.providedBy(candidate) and not tentative:\n        return True\n\n    # The candidate claims that it *cannot* provide the interface.  We\n    # do this here instead of in ``providedBy`` to avoid dependency on\n    # ``zope.interface`` when we need to.\n    try:\n        providedBy(candidate)\n    except CannotProvide:\n        if not tentative:\n            raise\n\n        return False\n\n    # The candidate claims that it *cannot* provide the interface.  We\n    # do this here instead of in ``providedBy`` to avoid dependency on\n    # ``zope.interface`` when we need to.\n    try:\n        providedBy(candidate, iface)\n    except CannotProvide:\n        if not tentative:\n            raise\n\n        return False\n\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyObject(iface, candidate, tentative=False):\n    if not iface.providedBy(candidate):\n        raise zope.interface.Invalid(\n            \"Object {0} does not provide {1}\".format(\n                candidate, iface.__name__))\n\n    if not hasattr(candidate, '__call__'):\n        raise zope.interface.Invalid(\n            \"Object {0} does not call {1}\".format(\n                candidate, iface.__name__))\n\n    # Check for declared methods\n    if not hasattr(candidate, '__call__'):\n        try:\n            candidate(None, None)\n        except zope.interface.Invalid:\n            pass\n        else:\n            return True\n\n    # Check for declared attributes\n    if tentative:\n        for name in iface.__dict__.keys():\n            if not hasattr(candidate, name):\n                raise zope.interface.Invalid(\n           ", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/verify.py", "project": "pexip/os-zope", "name": "verifyClass", "docstring": "Verify that the *candidate* might correctly provide *iface*.", "ques_id": "62b8b4c1eb7e40a82d2d1139", "code": ["def verifyClass(iface, candidate, tentative=False):\n    if candidate is None:\n        return\n    verifyClass(iface.__class__, candidate, tentative=tentative)\n", "def verifyClass(iface, candidate, tentative=False):\n    if not ITentative.providedBy(candidate):\n        raise TypeError(\n            \"%s is not a subclass of %s\" % (candidate, iface))\n\n    # Make sure that the candidate is actually a valid candidate and\n    # not just a regular candidate.\n    if not ITentative.providedBy(candidate):\n        if not tentative:\n            raise ValueError(\n                \"Can't provide %r as a candidate\" % (candidate,))\n        else:\n            return False\n\n    # Make sure that the candidate is actually a valid interface\n    # and not just a regular candidate.\n    if not IContent.providedBy(candidate):\n        if not tentative:\n            raise ValueError(\n                \"Can't provide %r as a candidate\" % (candidate,))\n        else:\n            return False\n\n    return True\n", "def verifyClass(iface, candidate, tentative=False):\n    if not issubclass(iface, Candidate):\n        return False\n    if not issubclass(candidate, iface):\n        if tentative:\n            return False\n        raise ValueError(\n            \"Class %s does not match Candidate %s\" % (iface, candidate)\n        )\n    return True\n", "def verifyClass(iface, candidate, tentative=False):\n    if not issubclass(iface, Candidate):\n        if tentative:\n            return False\n        else:\n            raise TypeError(\"%s is not a Candidate subclass\" % iface)\n    if iface is Candidate:\n        if not issubclass(candidate, iface):\n            if tentative:\n                return False\n            else:\n                raise TypeError(\"%s is not a subclass of %s\" % (candidate, iface))\n    else:\n        if not issubclass(candidate, iface):\n            if tentative:\n                return False\n            else:\n                raise TypeError(\"%s is not a subclass of %s\" % (candidate, iface))\n    return True\n", "def verifyClass(iface, candidate, tentative=False):\n    verify.verifyClass(iface, candidate)\n", "def verifyClass(iface, candidate, tentative=False):\n    if issubclass(iface, Candidate) and not tentative:\n        return\n\n    msg = \"%s must provide %s, got %s\" % (iface, candidate, type(candidate))\n    assert iface is candidate, msg\n", "def verifyClass(iface, candidate, tentative=False):\n    if not candidate.providedBy(iface):\n        if tentative:\n            return False\n        raise TypeError(\"%s doesn't provide %s\" % (iface, candidate))\n    return True\n", "def verifyClass(iface, candidate, tentative=False):\n    if not candidate.providedBy(iface):\n        if tentative:\n            return False\n        raise TypeError(\"%s is not a subclass of %s\" % (iface, candidate))\n    return True\n", "def verifyClass(iface, candidate, tentative=False):\n    verify.verifyClass(iface, candidate)\n    if not issubclass(candidate, iface):\n        if tentative:\n            return False\n        raise TypeError(\"%r is not a subclass of %r\" % (candidate, iface))\n    return True\n", "def verifyClass(iface, candidate, tentative=False):\n    if not verifyClassLocation(iface, candidate.__class__, tentative):\n        return False\n    if not verifyClassAttributes(iface, candidate):\n        return False\n    return True\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    if candidate is None:\n        return\n    verifyClass(iface.__class__, candidate, tentative=tentative)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    if not ITentative.providedBy(candidate):\n        raise TypeError(\n            \"%s is not a subclass of %s\" % (candidate, iface))\n\n    # Make sure that the candidate is actually a valid candidate and\n    # not just a regular candidate.\n    if not ITentative.providedBy(candidate):\n        if not tentative:\n            raise ValueError(\n                \"Can't provide %r as a candidate\" % (candidate,))\n        else:\n            return False\n\n    # Make sure that the candidate is actually a valid interface\n    # and not just a regular candidate.\n    if not IContent.providedBy(candidate):\n        if not tentative:\n            raise ValueError(\n                \"Can't provide %r as a candidate\" % (candidate,))\n        else:\n            return False\n\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    if not issubclass(iface, Candidate):\n        return False\n    if not issubclass(candidate, iface):\n        if tentative:\n            return False\n        raise ValueError(\n            \"Class %s does not match Candidate %s\" % (iface, candidate)\n        )\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    if not issubclass(iface, Candidate):\n        if tentative:\n            return False\n        else:\n            raise TypeError(\"%s is not a Candidate subclass\" % iface)\n    if iface is Candidate:\n        if not issubclass(candidate, iface):\n            if tentative:\n                return False\n            else:\n                raise TypeError(\"%s is not a subclass of %s\" % (candidate, iface))\n    else:\n        if not issubclass(candidate, iface):\n            if tentative:\n                return False\n            else:\n                raise TypeError(\"%s is not a subclass of %s\" % (candidate, iface))\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    verify.verifyClass(iface, candidate)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    if issubclass(iface, Candidate) and not tentative:\n        return\n\n    msg = \"%s must provide %s, got %s\" % (iface, candidate, type(candidate))\n    assert iface is candidate, msg\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    if not candidate.providedBy(iface):\n        if tentative:\n            return False\n        raise TypeError(\"%s doesn't provide %s\" % (iface, candidate))\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    if not candidate.providedBy(iface):\n        if tentative:\n            return False\n        raise TypeError(\"%s is not a subclass of %s\" % (iface, candidate))\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    verify.verifyClass(iface, candidate)\n    if not issubclass(candidate, iface):\n        if tentative:\n            return False\n        raise TypeError(\"%r is not a subclass of %r\" % (candidate, iface))\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verifyClass(iface, candidate, tentative=False):\n    if not verifyClassLocation(iface, candidate.__class__, tentative):\n        return False\n    if not verifyClassAttributes(iface, candidate):\n        return False\n    return True\n", "is_pass": false, "return_code": 1}]}
{"file_path": "src/zope/interface/advice.py", "project": "pexip/os-zope", "name": "determineMetaclass", "docstring": "Determine metaclass from 1+ bases and optional explicit __metaclass__", "ques_id": "62b8b559eb7e40a82d2d11f6", "code": ["def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = []\n\n    for base in bases:\n        if hasattr(base, '__metaclass__'):\n            if base.__metaclass__ not in explicit_mc:\n                return base.__metaclass__\n        elif hasattr(base, '__swagger_ref_object__'):\n            if base.__swagger_ref_object__ not in explicit_mc:\n                return base.__swagger_ref_object__\n        elif hasattr(base, '__swagger_ref_object__:'):\n            return base.__swagger_ref_object__\n\n    # No explicit metaclass found\n    return None\n", "def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = []\n    for base in bases:\n        if hasattr(base, \"__metaclass__\"):\n            if base.__metaclass__ not in explicit_mc:\n                explicit_mc.append(base.__metaclass__)\n                return base.__metaclass__\n    explicit_mc.append(type(\"UnknownMeta\", (object,), {}))\n    return type(\"UnknownMeta\", (object,), {})\n", "def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = {}\n    for base in bases:\n        if issubclass(base, type) and issubclass(base, MetaBase) and base in explicit_mc:\n            return base, explicit_mc[base]\n        elif issubclass(base, type):\n            return base, explicit_mc\n    return type, explicit_mc\n", "def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = []\n    for base in bases:\n        if issubclass(base, type) and base not in explicit_mc:\n            return base\n        elif issubclass(base, type) and base in explicit_mc:\n            return base\n        elif (issubclass(base, type) and\n                issubclass(base, type) and\n                base is not type):\n            return base\n        elif issubclass(base, type) and base not in explicit_mc:\n            return base\n    explicit_mc.append(bases[0])\n    return type\n", "def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = []\n    for base in bases:\n        if issubclass(base, Configurable):\n            return (base, explicit_mc)\n        if issubclass(base, ConfigurableMeta):\n            explicit_mc.append(base)\n            return (base, explicit_mc)\n    return (Configurable, explicit_mc)\n", "def determineMetaclass(bases, explicit_mc=None):\n    cls = None\n    if explicit_mc is None:\n        explicit_mc = []\n    for base in bases:\n        if hasattr(base, \"__abstractmethods__\"):\n            for meth in base.__abstractmethods__:\n                if meth not in explicit_mc:\n                    explicit_mc.append(meth)\n        if (issubclass(base, type) and\n                meth_is_abstract(meth) and\n                meth.__name__!= \"__abstractmethods__\"):\n            if meth.__module__ == base.__module__:\n                cls = base\n    if cls is None:\n        cls = type\n    return cls\n", "def determineMetaclass(bases, explicit_mc=None):\n    def getMetaclass(cls):\n        cls_meta = getattr(cls, \"__metaclass__\", None)\n        if cls_meta is not None:\n            return cls_meta\n        bases_meta = getattr(bases[0], \"__metaclass__\", None)\n        if bases_meta is not None:\n            return bases_meta\n        metaclass = getattr(cls, \"__qualname__\", None)\n        if metaclass is not None:\n            return metaclass\n        if explicit_mc is not None:\n            # explicit_mc is not None means we have a base class\n            # and we have to look at the __qualname__ of the bases\n            # classes and look for the metaclass of the bases\n            bases_meta = getattr(bases[0], explicit_mc, None)\n            if bases_meta is not None:\n            ", "def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = []\n    for base in bases:\n        if issubclass(base, type) and base not in explicit_mc:\n            return base\n        elif issubclass(base, type):\n            return class_meta\n        elif issubclass(base, types.ModuleType):\n            module_meta = type(\"Meta\", (type,), {})\n            return module_meta\n        elif issubclass(base, type) and base not in explicit_mc:\n            return class_meta\n        elif issubclass(base, type) and base in explicit_mc:\n            return explicit_mc.pop()\n    # No explicit metaclass was found\n    return class_meta\n", "def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = []\n    for base in bases:\n        if issubclass(base, type):\n            return base, explicit_mc\n        if issubclass(base, type) and base is not object:\n            return base, explicit_mc + [base]\n    return bases[0], explicit_mc\n", "def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = []\n    for base in bases:\n        if issubclass(base, type) and base not in explicit_mc:\n            return base\n        if issubclass(base, type) and base in explicit_mc:\n            return base\n        if issubclass(base, object) and base not in explicit_mc:\n            return base\n        if hasattr(base, '__metaclass__'):\n            if base.__metaclass__ not in explicit_mc:\n                return base.__metaclass__\n            else:\n                explicit_mc.append(base.__metaclass__)\n                continue\n        return None\n    return None\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = []\n\n    for base in bases:\n        if hasattr(base, '__metaclass__'):\n            if base.__metaclass__ not in explicit_mc:\n                return base.__metaclass__\n        elif hasattr(base, '__swagger_ref_object__'):\n            if base.__swagger_ref_object__ not in explicit_mc:\n                return base.__swagger_ref_object__\n        elif hasattr(base, '__swagger_ref_object__:'):\n            return base.__swagger_ref_object__\n\n    # No explicit metaclass found\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = []\n    for base in bases:\n        if hasattr(base, \"__metaclass__\"):\n            if base.__metaclass__ not in explicit_mc:\n                explicit_mc.append(base.__metaclass__)\n                return base.__metaclass__\n    explicit_mc.append(type(\"UnknownMeta\", (object,), {}))\n    return type(\"UnknownMeta\", (object,), {})\n", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = {}\n    for base in bases:\n        if issubclass(base, type) and issubclass(base, MetaBase) and base in explicit_mc:\n            return base, explicit_mc[base]\n        elif issubclass(base, type):\n            return base, explicit_mc\n    return type, explicit_mc\n", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = []\n    for base in bases:\n        if issubclass(base, type) and base not in explicit_mc:\n            return base\n        elif issubclass(base, type) and base in explicit_mc:\n            return base\n        elif (issubclass(base, type) and\n                issubclass(base, type) and\n                base is not type):\n            return base\n        elif issubclass(base, type) and base not in explicit_mc:\n            return base\n    explicit_mc.append(bases[0])\n    return type\n", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = []\n    for base in bases:\n        if issubclass(base, Configurable):\n            return (base, explicit_mc)\n        if issubclass(base, ConfigurableMeta):\n            explicit_mc.append(base)\n            return (base, explicit_mc)\n    return (Configurable, explicit_mc)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    cls = None\n    if explicit_mc is None:\n        explicit_mc = []\n    for base in bases:\n        if hasattr(base, \"__abstractmethods__\"):\n            for meth in base.__abstractmethods__:\n                if meth not in explicit_mc:\n                    explicit_mc.append(meth)\n        if (issubclass(base, type) and\n                meth_is_abstract(meth) and\n                meth.__name__!= \"__abstractmethods__\"):\n            if meth.__module__ == base.__module__:\n                cls = base\n    if cls is None:\n        cls = type\n    return cls\n", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    def getMetaclass(cls):\n        cls_meta = getattr(cls, \"__metaclass__\", None)\n        if cls_meta is not None:\n            return cls_meta\n        bases_meta = getattr(bases[0], \"__metaclass__\", None)\n        if bases_meta is not None:\n            return bases_meta\n        metaclass = getattr(cls, \"__qualname__\", None)\n        if metaclass is not None:\n            return metaclass\n        if explicit_mc is not None:\n            # explicit_mc is not None means we have a base class\n            # and we have to look at the __qualname__ of the bases\n            # classes and look for the metaclass of the bases\n            bases_meta = getattr(bases[0], explicit_mc, None)\n            if bases_meta is not None:\n            ", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = []\n    for base in bases:\n        if issubclass(base, type) and base not in explicit_mc:\n            return base\n        elif issubclass(base, type):\n            return class_meta\n        elif issubclass(base, types.ModuleType):\n            module_meta = type(\"Meta\", (type,), {})\n            return module_meta\n        elif issubclass(base, type) and base not in explicit_mc:\n            return class_meta\n        elif issubclass(base, type) and base in explicit_mc:\n            return explicit_mc.pop()\n    # No explicit metaclass was found\n    return class_meta\n", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = []\n    for base in bases:\n        if issubclass(base, type):\n            return base, explicit_mc\n        if issubclass(base, type) and base is not object:\n            return base, explicit_mc + [base]\n    return bases[0], explicit_mc\n", "is_pass": false, "return_code": 1}, {"generate_code": "def determineMetaclass(bases, explicit_mc=None):\n    if explicit_mc is None:\n        explicit_mc = []\n    for base in bases:\n        if issubclass(base, type) and base not in explicit_mc:\n            return base\n        if issubclass(base, type) and base in explicit_mc:\n            return base\n        if issubclass(base, object) and base not in explicit_mc:\n            return base\n        if hasattr(base, '__metaclass__'):\n            if base.__metaclass__ not in explicit_mc:\n                return base.__metaclass__\n            else:\n                explicit_mc.append(base.__metaclass__)\n                continue\n        return None\n    return None\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/cache.py", "project": "pexip/os-python-cachetools", "name": "pop", "docstring": "D.pop(k[,d]) -> v, remove specified key and return the corresponding value.\nIf key is not found, d is returned if given, otherwise KeyError is raised.", "ques_id": "62b8d22a48ba5a41d1c3f47d", "code": ["def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = None\n    value = super(DotDict, self).pop(key, default)\n    if value is not default:\n        self.__dirty = True\n    return value\n", "def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = self.__default\n    return super(DefaultGetDict, self).pop(key, default)\n", "def pop(self, key, default=__marker):\n    try:\n        value = self[key]\n        del self[key]\n        return value\n    except KeyError:\n        if default is self.__marker:\n            raise\n        return default\n", "def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = None\n    return super(MarkerDict, self).pop(key, default)\n", "def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = None\n    value = dict.pop(self, key, default)\n    if value is default:\n        if default is not self.__marker:\n            return default\n        raise KeyError(key)\n    return value\n", "def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = self[key] = type(self).__new__(self.__class__)\n    return super(_CaseInsensitiveDict, self).pop(key.lower(), default)\n", "def pop(self, key, default=__marker):\n    if key not in self:\n        if default is self.__marker:\n            raise KeyError(key)\n        return default\n    value = dict.pop(self, key)\n    self.__map.remove(key)\n    return value\n", "def pop(self, key, default=__marker):\n    if key in self:\n        super(DotDict, self).pop(key)\n        self.__dirty = True\n    elif default is self.__marker:\n        if len(self) == 0:\n            raise KeyError('pop from empty DotDict')\n        return self[-1]\n    else:\n        if default is not self.__marker:\n            return default\n        raise KeyError('Key not found: %r' % key)\n", "def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = None\n    return super(MarkDict, self).pop(key, default)\n", "def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = self[-1][2]\n    return super(DotDict, self).pop(key, default)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = None\n    value = super(DotDict, self).pop(key, default)\n    if value is not default:\n        self.__dirty = True\n    return value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = self.__default\n    return super(DefaultGetDict, self).pop(key, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    try:\n        value = self[key]\n        del self[key]\n        return value\n    except KeyError:\n        if default is self.__marker:\n            raise\n        return default\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = None\n    return super(MarkerDict, self).pop(key, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = None\n    value = dict.pop(self, key, default)\n    if value is default:\n        if default is not self.__marker:\n            return default\n        raise KeyError(key)\n    return value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = self[key] = type(self).__new__(self.__class__)\n    return super(_CaseInsensitiveDict, self).pop(key.lower(), default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    if key not in self:\n        if default is self.__marker:\n            raise KeyError(key)\n        return default\n    value = dict.pop(self, key)\n    self.__map.remove(key)\n    return value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    if key in self:\n        super(DotDict, self).pop(key)\n        self.__dirty = True\n    elif default is self.__marker:\n        if len(self) == 0:\n            raise KeyError('pop from empty DotDict')\n        return self[-1]\n    else:\n        if default is not self.__marker:\n            return default\n        raise KeyError('Key not found: %r' % key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = None\n    return super(MarkDict, self).pop(key, default)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def pop(self, key, default=__marker):\n    if default is self.__marker:\n        default = self[-1][2]\n    return super(DotDict, self).pop(key, default)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/lfu.py", "project": "pexip/os-python-cachetools", "name": "popitem", "docstring": "Remove and return the `(key, value)` pair least frequently used.", "ques_id": "62b8d23748ba5a41d1c3f497", "code": ["def popitem(self):\n    freq = dict.popitem(self)\n    return (freq[0], freq[1])\n", "def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    freq_dct = dict.popitem(self)\n    key = freq_dct.pop(self._freq)\n    return (key, freq_dct[self._key_field])\n", "def popitem(self):\n    freq = dict.popitem(self)\n    return freq[0], freq[1]\n", "def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    return FrequentTree.popitem(self)\n", "def popitem(self):\n    try:\n        key = next(iter(self))\n        value = self[key]\n        del self[key]\n        return key, value\n    except KeyError:\n        raise KeyError('Nothing to popitem.')\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def popitem(self):\n    freq = dict.popitem(self)\n    return (freq[0], freq[1])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    freq_dct = dict.popitem(self)\n    key = freq_dct.pop(self._freq)\n    return (key, freq_dct[self._key_field])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    freq = dict.popitem(self)\n    return freq[0], freq[1]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return FrequentTree.popitem(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = next(iter(self))\n        value = self[key]\n        del self[key]\n        return key, value\n    except KeyError:\n        raise KeyError('Nothing to popitem.')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/lru.py", "project": "pexip/os-python-cachetools", "name": "popitem", "docstring": "Remove and return the `(key, value)` pair least recently used.", "ques_id": "62b8d23a48ba5a41d1c3f499", "code": ["def popitem(self):\n    try:\n        return dict.popitem(self)\n    except KeyError as e:\n        raise exceptions.DoesNotExist(str(e))\n", "def popitem(self):\n    for k in reversed(self._shallow_copy):\n        try:\n            del self[k]\n        except KeyError:\n            pass\n    return self._shallow_copy.pop()\n", "def popitem(self):\n    value = dict.popitem(self)\n    self._setitem(value[0], value[1])\n    return value\n", "def popitem(self):\n    try:\n        key = list(self._table.keys())[0]\n        return (key, self._table[key])\n    except IndexError:\n        raise KeyError('popitem(): dictionary is already empty')\n", "def popitem(self):\n    try:\n        key = list(self._map.keys())[0]\n        value = self[key]\n        del self[key]\n        return (key, value)\n    except IndexError:\n        raise KeyError('popitem(): dictionary is already empty')\n", "def popitem(self):\n    if not self:\n        raise KeyError('popitem(): dictionary is empty')\n    key = self._keys[-1]\n    value = dict.pop(self, key)\n    self._keys.remove(key)\n    return (key, value)\n", "def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    if not self:\n        raise KeyError('popitem(): dictionary is already empty')\n    key = list(self._table.keys())[0]\n    value = self._table[key]\n    self._table.pop(key)\n    return (key, value)\n", "def popitem(self):\n    try:\n        key = next(iter(self))\n        value = self[key]\n        del self[key]\n        return key, value\n    except (StopIteration, KeyError):\n        raise KeyError('popitem(): dictionary is already empty')\n", "def popitem(self):\n    if not len(self):\n        raise KeyError('popitem(): dictionary is already empty')\n\n    key = list(self._map.keys())[0]\n    item = self._map.pop(key)\n    self._list.remove(item)\n    return (key, item[1])\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def popitem(self):\n    try:\n        return dict.popitem(self)\n    except KeyError as e:\n        raise exceptions.DoesNotExist(str(e))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    for k in reversed(self._shallow_copy):\n        try:\n            del self[k]\n        except KeyError:\n            pass\n    return self._shallow_copy.pop()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    value = dict.popitem(self)\n    self._setitem(value[0], value[1])\n    return value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = list(self._table.keys())[0]\n        return (key, self._table[key])\n    except IndexError:\n        raise KeyError('popitem(): dictionary is already empty')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = list(self._map.keys())[0]\n        value = self[key]\n        del self[key]\n        return (key, value)\n    except IndexError:\n        raise KeyError('popitem(): dictionary is already empty')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    if not self:\n        raise KeyError('popitem(): dictionary is empty')\n    key = self._keys[-1]\n    value = dict.pop(self, key)\n    self._keys.remove(key)\n    return (key, value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    if not self:\n        raise KeyError('popitem(): dictionary is already empty')\n    key = list(self._table.keys())[0]\n    value = self._table[key]\n    self._table.pop(key)\n    return (key, value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = next(iter(self))\n        value = self[key]\n        del self[key]\n        return key, value\n    except (StopIteration, KeyError):\n        raise KeyError('popitem(): dictionary is already empty')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    if not len(self):\n        raise KeyError('popitem(): dictionary is already empty')\n\n    key = list(self._map.keys())[0]\n    item = self._map.pop(key)\n    self._list.remove(item)\n    return (key, item[1])\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/mru.py", "project": "pexip/os-python-cachetools", "name": "popitem", "docstring": "Remove and return the `(key, value)` pair most recently used.", "ques_id": "62b8d23c48ba5a41d1c3f49b", "code": ["def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    if not self:\n        raise KeyError('popitem(): dictionary is already empty')\n\n    key = list(self._saved_keys)[-1]\n    value = dict.pop(self, key)\n    self._saved_keys.remove(key)\n    return (key, value)\n", "def popitem(self):\n    raise NotImplementedError\n", "def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    key = self._dict.popitem()[0]\n    return (key, self[key])\n", "def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    try:\n        return dict.popitem(self)\n    except KeyError as e:\n        raise exceptions.BadRequestKeyError(e)\n", "def popitem(self):\n    return dict.popitem(self)[0]\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    if not self:\n        raise KeyError('popitem(): dictionary is already empty')\n\n    key = list(self._saved_keys)[-1]\n    value = dict.pop(self, key)\n    self._saved_keys.remove(key)\n    return (key, value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    raise NotImplementedError\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    key = self._dict.popitem()[0]\n    return (key, self[key])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        return dict.popitem(self)\n    except KeyError as e:\n        raise exceptions.BadRequestKeyError(e)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "cachetools/rr.py", "project": "pexip/os-python-cachetools", "name": "popitem", "docstring": "Remove and return a random `(key, value)` pair.", "ques_id": "62b8d23e48ba5a41d1c3f49e", "code": ["def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    try:\n        key = random.choice(list(self))\n    except IndexError:\n        raise KeyError('popitem(): dictionary is empty')\n    else:\n        value = dict.pop(self, key)\n        return key, value\n", "def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    return dict.popitem(self)[0]\n", "def popitem(self):\n    try:\n        return dict.popitem(self)\n    except KeyError as e:\n        raise exceptions.NotFound(str(e))\n", "def popitem(self):\n    return self._db.spop(self.key)\n", "def popitem(self):\n    return super(Documents, self).popitem()[0]\n", "def popitem(self):\n    return dict.popitem(self)\n", "def popitem(self):\n    try:\n        key = random.choice(self._table)\n        self._table.pop(key)\n        return key, self[key]\n    except KeyError:\n        raise KeyError('Popitem from an empty hash table.')\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = random.choice(list(self))\n    except IndexError:\n        raise KeyError('popitem(): dictionary is empty')\n    else:\n        value = dict.pop(self, key)\n        return key, value\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        return dict.popitem(self)\n    except KeyError as e:\n        raise exceptions.NotFound(str(e))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return self._db.spop(self.key)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return super(Documents, self).popitem()[0]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    return dict.popitem(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def popitem(self):\n    try:\n        key = random.choice(self._table)\n        self._table.pop(key)\n        return key, self[key]\n    except KeyError:\n        raise KeyError('Popitem from an empty hash table.')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "sqlparams/__init__.py", "project": "cpburnz/python-sql-parameters", "name": "_create_in_regex", "docstring": "Create the in-style parameter regular expression.\n\nReturns the in-style parameter regular expression (:class:`re.Pattern`).", "ques_id": "62b43425903eeb48555d3ea1", "code": ["def _create_in_regex(self) -> Pattern:\n    in_regex = Pattern(r\"\\b(?:{})\\b\".format(self._pattern))\n    in_regex.group = \"parameter\"\n    return in_regex\n", "def _create_in_regex(self) -> Pattern:\n    return re.compile(r\"\\b({})\\b\".format(\n        '|'.join('(?:{})'.format(x) for x in STATIC_ATTRIBUTES)), flags=re.IGNORECASE)\n", "def _create_in_regex(self) -> Pattern:\n    return re.compile(r\"(?:\\b([a-zA-Z_][a-zA-Z_0-9]*)\\b)\")\n", "def _create_in_regex(self) -> Pattern:\n    return re.compile(r'\\[([a-zA-Z0-9_]+)\\]')\n", "def _create_in_regex(self) -> Pattern:\n    return re.compile(r\"(?i)\\b({param})\\b\".format(\n        param=ParameterName.IN.value\n    ))\n", "def _create_in_regex(self) -> Pattern:\n    return re.compile(r'(\\b(?:{})\\b)'.format(\n        '|'.join(\n            '(?P<{}>{})'.format(name, pattern) for name, pattern in self._patterns\n        )\n    ), flags=re.IGNORECASE)\n", "def _create_in_regex(self) -> Pattern:\n    return re.compile(r\"\\b({param_name})\\b\".format(\n        param_name=Parameter._in_re.param_name\n    ), flags=re.IGNORECASE)\n", "def _create_in_regex(self) -> Pattern:\n    return re.compile(r\"\\[([^\\]]+)\\]\")\n", "def _create_in_regex(self) -> Pattern:\n    return re.compile(IN_STYLE_PATTERN)\n", "def _create_in_regex(self) -> Pattern:\n    return re.compile(r'(?P<{param_name}>[^/]*)(/(?P<{param_name}>[^/]*))?'.format(\n        param_name=self._in_param_regex_name\n    ))\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def _create_in_regex(self) -> Pattern:\n    in_regex = Pattern(r\"\\b(?:{})\\b\".format(self._pattern))\n    in_regex.group = \"parameter\"\n    return in_regex\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n    return re.compile(r\"\\b({})\\b\".format(\n        '|'.join('(?:{})'.format(x) for x in STATIC_ATTRIBUTES)), flags=re.IGNORECASE)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n    return re.compile(r\"(?:\\b([a-zA-Z_][a-zA-Z_0-9]*)\\b)\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n    return re.compile(r'\\[([a-zA-Z0-9_]+)\\]')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n    return re.compile(r\"(?i)\\b({param})\\b\".format(\n        param=ParameterName.IN.value\n    ))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n    return re.compile(r'(\\b(?:{})\\b)'.format(\n        '|'.join(\n            '(?P<{}>{})'.format(name, pattern) for name, pattern in self._patterns\n        )\n    ), flags=re.IGNORECASE)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n    return re.compile(r\"\\b({param_name})\\b\".format(\n        param_name=Parameter._in_re.param_name\n    ), flags=re.IGNORECASE)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n    return re.compile(r\"\\[([^\\]]+)\\]\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n    return re.compile(IN_STYLE_PATTERN)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_in_regex(self) -> Pattern:\n    return re.compile(r'(?P<{param_name}>[^/]*)(/(?P<{param_name}>[^/]*))?'.format(\n        param_name=self._in_param_regex_name\n    ))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "sqlparams/__init__.py", "project": "cpburnz/python-sql-parameters", "name": "_create_converter", "docstring": "Create the parameter style converter.\n\nReturns the parameter style converter (:class:`._converting._Converter`).", "ques_id": "62b43426903eeb48555d3ea2", "code": ["def _create_converter(self) -> _converting._Converter:\n    return _Converter()\n", "def _create_converter(self) -> _converting._Converter:\n    return _Converter()\n", "def _create_converter(self) -> _converting._Converter:\n    return _Converter(self)\n", "def _create_converter(self) -> _converting._Converter:\n    return _Converter(self)\n", "def _create_converter(self) -> _converting._Converter:\n    return _Converter()\n", "def _create_converter(self) -> _converting._Converter:\n    converter = _converting._Converter()\n    converter.for_type(_to_enum(\n        'FLOAT_TYPE', float), float)\n    converter.for_type(_to_enum(\n        'DOUBLE_PRECISION', int), float)\n    converter.for_type(_to_enum(\n        'LONG_TYPE', long), long)\n    converter.for_type(_to_enum(\n        'STRING_TYPE', str), str)\n    converter.for_type(_to_enum(\n        'UNICODE_TYPE', unicode), str)\n    return converter\n", "def _create_converter(self) -> _converting._Converter:\n    return _Converter()\n", "def _create_converter(self) -> _converting._Converter:\n    return _Converter()\n", "def _create_converter(self) -> _converting._Converter:\n    return _Converter()\n", "def _create_converter(self) -> _converting._Converter:\n    return _Converter(self)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def _create_converter(self) -> _converting._Converter:\n    return _Converter()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n    return _Converter()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n    return _Converter(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n    return _Converter(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n    return _Converter()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n    converter = _converting._Converter()\n    converter.for_type(_to_enum(\n        'FLOAT_TYPE', float), float)\n    converter.for_type(_to_enum(\n        'DOUBLE_PRECISION', int), float)\n    converter.for_type(_to_enum(\n        'LONG_TYPE', long), long)\n    converter.for_type(_to_enum(\n        'STRING_TYPE', str), str)\n    converter.for_type(_to_enum(\n        'UNICODE_TYPE', unicode), str)\n    return converter\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n    return _Converter()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n    return _Converter()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n    return _Converter()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _create_converter(self) -> _converting._Converter:\n    return _Converter(self)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "dateutil/parser/isoparser.py", "project": "pexip/os-python-dateutil", "name": "isoparse", "docstring": "Parse an ISO-8601 datetime string into a :class:`datetime.datetime`.\n\nAn ISO-8601 datetime string consists of a date portion, followed\noptionally by a time portion - the date and time portions are separated\nby a single character separator, which is ``T`` in the official\nstandard. Incomplete date formats (such as ``YYYY-MM``) may *not* be\ncombined with a time portion.\n\nSupported date formats are:\n\nCommon:\n\n- ``YYYY``\n- ``YYYY-MM`` or ``YYYYMM``\n- ``YYYY-MM-DD`` or ``YYYYMMDD``\n\nUncommon:\n\n- ``YYYY-Www`` or ``YYYYWww`` - ISO week (day defaults to 0)\n- ``YYYY-Www-D`` or ``YYYYWwwD`` - ISO week and day\n\nThe ISO week and day numbering follows the same logic as\n:func:`datetime.date.isocalendar`.\n\nSupported time formats are:\n\n- ``hh``\n- ``hh:mm`` or ``hhmm``\n- ``hh:mm:ss`` or ``hhmmss``\n- ``hh:mm:ss.ssssss`` (Up to 6 sub-second digits)\n\nMidnight is a special case for `hh`, as the standard supports both\n00:00 and 24:00 as a representation. The decimal separator can be\neither a dot or a comma.\n\n\n.. caution::\n\n    Support for fractional components other than seconds is part of the\n    ISO-8601 standard, but is not currently implemented in this parser.\n\nSupported time zone offset formats are:\n\n- `Z` (UTC)\n- `\u00b1HH:MM`\n- `\u00b1HHMM`\n- `\u00b1HH`\n\nOffsets will be represented as :class:`dateutil.tz.tzoffset` objects,\nwith the exception of UTC, which will be represented as\n:class:`dateutil.tz.tzutc`. Time zone offsets equivalent to UTC (such\nas `+00:00`) will also be represented as :class:`dateutil.tz.tzutc`.\n\n:param dt_str:\n    A string or stream containing only an ISO-8601 datetime string\n\n:return:\n    Returns a :class:`datetime.datetime` representing the string.\n    Unspecified components default to their lowest value.\n\n.. warning::\n\n    As of version 2.7.0, the strictness of the parser should not be\n    considered a stable part of the contract. Any valid ISO-8601 string\n    that parses correctly with the default settings will continue to\n    parse correctly in future versions, but invalid strings that\n    currently fail (e.g. ``2017-01-01T00:00+00:00:00``) are not\n    guaranteed to continue failing in future versions if they encode\n    a valid date.\n\n.. versionadded:: 2.7.0", "ques_id": "62b8966c755ee91dce50a154", "code": ["def isoparse(self, dt_str):\n    if not dt_str:\n        return None\n\n    try:\n        dt = datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S')\n    except ValueError:\n        try:\n            dt = datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S.%f')\n        except ValueError:\n            dt = datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S.%f%z')\n        else:\n            # Assume UTC\n            dt = dt - timedelta(seconds=dt.microsecond)\n\n    return dt.replace(tzinfo=None)\n", "def isoparse(self, dt_str):\n    parsed = parse(dt_str, default=None)\n    if parsed is None:\n        raise ValueError('Not a valid datetime string')\n    if parsed.tzinfo:\n        raise ValueError('Not a valid datetime with timezone')\n\n    return parsed\n", "def isoparse(self, dt_str):\n    if 'Z' in dt_str:\n        dt_str = dt_str.replace('Z', 'UTC')\n    dt_str = dt_str.strip()\n\n    if '+' in dt_str:\n        dt_str, tz = dt_str.split('+')\n    else:\n        tz = ''\n\n    if '-' in tz:\n        tz, offset = tz.split('-')\n    else:\n        offset = ''\n\n    try:\n        dt_obj = datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S')\n    except ValueError:\n        raise ParseError('Invalid datetime string: %s' % dt_str)\n\n    if 'Z' in tz:\n        dt_obj = dt_obj.replace(tz, 'UTC%+03d' % int(offset))\n    else:\n        dt_obj = dt_obj.replace(tz, 'UTC%02d' % int(offset))\n\n    return dt_obj.replace(tz=tz)\n", "def isoparse(self, dt_str):\n    if isinstance(dt_str, datetime.datetime):\n        return dt_str\n    elif isinstance(dt_str, six.string_types):\n        dt_str = dt_str.strip()\n\n        if dt_str.endswith('Z'):\n            return datetime.datetime.strptime(dt_str[:-3], '%Y-%m-%dT%H:%M:%S')\n        elif dt_str.endswith('+00:00'):\n            return datetime.datetime.strptime(dt_str[:-9], '%Y-%m-%dT%H:%M:%S')\n\n        return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S')\n\n    raise ValueError('Invalid time zone specified')\n", "def isoparse(self, dt_str):\n    if not isinstance(dt_str, str):\n        raise ValueError('isoparse() expects a string, not %s' % type(dt_str))\n    parsed = dt_str.split(':')\n    if len(parsed) == 1:\n        return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S')\n    elif len(parsed) == 2:\n        return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S.%f')\n    elif len(parsed) == 3:\n        return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S.%f%z')\n    elif len(parsed) == 4:\n        return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S.%f%z')\n    else:\n        raise ValueError('isoparse() expects a single colon, not %s' % parsed)\n", "def isoparse(self, dt_str):\n    # -- SOFT-HYPHEN DATE: YYYY-MM-DD HH:MM:SS.sssss (or eg. +HH:MM:SS.ssss)\n    # -- UNCOMMON DATE: YYYY-MM-DD HH:MM:SS.sssss\n    # -- OFFSET: HHMM:MM\n    # -- SUPPORTED time zone offsets:\n    # -- CURRENCY (UTC) - (Not standard standard)\n    # -- TZ (UTC) - (Not standard standard)\n    # -- TZ (UTC) - (Not standard standard)\n    # -- UTC - (Not standard standard)\n    # -- LAST COMMA DATE: YYYY-MM-DD HH:MM:SS.sssss (or eg. +HH:MM:SS.ssss)\n    # -- LAST COMMA DATE: YYYY-MM-DD HH:MM:SS.ssss\n    # -- LAST COMMA DATE: HH:MM:SS.ssss\n    return isoparser.parse(dt_str, strict=False, ignoretz=False, parse_tzinfo=False)\n", "def isoparse(self, dt_str):\n    parsed = parse(dt_str, default_zone='UTC')\n    if parsed.tzinfo is None:\n        raise ValueError('Date parsing error')\n    return parsed.replace(tzinfo=UTC)\n", "def isoparse(self, dt_str):\n    parsed = parsedatetime.Calendar().parseDT(dt_str)\n    if parsed is None:\n        raise ValueError('isoparse returned None')\n    if parsed[1] is None:\n        offset_str = None\n    else:\n        offset_str, _, _ = parsed[1].partition(':')\n    if parsed[0] is None:\n        return datetime.datetime(*parsed[:3]) + datetime.timedelta(\n            hours=int(offset_str),\n            minutes=int(offset_str)\n        )\n    else:\n        return datetime.datetime(*parsed[:3]) + datetime.timedelta(\n            hours=int(parsed[0]),\n            minutes=int(offset_str),\n            seconds=int(offset_str)\n        )\n", "def isoparse(self, dt_str):\n    try:\n        return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S')\n    except ValueError:\n        return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%SZ')\n", "def isoparse(self, dt_str):\n    return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S')\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def isoparse(self, dt_str):\n    if not dt_str:\n        return None\n\n    try:\n        dt = datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S')\n    except ValueError:\n        try:\n            dt = datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S.%f')\n        except ValueError:\n            dt = datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S.%f%z')\n        else:\n            # Assume UTC\n            dt = dt - timedelta(seconds=dt.microsecond)\n\n    return dt.replace(tzinfo=None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    parsed = parse(dt_str, default=None)\n    if parsed is None:\n        raise ValueError('Not a valid datetime string')\n    if parsed.tzinfo:\n        raise ValueError('Not a valid datetime with timezone')\n\n    return parsed\n", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    if 'Z' in dt_str:\n        dt_str = dt_str.replace('Z', 'UTC')\n    dt_str = dt_str.strip()\n\n    if '+' in dt_str:\n        dt_str, tz = dt_str.split('+')\n    else:\n        tz = ''\n\n    if '-' in tz:\n        tz, offset = tz.split('-')\n    else:\n        offset = ''\n\n    try:\n        dt_obj = datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S')\n    except ValueError:\n        raise ParseError('Invalid datetime string: %s' % dt_str)\n\n    if 'Z' in tz:\n        dt_obj = dt_obj.replace(tz, 'UTC%+03d' % int(offset))\n    else:\n        dt_obj = dt_obj.replace(tz, 'UTC%02d' % int(offset))\n\n    return dt_obj.replace(tz=tz)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    if isinstance(dt_str, datetime.datetime):\n        return dt_str\n    elif isinstance(dt_str, six.string_types):\n        dt_str = dt_str.strip()\n\n        if dt_str.endswith('Z'):\n            return datetime.datetime.strptime(dt_str[:-3], '%Y-%m-%dT%H:%M:%S')\n        elif dt_str.endswith('+00:00'):\n            return datetime.datetime.strptime(dt_str[:-9], '%Y-%m-%dT%H:%M:%S')\n\n        return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S')\n\n    raise ValueError('Invalid time zone specified')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    if not isinstance(dt_str, str):\n        raise ValueError('isoparse() expects a string, not %s' % type(dt_str))\n    parsed = dt_str.split(':')\n    if len(parsed) == 1:\n        return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S')\n    elif len(parsed) == 2:\n        return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S.%f')\n    elif len(parsed) == 3:\n        return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S.%f%z')\n    elif len(parsed) == 4:\n        return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S.%f%z')\n    else:\n        raise ValueError('isoparse() expects a single colon, not %s' % parsed)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    # -- SOFT-HYPHEN DATE: YYYY-MM-DD HH:MM:SS.sssss (or eg. +HH:MM:SS.ssss)\n    # -- UNCOMMON DATE: YYYY-MM-DD HH:MM:SS.sssss\n    # -- OFFSET: HHMM:MM\n    # -- SUPPORTED time zone offsets:\n    # -- CURRENCY (UTC) - (Not standard standard)\n    # -- TZ (UTC) - (Not standard standard)\n    # -- TZ (UTC) - (Not standard standard)\n    # -- UTC - (Not standard standard)\n    # -- LAST COMMA DATE: YYYY-MM-DD HH:MM:SS.sssss (or eg. +HH:MM:SS.ssss)\n    # -- LAST COMMA DATE: YYYY-MM-DD HH:MM:SS.ssss\n    # -- LAST COMMA DATE: HH:MM:SS.ssss\n    return isoparser.parse(dt_str, strict=False, ignoretz=False, parse_tzinfo=False)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    parsed = parse(dt_str, default_zone='UTC')\n    if parsed.tzinfo is None:\n        raise ValueError('Date parsing error')\n    return parsed.replace(tzinfo=UTC)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    parsed = parsedatetime.Calendar().parseDT(dt_str)\n    if parsed is None:\n        raise ValueError('isoparse returned None')\n    if parsed[1] is None:\n        offset_str = None\n    else:\n        offset_str, _, _ = parsed[1].partition(':')\n    if parsed[0] is None:\n        return datetime.datetime(*parsed[:3]) + datetime.timedelta(\n            hours=int(offset_str),\n            minutes=int(offset_str)\n        )\n    else:\n        return datetime.datetime(*parsed[:3]) + datetime.timedelta(\n            hours=int(parsed[0]),\n            minutes=int(offset_str),\n            seconds=int(offset_str)\n        )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    try:\n        return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S')\n    except ValueError:\n        return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%SZ')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def isoparse(self, dt_str):\n    return datetime.datetime.strptime(dt_str, '%Y-%m-%dT%H:%M:%S')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "dateutil/parser/_parser.py", "project": "pexip/os-python-dateutil", "name": "parse", "docstring": "Parse the date/time string into a :class:`datetime.datetime` object.\n\n:param timestr:\n    Any date/time string using the supported formats.\n\n:param default:\n    The default datetime object, if this is a datetime object and not\n    ``None``, elements specified in ``timestr`` replace elements in the\n    default object.\n\n:param ignoretz:\n    If set ``True``, time zones in parsed strings are ignored and a\n    naive :class:`datetime.datetime` object is returned.\n\n:param tzinfos:\n    Additional time zone names / aliases which may be present in the\n    string. This argument maps time zone names (and optionally offsets\n    from those time zones) to time zones. This parameter can be a\n    dictionary with timezone aliases mapping time zone names to time\n    zones or a function taking two parameters (``tzname`` and\n    ``tzoffset``) and returning a time zone.\n\n    The timezones to which the names are mapped can be an integer\n    offset from UTC in seconds or a :class:`tzinfo` object.\n\n    .. doctest::\n       :options: +NORMALIZE_WHITESPACE\n\n        >>> from dateutil.parser import parse\n        >>> from dateutil.tz import gettz\n        >>> tzinfos = {\"BRST\": -7200, \"CST\": gettz(\"America/Chicago\")}\n        >>> parse(\"2012-01-19 17:21:00 BRST\", tzinfos=tzinfos)\n        datetime.datetime(2012, 1, 19, 17, 21, tzinfo=tzoffset(u'BRST', -7200))\n        >>> parse(\"2012-01-19 17:21:00 CST\", tzinfos=tzinfos)\n        datetime.datetime(2012, 1, 19, 17, 21,\n                          tzinfo=tzfile('/usr/share/zoneinfo/America/Chicago'))\n\n    This parameter is ignored if ``ignoretz`` is set.\n\n:param \\*\\*kwargs:\n    Keyword arguments as passed to ``_parse()``.\n\n:return:\n    Returns a :class:`datetime.datetime` object or, if the\n    ``fuzzy_with_tokens`` option is ``True``, returns a tuple, the\n    first element being a :class:`datetime.datetime` object, the second\n    a tuple containing the fuzzy tokens.\n\n:raises ParserError:\n    Raised for invalid or unknown string format, if the provided\n    :class:`tzinfo` is not in a valid format, or if an invalid date\n    would be created.\n\n:raises TypeError:\n    Raised for non-string or character stream input.\n\n:raises OverflowError:\n    Raised if the parsed date exceeds the largest valid C integer on\n    your system.", "ques_id": "62b896de755ee91dce50a183", "code": ["def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime\n        object and not ``None``\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n        ignored and a naive :class:`datetime.datetime` object is returned.\n    :param tzinfos: Additional time zone names which may be present\n        in the string.\n\n       .. doctest::\n            :options: +NORMALIZE_WHITESPACE\n\n            >>> from dateutil.parser import parse\n            >>> from dateutil.tz import gettz\n            >>> parse(\"2012-01-19 17:21:00 BRST\",\n           ...         tzinfos={\"BRST\": gettz(\"UTC\")})\n            datetime.datetime(2012, 1, 19, 17, tzinfo=tzoffset(\"BRST\", -7200))\n    \"\"\"\n", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n\n    :param default: The default datetime object, if this is a datetime\n        object and not ``None``\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n        ignored and a naive :class:`datetime.datetime` object is returned.\n\n    :param tzinfos: Additional time zone names which may be present\n        in the string. This parameter maps time zones (and optionally\n        replacements from those time zones) to time zones.\n\n        This parameter can be a dictionary with time zones names and\n        time zones or a function taking two parameters (``tzname`` and\n        ``tzoffset``) and returning a time zone.\n\n   ..doctest::options: +NORMALIZE_WHITESPACE\n\n        >>> from dateutil.parser import parse\n        >>> parse(\"2012-01-19 17:21:00 BRST\", tzinfo", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n\n    :param default: The default datetime object, if this is a datetime\n        object and not ``None``\n\n    :param ignoretz: If set ``True``, time zones in parsed strings\n        are ignored and a naive :class:`datetime.datetime` object is\n        returned.\n\n    :param tzinfos: Additional time zone names / aliases which may\n        be present in the string. This parameter maps time zones\n        (and optionally replace elements specified in the format\n        ``tzname`` elements with timezones or a function\n        taking two parameters (``tzname`` and ``tzoffset``))\n        to time zones. This parameter can be a dictionary with\n        time zone names and time zones or a function taking two\n        parameters (``tzname`` and ``tzoffset``)\n\n   .. doctest::options: +NOR", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n\n    :param default: The default datetime object, if this is a datetime object\n        and not ``None``, elements specified in ``timestr`` replace\n        elements in the default object.\n\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n        ignored and a naive :class:`datetime.datetime` object is returned.\n\n    :param tzinfos: Additional time zone names / aliases which may be\n        present in the string. This parameter maps time zones (and\n        optionally offsets from these time zones) to time zones.\n\n        This parameter can be a dictionary with time zones names and\n        time zones or a function taking two parameters (``tzname`` and\n        ``tzoffset``) and return a time zone.\n\n   .. doctest::options: +NORMALIZE_WHITESPACE\n\n        >>> from dateuti", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n\n    :param default: The default datetime object, if this is a datetime object\n        and not ``None``, elements specified in ``timestr`` replace\n        elements in the default object.\n\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n        ignored and a naive :class:`datetime.datetime` object is returned.\n\n    :param tzinfos: Additional time zone names / aliases which may\n        be present in the string. This parameter maps time zones (and\n        optionally offsets from the time zones) to time zones.\n\n        This parameter can be a dictionary with time zones names and\n        time zones or a function taking two parameters (``tzname`` and\n        ``tzoffset``) and returning a time zone.\n\n   .. doctest::options: +NORMALIZE_WHITESPACE\n\n    \"\"\"\n    return", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime object\n        and not ``None``, elements specified in ``timestr`` replace\n        elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n        ignored and a naive :class:`datetime.datetime` object is returned.\n    :param tzinfos: Additional time zone names / aliases which may\n        be present in the string.\n\n       .. doctest::\n            :options: +NORMALIZE_WHITESPACE\n\n            >>> from dateutil.parser import parse\n            >>> from dateutil.tz import gettz\n            >>> parse(\"2012-01-19 17:21:00 BRST\", tzinfos=tzinfos)\n            datetime.datetime(2012, 1, 19, 21, tzinfo=tzoffset(u'BRST',", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n\n    :param default: The default datetime object, if this is a datetime object\n        and not ``None``, elements specified in ``timestr`` replace\n        elements in the default object.\n\n    :param ignoretz: If set ``True``, time zones in parsed strings\n        are ignored and a naive :class:`datetime.datetime` object\n        is returned.\n\n    :param tzinfos: Additional time zone names / aliases which may\n        be present in the string. This parameter maps time zones\n        (and optionally offsets from the time zones) to time zones.\n\n        This parameter can be a dictionary with time zones (and optionally\n        add time zone aliases to the names with tzname) and\n        return a time zone.\n\n   ..doctest::options: +NORMALIZE_WHITESPACE\n\n    \"\"\"\n    return parse_datetime(\n ", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime object\n                    and not ``None``, elements specified in ``timestr``\n                    replace elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n                    ignored and a naive :class:`datetime.datetime` object\n                    is returned.\n\n    :param tzinfos: Additional time zone names / aliases which may\n                   be present in the string. This parameter maps\n                    time zone names (and optionally offsets from these\n                    time zones) to time zones.\n\n   .. doctest::options: +NORMALIZE_WHITESPACE\n\n    \"\"\"\n    return parse(tim", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n\n    :param default: The default datetime object, if this is a datetime\n        object and not ``None``\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n        ignored and a naive :class:`datetime.datetime` object is returned.\n\n    :param tzinfos: Additional time zone names which may be present\n        in the string. This parameter maps time zones (and optionally\n        replaces elements specified in the time zones) to time zones\n        or a function taking two parameters (``tzname`` and ``tzoffset``)\n        and returning a time zone.\n\n       .. doctest::options: +NORMALIZE_WHITESPACE\n\n        >>> from dateutil.parser import parse\n        >>> parse(\"2012-01-19 17:21:00 BRST\", tzinfos=tzinfos)\n        datetime.datetime(2012, 1, 19, 1", "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime object\n        and not ``None``, elements specified in ``timestr`` replace\n        elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings\n        are ignored and a naive :class:`datetime.datetime` object is\n        returned.\n    :param tzinfos: Additional time zone names which may be present\n        in the string. This parameter maps time zone names (and\n        optionally offsets from these time zones) to time zones.\n        This parameter can be a dictionary with time zones names and\n        time zones or a function taking two parameters (``tzname`` and\n        ``tzoffset``) and return a time zone.\n\n   .. doctest::options: +NORMALIZE_WHITESPACE\n    \"\"\"\n    return pa"], "level": "project_runnable", "generate_results": [{"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime\n        object and not ``None``\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n        ignored and a naive :class:`datetime.datetime` object is returned.\n    :param tzinfos: Additional time zone names which may be present\n        in the string.\n\n       .. doctest::\n            :options: +NORMALIZE_WHITESPACE\n\n            >>> from dateutil.parser import parse\n            >>> from dateutil.tz import gettz\n            >>> parse(\"2012-01-19 17:21:00 BRST\",\n           ...         tzinfos={\"BRST\": gettz(\"UTC\")})\n            datetime.datetime(2012, 1, 19, 17, tzinfo=tzoffset(\"BRST\", -7200))\n    \"\"\"\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n\n    :param default: The default datetime object, if this is a datetime\n        object and not ``None``\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n        ignored and a naive :class:`datetime.datetime` object is returned.\n\n    :param tzinfos: Additional time zone names which may be present\n        in the string. This parameter maps time zones (and optionally\n        replacements from those time zones) to time zones.\n\n        This parameter can be a dictionary with time zones names and\n        time zones or a function taking two parameters (``tzname`` and\n        ``tzoffset``) and returning a time zone.\n\n   ..doctest::options: +NORMALIZE_WHITESPACE\n\n        >>> from dateutil.parser import parse\n        >>> parse(\"2012-01-19 17:21:00 BRST\", tzinfo", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n\n    :param default: The default datetime object, if this is a datetime\n        object and not ``None``\n\n    :param ignoretz: If set ``True``, time zones in parsed strings\n        are ignored and a naive :class:`datetime.datetime` object is\n        returned.\n\n    :param tzinfos: Additional time zone names / aliases which may\n        be present in the string. This parameter maps time zones\n        (and optionally replace elements specified in the format\n        ``tzname`` elements with timezones or a function\n        taking two parameters (``tzname`` and ``tzoffset``))\n        to time zones. This parameter can be a dictionary with\n        time zone names and time zones or a function taking two\n        parameters (``tzname`` and ``tzoffset``)\n\n   .. doctest::options: +NOR", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n\n    :param default: The default datetime object, if this is a datetime object\n        and not ``None``, elements specified in ``timestr`` replace\n        elements in the default object.\n\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n        ignored and a naive :class:`datetime.datetime` object is returned.\n\n    :param tzinfos: Additional time zone names / aliases which may be\n        present in the string. This parameter maps time zones (and\n        optionally offsets from these time zones) to time zones.\n\n        This parameter can be a dictionary with time zones names and\n        time zones or a function taking two parameters (``tzname`` and\n        ``tzoffset``) and return a time zone.\n\n   .. doctest::options: +NORMALIZE_WHITESPACE\n\n        >>> from dateuti", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n\n    :param default: The default datetime object, if this is a datetime object\n        and not ``None``, elements specified in ``timestr`` replace\n        elements in the default object.\n\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n        ignored and a naive :class:`datetime.datetime` object is returned.\n\n    :param tzinfos: Additional time zone names / aliases which may\n        be present in the string. This parameter maps time zones (and\n        optionally offsets from the time zones) to time zones.\n\n        This parameter can be a dictionary with time zones names and\n        time zones or a function taking two parameters (``tzname`` and\n        ``tzoffset``) and returning a time zone.\n\n   .. doctest::options: +NORMALIZE_WHITESPACE\n\n    \"\"\"\n    return", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime object\n        and not ``None``, elements specified in ``timestr`` replace\n        elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n        ignored and a naive :class:`datetime.datetime` object is returned.\n    :param tzinfos: Additional time zone names / aliases which may\n        be present in the string.\n\n       .. doctest::\n            :options: +NORMALIZE_WHITESPACE\n\n            >>> from dateutil.parser import parse\n            >>> from dateutil.tz import gettz\n            >>> parse(\"2012-01-19 17:21:00 BRST\", tzinfos=tzinfos)\n            datetime.datetime(2012, 1, 19, 21, tzinfo=tzoffset(u'BRST',", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n\n    :param default: The default datetime object, if this is a datetime object\n        and not ``None``, elements specified in ``timestr`` replace\n        elements in the default object.\n\n    :param ignoretz: If set ``True``, time zones in parsed strings\n        are ignored and a naive :class:`datetime.datetime` object\n        is returned.\n\n    :param tzinfos: Additional time zone names / aliases which may\n        be present in the string. This parameter maps time zones\n        (and optionally offsets from the time zones) to time zones.\n\n        This parameter can be a dictionary with time zones (and optionally\n        add time zone aliases to the names with tzname) and\n        return a time zone.\n\n   ..doctest::options: +NORMALIZE_WHITESPACE\n\n    \"\"\"\n    return parse_datetime(\n ", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime object\n                    and not ``None``, elements specified in ``timestr``\n                    replace elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n                    ignored and a naive :class:`datetime.datetime` object\n                    is returned.\n\n    :param tzinfos: Additional time zone names / aliases which may\n                   be present in the string. This parameter maps\n                    time zone names (and optionally offsets from these\n                    time zones) to time zones.\n\n   .. doctest::options: +NORMALIZE_WHITESPACE\n\n    \"\"\"\n    return parse(tim", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n\n    :param default: The default datetime object, if this is a datetime\n        object and not ``None``\n    :param ignoretz: If set ``True``, time zones in parsed strings are\n        ignored and a naive :class:`datetime.datetime` object is returned.\n\n    :param tzinfos: Additional time zone names which may be present\n        in the string. This parameter maps time zones (and optionally\n        replaces elements specified in the time zones) to time zones\n        or a function taking two parameters (``tzname`` and ``tzoffset``)\n        and returning a time zone.\n\n       .. doctest::options: +NORMALIZE_WHITESPACE\n\n        >>> from dateutil.parser import parse\n        >>> parse(\"2012-01-19 17:21:00 BRST\", tzinfos=tzinfos)\n        datetime.datetime(2012, 1, 19, 1", "is_pass": false, "return_code": 1}, {"generate_code": "def parse(self, timestr, default=None,\n              ignoretz=False, tzinfos=None, **kwargs):\n    \"\"\"\n    Parse the date/time string into a :class:`datetime.datetime` object.\n\n    :param timestr: Any date/time string using the supported formats.\n    :param default: The default datetime object, if this is a datetime object\n        and not ``None``, elements specified in ``timestr`` replace\n        elements in the default object.\n    :param ignoretz: If set ``True``, time zones in parsed strings\n        are ignored and a naive :class:`datetime.datetime` object is\n        returned.\n    :param tzinfos: Additional time zone names which may be present\n        in the string. This parameter maps time zone names (and\n        optionally offsets from these time zones) to time zones.\n        This parameter can be a dictionary with time zones names and\n        time zones or a function taking two parameters (``tzname`` and\n        ``tzoffset``) and return a time zone.\n\n   .. doctest::options: +NORMALIZE_WHITESPACE\n    \"\"\"\n    return pa", "is_pass": false, "return_code": 1}]}
{"file_path": "dateutil/tz/_common.py", "project": "pexip/os-python-dateutil", "name": "fromutc", "docstring": "Given a timezone-aware datetime in a given timezone, calculates a\ntimezone-aware datetime in a new timezone.\n\nSince this is the one time that we *know* we have an unambiguous\ndatetime object, we take this opportunity to determine whether the\ndatetime is ambiguous and in a \"fold\" state (e.g. if it's the first\noccurrence, chronologically, of the ambiguous datetime).\n\n:param dt:\n    A timezone-aware :class:`datetime.datetime` object.", "ques_id": "62b8a4a4755ee91dce50a3d3", "code": ["def fromutc(self, dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=UTC)\n\n    return dt.astimezone(self)\n", "def fromutc(self, dt):\n    return dt.astimezone(self)\n", "def fromutc(self, dt):\n    return dt.astimezone(self)\n", "def fromutc(self, dt):\n    return dt.astimezone(self)\n", "def fromutc(self, dt):\n    return dt.replace(tzinfo=None)\n", "def fromutc(self, dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=UTC)\n\n    return dt.astimezone(self)\n", "def fromutc(self, dt):\n    return dt.replace(tzinfo=self)\n", "def fromutc(self, dt):\n    if dt.tzinfo is None:\n        # No timezone, just return the datetime unmodified.\n        return dt\n    if dt.tzinfo.utcoffset(dt) is None:\n        # Datetimes after UTC are in the local timezone.\n        return dt.replace(tzinfo=LOCAL)\n    return dt.astimezone(LOCAL)\n", "def fromutc(self, dt):\n    return dt.replace(tzinfo=None)\n", "def fromutc(self, dt):\n    if dt.tzinfo is None:\n        raise ValueError(\"fromutc() requires a timezone-aware datetime\")\n\n    return dt.astimezone(self)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def fromutc(self, dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=UTC)\n\n    return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n    return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n    return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n    return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n    return dt.replace(tzinfo=None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=UTC)\n\n    return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n    return dt.replace(tzinfo=self)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n    if dt.tzinfo is None:\n        # No timezone, just return the datetime unmodified.\n        return dt\n    if dt.tzinfo.utcoffset(dt) is None:\n        # Datetimes after UTC are in the local timezone.\n        return dt.replace(tzinfo=LOCAL)\n    return dt.astimezone(LOCAL)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n    return dt.replace(tzinfo=None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fromutc(self, dt):\n    if dt.tzinfo is None:\n        raise ValueError(\"fromutc() requires a timezone-aware datetime\")\n\n    return dt.astimezone(self)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "dateutil/utils.py", "project": "pexip/os-python-dateutil", "name": "default_tzinfo", "docstring": "Sets the ``tzinfo`` parameter on naive datetimes only\n\nThis is useful for example when you are provided a datetime that may have\neither an implicit or explicit time zone, such as when parsing a time zone\nstring.\n\n.. doctest::\n\n    >>> from dateutil.tz import tzoffset\n    >>> from dateutil.parser import parse\n    >>> from dateutil.utils import default_tzinfo\n    >>> dflt_tz = tzoffset(\"EST\", -18000)\n    >>> print(default_tzinfo(parse('2014-01-01 12:30 UTC'), dflt_tz))\n    2014-01-01 12:30:00+00:00\n    >>> print(default_tzinfo(parse('2014-01-01 12:30'), dflt_tz))\n    2014-01-01 12:30:00-05:00\n\n:param dt:\n    The datetime on which to replace the time zone\n\n:param tzinfo:\n    The :py:class:`datetime.tzinfo` subclass instance to assign to\n    ``dt`` if (and only if) it is naive.\n\n:return:\n    Returns an aware :py:class:`datetime.datetime`.", "ques_id": "62b8a7b2755ee91dce50a4a7", "code": ["def default_tzinfo(dt, tzinfo):\n    if tzinfo is None:\n        return dt\n\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n    if isinstance(dt, datetime) and dt.tzinfo is None:\n        return dt.replace(tzinfo=tzinfo)\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n    if tzinfo is None:\n        return dt\n\n    if isinstance(dt, datetime):\n        # Convert to UTC\n        dt = dt.replace(tzinfo=tzinfo)\n\n    elif isinstance(dt, date):\n        dt = datetime(dt.year, dt.month, dt.day)\n\n    return dt.replace(tzinfo=tzinfo)\n", "def default_tzinfo(dt, tzinfo):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n    if tzinfo is None:\n        return dt\n\n    if isinstance(dt, datetime):\n        return dt.replace(tzinfo=tzinfo)\n    if isinstance(dt, date):\n        return datetime(dt.year, dt.month, dt.day, tzinfo=tzinfo)\n    raise TypeError(\"Unsupported type %r for dt. Expected datetime or date\"\n                    \" instance\" % type(dt))\n", "def default_tzinfo(dt, tzinfo):\n    if tzinfo is None:\n        return dt\n\n    if not isinstance(tzinfo, datetime.tzinfo):\n        tzinfo = datetime.tzinfo._from_timezone(tzinfo)\n\n    return dt.replace(tzinfo=tzinfo)\n", "def default_tzinfo(dt, tzinfo):\n    if isinstance(dt, datetime) and dt.tzinfo is None:\n        return dt.replace(tzinfo=tzinfo)\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n    if not isinstance(dt, datetime):\n        raise TypeError('dt must be a datetime.datetime, not'+ repr(dt))\n\n    if tzinfo is None:\n        # Assume UTC if no tzinfo was passed\n        return dt\n\n    if isinstance(dt, datetime):\n        dt = dt.replace(tzinfo=tzinfo)\n\n    return dt\n", "def default_tzinfo(dt, tzinfo):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n    return dt\n"], "level": "self_contained", "generate_results": [{"generate_code": "def default_tzinfo(dt, tzinfo):\n    if tzinfo is None:\n        return dt\n\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n\n    return dt\n", "is_pass": true, "return_code": 0}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n\n    return dt\n", "is_pass": true, "return_code": 0}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n    if isinstance(dt, datetime) and dt.tzinfo is None:\n        return dt.replace(tzinfo=tzinfo)\n    return dt\n", "is_pass": true, "return_code": 0}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n    if tzinfo is None:\n        return dt\n\n    if isinstance(dt, datetime):\n        # Convert to UTC\n        dt = dt.replace(tzinfo=tzinfo)\n\n    elif isinstance(dt, date):\n        dt = datetime(dt.year, dt.month, dt.day)\n\n    return dt.replace(tzinfo=tzinfo)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n    return dt\n", "is_pass": true, "return_code": 0}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n    if tzinfo is None:\n        return dt\n\n    if isinstance(dt, datetime):\n        return dt.replace(tzinfo=tzinfo)\n    if isinstance(dt, date):\n        return datetime(dt.year, dt.month, dt.day, tzinfo=tzinfo)\n    raise TypeError(\"Unsupported type %r for dt. Expected datetime or date\"\n                    \" instance\" % type(dt))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n    if tzinfo is None:\n        return dt\n\n    if not isinstance(tzinfo, datetime.tzinfo):\n        tzinfo = datetime.tzinfo._from_timezone(tzinfo)\n\n    return dt.replace(tzinfo=tzinfo)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n    if isinstance(dt, datetime) and dt.tzinfo is None:\n        return dt.replace(tzinfo=tzinfo)\n    return dt\n", "is_pass": true, "return_code": 0}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n    if not isinstance(dt, datetime):\n        raise TypeError('dt must be a datetime.datetime, not'+ repr(dt))\n\n    if tzinfo is None:\n        # Assume UTC if no tzinfo was passed\n        return dt\n\n    if isinstance(dt, datetime):\n        dt = dt.replace(tzinfo=tzinfo)\n\n    return dt\n", "is_pass": false, "return_code": 1}, {"generate_code": "def default_tzinfo(dt, tzinfo):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=tzinfo)\n    return dt\n", "is_pass": true, "return_code": 0}]}
{"file_path": "src/lithium/testcases.py", "project": "MozillaSecurity/lithium", "name": "set_cut_chars", "docstring": "Set the bytes used to delimit slice points.\n\nArgs:\n    before: Split file before these delimiters.\n    after: Split file after these delimiters.", "ques_id": "6305f9991d275c6667163c50", "code": ["def set_cut_chars(self, before: bytes, after: bytes):\n    self.before = before\n    self.after = after\n", "def set_cut_chars(self, before: bytes, after: bytes):\n    self.cut_chars = before + b',' + after\n", "def set_cut_chars(self, before: bytes, after: bytes):\n    self.before = before\n    self.after = after\n", "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self.before = before\n    self.after = after\n", "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._bytes_per_slice = len(before) + len(after)\n    self._cut_chars = before + b'\\x00' * (self._bytes_per_slice - 1) + after\n", "def set_cut_chars(self, before: str, after: str) -> None:\n    self._bytes_per_slice = (\n        int(before) if before!= \"\" else None\n    ) + (int(after) if after!= \"\" else None)\n", "def set_cut_chars(self, before: str, after: str) -> None:\n    self.cut_chars = before + ',' + after\n", "def set_cut_chars(self, before: bytes, after: bytes):\n    self.cut_chars = before, after\n", "def set_cut_chars(self, before: str, after: str) -> None:\n    self.before = before\n    self.after = after\n", "def set_cut_chars(self, before: bytes, after: bytes):\n    self._j_split_file = self._j_split_file.setCutChars(before, after)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def set_cut_chars(self, before: bytes, after: bytes):\n    self.before = before\n    self.after = after\n", "is_pass": true, "return_code": 0}, {"generate_code": "def set_cut_chars(self, before: bytes, after: bytes):\n    self.cut_chars = before + b',' + after\n", "is_pass": true, "return_code": 0}, {"generate_code": "def set_cut_chars(self, before: bytes, after: bytes):\n    self.before = before\n    self.after = after\n", "is_pass": true, "return_code": 0}, {"generate_code": "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self.before = before\n    self.after = after\n", "is_pass": true, "return_code": 0}, {"generate_code": "def set_cut_chars(self, before: bytes, after: bytes) -> None:\n    self._bytes_per_slice = len(before) + len(after)\n    self._cut_chars = before + b'\\x00' * (self._bytes_per_slice - 1) + after\n", "is_pass": true, "return_code": 0}, {"generate_code": "def set_cut_chars(self, before: str, after: str) -> None:\n    self._bytes_per_slice = (\n        int(before) if before!= \"\" else None\n    ) + (int(after) if after!= \"\" else None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def set_cut_chars(self, before: str, after: str) -> None:\n    self.cut_chars = before + ',' + after\n", "is_pass": false, "return_code": 1}, {"generate_code": "def set_cut_chars(self, before: bytes, after: bytes):\n    self.cut_chars = before, after\n", "is_pass": true, "return_code": 0}, {"generate_code": "def set_cut_chars(self, before: str, after: str) -> None:\n    self.before = before\n    self.after = after\n", "is_pass": true, "return_code": 0}, {"generate_code": "def set_cut_chars(self, before: bytes, after: bytes):\n    self._j_split_file = self._j_split_file.setCutChars(before, after)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/protocols/diaspora/protocol.py", "project": "jaywink/federation", "name": "identify_request", "docstring": "Try to identify whether this is a Diaspora request.\n\nTry first public message. Then private message. The check if this is a legacy payload.", "ques_id": "6306292052e177c0ba469f09", "code": ["def identify_request(request: Request) -> bool:\n    if request.method == \"POST\":\n        return True\n    private = request.headers.get(\"x-legacy-payload\")\n    public = request.headers.get(\"x-rh-payload\")\n    return private is None and public is None\n", "def identify_request(request: Request) -> bool:\n    return request.method in ('POST', 'PUT', 'PATCH', 'DELETE') and request.json.get('private')\n", "def identify_request(request: Request) -> bool:\n    if request.method == 'POST':\n        return True\n\n    public_messages = request.transport.get_message().public_recipients\n    legacy_payloads = [request.transport.get_message()]\n    for payload in legacy_payloads:\n        if payload.is_legacy():\n            continue\n\n        for message in public_messages:\n            if message.is_received_by(payload):\n                break\n\n        else:\n            # No legacy public recipients found. Check if this is a legacy\n            # message.\n            if request.method == 'PUT' and payload.is_legacy():\n                return False\n\n            return True\n\n    return False\n", "def identify_request(request: Request) -> bool:\n    if request.method == \"POST\" and request.headers.get(\"content-type\", \"\").startswith(\"multipart/form-data\"):\n        return True\n\n    if request.method == \"POST\" and request.headers.get(\"content-type\", \"\").startswith(\"application/x-www-form-urlencoded\"):\n        return True\n\n    if request.method == \"POST\" and request.headers.get(\"content-type\", \"\").startswith(\"multipart/form-data\"):\n        return False\n\n    if request.headers.get(\"content-type\", \"\").startswith(\"application/json\"):\n        return True\n\n    if request.headers.get(\"content-type\", \"\").startswith(\"application/x-www-form-urlencoded\"):\n        return False\n\n    if request.headers.get(\"content-type\", \"\").startswith(\"multipart/form\"):\n        return False\n\n    return True\n", "def identify_request(request: dict, payload: dict) -> bool:\n    if 'private' in request:\n        return False\n    if 'public' in request:\n        return True\n    if payload['type'] =='message' and payload.get('type') == 'legacy_request':\n        return False\n    return True\n", "def identify_request(request: Request):\n    if request.method == 'POST':\n        return request.body\n\n    if request.method == 'GET':\n        return request.args.get('message', None) or request.args.get('private', None)\n", "def identify_request(request: Request) -> bool:\n    if request.method == \"GET\" and request.GET.get(\"msg\"):\n        return True\n\n    private_message = request.GET.get(\"msg\")\n\n    if private_message and request.method == \"POST\":\n        return True\n\n    public_message = request.META.get(\"wsgi.errors\")\n\n    if public_message and request.method == \"OPTIONS\":\n        return True\n\n    return False\n", "def identify_request(request: Request) -> bool:\n    if request.method == \"POST\":\n        return True\n\n    # Send private message first if it is a legacy payload\n    if request.method == \"PUT\" and request.json.get(\"payload\") == \"legacy\":\n        return True\n\n    try:\n        payload = request.json\n        if \"private\" in payload:\n            return True\n    except Exception:\n        pass\n\n    return False\n", "def identify_request(request: Request) -> bool:\n    if request.method == \"POST\":\n        if request.POST.get(\"private\") == \"1\":\n            return True\n        elif request.POST.get(\"public\") == \"1\":\n            return False\n        elif request.POST.get(\"payload\") == \"legacy\":\n            return True\n        elif request.POST.get(\"payload\") == \"legacy\":\n            return False\n    elif request.method == \"GET\":\n        if request.GET.get(\"payload\") == \"legacy\":\n            return True\n        elif request.GET.get(\"payload\") == \"legacy\":\n            return False\n    elif request.method == \"PUT\":\n        if request.PUT.get(\"payload\") == \"legacy\":\n            return True\n        elif request.PUT.get(\"payload\") == \"legacy\":\n            return False\n\n    return False\n", "def identify_request(request: Request):\n    if request.method not in ('POST', 'PUT'):\n        return False\n\n    if request.method == 'POST' and request.headers.get('Content-Type', '').startswith('multipart/form-data'):\n        return True\n\n    private_message = request.headers.get('X-Issue-Private-Message', '')\n    if private_message.lower().startswith('true'):\n        return True\n\n    payload = request.get_data()\n    if payload and payload.startswith('{') and '}' in payload:\n        return True\n\n    return False\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def identify_request(request: Request) -> bool:\n    if request.method == \"POST\":\n        return True\n    private = request.headers.get(\"x-legacy-payload\")\n    public = request.headers.get(\"x-rh-payload\")\n    return private is None and public is None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: Request) -> bool:\n    return request.method in ('POST', 'PUT', 'PATCH', 'DELETE') and request.json.get('private')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: Request) -> bool:\n    if request.method == 'POST':\n        return True\n\n    public_messages = request.transport.get_message().public_recipients\n    legacy_payloads = [request.transport.get_message()]\n    for payload in legacy_payloads:\n        if payload.is_legacy():\n            continue\n\n        for message in public_messages:\n            if message.is_received_by(payload):\n                break\n\n        else:\n            # No legacy public recipients found. Check if this is a legacy\n            # message.\n            if request.method == 'PUT' and payload.is_legacy():\n                return False\n\n            return True\n\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: Request) -> bool:\n    if request.method == \"POST\" and request.headers.get(\"content-type\", \"\").startswith(\"multipart/form-data\"):\n        return True\n\n    if request.method == \"POST\" and request.headers.get(\"content-type\", \"\").startswith(\"application/x-www-form-urlencoded\"):\n        return True\n\n    if request.method == \"POST\" and request.headers.get(\"content-type\", \"\").startswith(\"multipart/form-data\"):\n        return False\n\n    if request.headers.get(\"content-type\", \"\").startswith(\"application/json\"):\n        return True\n\n    if request.headers.get(\"content-type\", \"\").startswith(\"application/x-www-form-urlencoded\"):\n        return False\n\n    if request.headers.get(\"content-type\", \"\").startswith(\"multipart/form\"):\n        return False\n\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: dict, payload: dict) -> bool:\n    if 'private' in request:\n        return False\n    if 'public' in request:\n        return True\n    if payload['type'] =='message' and payload.get('type') == 'legacy_request':\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: Request):\n    if request.method == 'POST':\n        return request.body\n\n    if request.method == 'GET':\n        return request.args.get('message', None) or request.args.get('private', None)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: Request) -> bool:\n    if request.method == \"GET\" and request.GET.get(\"msg\"):\n        return True\n\n    private_message = request.GET.get(\"msg\")\n\n    if private_message and request.method == \"POST\":\n        return True\n\n    public_message = request.META.get(\"wsgi.errors\")\n\n    if public_message and request.method == \"OPTIONS\":\n        return True\n\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: Request) -> bool:\n    if request.method == \"POST\":\n        return True\n\n    # Send private message first if it is a legacy payload\n    if request.method == \"PUT\" and request.json.get(\"payload\") == \"legacy\":\n        return True\n\n    try:\n        payload = request.json\n        if \"private\" in payload:\n            return True\n    except Exception:\n        pass\n\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: Request) -> bool:\n    if request.method == \"POST\":\n        if request.POST.get(\"private\") == \"1\":\n            return True\n        elif request.POST.get(\"public\") == \"1\":\n            return False\n        elif request.POST.get(\"payload\") == \"legacy\":\n            return True\n        elif request.POST.get(\"payload\") == \"legacy\":\n            return False\n    elif request.method == \"GET\":\n        if request.GET.get(\"payload\") == \"legacy\":\n            return True\n        elif request.GET.get(\"payload\") == \"legacy\":\n            return False\n    elif request.method == \"PUT\":\n        if request.PUT.get(\"payload\") == \"legacy\":\n            return True\n        elif request.PUT.get(\"payload\") == \"legacy\":\n            return False\n\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: Request):\n    if request.method not in ('POST', 'PUT'):\n        return False\n\n    if request.method == 'POST' and request.headers.get('Content-Type', '').startswith('multipart/form-data'):\n        return True\n\n    private_message = request.headers.get('X-Issue-Private-Message', '')\n    if private_message.lower().startswith('true'):\n        return True\n\n    payload = request.get_data()\n    if payload and payload.startswith('{') and '}' in payload:\n        return True\n\n    return False\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/protocols/matrix/protocol.py", "project": "jaywink/federation", "name": "identify_request", "docstring": "Try to identify whether this is a Matrix request", "ques_id": "6306292152e177c0ba469f0d", "code": ["def identify_request(request: Request) -> bool:\n    if request.method in [\"POST\", \"PUT\"]:\n        return True\n    if request.method == \"DELETE\":\n        return False\n    return False\n", "def identify_request(request: Request) -> bool:\n    if request.method == 'POST' and request.content_length > 0:\n        return True\n\n    return False\n", "def identify_request(request: Request) -> bool:\n    if isinstance(request, Request) and request.method == \"Matrix\":\n        return True\n\n    return False\n", "def identify_request(request: Request) -> bool:\n    return request.method in (\"GET\", \"HEAD\")\n", "def identify_request(request: str):\n    if request == \"Matrix\":\n        return True\n\n    return False\n", "def identify_request(request: Dict[str, Any]) -> bool:\n    try:\n        # As soon as we have a valid JSON request, we identify whether we\n        # are being overriden in a specific way. We do this here instead of in\n        # ``__init__`` to avoid importing Matrix for the time being, because\n        # importing the ``Matrix`` module doesn't work as expected.\n        from mscxyz import Matrix\n        return issubclass(Matrix, Request)\n    except ImportError:\n        pass\n\n    return False\n", "def identify_request(request: Request) -> bool:\n    return (\n        isinstance(request, Request)\n        and request.method in (\"GET\", \"HEAD\")\n        and request.url == \"/\"\n    )\n", "def identify_request(request: Dict[str, Any]) -> bool:\n    try:\n        return request['method'] == 'Matrix'\n    except KeyError:\n        return False\n", "def identify_request(request: Request) -> bool:\n    if isinstance(request, MatrixRequest):\n        return True\n    return False\n", "def identify_request(request: Dict[str, Any]) -> bool:\n    return request.get('method') =='matrix'\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def identify_request(request: Request) -> bool:\n    if request.method in [\"POST\", \"PUT\"]:\n        return True\n    if request.method == \"DELETE\":\n        return False\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: Request) -> bool:\n    if request.method == 'POST' and request.content_length > 0:\n        return True\n\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: Request) -> bool:\n    if isinstance(request, Request) and request.method == \"Matrix\":\n        return True\n\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: Request) -> bool:\n    return request.method in (\"GET\", \"HEAD\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: str):\n    if request == \"Matrix\":\n        return True\n\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: Dict[str, Any]) -> bool:\n    try:\n        # As soon as we have a valid JSON request, we identify whether we\n        # are being overriden in a specific way. We do this here instead of in\n        # ``__init__`` to avoid importing Matrix for the time being, because\n        # importing the ``Matrix`` module doesn't work as expected.\n        from mscxyz import Matrix\n        return issubclass(Matrix, Request)\n    except ImportError:\n        pass\n\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: Request) -> bool:\n    return (\n        isinstance(request, Request)\n        and request.method in (\"GET\", \"HEAD\")\n        and request.url == \"/\"\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: Dict[str, Any]) -> bool:\n    try:\n        return request['method'] == 'Matrix'\n    except KeyError:\n        return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: Request) -> bool:\n    if isinstance(request, MatrixRequest):\n        return True\n    return False\n", "is_pass": false, "return_code": 1}, {"generate_code": "def identify_request(request: Dict[str, Any]) -> bool:\n    return request.get('method') =='matrix'\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/entities/diaspora/utils.py", "project": "jaywink/federation", "name": "format_dt", "docstring": "Format a datetime in the way that D* nodes expect.", "ques_id": "6306292252e177c0ba469f11", "code": ["def format_dt(dt):\n    return dt.strftime('%Y-%m-%d %H:%M:%S')\n", "def format_dt(dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=dateutil.tz.tzutc())\n    return dt.isoformat()\n", "def format_dt(dt):\n    return dt.strftime(\"%Y-%m-%d %H:%M\")\n", "def format_dt(dt):\n    return dt.strftime('%Y-%m-%d %H:%M:%S')\n", "def format_dt(dt):\n    return dt.isoformat() if dt else None\n", "def format_dt(dt):\n    return dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n", "def format_dt(dt):\n    if dt.tzinfo is not None:\n        raise ValueError(\"Input cannot be timezone-aware.\")\n\n    return dt.strftime('%Y-%m-%d %H:%M:%S')\n", "def format_dt(dt):\n    return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n", "def format_dt(dt):\n    return dt.strftime('%Y-%m-%d %H:%M:%S')\n", "def format_dt(dt):\n    return dt.strftime('%Y-%m-%d %H:%M:%S')\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def format_dt(dt):\n    return dt.strftime('%Y-%m-%d %H:%M:%S')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    if dt.tzinfo is None:\n        dt = dt.replace(tzinfo=dateutil.tz.tzutc())\n    return dt.isoformat()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    return dt.strftime(\"%Y-%m-%d %H:%M\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    return dt.strftime('%Y-%m-%d %H:%M:%S')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    return dt.isoformat() if dt else None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    return dt.strftime('%Y-%m-%dT%H:%M:%SZ')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    if dt.tzinfo is not None:\n        raise ValueError(\"Input cannot be timezone-aware.\")\n\n    return dt.strftime('%Y-%m-%d %H:%M:%S')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    return dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    return dt.strftime('%Y-%m-%d %H:%M:%S')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def format_dt(dt):\n    return dt.strftime('%Y-%m-%d %H:%M:%S')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/utils/text.py", "project": "jaywink/federation", "name": "find_tags", "docstring": "Find tags in text.\n\nTries to ignore tags inside code blocks.\n\nOptionally, if passed a \"replacer\", will also replace the tag word with the result\nof the replacer function called with the tag word.\n\nReturns a set of tags and the original or replaced text.", "ques_id": "6306292352e177c0ba469f1d", "code": ["def find_tags(text: str, replacer: Callable[[str], str] = None) -> Tuple[Set[str], str]:\n    tags = set()\n    original = text\n    if replacer:\n        text = replacer(text)\n    for match in re.finditer(r\"(\\`(?![\\w-]+\\`)|\\[(?![\\w-]+\\`)|\\](?![\\w-]+\\`))\", text):\n        original = text[:match.start()]\n        text = text[match.end():]\n        tags.add(match.group(1))\n    if text:\n        tags.add(original)\n    return tags, original\n", "def find_tags(text: str, replacer: Callable = None) -> Tuple[Set[str], str]:\n    if replacer:\n        text = replacer(text)\n\n    found = re.findall(r\"<(?!code.*?/).*?>\", text)\n\n    return {tag for tag in found if not tag.startswith(\"<code>\")}, text\n", "def find_tags(text: str, replacer: Callable[[str], str] = None) -> Tuple[Set[str], str]:\n    # search for tags inside code blocks\n    code_block_re = re.compile(r'<!--[\\s\\S]*?-->')\n    text = code_block_re.sub(replacer, text)\n\n    # search for tags inside comments\n    comment_re = re.compile(r'<!--[\\s\\S]*?-->', re.MULTILINE | re.DOTALL)\n    text = comment_re.sub(replacer, text)\n\n    # search for tags inside code\n    code_single_re = re.compile(r'<code>(.*?)</code>')\n    text = code_single_re.sub(replacer, text)\n\n    # search for tags inside blocks\n    block_re = re.compile(r'(?m)\\s*(<!--.*?-->)')\n    text = block_re.sub(replacer, text)\n\n    # remove tags that should not be in text\n    return set(re.findall(r'<[^>]*?>', text)), text\n", "def find_tags(text: str, replacer: Callable = None) -> Tuple[Set[str], str]:\n    if replacer is not None:\n        text = replacer(text)\n\n    soup = BeautifulSoup(text, \"html.parser\")\n\n    # Find all code blocks\n    code_blocks = [\n        b for b in soup.find_all(\"code\")\n        if b.name!= \"pre\" and not b.name.startswith(\"pre\")\n    ]\n\n    # Find all tags (or code blocks) inside code blocks\n    tags = set()\n    for code_block in code_blocks:\n        tags.update(\n            [tag.name for tag in code_block.find_all(\"tag\")]\n        )\n\n    # Remove any tags that are not code or code-blocks\n    return {\n        tag for tag in tags if not tag in [\"pre\", \"code\"]\n    }, text\n", "def find_tags(text: str, replacer: Callable = None) -> Set[str]:\n    replacer = replacer or (lambda x: x)\n    return set(replacer(tag) for tag in re.findall(r\"<[^>]*>\", text))\n", "def find_tags(text: str, replacer: Callable[[str, str], str] = None) -> set:\n    pattern = re.compile(r'(\\p{L})')\n    replacer = replacer or (lambda match: match.group(0))\n    result = pattern.findall(text)\n    return set(map(replacer, result))\n", "def find_tags(text: str, replacer=None) -> Tuple[Set[str], str]:\n    ignore_code_block = False\n    if replacer is None:\n        ignore_code_block = True\n        replacer = lambda m: m.group(0)\n    results = set()\n    tag_re = re.compile(r\"(?i)(<!\\\\)([^>]+)(?=</code>)\", re.I)\n    text = replacer(text)\n    for match in tag_re.finditer(text):\n        results.add(match.group(1))\n    if ignore_code_block:\n        return results, \"\"\n    return results, replacer(text)\n", "def find_tags(text: str, replacer=None):\n    if replacer is None:\n        return set([])\n\n    def replacer(match):\n        tag = match.group(1)\n        return replacer(match.group(0))\n\n    pattern = r'<(\\/?)([^>]*)>'\n    return re.sub(pattern, replacer, text)\n", "def find_tags(text: str, replacer: Callable[[str], str] = None) -> Tuple[Set[str], str]:\n    if replacer is not None:\n        text = replacer(text)\n\n    soup = BeautifulSoup(text, \"html.parser\")\n    code_blocks = [\n        block for block in soup.find_all(\"code\")\n        if not block.string or block.string.isspace()\n    ]\n    if not code_blocks:\n        return set([text]), text\n\n    code_block = code_blocks[0]\n    tags = set()\n    for match in re.finditer(r\"\\/(\\w*)\\/\", code_block.string):\n        tags.add(match.group(1))\n\n    text = re.sub(r\"\\/\\/(\\w*)\\/\", replacer, code_block.string)\n    text = text.replace(\"//\", \"/\")\n    text = text.replace(\"/*\", \"/\")\n    text = text.replace(\"*/\", \"*\")\n\n    return tags, text\n", "def find_tags(text: str, replacer: Callable[[str], str] = None) -> Tuple[Set[str], str]:\n    ignore_tags = set([\"<!--\", \"-->\", \"&#160;\", \"&#160;\"])\n\n    def replacer_func(match):\n        if match.group(1) in ignore_tags:\n            return match.group(0), \"\"\n        return match.group(0)\n\n    replacer = replacer_func if replacer is None else replacer\n\n    def replace_tag(match: re.Match) -> str:\n        return replacer(match.group(1))\n\n    pattern = r\"\"\"\n    (?P<tag>(?:<!--|&#160;|&#160;)[^\\s]+?)\n    \\s*\n    (?P<text>(?:(?:\\\\\\\\)+(?:\\\\\\\\)*)+)\n    (?:\\s+(?P<attrs>(?:\\\\\\\\)+)+)\n    (?:\\s+(?P<eq>(?:\\\\\\\\)+)+)\n    \"\"\"\n    return re.sub(pattern, replace_tag, re.sub(r\"\\s+\", \" \", text)), text\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def find_tags(text: str, replacer: Callable[[str], str] = None) -> Tuple[Set[str], str]:\n    tags = set()\n    original = text\n    if replacer:\n        text = replacer(text)\n    for match in re.finditer(r\"(\\`(?![\\w-]+\\`)|\\[(?![\\w-]+\\`)|\\](?![\\w-]+\\`))\", text):\n        original = text[:match.start()]\n        text = text[match.end():]\n        tags.add(match.group(1))\n    if text:\n        tags.add(original)\n    return tags, original\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer: Callable = None) -> Tuple[Set[str], str]:\n    if replacer:\n        text = replacer(text)\n\n    found = re.findall(r\"<(?!code.*?/).*?>\", text)\n\n    return {tag for tag in found if not tag.startswith(\"<code>\")}, text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer: Callable[[str], str] = None) -> Tuple[Set[str], str]:\n    # search for tags inside code blocks\n    code_block_re = re.compile(r'<!--[\\s\\S]*?-->')\n    text = code_block_re.sub(replacer, text)\n\n    # search for tags inside comments\n    comment_re = re.compile(r'<!--[\\s\\S]*?-->', re.MULTILINE | re.DOTALL)\n    text = comment_re.sub(replacer, text)\n\n    # search for tags inside code\n    code_single_re = re.compile(r'<code>(.*?)</code>')\n    text = code_single_re.sub(replacer, text)\n\n    # search for tags inside blocks\n    block_re = re.compile(r'(?m)\\s*(<!--.*?-->)')\n    text = block_re.sub(replacer, text)\n\n    # remove tags that should not be in text\n    return set(re.findall(r'<[^>]*?>', text)), text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer: Callable = None) -> Tuple[Set[str], str]:\n    if replacer is not None:\n        text = replacer(text)\n\n    soup = BeautifulSoup(text, \"html.parser\")\n\n    # Find all code blocks\n    code_blocks = [\n        b for b in soup.find_all(\"code\")\n        if b.name!= \"pre\" and not b.name.startswith(\"pre\")\n    ]\n\n    # Find all tags (or code blocks) inside code blocks\n    tags = set()\n    for code_block in code_blocks:\n        tags.update(\n            [tag.name for tag in code_block.find_all(\"tag\")]\n        )\n\n    # Remove any tags that are not code or code-blocks\n    return {\n        tag for tag in tags if not tag in [\"pre\", \"code\"]\n    }, text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer: Callable = None) -> Set[str]:\n    replacer = replacer or (lambda x: x)\n    return set(replacer(tag) for tag in re.findall(r\"<[^>]*>\", text))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer: Callable[[str, str], str] = None) -> set:\n    pattern = re.compile(r'(\\p{L})')\n    replacer = replacer or (lambda match: match.group(0))\n    result = pattern.findall(text)\n    return set(map(replacer, result))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer=None) -> Tuple[Set[str], str]:\n    ignore_code_block = False\n    if replacer is None:\n        ignore_code_block = True\n        replacer = lambda m: m.group(0)\n    results = set()\n    tag_re = re.compile(r\"(?i)(<!\\\\)([^>]+)(?=</code>)\", re.I)\n    text = replacer(text)\n    for match in tag_re.finditer(text):\n        results.add(match.group(1))\n    if ignore_code_block:\n        return results, \"\"\n    return results, replacer(text)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer=None):\n    if replacer is None:\n        return set([])\n\n    def replacer(match):\n        tag = match.group(1)\n        return replacer(match.group(0))\n\n    pattern = r'<(\\/?)([^>]*)>'\n    return re.sub(pattern, replacer, text)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer: Callable[[str], str] = None) -> Tuple[Set[str], str]:\n    if replacer is not None:\n        text = replacer(text)\n\n    soup = BeautifulSoup(text, \"html.parser\")\n    code_blocks = [\n        block for block in soup.find_all(\"code\")\n        if not block.string or block.string.isspace()\n    ]\n    if not code_blocks:\n        return set([text]), text\n\n    code_block = code_blocks[0]\n    tags = set()\n    for match in re.finditer(r\"\\/(\\w*)\\/\", code_block.string):\n        tags.add(match.group(1))\n\n    text = re.sub(r\"\\/\\/(\\w*)\\/\", replacer, code_block.string)\n    text = text.replace(\"//\", \"/\")\n    text = text.replace(\"/*\", \"/\")\n    text = text.replace(\"*/\", \"*\")\n\n    return tags, text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def find_tags(text: str, replacer: Callable[[str], str] = None) -> Tuple[Set[str], str]:\n    ignore_tags = set([\"<!--\", \"-->\", \"&#160;\", \"&#160;\"])\n\n    def replacer_func(match):\n        if match.group(1) in ignore_tags:\n            return match.group(0), \"\"\n        return match.group(0)\n\n    replacer = replacer_func if replacer is None else replacer\n\n    def replace_tag(match: re.Match) -> str:\n        return replacer(match.group(1))\n\n    pattern = r\"\"\"\n    (?P<tag>(?:<!--|&#160;|&#160;)[^\\s]+?)\n    \\s*\n    (?P<text>(?:(?:\\\\\\\\)+(?:\\\\\\\\)*)+)\n    (?:\\s+(?P<attrs>(?:\\\\\\\\)+)+)\n    (?:\\s+(?P<eq>(?:\\\\\\\\)+)+)\n    \"\"\"\n    return re.sub(pattern, replace_tag, re.sub(r\"\\s+\", \" \", text)), text\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/utils/text.py", "project": "jaywink/federation", "name": "process_text_links", "docstring": "Process links in text, adding some attributes and linkifying textual links.", "ques_id": "6306292352e177c0ba469f1e", "code": ["def process_text_links(text):\n    text = re.sub(r'([a-z0-9\\-\\.]+)\\s*\\]\\(([^\\)]+)\\)', r'\\1<a href=\"\\2\">\\2</a>', text)\n    text = re.sub(r'([a-z0-9\\-\\.]+)\\s*\\]\\(([^\\)]+)\\)', r'\\1<a href=\"\\2\">\\2</a>', text)\n    text = re.sub(r'([a-z0-9\\-\\.]+)\\s*\\]\\(([^\\)]+)\\)', r'\\1<a href=\"\\2\">\\2</a>', text)\n    text = re.sub(r'([a-z0-9\\-\\.]+)\\s*\\]\\(([^\\)]+)\\)', r'\\1<a href=\"\\2\">\\2</a>', text)\n    text = re.sub(r'([a-z0-9\\-\\.]+)\\s*\\]\\(([^\\)]+)\\)', r'\\1<a href=\"\\2\">\\2</a>', text)\n    text = re.sub(r'([a-z0-9\\-\\.]+)\\s*\\]\\(([^\\)]+)\\)', r'\\1<a href=\"\\2\">\\2</a>', text)\n    text = re.sub(r'([a-z0-9\\-\\.]+)\\s*\\]\\(([^\\)]+)\\)', ", "def process_text_links(text):\n    text = re.sub(r'(?<=\\[\\[)(https?://)?(www\\.)?([\\w\\d:#@%&\\.=+\\-=]+)',\n                  '<a href=\"https://', text)\n    text = re.sub(r'(?<=\\]\\])(https?://)?(www\\.)?([\\w\\d:#@%&\\.=+\\-=]+)',\n                  '<a href=\"https://', text)\n    return text\n", "def process_text_links(text):\n    return linkify(text, get_links_extractor())\n", "def process_text_links(text):\n    links = []\n    for link in re.findall(r'(?:\\[\\[(.+?)\\]\\])|(?:\\[\\[([^\\]]+?)\\]\\])', text):\n        if not link:\n            continue\n        href, text = link\n        if href.startswith('http://') or href.startswith('https://'):\n            text = link\n        elif '[' in href:\n            links.append((href, text))\n        else:\n            text = '<a href=\"%s\">%s</a>' % (href, text)\n            links.append((href, text))\n    return''.join(links)\n", "def process_text_links(text):\n    text = text.replace('[[', '[[').replace(']]', ']]')\n    text = re.sub(r'\\[\\[([^\\]]*)\\]\\]', r'<a href=\"\\1\">\\1</a>', text)\n    text = text.replace('\\n', '<br>\\n')\n    text = linkify(text, reftype='text/plain')\n    return text\n", "def process_text_links(text):\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n   ", "def process_text_links(text):\n    if not text:\n        return text\n\n    linkified = linkify(text, parse_email=True)\n    if linkified:\n        text = \"[{}]({})\".format(text, linkified)\n\n    return text\n", "def process_text_links(text):\n    links = []\n    for match in re.finditer(r'((?:\\[\\[)(.*?)(?:\\]\\]))', text):\n        if match.group(2) is None:\n            links.append(match.group(1))\n        else:\n            links.append(match.group(1) + match.group(2))\n\n    return ''.join(['[[', '|'.join(links), ']]'])\n", "def process_text_links(text):\n    text = text.replace('[[', '').replace(']]', '')\n    # Linkify\n    text = LINK_RE.sub(linkify_text, text)\n    return text\n", "def process_text_links(text):\n    text = linkify(text)\n    text = remove_external_links(text)\n    text = remove_urls(text)\n    text = add_images(text)\n    text = remove_hashtags(text)\n    text = remove_emoticons(text)\n    text = remove_non_alphanumerics(text)\n    return text\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def process_text_links(text):\n    text = re.sub(r'([a-z0-9\\-\\.]+)\\s*\\]\\(([^\\)]+)\\)', r'\\1<a href=\"\\2\">\\2</a>', text)\n    text = re.sub(r'([a-z0-9\\-\\.]+)\\s*\\]\\(([^\\)]+)\\)', r'\\1<a href=\"\\2\">\\2</a>', text)\n    text = re.sub(r'([a-z0-9\\-\\.]+)\\s*\\]\\(([^\\)]+)\\)', r'\\1<a href=\"\\2\">\\2</a>', text)\n    text = re.sub(r'([a-z0-9\\-\\.]+)\\s*\\]\\(([^\\)]+)\\)', r'\\1<a href=\"\\2\">\\2</a>', text)\n    text = re.sub(r'([a-z0-9\\-\\.]+)\\s*\\]\\(([^\\)]+)\\)', r'\\1<a href=\"\\2\">\\2</a>', text)\n    text = re.sub(r'([a-z0-9\\-\\.]+)\\s*\\]\\(([^\\)]+)\\)', r'\\1<a href=\"\\2\">\\2</a>', text)\n    text = re.sub(r'([a-z0-9\\-\\.]+)\\s*\\]\\(([^\\)]+)\\)', ", "is_pass": false, "return_code": 1}, {"generate_code": "def process_text_links(text):\n    text = re.sub(r'(?<=\\[\\[)(https?://)?(www\\.)?([\\w\\d:#@%&\\.=+\\-=]+)',\n                  '<a href=\"https://', text)\n    text = re.sub(r'(?<=\\]\\])(https?://)?(www\\.)?([\\w\\d:#@%&\\.=+\\-=]+)',\n                  '<a href=\"https://', text)\n    return text\n", "is_pass": true, "return_code": 0}, {"generate_code": "def process_text_links(text):\n    return linkify(text, get_links_extractor())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def process_text_links(text):\n    links = []\n    for link in re.findall(r'(?:\\[\\[(.+?)\\]\\])|(?:\\[\\[([^\\]]+?)\\]\\])', text):\n        if not link:\n            continue\n        href, text = link\n        if href.startswith('http://') or href.startswith('https://'):\n            text = link\n        elif '[' in href:\n            links.append((href, text))\n        else:\n            text = '<a href=\"%s\">%s</a>' % (href, text)\n            links.append((href, text))\n    return''.join(links)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def process_text_links(text):\n    text = text.replace('[[', '[[').replace(']]', ']]')\n    text = re.sub(r'\\[\\[([^\\]]*)\\]\\]', r'<a href=\"\\1\">\\1</a>', text)\n    text = text.replace('\\n', '<br>\\n')\n    text = linkify(text, reftype='text/plain')\n    return text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def process_text_links(text):\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n    text = re.sub(r'\\[\\[([^\\]]+)\\]\\]', r'[\\1]', text)\n   ", "is_pass": false, "return_code": 1}, {"generate_code": "def process_text_links(text):\n    if not text:\n        return text\n\n    linkified = linkify(text, parse_email=True)\n    if linkified:\n        text = \"[{}]({})\".format(text, linkified)\n\n    return text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def process_text_links(text):\n    links = []\n    for match in re.finditer(r'((?:\\[\\[)(.*?)(?:\\]\\]))', text):\n        if match.group(2) is None:\n            links.append(match.group(1))\n        else:\n            links.append(match.group(1) + match.group(2))\n\n    return ''.join(['[[', '|'.join(links), ']]'])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def process_text_links(text):\n    text = text.replace('[[', '').replace(']]', '')\n    # Linkify\n    text = LINK_RE.sub(linkify_text, text)\n    return text\n", "is_pass": false, "return_code": 1}, {"generate_code": "def process_text_links(text):\n    text = linkify(text)\n    text = remove_external_links(text)\n    text = remove_urls(text)\n    text = add_images(text)\n    text = remove_hashtags(text)\n    text = remove_emoticons(text)\n    text = remove_non_alphanumerics(text)\n    return text\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/utils/network.py", "project": "jaywink/federation", "name": "fetch_content_type", "docstring": "Fetch the HEAD of the remote url to determine the content type.", "ques_id": "6306292652e177c0ba469f34", "code": ["def fetch_content_type(url: str) -> str:\n    response = requests.head(url)\n    if response.status_code == 200:\n        return response.headers.get('content-type')\n\n    return None\n", "def fetch_content_type(url: str) -> str:\n    response = requests.head(url, allow_redirects=True)\n    if response.status_code!= 200:\n        raise NotFound(url)\n    return response.headers[\"content-type\"]\n", "def fetch_content_type(url: str) -> Optional[str]:\n    try:\n        response = requests.head(url, allow_redirects=True)\n    except requests.exceptions.RequestException:\n        return None\n\n    if response.status_code == 200:\n        return response.headers.get(\"content-type\", None)\n\n    return None\n", "def fetch_content_type(url: str) -> Optional[str]:\n    response = requests.head(url, allow_redirects=False, timeout=10)\n    return response.headers.get(\"content-type\")\n", "def fetch_content_type(url: str) -> str:\n    response = requests.head(url, allow_redirects=True)\n    return response.headers.get('content-type')\n", "def fetch_content_type(url: str) -> str:\n    response = requests.head(url, allow_redirects=True)\n    response.raise_for_status()\n    return response.headers['content-type']\n", "def fetch_content_type(url: str) -> str:\n    response = requests.head(url)\n    return response.headers[\"content-type\"]\n", "def fetch_content_type(url: str) -> Optional[str]:\n    response = requests.head(url)\n\n    if response.status_code == 200:\n        return response.headers.get(\"content-type\")\n\n    return None\n", "def fetch_content_type(url: str) -> str:\n    response = requests.head(url)\n    response.raise_for_status()\n    return response.headers['content-type']\n", "def fetch_content_type(url: str) -> str:\n    response = requests.head(url, allow_redirects=True)\n    return response.headers.get('content-type')\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def fetch_content_type(url: str) -> str:\n    response = requests.head(url)\n    if response.status_code == 200:\n        return response.headers.get('content-type')\n\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fetch_content_type(url: str) -> str:\n    response = requests.head(url, allow_redirects=True)\n    if response.status_code!= 200:\n        raise NotFound(url)\n    return response.headers[\"content-type\"]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fetch_content_type(url: str) -> Optional[str]:\n    try:\n        response = requests.head(url, allow_redirects=True)\n    except requests.exceptions.RequestException:\n        return None\n\n    if response.status_code == 200:\n        return response.headers.get(\"content-type\", None)\n\n    return None\n", "is_pass": true, "return_code": 0}, {"generate_code": "def fetch_content_type(url: str) -> Optional[str]:\n    response = requests.head(url, allow_redirects=False, timeout=10)\n    return response.headers.get(\"content-type\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fetch_content_type(url: str) -> str:\n    response = requests.head(url, allow_redirects=True)\n    return response.headers.get('content-type')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fetch_content_type(url: str) -> str:\n    response = requests.head(url, allow_redirects=True)\n    response.raise_for_status()\n    return response.headers['content-type']\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fetch_content_type(url: str) -> str:\n    response = requests.head(url)\n    return response.headers[\"content-type\"]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fetch_content_type(url: str) -> Optional[str]:\n    response = requests.head(url)\n\n    if response.status_code == 200:\n        return response.headers.get(\"content-type\")\n\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fetch_content_type(url: str) -> str:\n    response = requests.head(url)\n    response.raise_for_status()\n    return response.headers['content-type']\n", "is_pass": false, "return_code": 1}, {"generate_code": "def fetch_content_type(url: str) -> str:\n    response = requests.head(url, allow_redirects=True)\n    return response.headers.get('content-type')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/utils/text.py", "project": "jaywink/federation", "name": "test_tag", "docstring": "Test a word whether it could be accepted as a tag.", "ques_id": "6306292a52e177c0ba469f41", "code": ["def test_tag(tag: str, word: str) -> bool:\n    return (\n        len(tag) > 0 and word.startswith(tag) and not word.endswith(tag)\n    )\n", "def test_tag(tag: str) -> bool:\n    return bool(tag_pattern.match(tag))\n", "def test_tag(tag: str) -> bool:\n    return tag in TAGS\n", "def test_tag(tag: str) -> bool:\n    return len(tag) > 3 and tag[0] in ['@', '#']\n", "def test_tag(tag: str, word: str) -> bool:\n    if not tag or not word:\n        return False\n    return (word.lower() in get_wordnet_pos(tag))\n", "def test_tag(tag: str, word: str) -> bool:\n    return not ((tag and tag.startswith('?')) or (not tag and word.startswith('?')))\n", "def test_tag(tag: str, word: str) -> bool:\n    return tag in wordnet.TAGS\n", "def test_tag(tag: str) -> bool:\n    return bool(TAG_PATTERN.match(tag))\n", "def test_tag(tag: str) -> bool:\n    return (len(tag) > 2 and tag[0] == \"#\") or (len(tag) == 0 and False)\n", "def test_tag(tag: str, word: str) -> bool:\n    return tag in WORD_TEST_SET and word in WORD_TEST_SET[tag]\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def test_tag(tag: str, word: str) -> bool:\n    return (\n        len(tag) > 0 and word.startswith(tag) and not word.endswith(tag)\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str) -> bool:\n    return bool(tag_pattern.match(tag))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str) -> bool:\n    return tag in TAGS\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str) -> bool:\n    return len(tag) > 3 and tag[0] in ['@', '#']\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str, word: str) -> bool:\n    if not tag or not word:\n        return False\n    return (word.lower() in get_wordnet_pos(tag))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str, word: str) -> bool:\n    return not ((tag and tag.startswith('?')) or (not tag and word.startswith('?')))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str, word: str) -> bool:\n    return tag in wordnet.TAGS\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str) -> bool:\n    return bool(TAG_PATTERN.match(tag))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str) -> bool:\n    return (len(tag) > 2 and tag[0] == \"#\") or (len(tag) == 0 and False)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def test_tag(tag: str, word: str) -> bool:\n    return tag in WORD_TEST_SET and word in WORD_TEST_SET[tag]\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/entities/diaspora/mappers.py", "project": "jaywink/federation", "name": "xml_children_as_dict", "docstring": "Turn the children of node <xml> into a dict, keyed by tag name.\n\nThis is only a shallow conversation - child nodes are not recursively processed.", "ques_id": "6306298b52e177c0ba469fdc", "code": ["def xml_children_as_dict(node):\n    children_as_dict = {}\n    for child in node:\n        tag = child.tag\n        children_as_dict[tag] = child\n    return children_as_dict\n", "def xml_children_as_dict(node):\n    d = {}\n    for child in node.childNodes:\n        if child.nodeType == child.ELEMENT_NODE:\n            d[child.tagName] = child.nodeValue\n    return d\n", "def xml_children_as_dict(node):\n    return {child.tag: child.text for child in node}\n", "def xml_children_as_dict(node):\n    result = {}\n    for child in node:\n        tag = child.tag\n        result[tag] = child.text\n    return result\n", "def xml_children_as_dict(node):\n    return dict((child.tag, child.text) for child in node)\n", "def xml_children_as_dict(node):\n    return {child.tag: child.text for child in node}\n", "def xml_children_as_dict(node):\n    d = {}\n    for c in node:\n        d[c.tag] = c\n    return d\n", "def xml_children_as_dict(node):\n    d = {}\n    for child in node:\n        tag = child.tag\n        d[tag] = child.text\n    return d\n", "def xml_children_as_dict(node):\n    children = {}\n    for child in node:\n        tag = child.tag\n        children[tag] = child\n    return children\n", "def xml_children_as_dict(node):\n    d = {}\n    for child in node.childNodes:\n        if child.nodeType == child.TEXT_NODE:\n            d[child.tagName] = child.data\n    return d\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def xml_children_as_dict(node):\n    children_as_dict = {}\n    for child in node:\n        tag = child.tag\n        children_as_dict[tag] = child\n    return children_as_dict\n", "is_pass": true, "return_code": 0}, {"generate_code": "def xml_children_as_dict(node):\n    d = {}\n    for child in node.childNodes:\n        if child.nodeType == child.ELEMENT_NODE:\n            d[child.tagName] = child.nodeValue\n    return d\n", "is_pass": false, "return_code": 1}, {"generate_code": "def xml_children_as_dict(node):\n    return {child.tag: child.text for child in node}\n", "is_pass": true, "return_code": 0}, {"generate_code": "def xml_children_as_dict(node):\n    result = {}\n    for child in node:\n        tag = child.tag\n        result[tag] = child.text\n    return result\n", "is_pass": true, "return_code": 0}, {"generate_code": "def xml_children_as_dict(node):\n    return dict((child.tag, child.text) for child in node)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def xml_children_as_dict(node):\n    return {child.tag: child.text for child in node}\n", "is_pass": true, "return_code": 0}, {"generate_code": "def xml_children_as_dict(node):\n    d = {}\n    for c in node:\n        d[c.tag] = c\n    return d\n", "is_pass": true, "return_code": 0}, {"generate_code": "def xml_children_as_dict(node):\n    d = {}\n    for child in node:\n        tag = child.tag\n        d[tag] = child.text\n    return d\n", "is_pass": true, "return_code": 0}, {"generate_code": "def xml_children_as_dict(node):\n    children = {}\n    for child in node:\n        tag = child.tag\n        children[tag] = child\n    return children\n", "is_pass": true, "return_code": 0}, {"generate_code": "def xml_children_as_dict(node):\n    d = {}\n    for child in node.childNodes:\n        if child.nodeType == child.TEXT_NODE:\n            d[child.tagName] = child.data\n    return d\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/entities/diaspora/mappers.py", "project": "jaywink/federation", "name": "check_sender_and_entity_handle_match", "docstring": "Ensure that sender and entity handles match.\n\nBasically we've already verified the sender is who they say when receiving the payload. However, the sender might\nbe trying to set another author in the payload itself, since Diaspora has the sender in both the payload headers\nAND the object. We must ensure they're the same.", "ques_id": "6306299052e177c0ba469fe8", "code": ["def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle == entity_handle:\n        return\n\n    msg_from = entity_handle['from']\n    msg_to = sender_handle['to']\n    if msg_from!= msg_to:\n        raise Exception(\"Sender and receiver handle don't match. Received: {0} {1}\".format(msg_from, msg_to))\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle!= entity_handle:\n        raise ValueError(\"Sender handle mismatch (expected {0}, actual {1})\".format(sender_handle, entity_handle))\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle!= entity_handle:\n        raise BadRequest(\"Sender handle mismatch.\")\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle!= entity_handle:\n        raise BadRequest(\"Sender handle mismatch. Expected: {}, received: {}\".format(entity_handle, sender_handle))\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n\n    if sender_handle!= entity_handle:\n        raise ValueError(\n            'Sender handle does not match the entity handle, '\n           'sender: {}, entity: {}'.format(sender_handle, entity_handle)\n        )\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle!= entity_handle:\n        raise BadRequest(\"Sender handle mismatch\")\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle == entity_handle:\n        return\n    if sender_handle is None or entity_handle is None:\n        return\n    raise ValueError(\n        'Sender and entity handles do not match. '\n        'Sender: {}, Entity: {}'.format(sender_handle, entity_handle)\n    )\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle == entity_handle:\n        return True\n    if '@' in sender_handle:\n        if sender_handle.startswith('@'):\n            return True\n        if entity_handle == sender_handle:\n            return True\n    if '/' in sender_handle:\n        if sender_handle.startswith('/'):\n            return True\n        if entity_handle == sender_handle:\n            return True\n    return False\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle!= entity_handle:\n        raise ValueError(\n            'Sender handle mismatch, expected {}, received {}.'.format(\n                sender_handle, entity_handle))\n", "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n\n    if sender_handle!= entity_handle:\n        raise exceptions.SenderHandleMismatch(\n            'Sender handle does not match entity handle')\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle == entity_handle:\n        return\n\n    msg_from = entity_handle['from']\n    msg_to = sender_handle['to']\n    if msg_from!= msg_to:\n        raise Exception(\"Sender and receiver handle don't match. Received: {0} {1}\".format(msg_from, msg_to))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle!= entity_handle:\n        raise ValueError(\"Sender handle mismatch (expected {0}, actual {1})\".format(sender_handle, entity_handle))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle!= entity_handle:\n        raise BadRequest(\"Sender handle mismatch.\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle!= entity_handle:\n        raise BadRequest(\"Sender handle mismatch. Expected: {}, received: {}\".format(entity_handle, sender_handle))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n\n    if sender_handle!= entity_handle:\n        raise ValueError(\n            'Sender handle does not match the entity handle, '\n           'sender: {}, entity: {}'.format(sender_handle, entity_handle)\n        )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle!= entity_handle:\n        raise BadRequest(\"Sender handle mismatch\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle == entity_handle:\n        return\n    if sender_handle is None or entity_handle is None:\n        return\n    raise ValueError(\n        'Sender and entity handles do not match. '\n        'Sender: {}, Entity: {}'.format(sender_handle, entity_handle)\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle == entity_handle:\n        return True\n    if '@' in sender_handle:\n        if sender_handle.startswith('@'):\n            return True\n        if entity_handle == sender_handle:\n            return True\n    if '/' in sender_handle:\n        if sender_handle.startswith('/'):\n            return True\n        if entity_handle == sender_handle:\n            return True\n    return False\n", "is_pass": true, "return_code": 0}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n    if sender_handle!= entity_handle:\n        raise ValueError(\n            'Sender handle mismatch, expected {}, received {}.'.format(\n                sender_handle, entity_handle))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def check_sender_and_entity_handle_match(sender_handle, entity_handle):\n\n    if sender_handle!= entity_handle:\n        raise exceptions.SenderHandleMismatch(\n            'Sender handle does not match entity handle')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/hostmeta/generators.py", "project": "jaywink/federation", "name": "get_nodeinfo_well_known_document", "docstring": "Generate a NodeInfo .well-known document.\n\nSee spec: http://nodeinfo.diaspora.software\n\n:arg url: The full base url with protocol, ie https://example.com\n:arg document_path: Custom NodeInfo document path if supplied (optional)\n:returns: dict", "ques_id": "630629b952e177c0ba46a043", "code": ["def get_nodeinfo_well_known_document(url, document_path=None):\n    if document_path is not None:\n        url = '{}/{}'.format(url, document_path)\n\n    resp = requests.get(url, auth=(settings.USER, settings.PASSWORD))\n    resp.raise_for_status()\n\n    return resp.json()\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    if document_path is None:\n        document_path = \"/node-info/document.well-known.doc\"\n    return {\n        \"url\": url,\n        \"document_path\": document_path,\n        \"namespace\": \"http://example.com\",\n        \"node_info\": {\"version\": \"1.0\"},\n    }\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    document = {\n        \"@type\": \"NodeInfo\",\n        \"serial\": \"0000000000-0000-0000-0000-000000000001\",\n        \"ip\": \"127.0.0.1\",\n        \"os\": \"Windows\",\n        \"browser\": \"Firefox\",\n        \"version\": \"1\",\n        \"manufacturer\": \"Firefox\",\n        \"model\": \"1\",\n        \"os_version\": \"1\",\n        \"cpu\": \"100\",\n        \"memory\": \"500\",\n        \"os_arch\": \"x86_64\",\n        \"os_release\": \"\",\n        \"os_version_codename\": \"\",\n        \"disk_space\": \"50\",\n        \"os_machine\": \"i386\",\n        \"os_type\": \"Linux\",\n        \"os_os_version\": \"\",\n        \"os_release_codename\": \"\",\n        \"os_arch\": \"\",\n        \"os_arch_codename\": \"\",\n    }\n\n    if document_path:\n        document['document_path'] = document_path\n\n    return document", "def get_nodeinfo_well_known_document(url, document_path=None):\n    document_path = document_path or ''\n    if document_path:\n        base_url = '%s/%s' % (url, document_path)\n    else:\n        base_url = url\n    return {\n        'base_url': base_url,\n        'document_path': document_path,\n        'document_name': os.path.basename(document_path),\n        'document_version': '1.0',\n        'document_created': datetime.datetime.utcnow(),\n        'document_last_modified': datetime.datetime.utcnow(),\n    }\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    if document_path is None:\n        url += '/document'\n    else:\n        url += '/' + document_path\n\n    r = requests.get(url, auth=(settings.USER, settings.PASSWORD))\n    r.raise_for_status()\n\n    return r.json()\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    if document_path is None:\n        document_path = ''\n\n    return {\n        \"version\": \"1.2.3\",\n        \"document_root\": url,\n        \"document_path\": document_path,\n        \"schema_version\": 1,\n        \"tags\": [],\n    }\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    if document_path is None:\n        document_path = '/'.join([url.rstrip('/').split('/')[:-1], 'document.well-known'])\n\n    result = requests.get(url, stream=True)\n    with open(document_path, 'wb') as stream:\n        for chunk in result.iter_content(chunk_size=1024):\n            if chunk:  # filter out keep-alive new chunks\n                stream.write(chunk)\n\n    return result.json()\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n\n    document_path = document_path or \"/node-info.well-known\"\n\n    return {\n        \"version\": \"1.0\",\n        \"path\": document_path,\n        \"base_url\": url,\n        \"document_path\": document_path,\n    }\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    document_path = document_path or ''\n    url = '%s/%s' % (url, document_path)\n\n    resp = requests.get(url, auth=('sandbox', 'api-token'))\n    resp.raise_for_status()\n\n    return resp.json()\n", "def get_nodeinfo_well_known_document(url, document_path=None):\n    if document_path is None:\n        document_path = '/'.join([url, 'document'])\n\n    return {\n        'document_path': document_path,\n        'document_url': url,\n        'document_type': 'well-known',\n    }\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    if document_path is not None:\n        url = '{}/{}'.format(url, document_path)\n\n    resp = requests.get(url, auth=(settings.USER, settings.PASSWORD))\n    resp.raise_for_status()\n\n    return resp.json()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    if document_path is None:\n        document_path = \"/node-info/document.well-known.doc\"\n    return {\n        \"url\": url,\n        \"document_path\": document_path,\n        \"namespace\": \"http://example.com\",\n        \"node_info\": {\"version\": \"1.0\"},\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    document = {\n        \"@type\": \"NodeInfo\",\n        \"serial\": \"0000000000-0000-0000-0000-000000000001\",\n        \"ip\": \"127.0.0.1\",\n        \"os\": \"Windows\",\n        \"browser\": \"Firefox\",\n        \"version\": \"1\",\n        \"manufacturer\": \"Firefox\",\n        \"model\": \"1\",\n        \"os_version\": \"1\",\n        \"cpu\": \"100\",\n        \"memory\": \"500\",\n        \"os_arch\": \"x86_64\",\n        \"os_release\": \"\",\n        \"os_version_codename\": \"\",\n        \"disk_space\": \"50\",\n        \"os_machine\": \"i386\",\n        \"os_type\": \"Linux\",\n        \"os_os_version\": \"\",\n        \"os_release_codename\": \"\",\n        \"os_arch\": \"\",\n        \"os_arch_codename\": \"\",\n    }\n\n    if document_path:\n        document['document_path'] = document_path\n\n    return document", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    document_path = document_path or ''\n    if document_path:\n        base_url = '%s/%s' % (url, document_path)\n    else:\n        base_url = url\n    return {\n        'base_url': base_url,\n        'document_path': document_path,\n        'document_name': os.path.basename(document_path),\n        'document_version': '1.0',\n        'document_created': datetime.datetime.utcnow(),\n        'document_last_modified': datetime.datetime.utcnow(),\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    if document_path is None:\n        url += '/document'\n    else:\n        url += '/' + document_path\n\n    r = requests.get(url, auth=(settings.USER, settings.PASSWORD))\n    r.raise_for_status()\n\n    return r.json()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    if document_path is None:\n        document_path = ''\n\n    return {\n        \"version\": \"1.2.3\",\n        \"document_root\": url,\n        \"document_path\": document_path,\n        \"schema_version\": 1,\n        \"tags\": [],\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    if document_path is None:\n        document_path = '/'.join([url.rstrip('/').split('/')[:-1], 'document.well-known'])\n\n    result = requests.get(url, stream=True)\n    with open(document_path, 'wb') as stream:\n        for chunk in result.iter_content(chunk_size=1024):\n            if chunk:  # filter out keep-alive new chunks\n                stream.write(chunk)\n\n    return result.json()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n\n    document_path = document_path or \"/node-info.well-known\"\n\n    return {\n        \"version\": \"1.0\",\n        \"path\": document_path,\n        \"base_url\": url,\n        \"document_path\": document_path,\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    document_path = document_path or ''\n    url = '%s/%s' % (url, document_path)\n\n    resp = requests.get(url, auth=('sandbox', 'api-token'))\n    resp.raise_for_status()\n\n    return resp.json()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nodeinfo_well_known_document(url, document_path=None):\n    if document_path is None:\n        document_path = '/'.join([url, 'document'])\n\n    return {\n        'document_path': document_path,\n        'document_url': url,\n        'document_type': 'well-known',\n    }\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/protocols/diaspora/signatures.py", "project": "jaywink/federation", "name": "verify_relayable_signature", "docstring": "Verify the signed XML elements to have confidence that the claimed\nauthor did actually generate this message.", "ques_id": "630629d052e177c0ba46a0a1", "code": ["def verify_relayable_signature(public_key, doc, signature):\n\n    if signature is None:\n        return True\n\n    # TODO: verify the signature using the public key\n    return True\n", "def verify_relayable_signature(public_key, doc, signature):\n    return _verify_signature(public_key, doc, signature,'relayable')\n", "def verify_relayable_signature(public_key, doc, signature):\n    return _verify_signature(public_key, doc, signature)\n", "def verify_relayable_signature(public_key, doc, signature):\n    if not signature:\n        return\n\n    key = etree.XML(public_key)\n    digest = hashlib.sha256(etree.tostring(doc, encoding='utf-8')).digest()\n\n    if not key.find(\".//Signature\").text:\n        return\n\n    sighash = key.find(\".//Signature[@SIGNATURE]\").text\n    if sighash!= digest:\n        raise ValueError(\"Message signature does not match claimed signature\")\n", "def verify_relayable_signature(public_key, doc, signature):\n    return _verify_signature(public_key, doc, signature,'relayable')\n", "def verify_relayable_signature(public_key, doc, signature):\n    cert_str = doc.xpath(\".//tei:Signature/tei:Certificate\",\n                         namespaces=NSMAP)[0].text\n    cert = X509.load_cert_string(cert_str, X509.FORMAT_DER)\n    h = SHA256.new()\n    h.update(public_key.encode('ascii'))\n    signer = PKCS1_v1_5.new(cert)\n    digest = SHA256.new()\n    digest.update(signature.encode('ascii'))\n    if (cert.get_signature_algorithm()!=\n            signer.signature_algorithm):\n        raise SignatureMismatch()\n    if cert.get_signature_algorithm() == X509.SIGN_VERIFY:\n        if signer.verify(h, digest):\n            return True\n        else:\n            raise SignatureMismatch()\n    else:\n        if signer.verify(h, digest):\n            return True\n        else:\n            raise SignatureMismatch()\n", "def verify_relayable_signature(public_key, doc, signature):\n\n    if not signature:\n        return\n\n    return verify_signature(public_key, doc, signature)\n", "def verify_relayable_signature(public_key, doc, signature):\n    signer = PKCS1_v1_5.new(public_key)\n    return signer.verify(signature, doc.toxml())\n", "def verify_relayable_signature(public_key, doc, signature):\n    if not signature.startswith('Signature='):\n        return False\n    sig = signature.split('=', 1)[1]\n    return _verify_relayable_signature(public_key, doc, sig)\n", "def verify_relayable_signature(public_key, doc, signature):\n    try:\n        return _verify_signature(public_key, signature, doc)\n    except SignatureMismatch:\n        return False\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n\n    if signature is None:\n        return True\n\n    # TODO: verify the signature using the public key\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n    return _verify_signature(public_key, doc, signature,'relayable')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n    return _verify_signature(public_key, doc, signature)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n    if not signature:\n        return\n\n    key = etree.XML(public_key)\n    digest = hashlib.sha256(etree.tostring(doc, encoding='utf-8')).digest()\n\n    if not key.find(\".//Signature\").text:\n        return\n\n    sighash = key.find(\".//Signature[@SIGNATURE]\").text\n    if sighash!= digest:\n        raise ValueError(\"Message signature does not match claimed signature\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n    return _verify_signature(public_key, doc, signature,'relayable')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n    cert_str = doc.xpath(\".//tei:Signature/tei:Certificate\",\n                         namespaces=NSMAP)[0].text\n    cert = X509.load_cert_string(cert_str, X509.FORMAT_DER)\n    h = SHA256.new()\n    h.update(public_key.encode('ascii'))\n    signer = PKCS1_v1_5.new(cert)\n    digest = SHA256.new()\n    digest.update(signature.encode('ascii'))\n    if (cert.get_signature_algorithm()!=\n            signer.signature_algorithm):\n        raise SignatureMismatch()\n    if cert.get_signature_algorithm() == X509.SIGN_VERIFY:\n        if signer.verify(h, digest):\n            return True\n        else:\n            raise SignatureMismatch()\n    else:\n        if signer.verify(h, digest):\n            return True\n        else:\n            raise SignatureMismatch()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n\n    if not signature:\n        return\n\n    return verify_signature(public_key, doc, signature)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n    signer = PKCS1_v1_5.new(public_key)\n    return signer.verify(signature, doc.toxml())\n", "is_pass": false, "return_code": 1}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n    if not signature.startswith('Signature='):\n        return False\n    sig = signature.split('=', 1)[1]\n    return _verify_relayable_signature(public_key, doc, sig)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def verify_relayable_signature(public_key, doc, signature):\n    try:\n        return _verify_signature(public_key, signature, doc)\n    except SignatureMismatch:\n        return False\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/utils/diaspora.py", "project": "jaywink/federation", "name": "parse_diaspora_webfinger", "docstring": "Parse Diaspora webfinger which is either in JSON format (new) or XRD (old).\n\nhttps://diaspora.github.io/diaspora_federation/discovery/webfinger.html", "ques_id": "630629e052e177c0ba46a0c4", "code": ["def parse_diaspora_webfinger(document: Document, url: str) -> Optional[Webfinger]:\n    # JSON format is the default\n    if \"json\" in document.url:\n        return Webfinger.from_url(url)\n    # XRD format is the old format\n    elif \"xrd\" in document.url:\n        return Webfinger.from_url(url, is_legacy=True)\n\n    return None\n", "def parse_diaspora_webfinger(document: Document, url: str) -> Webfinger:\n    if \"webfinger.com\" in url:\n        try:\n            return Webfinger(url)\n        except ValueError:\n            pass\n    elif \"json\" in url:\n        try:\n            data = json.loads(document.text)\n        except json.decoder.JSONDecodeError:\n            pass\n        else:\n            return Webfinger(data)\n    elif \"xrd\" in url:\n        return Webfinger(url)\n    else:\n        raise ValueError(\"Unrecognized URL format: {}\".format(url))\n", "def parse_diaspora_webfinger(document: Document, url: str) -> WebfingerJsonParser:\n    if not document.get('webfinger'):\n        return WebfingerJsonParser(url=url).read()\n    else:\n        return WebfingerJsonParser(url=url, document=document).read()\n", "def parse_diaspora_webfinger(document: Document, url: str) -> Dict[str, Any]:\n    if url.endswith('.json'):\n        return json.loads(document.text)\n    else:\n        with open(url) as fp:\n            return json.load(fp)\n", "def parse_diaspora_webfinger(document: Document, url: str) -> WebfingerJsonParsed:\n    if url.endswith('.json'):\n        return WebfingerJsonParsed.from_json_file(url)\n    elif url.endswith('.xrd'):\n        return WebfingerJsonParsed.from_xrd_file(url)\n    else:\n        raise ValueError('unknown file type')\n", "def parse_diaspora_webfinger(document: Document) -> dict:\n    if not document.get(\"webfinger\"):\n        return {\"version\": \"unknown\"}\n    if not document.get(\"webfinger_version\"):\n        return {\"version\": \"unknown\"}\n    return {\"webfinger\": document[\"webfinger\"]}\n", "def parse_diaspora_webfinger(document: Document, url: str) -> WebfingerJson:\n    if url.endswith('.json'):\n        return parse_webfinger_json(document, url)\n    else:\n        return parse_webfinger_xrd(document, url)\n", "def parse_diaspora_webfinger(document: Document) -> Dict[str, str]:\n    if document.get('type', '') == 'diaspora_webfinger':\n        return {\n            'fingerprint': document.get('fingerprint'),\n            'identifier': document.get('identifier'),\n        }\n\n    return {}\n", "def parse_diaspora_webfinger(document: Document, resource: IResource) -> Iterator[Webfinger]:\n    if document.get('format')!= 'json':\n        return\n\n    webfinger = Webfinger()\n    webfinger.name = resource.name\n    webfinger.id = resource.id\n    webfinger.url = resource.url\n\n    yield webfinger\n", "def parse_diaspora_webfinger(document: Document) -> dict:\n    if document.url is None:\n        return {\"webfinger\": document.json[\"webfinger\"]}\n    return {\"webfinger\": document.url}\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def parse_diaspora_webfinger(document: Document, url: str) -> Optional[Webfinger]:\n    # JSON format is the default\n    if \"json\" in document.url:\n        return Webfinger.from_url(url)\n    # XRD format is the old format\n    elif \"xrd\" in document.url:\n        return Webfinger.from_url(url, is_legacy=True)\n\n    return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: Document, url: str) -> Webfinger:\n    if \"webfinger.com\" in url:\n        try:\n            return Webfinger(url)\n        except ValueError:\n            pass\n    elif \"json\" in url:\n        try:\n            data = json.loads(document.text)\n        except json.decoder.JSONDecodeError:\n            pass\n        else:\n            return Webfinger(data)\n    elif \"xrd\" in url:\n        return Webfinger(url)\n    else:\n        raise ValueError(\"Unrecognized URL format: {}\".format(url))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: Document, url: str) -> WebfingerJsonParser:\n    if not document.get('webfinger'):\n        return WebfingerJsonParser(url=url).read()\n    else:\n        return WebfingerJsonParser(url=url, document=document).read()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: Document, url: str) -> Dict[str, Any]:\n    if url.endswith('.json'):\n        return json.loads(document.text)\n    else:\n        with open(url) as fp:\n            return json.load(fp)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: Document, url: str) -> WebfingerJsonParsed:\n    if url.endswith('.json'):\n        return WebfingerJsonParsed.from_json_file(url)\n    elif url.endswith('.xrd'):\n        return WebfingerJsonParsed.from_xrd_file(url)\n    else:\n        raise ValueError('unknown file type')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: Document) -> dict:\n    if not document.get(\"webfinger\"):\n        return {\"version\": \"unknown\"}\n    if not document.get(\"webfinger_version\"):\n        return {\"version\": \"unknown\"}\n    return {\"webfinger\": document[\"webfinger\"]}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: Document, url: str) -> WebfingerJson:\n    if url.endswith('.json'):\n        return parse_webfinger_json(document, url)\n    else:\n        return parse_webfinger_xrd(document, url)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: Document) -> Dict[str, str]:\n    if document.get('type', '') == 'diaspora_webfinger':\n        return {\n            'fingerprint': document.get('fingerprint'),\n            'identifier': document.get('identifier'),\n        }\n\n    return {}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: Document, resource: IResource) -> Iterator[Webfinger]:\n    if document.get('format')!= 'json':\n        return\n\n    webfinger = Webfinger()\n    webfinger.name = resource.name\n    webfinger.id = resource.id\n    webfinger.url = resource.url\n\n    yield webfinger\n", "is_pass": false, "return_code": 1}, {"generate_code": "def parse_diaspora_webfinger(document: Document) -> dict:\n    if document.url is None:\n        return {\"webfinger\": document.json[\"webfinger\"]}\n    return {\"webfinger\": document.url}\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/utils/network.py", "project": "jaywink/federation", "name": "try_retrieve_webfinger_document", "docstring": "Try to retrieve an RFC7033 webfinger document. Does not raise if it fails.", "ques_id": "630629e152e177c0ba46a0d1", "code": ["def try_retrieve_webfinger_document(handle: BinaryIO) -> str:\n    response = handle.read()\n    if response!= b\"\":\n        try:\n            webfinger_document = response.decode(\"utf-8\")\n        except UnicodeDecodeError:\n            webfinger_document = response.decode(\"latin-1\")\n        return webfinger_document\n    else:\n        return \"\"\n", "def try_retrieve_webfinger_document(handle: TextIO) -> Optional[str]:\n    try:\n        handle.seek(0)\n        return handle.read()\n    except Exception:\n        return None\n", "def try_retrieve_webfinger_document(handle: TextIO) -> bytes:\n    for response in handle:\n        if response.status == codes.ok:\n            return response.read()\n    return b''\n", "def try_retrieve_webfinger_document(handle: TextIO) -> bytes:\n    try:\n        handle.seek(0)\n        return handle.read(131072)\n    except (URLError, HTTPError):\n        return b\"\"\n", "def try_retrieve_webfinger_document(handle: TextIO, separator: str = ';'):\n    try:\n        return handle.read().decode('utf-8').split(separator)\n    except (UnicodeDecodeError, TypeError):\n        return []\n", "def try_retrieve_webfinger_document(handle: TextIO, timeout: int = 10) -> str:\n    handle.seek(0)\n    return handle.read(timeout)\n", "def try_retrieve_webfinger_document(handle: BinaryIO, timeout: int = 5) -> str:\n    try:\n        handle.open(timeout=timeout)\n    except (URLError, HTTPError) as e:\n        if e.code == 404:\n            # Found nothing. Don't try again.\n            return \"\"\n        raise\n    else:\n        handle.close()\n        return handle.read().decode(\"utf-8\")\n", "def try_retrieve_webfinger_document(handle: BinaryIO, username: str) -> bytes:\n    handle.seek(0)\n    data = handle.read(1024)\n    if len(data) < 1024:\n        return data\n\n    # Try to retrieve the document using a mocked webfinger token.\n    resp = requests.get(\n        'https://docs.google.com/document/d/{}/'.format(username),\n        auth=('user', 'pass'),\n        headers={'Referer': 'https://docs.google.com/document/d/{}/'.format(username)},\n        stream=True,\n    )\n    resp.raise_for_status()\n\n    return resp.content\n", "def try_retrieve_webfinger_document(handle: TextIO) -> str:\n    try:\n        handle.seek(0)\n        return handle.read()\n    except (URLError, HTTPError):\n        return \"\"\n", "def try_retrieve_webfinger_document(handle: BinaryIO, url: str):\n    # Do not try to retrieve a URL that has already been downloaded.\n    if url in handle.name:\n        return\n\n    handle.seek(0)\n    try:\n        handle.read(1024)\n        handle.seek(0)\n    except Exception:\n        raise ValueError('Unable to retrieve webfinger document from URL \"{}\"'.format(url))\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def try_retrieve_webfinger_document(handle: BinaryIO) -> str:\n    response = handle.read()\n    if response!= b\"\":\n        try:\n            webfinger_document = response.decode(\"utf-8\")\n        except UnicodeDecodeError:\n            webfinger_document = response.decode(\"latin-1\")\n        return webfinger_document\n    else:\n        return \"\"\n", "is_pass": false, "return_code": 1}, {"generate_code": "def try_retrieve_webfinger_document(handle: TextIO) -> Optional[str]:\n    try:\n        handle.seek(0)\n        return handle.read()\n    except Exception:\n        return None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def try_retrieve_webfinger_document(handle: TextIO) -> bytes:\n    for response in handle:\n        if response.status == codes.ok:\n            return response.read()\n    return b''\n", "is_pass": false, "return_code": 1}, {"generate_code": "def try_retrieve_webfinger_document(handle: TextIO) -> bytes:\n    try:\n        handle.seek(0)\n        return handle.read(131072)\n    except (URLError, HTTPError):\n        return b\"\"\n", "is_pass": false, "return_code": 1}, {"generate_code": "def try_retrieve_webfinger_document(handle: TextIO, separator: str = ';'):\n    try:\n        return handle.read().decode('utf-8').split(separator)\n    except (UnicodeDecodeError, TypeError):\n        return []\n", "is_pass": false, "return_code": 1}, {"generate_code": "def try_retrieve_webfinger_document(handle: TextIO, timeout: int = 10) -> str:\n    handle.seek(0)\n    return handle.read(timeout)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def try_retrieve_webfinger_document(handle: BinaryIO, timeout: int = 5) -> str:\n    try:\n        handle.open(timeout=timeout)\n    except (URLError, HTTPError) as e:\n        if e.code == 404:\n            # Found nothing. Don't try again.\n            return \"\"\n        raise\n    else:\n        handle.close()\n        return handle.read().decode(\"utf-8\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def try_retrieve_webfinger_document(handle: BinaryIO, username: str) -> bytes:\n    handle.seek(0)\n    data = handle.read(1024)\n    if len(data) < 1024:\n        return data\n\n    # Try to retrieve the document using a mocked webfinger token.\n    resp = requests.get(\n        'https://docs.google.com/document/d/{}/'.format(username),\n        auth=('user', 'pass'),\n        headers={'Referer': 'https://docs.google.com/document/d/{}/'.format(username)},\n        stream=True,\n    )\n    resp.raise_for_status()\n\n    return resp.content\n", "is_pass": false, "return_code": 1}, {"generate_code": "def try_retrieve_webfinger_document(handle: TextIO) -> str:\n    try:\n        handle.seek(0)\n        return handle.read()\n    except (URLError, HTTPError):\n        return \"\"\n", "is_pass": false, "return_code": 1}, {"generate_code": "def try_retrieve_webfinger_document(handle: BinaryIO, url: str):\n    # Do not try to retrieve a URL that has already been downloaded.\n    if url in handle.name:\n        return\n\n    handle.seek(0)\n    try:\n        handle.read(1024)\n        handle.seek(0)\n    except Exception:\n        raise ValueError('Unable to retrieve webfinger document from URL \"{}\"'.format(url))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/utils/diaspora.py", "project": "jaywink/federation", "name": "retrieve_and_parse_diaspora_webfinger", "docstring": "Retrieve a and parse a remote Diaspora webfinger document.\n\n:arg handle: Remote handle to retrieve\n:returns: dict", "ques_id": "630629e152e177c0ba46a0d2", "code": ["def retrieve_and_parse_diaspora_webfinger(handle):\n    result = retrieve_remote_content(handle, 'Webfinger')\n    return parse_webfinger_result(result)\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = handle.get('ds.webfinger.get')\n    return parse_webfinger_response(response)\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = handle.get('https://diaspora.com/fingerprint')\n    return parse_webfinger_response(response.text)\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = handle.get_records(0, 100)\n    return parse_diaspora_response(response)\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    doc = handle.read()\n    doc = str(doc)\n    return json.loads(doc)\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = handle.get('/v2/documents/webfinger')\n    if not response.ok:\n        return None\n\n    return parse_webfinger_response(response)\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = handle.get_records(1, 1)\n    return response\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = handle.get('/webfinger/document.xml')\n    root = ElementTree.fromstring(response.content)\n\n    # If we get a successful response, return the result\n    if root.tag =='response':\n        return root.attrib\n\n    # Otherwise, we try to parse the response as a dictionary\n    try:\n        return parse_xml_as_dict(root)\n    except ElementTree.ParseError:\n        pass\n\n    # If we get a failed response, return None\n    try:\n        return None\n    except AttributeError:\n        pass\n\n    raise Exception('Received invalid XML: %s' % response.content)\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = handle.get('/webfinger')\n    return response.json()\n", "def retrieve_and_parse_diaspora_webfinger(handle):\n    content = handle.read()\n    soup = BeautifulSoup(content, \"html.parser\")\n    result = {\n        \"handle\": handle.geturl(),\n        \"name\": soup.find(\"div\", {\"class\": \"diaspora-name\"}).text.strip(),\n        \"email\": soup.find(\"div\", {\"class\": \"diaspora-email\"}).text.strip(),\n        \"phone\": soup.find(\"div\", {\"class\": \"diaspora-phone\"}).text.strip(),\n        \"domain\": soup.find(\"div\", {\"class\": \"diaspora-domain\"}).text.strip(),\n    }\n    return result\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    result = retrieve_remote_content(handle, 'Webfinger')\n    return parse_webfinger_result(result)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = handle.get('ds.webfinger.get')\n    return parse_webfinger_response(response)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = handle.get('https://diaspora.com/fingerprint')\n    return parse_webfinger_response(response.text)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = handle.get_records(0, 100)\n    return parse_diaspora_response(response)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    doc = handle.read()\n    doc = str(doc)\n    return json.loads(doc)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = handle.get('/v2/documents/webfinger')\n    if not response.ok:\n        return None\n\n    return parse_webfinger_response(response)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = handle.get_records(1, 1)\n    return response\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = handle.get('/webfinger/document.xml')\n    root = ElementTree.fromstring(response.content)\n\n    # If we get a successful response, return the result\n    if root.tag =='response':\n        return root.attrib\n\n    # Otherwise, we try to parse the response as a dictionary\n    try:\n        return parse_xml_as_dict(root)\n    except ElementTree.ParseError:\n        pass\n\n    # If we get a failed response, return None\n    try:\n        return None\n    except AttributeError:\n        pass\n\n    raise Exception('Received invalid XML: %s' % response.content)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    response = handle.get('/webfinger')\n    return response.json()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_and_parse_diaspora_webfinger(handle):\n    content = handle.read()\n    soup = BeautifulSoup(content, \"html.parser\")\n    result = {\n        \"handle\": handle.geturl(),\n        \"name\": soup.find(\"div\", {\"class\": \"diaspora-name\"}).text.strip(),\n        \"email\": soup.find(\"div\", {\"class\": \"diaspora-email\"}).text.strip(),\n        \"phone\": soup.find(\"div\", {\"class\": \"diaspora-phone\"}).text.strip(),\n        \"domain\": soup.find(\"div\", {\"class\": \"diaspora-domain\"}).text.strip(),\n    }\n    return result\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/utils/diaspora.py", "project": "jaywink/federation", "name": "retrieve_diaspora_host_meta", "docstring": "Retrieve a remote Diaspora host-meta document.\n\n:arg host: Host to retrieve from\n:returns: ``XRD`` instance", "ques_id": "630629e252e177c0ba46a0d6", "code": ["def retrieve_diaspora_host_meta(host):\n    url = \"https://api.hostmeta.org/hosts/{0}/document\".format(host)\n    resp = requests.get(url)\n    resp.raise_for_status()\n    return resp.json()\n", "def retrieve_diaspora_host_meta(host):\n    response = requests.get(\n        DIAsporaHostMetaData.host_meta_url.format(host),\n        auth=(settings.USER, settings.PASSWORD),\n        timeout=settings.TIMEOUT)\n\n    response.raise_for_status()\n\n    return XRD(response.content)\n", "def retrieve_diaspora_host_meta(host):\n    # Get XRD\n    xrd = xrd_manager.get_diaspora_xrd(host)\n    if xrd is None:\n        raise Exception(\"Couldn't get XRD for host %s\" % host)\n\n    # Return XRD\n    return xrd\n", "def retrieve_diaspora_host_meta(host):\n    if host == 'localhost':\n        host = '127.0.0.1'\n    url = 'http://%s/xrd' % host\n    r = requests.get(url)\n    return r.content\n", "def retrieve_diaspora_host_meta(host):\n    xrd = xrdapi.XRD(host)\n    return xrd.retrieve_metadata()\n", "def retrieve_diaspora_host_meta(host):\n    url = 'https://{host}/api/v1/documents/meta'.format(host=host)\n    r = requests.get(url)\n    if r.status_code!= 200:\n        raise RuntimeError('Retrieving diaspora host-meta failed: %d' % r.status_code)\n    return r.json()\n", "def retrieve_diaspora_host_meta(host):\n    response = requests.get(\n        'https://%s/xrd/host-meta' % host,\n        auth=(settings.XRD_USER, settings.XRD_PASSWORD))\n    response.raise_for_status()\n    return response.json()\n", "def retrieve_diaspora_host_meta(host):\n    url = '%s/host-meta' % host\n    resp = requests.get(url)\n    resp.raise_for_status()\n    return XRD(resp.content)\n", "def retrieve_diaspora_host_meta(host):\n    url = \"https://%s/api/v1/host-meta\" % host\n    r = requests.get(url)\n    r.raise_for_status()\n    return r.json()\n", "def retrieve_diaspora_host_meta(host):\n    url = (\n        \"https://api.diaspora.org/v1/hosts/{host}?key={api_key}\"\n    ).format(\n        host=host,\n        api_key=DIAspora.API_KEY\n    )\n\n    r = requests.get(url)\n    r.raise_for_status()\n\n    return r.json()\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def retrieve_diaspora_host_meta(host):\n    url = \"https://api.hostmeta.org/hosts/{0}/document\".format(host)\n    resp = requests.get(url)\n    resp.raise_for_status()\n    return resp.json()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    response = requests.get(\n        DIAsporaHostMetaData.host_meta_url.format(host),\n        auth=(settings.USER, settings.PASSWORD),\n        timeout=settings.TIMEOUT)\n\n    response.raise_for_status()\n\n    return XRD(response.content)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    # Get XRD\n    xrd = xrd_manager.get_diaspora_xrd(host)\n    if xrd is None:\n        raise Exception(\"Couldn't get XRD for host %s\" % host)\n\n    # Return XRD\n    return xrd\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    if host == 'localhost':\n        host = '127.0.0.1'\n    url = 'http://%s/xrd' % host\n    r = requests.get(url)\n    return r.content\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    xrd = xrdapi.XRD(host)\n    return xrd.retrieve_metadata()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    url = 'https://{host}/api/v1/documents/meta'.format(host=host)\n    r = requests.get(url)\n    if r.status_code!= 200:\n        raise RuntimeError('Retrieving diaspora host-meta failed: %d' % r.status_code)\n    return r.json()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    response = requests.get(\n        'https://%s/xrd/host-meta' % host,\n        auth=(settings.XRD_USER, settings.XRD_PASSWORD))\n    response.raise_for_status()\n    return response.json()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    url = '%s/host-meta' % host\n    resp = requests.get(url)\n    resp.raise_for_status()\n    return XRD(resp.content)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    url = \"https://%s/api/v1/host-meta\" % host\n    r = requests.get(url)\n    r.raise_for_status()\n    return r.json()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def retrieve_diaspora_host_meta(host):\n    url = (\n        \"https://api.diaspora.org/v1/hosts/{host}?key={api_key}\"\n    ).format(\n        host=host,\n        api_key=DIAspora.API_KEY\n    )\n\n    r = requests.get(url)\n    r.raise_for_status()\n\n    return r.json()\n", "is_pass": false, "return_code": 1}]}
{"file_path": "federation/utils/network.py", "project": "jaywink/federation", "name": "send_document", "docstring": "Helper method to send a document via POST.\n\nAdditional ``*args`` and ``**kwargs`` will be passed on to ``requests.post``.\n\n:arg url: Full url to send to, including protocol\n:arg data: Dictionary (will be form-encoded), bytes, or file-like object to send in the body\n:arg timeout: Seconds to wait for response (defaults to 10)\n:arg method: Method to use, defaults to post\n:returns: Tuple of status code (int or None) and error (exception class instance or None)", "ques_id": "630629e752e177c0ba46a0fb", "code": ["def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(url, data=data, timeout=timeout, *args, **kwargs)\n    if response.status_code == 200:\n        return (response.status_code, response)\n    return (response.status_code, response.text)\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(url, data=data, timeout=timeout, **kwargs)\n    response.raise_for_status()\n    return response.status_code, response\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    return _send_document(url, data, timeout, method, *args, **kwargs)\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = None\n\n    # if data is file-like, then send it as multipart/form-data content\n    if hasattr(data, \"read\"):\n        response = requests.post(url, data=data, headers={\"Content-Type\": \"multipart/form-data\"}, timeout=timeout, *args, **kwargs)\n    else:\n        response = requests.post(url, data=data, headers={\"Content-Type\": \"application/x-www-form-urlencoded\"}, timeout=timeout, *args, **kwargs)\n\n    if response.status_code!= 200:\n        response.raise_for_status()\n\n    return response\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    kwargs.setdefault(\"allow_redirects\", True)\n    response = requests.post(\n        url, data=data, timeout=timeout, *args, **kwargs\n    )\n    return response.status_code, response.json()\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(\n        url, data=data, timeout=timeout, headers={\"Content-Type\": \"application/x-www-form-urlencoded\"}, *args, **kwargs\n    )\n\n    if response.status_code!= 200:\n        try:\n            response.raise_for_status()\n        except requests.exceptions.HTTPError as e:\n            return (response.status_code, e)\n\n    return (response.status_code, response)\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(url, data=data, timeout=timeout,\n                             headers={\"Content-Type\": \"application/x-www-form-urlencoded\"}, *args, **kwargs)\n    return response.status_code, response\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(\n        url, data=data, timeout=timeout, *args, **kwargs\n    )\n    if response.status_code!= requests.codes.ok:\n        response.raise_for_status()\n    return response.status_code, response\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(url, data=data, timeout=timeout, *args, **kwargs)\n    return response.status_code, response.exception\n", "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(url, data=data, timeout=timeout,\n                             headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n                             *args, **kwargs)\n    return response.status_code, response.json()\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(url, data=data, timeout=timeout, *args, **kwargs)\n    if response.status_code == 200:\n        return (response.status_code, response)\n    return (response.status_code, response.text)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(url, data=data, timeout=timeout, **kwargs)\n    response.raise_for_status()\n    return response.status_code, response\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    return _send_document(url, data, timeout, method, *args, **kwargs)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = None\n\n    # if data is file-like, then send it as multipart/form-data content\n    if hasattr(data, \"read\"):\n        response = requests.post(url, data=data, headers={\"Content-Type\": \"multipart/form-data\"}, timeout=timeout, *args, **kwargs)\n    else:\n        response = requests.post(url, data=data, headers={\"Content-Type\": \"application/x-www-form-urlencoded\"}, timeout=timeout, *args, **kwargs)\n\n    if response.status_code!= 200:\n        response.raise_for_status()\n\n    return response\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    kwargs.setdefault(\"allow_redirects\", True)\n    response = requests.post(\n        url, data=data, timeout=timeout, *args, **kwargs\n    )\n    return response.status_code, response.json()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(\n        url, data=data, timeout=timeout, headers={\"Content-Type\": \"application/x-www-form-urlencoded\"}, *args, **kwargs\n    )\n\n    if response.status_code!= 200:\n        try:\n            response.raise_for_status()\n        except requests.exceptions.HTTPError as e:\n            return (response.status_code, e)\n\n    return (response.status_code, response)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(url, data=data, timeout=timeout,\n                             headers={\"Content-Type\": \"application/x-www-form-urlencoded\"}, *args, **kwargs)\n    return response.status_code, response\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(\n        url, data=data, timeout=timeout, *args, **kwargs\n    )\n    if response.status_code!= requests.codes.ok:\n        response.raise_for_status()\n    return response.status_code, response\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(url, data=data, timeout=timeout, *args, **kwargs)\n    return response.status_code, response.exception\n", "is_pass": false, "return_code": 1}, {"generate_code": "def send_document(url, data, timeout=10, method=\"post\", *args, **kwargs):\n    response = requests.post(url, data=data, timeout=timeout,\n                             headers={\"Content-Type\": \"application/x-www-form-urlencoded\"},\n                             *args, **kwargs)\n    return response.status_code, response.json()\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/utils/dict_utils.py", "project": "redhat-openstack/infrared", "name": "dict_insert", "docstring": "insert a value of a nested key into a dictionary\n\nto insert value for a nested key, all ancestor keys should be given as\nmethod's arguments\n\nexample:\n  dict_insert({}, 'val', 'key1.key2'.split('.'))\n\n:param dic: a dictionary object to insert the nested key value into\n:param val: a value to insert to the given dictionary\n:param key: first key in a chain of key that will store the value\n:param keys: sub keys in the keys chain", "ques_id": "6306091073426c38ae68acac", "code": ["def dict_insert(dic, val, key, *keys):\n    if not isinstance(key, string_types):\n        raise TypeError('keys must be strings')\n\n    if not isinstance(val, dict):\n        raise TypeError('val must be a dictionary')\n\n    for key in keys:\n        if key not in val:\n            val[key] = {}\n        dic = val[key]\n    dic[key] = val\n", "def dict_insert(dic, val, key, *keys):\n    for key in keys:\n        if key not in dic:\n            dic[key] = {}\n        dic = dic[key]\n    dic[key] = val\n", "def dict_insert(dic, val, key, *keys):\n    if not keys:\n        keys = [key]\n    for k in keys:\n        if k in dic:\n            dic[k].append(val)\n        else:\n            dic[k] = [val]\n", "def dict_insert(dic, val, key, *keys):\n    if not isinstance(key, str):\n        raise ValueError('key must be a string')\n    if not isinstance(keys, list):\n        raise ValueError('keys must be a list')\n    for k in keys:\n        try:\n            dic = dic[k]\n        except (TypeError, KeyError):\n            dic = {}\n            dic[k] = {}\n        if isinstance(val, dict):\n            dic = dic[k]\n        elif val == None:\n            pass\n        else:\n            raise TypeError('invalid type for val')\n    dic[key] = val\n", "def dict_insert(dic, val, key, *keys):\n    for key in keys:\n        if not key.startswith('.'):\n            key = '.'.join([key, val])\n        dic = dic.setdefault(key, {})\n    dic[val] = None\n", "def dict_insert(dic, val, key, *keys):\n    if not keys:\n        dic[key] = val\n    else:\n        parent_key = keys[0]\n        if len(keys) == 1:\n            dic[parent_key] = val\n        else:\n            dic[parent_key] = dict_insert(dic[parent_key], val, key, *keys[1:])\n", "def dict_insert(dic, val, key, *keys):\n    for key_ in keys:\n        if key_ in dic:\n            if isinstance(dic[key_], dict):\n                dic[key_] = dict_insert(dic[key_], val, key_)\n            else:\n                dic[key_] = [dic[key_], val]\n        else:\n            dic[key_] = [val, key_]\n    return dic\n", "def dict_insert(dic, val, key, *keys):\n    if keys:\n        key = '.'.join([key, *keys])\n    dic[key] = val\n", "def dict_insert(dic, val, key, *keys):\n    if keys:\n        key = key + '.' + keys[0]\n    dic[key] = val\n", "def dict_insert(dic, val, key, *keys):\n    if keys:\n        key = '.'.join([key, *keys])\n    dic[key] = val\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def dict_insert(dic, val, key, *keys):\n    if not isinstance(key, string_types):\n        raise TypeError('keys must be strings')\n\n    if not isinstance(val, dict):\n        raise TypeError('val must be a dictionary')\n\n    for key in keys:\n        if key not in val:\n            val[key] = {}\n        dic = val[key]\n    dic[key] = val\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    for key in keys:\n        if key not in dic:\n            dic[key] = {}\n        dic = dic[key]\n    dic[key] = val\n", "is_pass": true, "return_code": 0}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    if not keys:\n        keys = [key]\n    for k in keys:\n        if k in dic:\n            dic[k].append(val)\n        else:\n            dic[k] = [val]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    if not isinstance(key, str):\n        raise ValueError('key must be a string')\n    if not isinstance(keys, list):\n        raise ValueError('keys must be a list')\n    for k in keys:\n        try:\n            dic = dic[k]\n        except (TypeError, KeyError):\n            dic = {}\n            dic[k] = {}\n        if isinstance(val, dict):\n            dic = dic[k]\n        elif val == None:\n            pass\n        else:\n            raise TypeError('invalid type for val')\n    dic[key] = val\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    for key in keys:\n        if not key.startswith('.'):\n            key = '.'.join([key, val])\n        dic = dic.setdefault(key, {})\n    dic[val] = None\n", "is_pass": true, "return_code": 0}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    if not keys:\n        dic[key] = val\n    else:\n        parent_key = keys[0]\n        if len(keys) == 1:\n            dic[parent_key] = val\n        else:\n            dic[parent_key] = dict_insert(dic[parent_key], val, key, *keys[1:])\n", "is_pass": true, "return_code": 0}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    for key_ in keys:\n        if key_ in dic:\n            if isinstance(dic[key_], dict):\n                dic[key_] = dict_insert(dic[key_], val, key_)\n            else:\n                dic[key_] = [dic[key_], val]\n        else:\n            dic[key_] = [val, key_]\n    return dic\n", "is_pass": false, "return_code": 1}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    if keys:\n        key = '.'.join([key, *keys])\n    dic[key] = val\n", "is_pass": true, "return_code": 0}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    if keys:\n        key = key + '.' + keys[0]\n    dic[key] = val\n", "is_pass": true, "return_code": 0}, {"generate_code": "def dict_insert(dic, val, key, *keys):\n    if keys:\n        key = '.'.join([key, *keys])\n    dic[key] = val\n", "is_pass": true, "return_code": 0}]}
{"file_path": "tests/test_complex_types.py", "project": "redhat-openstack/infrared", "name": "list_of_file_names", "docstring": "Create a new IniType complex type", "ques_id": "6306091a73426c38ae68acc8", "code": ["def list_of_file_names(settings_dirs, spec_option):\n    return [\n        IniType('', [\n            IniFile(path, spec_option=spec_option)\n            for path in settings_dir.list_paths()\n        ])\n    ]\n", "def list_of_file_names(settings_dirs, spec_option):\n    return _complex_type(\n        \"listOfFilesNames\", settings_dirs, spec_option)\n", "def list_of_file_names(settings_dirs, spec_option):\n    return [\n        IniType(\n            'file-list',\n            [\n                IniFile(f'{s}.ini', s, settings_dirs[s]),\n                IniFile(f'{s}-options.ini', s, settings_dirs[s]),\n            ],\n        )\n        for s in settings_dirs\n    ]\n", "def list_of_file_names(settings_dirs, spec_option):\n    return [\n        IniType(\n            '',\n            [\n                IniFile(os.path.join(sdir, fname))\n                for sdir in settings_dirs\n            ],\n            spec_option,\n            False,\n            '',\n        )\n        for fname in settings.get_file_names(\n            os.path.join(settings_dirs[0], 'pyproject.toml')\n        )\n    ]\n", "def list_of_file_names(settings_dirs, spec_option):\n    return complex(\n        '[{}]'.format(', '.join(s.path for s in settings_dirs)),\n        spec_option('list_of_file_names', default='[]'))\n", "def list_of_file_names(settings_dirs, spec_option):\n    return ComplexType(\n        'listOfFilesNames',\n        [FileSpec(*spec_option)],\n        settings_dirs,\n    )\n", "def list_of_file_names(settings_dirs, spec_option):\n    return [IniType('complex', None, [(spec_option, [str])])]\n", "def list_of_file_names(settings_dirs, spec_option):\n    return [\n        IniType('file-name-%d' % i, 'complex',\n                [\n                    IniOption('name', 'file-%d' % i, 'file'),\n                    IniOption('file-ext', 'file', 'ext')\n                ])\n        for i in range(1, settings_dirs + 1)\n    ]\n", "def list_of_file_names(settings_dirs, spec_option):\n    return complex(\n        '[{}]'.format(', '.join(\n            settings_dirs[setting_name]['path']\n            for setting_name in spec_option['file_names']\n        ))\n    )\n", "def list_of_file_names(settings_dirs, spec_option):\n    return _load_type_module('complextypes.{0}ListOfFiles'.format(\n        spec_option), settings_dirs, 'complextypes')\n"], "level": "plib_runnable", "generate_results": [{"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return [\n        IniType('', [\n            IniFile(path, spec_option=spec_option)\n            for path in settings_dir.list_paths()\n        ])\n    ]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return _complex_type(\n        \"listOfFilesNames\", settings_dirs, spec_option)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return [\n        IniType(\n            'file-list',\n            [\n                IniFile(f'{s}.ini', s, settings_dirs[s]),\n                IniFile(f'{s}-options.ini', s, settings_dirs[s]),\n            ],\n        )\n        for s in settings_dirs\n    ]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return [\n        IniType(\n            '',\n            [\n                IniFile(os.path.join(sdir, fname))\n                for sdir in settings_dirs\n            ],\n            spec_option,\n            False,\n            '',\n        )\n        for fname in settings.get_file_names(\n            os.path.join(settings_dirs[0], 'pyproject.toml')\n        )\n    ]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return complex(\n        '[{}]'.format(', '.join(s.path for s in settings_dirs)),\n        spec_option('list_of_file_names', default='[]'))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return ComplexType(\n        'listOfFilesNames',\n        [FileSpec(*spec_option)],\n        settings_dirs,\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return [IniType('complex', None, [(spec_option, [str])])]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return [\n        IniType('file-name-%d' % i, 'complex',\n                [\n                    IniOption('name', 'file-%d' % i, 'file'),\n                    IniOption('file-ext', 'file', 'ext')\n                ])\n        for i in range(1, settings_dirs + 1)\n    ]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return complex(\n        '[{}]'.format(', '.join(\n            settings_dirs[setting_name]['path']\n            for setting_name in spec_option['file_names']\n        ))\n    )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def list_of_file_names(settings_dirs, spec_option):\n    return _load_type_module('complextypes.{0}ListOfFiles'.format(\n        spec_option), settings_dirs, 'complextypes')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/services/__init__.py", "project": "redhat-openstack/infrared", "name": "ansible_config_manager", "docstring": "Gets the ansible config manager.", "ques_id": "6306091b73426c38ae68acd7", "code": ["def ansible_config_manager(cls):\n    return AnsibleConfigManager(cls)\n", "def ansible_config_manager(cls):\n    return AnsibleConfigManager(cls)\n", "def ansible_config_manager(cls):\n    return ConfigManager(cls.get_instance())\n", "def ansible_config_manager(cls):\n    return cls.get_ansible_config_manager()\n", "def ansible_config_manager(cls):\n    return AnsibleConfigManager(cls)\n", "def ansible_config_manager(cls):\n    return AnsibleConfigManager(cls)\n", "def ansible_config_manager(cls):\n    if cls.ANSIBLE_CONFIG_MANAGER is None:\n        cls.ANSIBLE_CONFIG_MANAGER = AnsibleConfigManager(cls)\n\n    return cls.ANSIBLE_CONFIG_MANAGER\n", "def ansible_config_manager(cls):\n    return cls.ansible_config_managers[cls.name]\n", "def ansible_config_manager(cls):\n    return cls.ansible_config_manager_class(cls)\n", "def ansible_config_manager(cls):\n    return AnsibleConfigManager(cls)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def ansible_config_manager(cls):\n    return AnsibleConfigManager(cls)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    return AnsibleConfigManager(cls)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    return ConfigManager(cls.get_instance())\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    return cls.get_ansible_config_manager()\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    return AnsibleConfigManager(cls)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    return AnsibleConfigManager(cls)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    if cls.ANSIBLE_CONFIG_MANAGER is None:\n        cls.ANSIBLE_CONFIG_MANAGER = AnsibleConfigManager(cls)\n\n    return cls.ANSIBLE_CONFIG_MANAGER\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    return cls.ansible_config_managers[cls.name]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    return cls.ansible_config_manager_class(cls)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def ansible_config_manager(cls):\n    return AnsibleConfigManager(cls)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "infrared/core/services/__init__.py", "project": "redhat-openstack/infrared", "name": "workspace_manager", "docstring": "Gets the workspace manager.", "ques_id": "6306091b73426c38ae68acd9", "code": ["def workspace_manager(cls):\n    if not hasattr(cls, '_workspace_manager'):\n        from tornado.wsgi import WSGIContainer\n        cls._workspace_manager = WSGIContainer([\n            ('/', Application),\n            ('/manage', ManageApplication),\n        ])\n    return cls._workspace_manager\n", "def workspace_manager(cls):\n    if not cls._workspace_manager:\n        cls._workspace_manager = WorkspaceManager(cls._context)\n\n    return cls._workspace_manager\n", "def workspace_manager(cls):\n    if not cls._workspace_manager:\n        cls._workspace_manager = WorkspaceManager(cls.context)\n    return cls._workspace_manager\n", "def workspace_manager(cls):\n    if cls._workspace_manager is None:\n        cls._workspace_manager = WorkspaceManager(cls)\n    return cls._workspace_manager\n", "def workspace_manager(cls):\n    try:\n        return cls._workspace_manager\n    except AttributeError:\n        pass\n\n    cls._workspace_manager = WorkspaceManager(cls)\n    return cls._workspace_manager\n", "def workspace_manager(cls):\n    if cls._workspace_manager is None:\n        cls._workspace_manager = WorkspaceManager(cls)\n    return cls._workspace_manager\n", "def workspace_manager(cls):\n    if cls._workspace_manager is None:\n        cls._workspace_manager = WorkspaceManager()\n    return cls._workspace_manager\n", "def workspace_manager(cls):\n    from. import workspace_manager as workspace_manager_\n\n    return workspace_manager_\n", "def workspace_manager(cls):\n    if cls._workspace_manager is None:\n        cls._workspace_manager = WorkspaceManager()\n    return cls._workspace_manager\n", "def workspace_manager(cls):\n    if not cls._workspace_manager:\n        from tornado.simple_httpclient import SimpleAsyncHTTPClient\n        cls._workspace_manager = SimpleAsyncHTTPClient()\n    return cls._workspace_manager\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def workspace_manager(cls):\n    if not hasattr(cls, '_workspace_manager'):\n        from tornado.wsgi import WSGIContainer\n        cls._workspace_manager = WSGIContainer([\n            ('/', Application),\n            ('/manage', ManageApplication),\n        ])\n    return cls._workspace_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    if not cls._workspace_manager:\n        cls._workspace_manager = WorkspaceManager(cls._context)\n\n    return cls._workspace_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    if not cls._workspace_manager:\n        cls._workspace_manager = WorkspaceManager(cls.context)\n    return cls._workspace_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    if cls._workspace_manager is None:\n        cls._workspace_manager = WorkspaceManager(cls)\n    return cls._workspace_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    try:\n        return cls._workspace_manager\n    except AttributeError:\n        pass\n\n    cls._workspace_manager = WorkspaceManager(cls)\n    return cls._workspace_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    if cls._workspace_manager is None:\n        cls._workspace_manager = WorkspaceManager(cls)\n    return cls._workspace_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    if cls._workspace_manager is None:\n        cls._workspace_manager = WorkspaceManager()\n    return cls._workspace_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    from. import workspace_manager as workspace_manager_\n\n    return workspace_manager_\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    if cls._workspace_manager is None:\n        cls._workspace_manager = WorkspaceManager()\n    return cls._workspace_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def workspace_manager(cls):\n    if not cls._workspace_manager:\n        from tornado.simple_httpclient import SimpleAsyncHTTPClient\n        cls._workspace_manager = SimpleAsyncHTTPClient()\n    return cls._workspace_manager\n", "is_pass": true, "return_code": 0}]}
{"file_path": "infrared/core/services/__init__.py", "project": "redhat-openstack/infrared", "name": "plugins_manager", "docstring": "Gets the plugin manager.", "ques_id": "6306091b73426c38ae68acda", "code": ["def plugins_manager(cls):\n    return cls._plugins_manager\n", "def plugins_manager(cls):\n    return cls._plugins_manager\n", "def plugins_manager(cls):\n    return cls._plugins_manager\n", "def plugins_manager(cls):\n    return _plugins_manager\n", "def plugins_manager(cls):\n    if cls._plugins_manager is None:\n        from tango_sdk.plugin_manager import PluginManager\n        cls._plugins_manager = PluginManager()\n    return cls._plugins_manager\n", "def plugins_manager(cls):\n    return cls._plugins_manager\n", "def plugins_manager(cls):\n    return cls._plugins_manager\n", "def plugins_manager(cls):\n    return cls._plugins_manager\n", "def plugins_manager(cls):\n    if cls._plugins_manager is None:\n        from tango_sdk.plugin_manager import PluginManager\n        cls._plugins_manager = PluginManager()\n    return cls._plugins_manager\n", "def plugins_manager(cls):\n    return cls._plugins_manager\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def plugins_manager(cls):\n    return cls._plugins_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    return cls._plugins_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    return cls._plugins_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    return _plugins_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    if cls._plugins_manager is None:\n        from tango_sdk.plugin_manager import PluginManager\n        cls._plugins_manager = PluginManager()\n    return cls._plugins_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    return cls._plugins_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    return cls._plugins_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    return cls._plugins_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    if cls._plugins_manager is None:\n        from tango_sdk.plugin_manager import PluginManager\n        cls._plugins_manager = PluginManager()\n    return cls._plugins_manager\n", "is_pass": true, "return_code": 0}, {"generate_code": "def plugins_manager(cls):\n    return cls._plugins_manager\n", "is_pass": true, "return_code": 0}]}
{"file_path": "infrared/core/utils/validators.py", "project": "redhat-openstack/infrared", "name": "validate_from_content", "docstring": "validates that spec (YAML) content has all required fields\n\n:param spec_content: content of spec file\n:raise IRValidatorException: when mandatory data\nis missing in spec file\n:return: Dictionary with data loaded from a spec (YAML) file", "ques_id": "6306091c73426c38ae68acdc", "code": ["def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException(\"No spec content provided\")\n\n    errors = {}\n    deployment_specs = cls.get_deployment_specs_from_content(spec_content)\n\n    for deployment_spec in deployment_specs:\n        if deployment_spec.get('name') is None:\n            errors[deployment_spec.get('type')] = \"Deployment name missing\"\n        if deployment_spec.get('status') is None:\n            errors[deployment_spec.get('type')] = \"Deployment status missing\"\n        if deployment_spec.get('start_date') is None:\n            errors[deployment_spec.get('type')] = \"Deployment start date missing\"\n        if deployment_spec.get('end_date') is None:\n            errors[deployment_spec.get('type')] = \"Deployment end date missing\"\n\n    if errors:\n        raise IRValidatorException(\"Incomplete deployment spec file: {}\".format(\", \".join(errors)))\n\n    return deployment_specs", "def validate_from_content(cls, spec_content=None):\n    if spec_content is None:\n        raise IRValidatorException(\"No content provided to load spec\")\n\n    # split into data in a list\n    data = yaml.safe_load(spec_content)\n    if not isinstance(data, list):\n        raise IRValidatorException(\"Malformed YAML file: expected a list\")\n\n    # check for required fields\n    required_fields = cls.required_fields()\n    for field in required_fields:\n        if field not in data:\n            raise IRValidatorException(\n                \"Missing required field '{}' in spec file\".format(field)\n            )\n\n    return data\n", "def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException(\"No content to load from.\")\n\n    validator_spec = cls.load_spec_from_content(spec_content)\n\n    if not validator_spec:\n        raise IRValidatorException(\"Missing required fields in spec file.\")\n\n    return validator_spec\n", "def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException(\"Missing required fields in spec file\")\n\n    if not isinstance(spec_content, dict):\n        raise IRValidatorException(\"Must be a dictionary\")\n\n    required_fields = (\"name\", \"version\", \"description\")\n    missing_fields = [key for key in required_fields if key not in spec_content]\n\n    if missing_fields:\n        raise IRValidatorException(\n            \"Missing required fields: {}\".format(missing_fields)\n        )\n\n    return spec_content\n", "def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException(\n            \"No spec content provided in the input file. \"\n            \"Please add the file to be processed before using it.\"\n        )\n\n    if 'id' not in spec_content or 'data' not in spec_content:\n        raise IRValidatorException(\n            \"No 'id' or 'data' fields in spec file. \"\n            \"Please add the file to be processed before using it.\"\n        )\n\n    return validate_data(spec_content)\n", "def validate_from_content(cls, spec_content=None):\n    data = cls.load_from_content(spec_content)\n    return cls.validate(data)\n", "def validate_from_content(cls, spec_content=None):\n    try:\n        validate(instance=spec_content, schema=SPEC_SCHEMA)\n    except ValidationError as e:\n        raise IRValidatorException('Failed to load or validate spec file: {}'.format(e))\n\n    return spec_content\n", "def validate_from_content(cls, spec_content=None):\n    try:\n        data = yaml.safe_load(spec_content)\n        return data\n    except yaml.YAMLError as exc:\n        raise IRValidatorException(exc)\n", "def validate_from_content(cls, spec_content=None):\n    if spec_content is None:\n        raise IRValidatorException('Missing spec file')\n\n    required_keys = ['name','version', 'description', 'author', 'url',\n                     'license', 'platform', 'files', 'packages','requires',\n                     'build_dependencies', 'build_tests']\n    data = yaml.safe_load(spec_content)\n\n    for key in required_keys:\n        if key not in data:\n            raise IRValidatorException('Missing required key {} in spec file'.format(key))\n\n    return data\n", "def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException(\"Missing required fields in spec file\")\n\n    return cls.load_from_content(spec_content)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException(\"No spec content provided\")\n\n    errors = {}\n    deployment_specs = cls.get_deployment_specs_from_content(spec_content)\n\n    for deployment_spec in deployment_specs:\n        if deployment_spec.get('name') is None:\n            errors[deployment_spec.get('type')] = \"Deployment name missing\"\n        if deployment_spec.get('status') is None:\n            errors[deployment_spec.get('type')] = \"Deployment status missing\"\n        if deployment_spec.get('start_date') is None:\n            errors[deployment_spec.get('type')] = \"Deployment start date missing\"\n        if deployment_spec.get('end_date') is None:\n            errors[deployment_spec.get('type')] = \"Deployment end date missing\"\n\n    if errors:\n        raise IRValidatorException(\"Incomplete deployment spec file: {}\".format(\", \".join(errors)))\n\n    return deployment_specs", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    if spec_content is None:\n        raise IRValidatorException(\"No content provided to load spec\")\n\n    # split into data in a list\n    data = yaml.safe_load(spec_content)\n    if not isinstance(data, list):\n        raise IRValidatorException(\"Malformed YAML file: expected a list\")\n\n    # check for required fields\n    required_fields = cls.required_fields()\n    for field in required_fields:\n        if field not in data:\n            raise IRValidatorException(\n                \"Missing required field '{}' in spec file\".format(field)\n            )\n\n    return data\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException(\"No content to load from.\")\n\n    validator_spec = cls.load_spec_from_content(spec_content)\n\n    if not validator_spec:\n        raise IRValidatorException(\"Missing required fields in spec file.\")\n\n    return validator_spec\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException(\"Missing required fields in spec file\")\n\n    if not isinstance(spec_content, dict):\n        raise IRValidatorException(\"Must be a dictionary\")\n\n    required_fields = (\"name\", \"version\", \"description\")\n    missing_fields = [key for key in required_fields if key not in spec_content]\n\n    if missing_fields:\n        raise IRValidatorException(\n            \"Missing required fields: {}\".format(missing_fields)\n        )\n\n    return spec_content\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException(\n            \"No spec content provided in the input file. \"\n            \"Please add the file to be processed before using it.\"\n        )\n\n    if 'id' not in spec_content or 'data' not in spec_content:\n        raise IRValidatorException(\n            \"No 'id' or 'data' fields in spec file. \"\n            \"Please add the file to be processed before using it.\"\n        )\n\n    return validate_data(spec_content)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    data = cls.load_from_content(spec_content)\n    return cls.validate(data)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    try:\n        validate(instance=spec_content, schema=SPEC_SCHEMA)\n    except ValidationError as e:\n        raise IRValidatorException('Failed to load or validate spec file: {}'.format(e))\n\n    return spec_content\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    try:\n        data = yaml.safe_load(spec_content)\n        return data\n    except yaml.YAMLError as exc:\n        raise IRValidatorException(exc)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    if spec_content is None:\n        raise IRValidatorException('Missing spec file')\n\n    required_keys = ['name','version', 'description', 'author', 'url',\n                     'license', 'platform', 'files', 'packages','requires',\n                     'build_dependencies', 'build_tests']\n    data = yaml.safe_load(spec_content)\n\n    for key in required_keys:\n        if key not in data:\n            raise IRValidatorException('Missing required key {} in spec file'.format(key))\n\n    return data\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_content(cls, spec_content=None):\n    if not spec_content:\n        raise IRValidatorException(\"Missing required fields in spec file\")\n\n    return cls.load_from_content(spec_content)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "infrared/core/utils/validators.py", "project": "redhat-openstack/infrared", "name": "validate_from_file", "docstring": "Loads & validates that a YAML file has all required fields\n\n:param yaml_file: Path to YAML file\n:raise IRValidatorException: when mandatory data is missing in file\n:return: Dictionary with data loaded from a YAML file", "ques_id": "6306091c73426c38ae68acdd", "code": ["def validate_from_file(cls, yaml_file=None):\n    if yaml_file is None:\n        raise IRValidatorException('Missing required parameter \"yaml_file\"')\n\n    with open(yaml_file, 'r') as ymlfile:\n        try:\n            data = yaml.safe_load(ymlfile)\n        except yaml.YAMLError as exc:\n            raise IRValidatorException(exc)\n\n    return data\n", "def validate_from_file(cls, yaml_file=None):\n    yaml_file = yaml_file or cls.DEFAULT_YAML_FILE\n    data = cls.load_yaml(yaml_file)\n    cls.validate_data(data)\n    return data\n", "def validate_from_file(cls, yaml_file=None):\n    if not yaml_file:\n        raise IRValidatorException('File path is missing')\n\n    with open(yaml_file, 'r') as file:\n        data = yaml.safe_load(file)\n\n    if data is None or data == {}:\n        raise IRValidatorException('Invalid YAML file')\n\n    if not isinstance(data, dict):\n        raise IRValidatorException('Invalid YAML file')\n\n    return data\n", "def validate_from_file(cls, yaml_file=None):\n\n    yaml_file = cls.validate_filename(yaml_file)\n\n    with open(yaml_file, 'r') as stream:\n        data = yaml.load(stream)\n\n    return cls.validate_data(data)\n", "def validate_from_file(cls, yaml_file=None):\n    data = cls.load_file(yaml_file)\n    cls.validate(data)\n    return data\n", "def validate_from_file(cls, yaml_file=None):\n    try:\n        with open(yaml_file, 'r') as yaml_file:\n            data = yaml.safe_load(yaml_file)\n            return cls.validate(data)\n    except (yaml.YAMLError, IOError) as e:\n        raise IRValidatorException(e)\n", "def validate_from_file(cls, yaml_file=None):\n    if not yaml_file:\n        raise IRValidatorException('No YAML file provided')\n\n    with open(yaml_file, 'r') as f:\n        yaml_data = yaml.safe_load(f)\n\n    validate_yaml(yaml_data)\n\n    return yaml_data\n", "def validate_from_file(cls, yaml_file=None):\n    if not yaml_file:\n        raise IRValidatorException(\"No file provided to load data\")\n\n    if not isinstance(yaml_file, str):\n        raise IRValidatorException(\"Invalid file path provided to load data\")\n\n    try:\n        with open(yaml_file, 'r') as f:\n            loaded_data = yaml.load(f, Loader=yaml.SafeLoader)\n    except IOError as e:\n        raise IRValidatorException(\"Unable to load YAML file: {}\".format(str(e)))\n\n    if not isinstance(loaded_data, dict):\n        raise IRValidatorException(\"Missing required fields in YAML file\")\n\n    return loaded_data\n", "def validate_from_file(cls, yaml_file=None):\n    yaml_file = cls._load_file(yaml_file)\n\n    try:\n        return cls._validate_data(yaml_file)\n    except IRValidatorException as e:\n        raise e\n", "def validate_from_file(cls, yaml_file=None):\n    if not yaml_file:\n        raise IRValidatorException(\n            \"Missing required fields in {} yaml file\".format(cls.__name__))\n\n    with open(yaml_file, 'r') as f:\n        data = yaml.safe_load(f)\n\n    return cls.validate_data(data)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_from_file(cls, yaml_file=None):\n    if yaml_file is None:\n        raise IRValidatorException('Missing required parameter \"yaml_file\"')\n\n    with open(yaml_file, 'r') as ymlfile:\n        try:\n            data = yaml.safe_load(ymlfile)\n        except yaml.YAMLError as exc:\n            raise IRValidatorException(exc)\n\n    return data\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n    yaml_file = yaml_file or cls.DEFAULT_YAML_FILE\n    data = cls.load_yaml(yaml_file)\n    cls.validate_data(data)\n    return data\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n    if not yaml_file:\n        raise IRValidatorException('File path is missing')\n\n    with open(yaml_file, 'r') as file:\n        data = yaml.safe_load(file)\n\n    if data is None or data == {}:\n        raise IRValidatorException('Invalid YAML file')\n\n    if not isinstance(data, dict):\n        raise IRValidatorException('Invalid YAML file')\n\n    return data\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n\n    yaml_file = cls.validate_filename(yaml_file)\n\n    with open(yaml_file, 'r') as stream:\n        data = yaml.load(stream)\n\n    return cls.validate_data(data)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n    data = cls.load_file(yaml_file)\n    cls.validate(data)\n    return data\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n    try:\n        with open(yaml_file, 'r') as yaml_file:\n            data = yaml.safe_load(yaml_file)\n            return cls.validate(data)\n    except (yaml.YAMLError, IOError) as e:\n        raise IRValidatorException(e)\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n    if not yaml_file:\n        raise IRValidatorException('No YAML file provided')\n\n    with open(yaml_file, 'r') as f:\n        yaml_data = yaml.safe_load(f)\n\n    validate_yaml(yaml_data)\n\n    return yaml_data\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n    if not yaml_file:\n        raise IRValidatorException(\"No file provided to load data\")\n\n    if not isinstance(yaml_file, str):\n        raise IRValidatorException(\"Invalid file path provided to load data\")\n\n    try:\n        with open(yaml_file, 'r') as f:\n            loaded_data = yaml.load(f, Loader=yaml.SafeLoader)\n    except IOError as e:\n        raise IRValidatorException(\"Unable to load YAML file: {}\".format(str(e)))\n\n    if not isinstance(loaded_data, dict):\n        raise IRValidatorException(\"Missing required fields in YAML file\")\n\n    return loaded_data\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n    yaml_file = cls._load_file(yaml_file)\n\n    try:\n        return cls._validate_data(yaml_file)\n    except IRValidatorException as e:\n        raise e\n", "is_pass": true, "return_code": 0}, {"generate_code": "def validate_from_file(cls, yaml_file=None):\n    if not yaml_file:\n        raise IRValidatorException(\n            \"Missing required fields in {} yaml file\".format(cls.__name__))\n\n    with open(yaml_file, 'r') as f:\n        data = yaml.safe_load(f)\n\n    return cls.validate_data(data)\n", "is_pass": true, "return_code": 0}]}
{"file_path": "infrared/core/inspector/helper.py", "project": "redhat-openstack/infrared", "name": "_include_groups", "docstring": "Resolves the include dict directive in the spec files.", "ques_id": "6306091d73426c38ae68ace5", "code": ["def _include_groups(self, parser_dict):\n    for group in parser_dict.get(\"include_groups\", []):\n        include_files = group.get(\"include_files\", [])\n        for include_file in include_files:\n            if include_file in self._include_files:\n                parser_dict[\"include_files\"] = [include_file]\n                break\n    return parser_dict\n", "def _include_groups(self, parser_dict):\n    include_groups = {}\n    for include_dict in parser_dict.get('include', []):\n        for include_directive in include_dict.get('directive', []):\n            # Include directives may contain multiple include groups, so we\n            # add the include group name to the result.\n            include_groups[include_directive['group']] = include_directive\n    return include_groups\n", "def _include_groups(self, parser_dict):\n    for group in parser_dict:\n        for include_directive in parser_dict[group]:\n            parser_dict[group].setdefault(include_directive, {})\n            parser_dict[group][include_directive] = _resolve_includes(\n                parser_dict[group][include_directive],\n                group\n            )\n\n    return parser_dict\n", "def _include_groups(self, parser_dict):\n    include_groups = []\n    for include_dict in parser_dict.get('include', []):\n        for include_directive in include_dict.get('includeDirective', []):\n            include_groups.append(include_directive)\n    return include_groups\n", "def _include_groups(self, parser_dict):\n    # Include groups should be a single key-value pair.\n    if not isinstance(parser_dict, dict):\n        raise InvalidSpecConfigError(\"Include groups should be a single key-value pair.\")\n\n    # Resolve the group name to a list of directive names.\n    group_names = []\n    for key, value in parser_dict.items():\n        if isinstance(value, dict):\n            # Recurse into the directive names if they exist.\n            group_names.extend(self._include_groups(value))\n        else:\n            # If this is a single group, make it a list.\n            if key not in group_names:\n                group_names.append(key)\n\n            # Otherwise, just add the directive name.\n            group_names.append(key)\n\n    # Remove duplicates and sort the list.\n    return sorted(list(set(group_names)))\n", "def _include_groups(self, parser_dict):\n    for include_group in parser_dict['include_groups']:\n        # Handle the single include group directive only\n        if include_group['name'] == 'include':\n            include_group['directive'] = 'include_group'\n            include_group['include'] = [\n                include_dict['name'] for include_dict in include_group['include_dicts']\n            ]\n            yield include_group\n", "def _include_groups(self, parser_dict):\n    include_groups = []\n    for include_directive in parser_dict['include']:\n        include_groups.append(include_directive.split(':', 1))\n    return include_groups\n", "def _include_groups(self, parser_dict):\n    include_groups = []\n    for include_line in parser_dict.get('include_groups', '').split(';'):\n        include_groups.append(include_line.strip())\n\n    return include_groups\n", "def _include_groups(self, parser_dict):\n    if 'include_groups' in parser_dict:\n        return parser_dict['include_groups']\n    return []\n", "def _include_groups(self, parser_dict):\n    if parser_dict:\n        return [{\n            \"path\": key,\n            \"content\": value\n        } for key, value in parser_dict.items()]\n    return []\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def _include_groups(self, parser_dict):\n    for group in parser_dict.get(\"include_groups\", []):\n        include_files = group.get(\"include_files\", [])\n        for include_file in include_files:\n            if include_file in self._include_files:\n                parser_dict[\"include_files\"] = [include_file]\n                break\n    return parser_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    include_groups = {}\n    for include_dict in parser_dict.get('include', []):\n        for include_directive in include_dict.get('directive', []):\n            # Include directives may contain multiple include groups, so we\n            # add the include group name to the result.\n            include_groups[include_directive['group']] = include_directive\n    return include_groups\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    for group in parser_dict:\n        for include_directive in parser_dict[group]:\n            parser_dict[group].setdefault(include_directive, {})\n            parser_dict[group][include_directive] = _resolve_includes(\n                parser_dict[group][include_directive],\n                group\n            )\n\n    return parser_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    include_groups = []\n    for include_dict in parser_dict.get('include', []):\n        for include_directive in include_dict.get('includeDirective', []):\n            include_groups.append(include_directive)\n    return include_groups\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    # Include groups should be a single key-value pair.\n    if not isinstance(parser_dict, dict):\n        raise InvalidSpecConfigError(\"Include groups should be a single key-value pair.\")\n\n    # Resolve the group name to a list of directive names.\n    group_names = []\n    for key, value in parser_dict.items():\n        if isinstance(value, dict):\n            # Recurse into the directive names if they exist.\n            group_names.extend(self._include_groups(value))\n        else:\n            # If this is a single group, make it a list.\n            if key not in group_names:\n                group_names.append(key)\n\n            # Otherwise, just add the directive name.\n            group_names.append(key)\n\n    # Remove duplicates and sort the list.\n    return sorted(list(set(group_names)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    for include_group in parser_dict['include_groups']:\n        # Handle the single include group directive only\n        if include_group['name'] == 'include':\n            include_group['directive'] = 'include_group'\n            include_group['include'] = [\n                include_dict['name'] for include_dict in include_group['include_dicts']\n            ]\n            yield include_group\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    include_groups = []\n    for include_directive in parser_dict['include']:\n        include_groups.append(include_directive.split(':', 1))\n    return include_groups\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    include_groups = []\n    for include_line in parser_dict.get('include_groups', '').split(';'):\n        include_groups.append(include_line.strip())\n\n    return include_groups\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    if 'include_groups' in parser_dict:\n        return parser_dict['include_groups']\n    return []\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _include_groups(self, parser_dict):\n    if parser_dict:\n        return [{\n            \"path\": key,\n            \"content\": value\n        } for key, value in parser_dict.items()]\n    return []\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "get_spec_defaults", "docstring": "Resolve arguments' values from spec and other sources.", "ques_id": "6306092373426c38ae68acfa", "code": ["def get_spec_defaults(self):\n    return {}\n", "def get_spec_defaults(self):\n    return {}\n", "def get_spec_defaults(self):\n    return {}\n", "def get_spec_defaults(self):\n    return {}\n", "def get_spec_defaults(self):\n    return {}\n", "def get_spec_defaults(self):\n    return {\n        k: v if isinstance(v, str) else v.default\n        for k, v in inspect.getargspec(self.__class__.__init__).args\n    }\n", "def get_spec_defaults(self):\n    return {\n       'select': None,\n        'window': None,\n       'min': None,\n       'max': None,\n       'resolution': None,\n        'unit': None,\n        'datatype': None,\n    }\n", "def get_spec_defaults(self):\n    pass\n", "def get_spec_defaults(self):\n    return {}\n", "def get_spec_defaults(self):\n    return {}\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def get_spec_defaults(self):\n    return {}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    return {}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    return {}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    return {}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    return {}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    return {\n        k: v if isinstance(v, str) else v.default\n        for k, v in inspect.getargspec(self.__class__.__init__).args\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    return {\n       'select': None,\n        'window': None,\n       'min': None,\n       'max': None,\n       'resolution': None,\n        'unit': None,\n        'datatype': None,\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    return {}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_spec_defaults(self):\n    return {}\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "get_deprecated_args", "docstring": "Returning dict with options which deprecate others.", "ques_id": "6306092973426c38ae68ad01", "code": ["def get_deprecated_args(self):\n    return {\n        \"always_rename\": False,\n        \"skip_git\": False,\n        \"update\": True,\n        \"show_path\": False,\n        \"root\": None,\n        \"dirty\": None,\n        \"verbose\": False,\n    }\n", "def get_deprecated_args(self):\n    return {}\n", "def get_deprecated_args(self):\n    return {'retries': {'deprecated': True}}\n", "def get_deprecated_args(self):\n    return {'url': 'https://api.github.com', 'token': 'a token'}\n", "def get_deprecated_args(self):\n    return {}\n", "def get_deprecated_args(self):\n    return {\n        'timeout': 'timeout',\n        'bind': 'bind',\n        'unix_socket': 'unix_socket',\n    }\n", "def get_deprecated_args(self):\n    return {\n        '--no-run-after-init': ['--no-run-after-init'],\n        '--no-sync-after-init': ['--no-sync-after-init'],\n        '--no-recursive-sync': ['--no-recursive-sync'],\n        '--no-sync-wait': ['--no-sync-wait'],\n    }\n", "def get_deprecated_args(self):\n    return {}\n", "def get_deprecated_args(self):\n    return {\n        \"force\": \"force\",\n        \"skip_checks\": \"skip_checks\",\n        \"skip_checks_tags\": \"skip_checks_tags\",\n    }\n", "def get_deprecated_args(self):\n    return {}\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def get_deprecated_args(self):\n    return {\n        \"always_rename\": False,\n        \"skip_git\": False,\n        \"update\": True,\n        \"show_path\": False,\n        \"root\": None,\n        \"dirty\": None,\n        \"verbose\": False,\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    return {}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    return {'retries': {'deprecated': True}}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    return {'url': 'https://api.github.com', 'token': 'a token'}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    return {}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    return {\n        'timeout': 'timeout',\n        'bind': 'bind',\n        'unix_socket': 'unix_socket',\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    return {\n        '--no-run-after-init': ['--no-run-after-init'],\n        '--no-sync-after-init': ['--no-sync-after-init'],\n        '--no-recursive-sync': ['--no-recursive-sync'],\n        '--no-sync-wait': ['--no-sync-wait'],\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    return {}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    return {\n        \"force\": \"force\",\n        \"skip_checks\": \"skip_checks\",\n        \"skip_checks_tags\": \"skip_checks_tags\",\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_deprecated_args(self):\n    return {}\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "validate_arg_deprecation", "docstring": "Validates and prints the deprecated arguments.\n\n:param cli_args: the dict of arguments from cli\n:param answer_file_args:  the dict of arguments from files", "ques_id": "6306092c73426c38ae68ad02", "code": ["def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecations = []\n\n    for key, value in cli_args.items():\n        if isinstance(value, dict) and 'deprecated' in value:\n            deprecations.append('{}: {}'.format(key, value['deprecated']))\n\n    for key, value in answer_file_args.items():\n        if isinstance(value, dict) and 'deprecated' in value:\n            deprecations.append('{}: {}'.format(key, value['deprecated']))\n\n    deprecations_str = ', '.join(deprecations)\n\n    if deprecations_str:\n        print('DEPRECATIONS: {}'.format(deprecations_str))\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecated_args = []\n    for key, value in cli_args.items():\n        if key in answer_file_args and cli_args[key]!= answer_file_args[key]:\n            deprecated_args.append(key)\n    if deprecated_args:\n        print('DEPRECATION WARNING: {} arguments are deprecated. Use {} instead.'\n             .format(', '.join(deprecated_args), ', '.join(answer_file_args)))\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecated_args = {\n        'input_args': cli_args,\n        'output_args': answer_file_args,\n    }\n    self._print_deprecated('input', deprecated_args)\n    self._print_deprecated('output', deprecated_args)\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecate_args = []\n    deprecate_args.extend(cli_args.get('deprecated', []))\n    deprecate_args.extend(answer_file_args.get('deprecated', []))\n    if deprecate_args:\n        deprecate_message = 'The following arguments are deprecated and will be removed: {}'\n        deprecate_message = deprecate_message.format(', '.join(deprecate_args))\n        print(deprecate_message)\n        deprecate_args = [answer_file_args['path']]\n\n    return deprecate_args\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecation_message = None\n    if cli_args['--debug']:\n        deprecation_message = 'Debugging is enabled. Please run:'\n        deprecation_message += '\\n'\n        deprecation_message +='   pip install -r requirements.txt'\n        deprecation_message += '\\n'\n        deprecation_message +='   pip install -r requirements-dev.txt'\n        deprecation_message += '\\n'\n        deprecation_message +='   pip install -r requirements-test.txt'\n        deprecation_message += '\\n'\n    if cli_args['--version']:\n        deprecation_message += 'This command is deprecated. Please use --install instead.'\n    if cli_args['--silent']:\n        deprecation_message += '\\n'\n        deprecation_message += 'This command is disabled.'\n    if answer_file_args['--version']:\n        deprecation_message += 'This command is", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecate_args = []\n    for argument in cli_args:\n        if cli_args[argument] is None:\n            deprecate_args.append(argument)\n    for argument in deprecate_args:\n        print('\\n{} is deprecated. Use {} instead.'.format(argument, cli_args[argument]))\n    for argument in answer_file_args:\n        if argument in cli_args:\n            print('\\n{} is deprecated. Use {} instead.'.format(argument, answer_file_args[argument]))\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecate_args = [\n        '--answer-file', answer_file_args['file'],\n        '--answer-file-name', answer_file_args['name']\n    ]\n    deprecate_args = deprecate_args + cli_args['deprecated']\n    if cli_args['deprecated']:\n        deprecate_args.append('--deprecated')\n    if cli_args['no_answer']:\n        deprecate_args.append('--no-answer')\n    if cli_args['no_deprecated']:\n        deprecate_args.append('--no-deprecated')\n    if cli_args['no_deprecated_from_file']:\n        deprecate_args.append('--no-deprecated-from-file')\n    deprecate_args = deprecate_args + cli_args['deprecated_from_file']\n    deprecate_args = deprecate_args + cli_args['deprecated_from_file_name']\n    print('Validating arguments: {}'.format(deprecate_args))\n    if not deprecate_args:\n        print('No arguments were deprecated.')\n        r", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecated_arguments = []\n    for key in cli_args:\n        if key in answer_file_args:\n            deprecated_arguments.append(key)\n    if deprecated_arguments:\n        msg = 'The following arguments are deprecated: {}. '.format(\n            ', '.join(deprecated_arguments))\n        msg += 'Please consult our documentation.'\n        print(msg)\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecated_args = {}\n    for key, value in cli_args.items():\n        if key in answer_file_args:\n            deprecated_args[key] = value\n        elif key in cli_args:\n            deprecated_args[key] = cli_args[key]\n        else:\n            deprecated_args[key] = value\n    if deprecated_args:\n        deprecation_message = \"{} arguments were deprecated. Use {} instead.\".format(\n            len(deprecated_args), len(cli_args))\n        raise UsageError(deprecation_message)\n", "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    if cli_args.deprecated is not None:\n        if cli_args.deprecated not in ['y', 'n']:\n            raise exceptions.CLIAbort(\n                'Invalid value for --deprecated: {}. Must be y or n'.format(cli_args.deprecated))\n        deprecated_args = answer_file_args.get('deprecated')\n        if deprecated_args is None:\n            raise exceptions.CLIAbort(\n                'Missing required argument: \"deprecated\"')\n        if cli_args.deprecated == 'y':\n            deprecated_args = answer_file_args.get('answer')\n        if deprecated_args is None:\n            raise exceptions.CLIAbort(\n                'Missing required argument: \"answer\"')\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecations = []\n\n    for key, value in cli_args.items():\n        if isinstance(value, dict) and 'deprecated' in value:\n            deprecations.append('{}: {}'.format(key, value['deprecated']))\n\n    for key, value in answer_file_args.items():\n        if isinstance(value, dict) and 'deprecated' in value:\n            deprecations.append('{}: {}'.format(key, value['deprecated']))\n\n    deprecations_str = ', '.join(deprecations)\n\n    if deprecations_str:\n        print('DEPRECATIONS: {}'.format(deprecations_str))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecated_args = []\n    for key, value in cli_args.items():\n        if key in answer_file_args and cli_args[key]!= answer_file_args[key]:\n            deprecated_args.append(key)\n    if deprecated_args:\n        print('DEPRECATION WARNING: {} arguments are deprecated. Use {} instead.'\n             .format(', '.join(deprecated_args), ', '.join(answer_file_args)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecated_args = {\n        'input_args': cli_args,\n        'output_args': answer_file_args,\n    }\n    self._print_deprecated('input', deprecated_args)\n    self._print_deprecated('output', deprecated_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecate_args = []\n    deprecate_args.extend(cli_args.get('deprecated', []))\n    deprecate_args.extend(answer_file_args.get('deprecated', []))\n    if deprecate_args:\n        deprecate_message = 'The following arguments are deprecated and will be removed: {}'\n        deprecate_message = deprecate_message.format(', '.join(deprecate_args))\n        print(deprecate_message)\n        deprecate_args = [answer_file_args['path']]\n\n    return deprecate_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecation_message = None\n    if cli_args['--debug']:\n        deprecation_message = 'Debugging is enabled. Please run:'\n        deprecation_message += '\\n'\n        deprecation_message +='   pip install -r requirements.txt'\n        deprecation_message += '\\n'\n        deprecation_message +='   pip install -r requirements-dev.txt'\n        deprecation_message += '\\n'\n        deprecation_message +='   pip install -r requirements-test.txt'\n        deprecation_message += '\\n'\n    if cli_args['--version']:\n        deprecation_message += 'This command is deprecated. Please use --install instead.'\n    if cli_args['--silent']:\n        deprecation_message += '\\n'\n        deprecation_message += 'This command is disabled.'\n    if answer_file_args['--version']:\n        deprecation_message += 'This command is", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecate_args = []\n    for argument in cli_args:\n        if cli_args[argument] is None:\n            deprecate_args.append(argument)\n    for argument in deprecate_args:\n        print('\\n{} is deprecated. Use {} instead.'.format(argument, cli_args[argument]))\n    for argument in answer_file_args:\n        if argument in cli_args:\n            print('\\n{} is deprecated. Use {} instead.'.format(argument, answer_file_args[argument]))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecate_args = [\n        '--answer-file', answer_file_args['file'],\n        '--answer-file-name', answer_file_args['name']\n    ]\n    deprecate_args = deprecate_args + cli_args['deprecated']\n    if cli_args['deprecated']:\n        deprecate_args.append('--deprecated')\n    if cli_args['no_answer']:\n        deprecate_args.append('--no-answer')\n    if cli_args['no_deprecated']:\n        deprecate_args.append('--no-deprecated')\n    if cli_args['no_deprecated_from_file']:\n        deprecate_args.append('--no-deprecated-from-file')\n    deprecate_args = deprecate_args + cli_args['deprecated_from_file']\n    deprecate_args = deprecate_args + cli_args['deprecated_from_file_name']\n    print('Validating arguments: {}'.format(deprecate_args))\n    if not deprecate_args:\n        print('No arguments were deprecated.')\n        r", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecated_arguments = []\n    for key in cli_args:\n        if key in answer_file_args:\n            deprecated_arguments.append(key)\n    if deprecated_arguments:\n        msg = 'The following arguments are deprecated: {}. '.format(\n            ', '.join(deprecated_arguments))\n        msg += 'Please consult our documentation.'\n        print(msg)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    deprecated_args = {}\n    for key, value in cli_args.items():\n        if key in answer_file_args:\n            deprecated_args[key] = value\n        elif key in cli_args:\n            deprecated_args[key] = cli_args[key]\n        else:\n            deprecated_args[key] = value\n    if deprecated_args:\n        deprecation_message = \"{} arguments were deprecated. Use {} instead.\".format(\n            len(deprecated_args), len(cli_args))\n        raise UsageError(deprecation_message)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_arg_deprecation(self, cli_args, answer_file_args):\n    if cli_args.deprecated is not None:\n        if cli_args.deprecated not in ['y', 'n']:\n            raise exceptions.CLIAbort(\n                'Invalid value for --deprecated: {}. Must be y or n'.format(cli_args.deprecated))\n        deprecated_args = answer_file_args.get('deprecated')\n        if deprecated_args is None:\n            raise exceptions.CLIAbort(\n                'Missing required argument: \"deprecated\"')\n        if cli_args.deprecated == 'y':\n            deprecated_args = answer_file_args.get('answer')\n        if deprecated_args is None:\n            raise exceptions.CLIAbort(\n                'Missing required argument: \"answer\"')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/helper.py", "project": "redhat-openstack/infrared", "name": "get_parser_option_specs", "docstring": "Gets all the options for the specified command\n\n:param command_name: the command name (main, virsh, ospd, etc...)\n:return: the list of all command options", "ques_id": "6306092d73426c38ae68ad04", "code": ["def get_parser_option_specs(self, command_name):\n    parser = self.get_command_parser(command_name)\n    return parser.option_list\n", "def get_parser_option_specs(self, command_name):\n    parser = self.get_parser(command_name)\n    return parser.option_list\n", "def get_parser_option_specs(self, command_name):\n    parser = self.get_command_parser(command_name)\n    return parser.option_list\n", "def get_parser_option_specs(self, command_name):\n    parser = self.get_parser(command_name)\n    return parser.option_list\n", "def get_parser_option_specs(self, command_name):\n    parser = self.get_parser(command_name)\n    options = []\n    for option in parser.option_list:\n        options.append((option.dest, option.get_help()))\n    return options\n", "def get_parser_option_specs(self, command_name):\n    parser = get_parser(command_name)\n    return parser.option_list\n", "def get_parser_option_specs(self, command_name):\n    parser = getattr(self, command_name + \"_parser\", None)\n    if parser is None:\n        return []\n    return parser.option_list\n", "def get_parser_option_specs(self, command_name):\n    return self.commands[command_name].option_specs\n", "def get_parser_option_specs(self, command_name):\n    return dict([option_spec for option_spec in\n                 self.parser.option_manager.option_specs[command_name]])\n", "def get_parser_option_specs(self, command_name):\n    return self.parser.option_list\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def get_parser_option_specs(self, command_name):\n    parser = self.get_command_parser(command_name)\n    return parser.option_list\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    parser = self.get_parser(command_name)\n    return parser.option_list\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    parser = self.get_command_parser(command_name)\n    return parser.option_list\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    parser = self.get_parser(command_name)\n    return parser.option_list\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    parser = self.get_parser(command_name)\n    options = []\n    for option in parser.option_list:\n        options.append((option.dest, option.get_help()))\n    return options\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    parser = get_parser(command_name)\n    return parser.option_list\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    parser = getattr(self, command_name + \"_parser\", None)\n    if parser is None:\n        return []\n    return parser.option_list\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    return self.commands[command_name].option_specs\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    return dict([option_spec for option_spec in\n                 self.parser.option_manager.option_specs[command_name]])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_parser_option_specs(self, command_name):\n    return self.parser.option_list\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/helper.py", "project": "redhat-openstack/infrared", "name": "get_option_spec", "docstring": "Gets the specification for the specified option name.", "ques_id": "6306092d73426c38ae68ad05", "code": ["def get_option_spec(self, command_name, argument_name):\n    raise NotImplementedError('Method from interface definition')\n", "def get_option_spec(self, command_name, argument_name):\n    # type: (str, str) -> OptionSpec\n    \"\"\"\n    Gets the specification for the specified option name.\n    \"\"\"\n    return self._get_option_class(command_name).get_spec(argument_name)\n", "def get_option_spec(self, command_name, argument_name):\n    # type: (str, str) -> Union[ArgumentSpec, ArgumentSpec]\n    \"\"\"\n    Gets the specification for the specified option name.\n    \"\"\"\n    return self._get_option_class(command_name).get_argument_spec(command_name, argument_name)\n", "def get_option_spec(self, command_name, argument_name):\n    raise NotImplementedError('Must be implemented by subclasses')\n", "def get_option_spec(self, command_name, argument_name):\n    raise NotImplementedError(\n        'operation get_option_spec(...) not yet implemented')\n", "def get_option_spec(self, command_name, argument_name):\n    raise NotImplementedError(\n        'operation get_option_spec(...) not yet implemented')\n", "def get_option_spec(self, command_name, argument_name):\n    raise NotImplementedError('Must be implemented by subclasses')\n", "def get_option_spec(self, command_name, argument_name):\n    raise NotImplementedError('Must be implemented by subclasses')\n", "def get_option_spec(self, command_name, argument_name):\n    raise NotImplementedError('Must be implemented by subclasses')\n", "def get_option_spec(self, command_name, argument_name):\n    raise NotImplementedError('Must be implemented by subclasses')\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def get_option_spec(self, command_name, argument_name):\n    raise NotImplementedError('Method from interface definition')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    # type: (str, str) -> OptionSpec\n    \"\"\"\n    Gets the specification for the specified option name.\n    \"\"\"\n    return self._get_option_class(command_name).get_spec(argument_name)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    # type: (str, str) -> Union[ArgumentSpec, ArgumentSpec]\n    \"\"\"\n    Gets the specification for the specified option name.\n    \"\"\"\n    return self._get_option_class(command_name).get_argument_spec(command_name, argument_name)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    raise NotImplementedError('Must be implemented by subclasses')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    raise NotImplementedError(\n        'operation get_option_spec(...) not yet implemented')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    raise NotImplementedError(\n        'operation get_option_spec(...) not yet implemented')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    raise NotImplementedError('Must be implemented by subclasses')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    raise NotImplementedError('Must be implemented by subclasses')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    raise NotImplementedError('Must be implemented by subclasses')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_option_spec(self, command_name, argument_name):\n    raise NotImplementedError('Must be implemented by subclasses')\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "get_silent_args", "docstring": "list of silenced argument\n\n:param args: The received arguments.\n:return: list, slienced argument names", "ques_id": "6306092d73426c38ae68ad06", "code": ["def get_silent_args(self, args):\n    return [arg for arg in args if arg is not None and arg!= self.silent_arg]\n", "def get_silent_args(self, args):\n    return [a for a in args if args[a] is True]\n", "def get_silent_args(self, args):\n    return [arg for arg in args if arg!= self.silent_arg]\n", "def get_silent_args(self, args):\n    return [arg for arg in args if arg.startswith('-')]\n", "def get_silent_args(self, args):\n    return [arg for arg in args if arg!= self._silent_arg_name]\n", "def get_silent_args(self, args):\n    return [name for name in args if args[name] is False]\n", "def get_silent_args(self, args):\n    return [arg for arg in args if arg!= self.__silent_arg]\n", "def get_silent_args(self, args):\n    return [a for a in args if args[a] is False]\n", "def get_silent_args(self, args):\n    return [arg for arg in args if arg!='self']\n", "def get_silent_args(self, args):\n    return [arg for arg in args if arg!='self']\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def get_silent_args(self, args):\n    return [arg for arg in args if arg is not None and arg!= self.silent_arg]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_silent_args(self, args):\n    return [a for a in args if args[a] is True]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def get_silent_args(self, args):\n    return [arg for arg in args if arg!= self.silent_arg]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_silent_args(self, args):\n    return [arg for arg in args if arg.startswith('-')]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def get_silent_args(self, args):\n    return [arg for arg in args if arg!= self._silent_arg_name]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_silent_args(self, args):\n    return [name for name in args if args[name] is False]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def get_silent_args(self, args):\n    return [arg for arg in args if arg!= self.__silent_arg]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_silent_args(self, args):\n    return [a for a in args if args[a] is False]\n", "is_pass": true, "return_code": 0}, {"generate_code": "def get_silent_args(self, args):\n    return [arg for arg in args if arg!='self']\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_silent_args(self, args):\n    return [arg for arg in args if arg!='self']\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "validate_requires_args", "docstring": "Check if all the required arguments have been provided.", "ques_id": "6306092d73426c38ae68ad07", "code": ["def validate_requires_args(self, args):\n    missing = []\n\n    for arg in self.required_args:\n        if arg not in args:\n            missing.append(arg)\n\n    if missing:\n        return missing\n", "def validate_requires_args(self, args):\n    missing = [arg for arg in self.required_args\n               if arg not in args]\n    if missing:\n        raise ValueError(\"Missing required arguments: %s\" % missing)\n", "def validate_requires_args(self, args):\n    missing = []\n    for arg in self.required_args:\n        if arg not in args:\n            missing.append(arg)\n\n    if missing:\n        raise MissingRequiredArguments(missing)\n", "def validate_requires_args(self, args):\n    missing = []\n    for arg in ['name', 'description','required']:\n        if arg not in args:\n            missing.append(arg)\n    if missing:\n        raise ValueError(\"Missing required arguments: %s\" % missing)\n", "def validate_requires_args(self, args):\n    missing = []\n\n    for name, required in self.required_args.items():\n        if name not in args:\n            missing.append(name)\n\n    if missing:\n        raise MissingRequiredArgumentsError(missing)\n", "def validate_requires_args(self, args):\n    return all([arg in args for arg in REQUIRED_ARGS])\n", "def validate_requires_args(self, args):\n    return all(args.get(arg) for arg in self.required_args)\n", "def validate_requires_args(self, args):\n    return all([args.get('name'), args.get('description'),\n                args.get('active'), args.get('owner'),\n                args.get('type'), args.get('group')])\n", "def validate_requires_args(self, args):\n    required_args = ['uuid', 'name', 'key', 'value']\n    for arg in required_args:\n        if arg not in args:\n            return (False, 'Missing required argument: {}.'.format(arg))\n    return (True, '')\n", "def validate_requires_args(self, args):\n    missing = [arg for arg in self.required_args if arg not in args]\n    if missing:\n        raise ArgumentMissingException(missing)\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_requires_args(self, args):\n    missing = []\n\n    for arg in self.required_args:\n        if arg not in args:\n            missing.append(arg)\n\n    if missing:\n        return missing\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n    missing = [arg for arg in self.required_args\n               if arg not in args]\n    if missing:\n        raise ValueError(\"Missing required arguments: %s\" % missing)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n    missing = []\n    for arg in self.required_args:\n        if arg not in args:\n            missing.append(arg)\n\n    if missing:\n        raise MissingRequiredArguments(missing)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n    missing = []\n    for arg in ['name', 'description','required']:\n        if arg not in args:\n            missing.append(arg)\n    if missing:\n        raise ValueError(\"Missing required arguments: %s\" % missing)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n    missing = []\n\n    for name, required in self.required_args.items():\n        if name not in args:\n            missing.append(name)\n\n    if missing:\n        raise MissingRequiredArgumentsError(missing)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n    return all([arg in args for arg in REQUIRED_ARGS])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n    return all(args.get(arg) for arg in self.required_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n    return all([args.get('name'), args.get('description'),\n                args.get('active'), args.get('owner'),\n                args.get('type'), args.get('group')])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n    required_args = ['uuid', 'name', 'key', 'value']\n    for arg in required_args:\n        if arg not in args:\n            return (False, 'Missing required argument: {}.'.format(arg))\n    return (True, '')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_requires_args(self, args):\n    missing = [arg for arg in self.required_args if arg not in args]\n    if missing:\n        raise ArgumentMissingException(missing)\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "_get_conditionally_required_args", "docstring": "List arguments with ``required_when`` condition matched.\n\n:param command_name: the command name.\n:param options_spec:  the list of command spec options.\n:param args: the received input arguments\n:return: list, list of argument names with matched ``required_when``\n    condition", "ques_id": "6306092d73426c38ae68ad08", "code": ["def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n        condition\n    \"\"\"\n    arg_names = []\n    for arg in args:\n        if arg in options_spec and arg not in arg_names:\n            arg_names.append(arg)\n    return arg_names, args\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n        condition\n    \"\"\"\n    arg_names = []\n    for arg in args:\n        if not arg[1] or arg[1] == '*':\n            arg_names.append(arg[0])\n        else:\n            arg_names.extend([arg[0], arg[1]])\n    return arg_names, args\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    required = []\n    condition = None\n    for arg in args:\n        if condition is None:\n            condition = arg.required\n        elif condition(arg):\n            required.append(arg.name)\n        else:\n            break\n    return required, condition\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    matched_args = []\n    for arg_name, arg_spec in options_spec.items():\n        if arg_spec.required and args.get(arg_name, None) is None:\n            matched_args.append(arg_name)\n\n    return matched_args\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    arg_names = []\n    for name, value in args:\n        if (command_name in options_spec\n                and name not in self.required_when):\n            arg_names.append(name)\n    return arg_names\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    matched_args = []\n    for arg in args:\n        if not arg or arg in options_spec[command_name]['required']:\n            matched_args.append(arg)\n\n    return matched_args\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    required_when = options_spec['required_when']\n    if required_when is not None:\n        args = [arg for arg in args if arg in required_when]\n    return args, required_when\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    condition = self._get_condition(command_name, options_spec, args)\n    return condition.required_when\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    matched_args = []\n    for arg_name in args:\n        condition = self._conditions.get(\n            (command_name, arg_name),\n            lambda args: True)\n        matched_args += condition(options_spec, args)\n    return matched_args\n", "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n        condition\n    \"\"\"\n    if not options_spec:\n        return []\n\n    arg_names = []\n    for arg in args:\n        if not options_spec[arg]['required']:\n            continue\n        arg_names.append(arg)\n\n    return arg_names\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n        condition\n    \"\"\"\n    arg_names = []\n    for arg in args:\n        if arg in options_spec and arg not in arg_names:\n            arg_names.append(arg)\n    return arg_names, args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n        condition\n    \"\"\"\n    arg_names = []\n    for arg in args:\n        if not arg[1] or arg[1] == '*':\n            arg_names.append(arg[0])\n        else:\n            arg_names.extend([arg[0], arg[1]])\n    return arg_names, args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    required = []\n    condition = None\n    for arg in args:\n        if condition is None:\n            condition = arg.required\n        elif condition(arg):\n            required.append(arg.name)\n        else:\n            break\n    return required, condition\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    matched_args = []\n    for arg_name, arg_spec in options_spec.items():\n        if arg_spec.required and args.get(arg_name, None) is None:\n            matched_args.append(arg_name)\n\n    return matched_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    arg_names = []\n    for name, value in args:\n        if (command_name in options_spec\n                and name not in self.required_when):\n            arg_names.append(name)\n    return arg_names\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    matched_args = []\n    for arg in args:\n        if not arg or arg in options_spec[command_name]['required']:\n            matched_args.append(arg)\n\n    return matched_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    required_when = options_spec['required_when']\n    if required_when is not None:\n        args = [arg for arg in args if arg in required_when]\n    return args, required_when\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    condition = self._get_condition(command_name, options_spec, args)\n    return condition.required_when\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"\n    List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n             condition\n    \"\"\"\n    matched_args = []\n    for arg_name in args:\n        condition = self._conditions.get(\n            (command_name, arg_name),\n            lambda args: True)\n        matched_args += condition(options_spec, args)\n    return matched_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _get_conditionally_required_args(self, command_name, options_spec,\n                                         args):\n    \"\"\"List arguments with ``required_when`` condition matched.\n\n    :param command_name: the command name.\n    :param options_spec: the list of command spec options.\n    :param args: the received input arguments\n    :return: list, list of argument names with matched ``required_when``\n        condition\n    \"\"\"\n    if not options_spec:\n        return []\n\n    arg_names = []\n    for arg in args:\n        if not options_spec[arg]['required']:\n            continue\n        arg_names.append(arg)\n\n    return arg_names\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "validate_length_args", "docstring": "Check if value of arguments is not longer than length specified.\n\n:param args: The received arguments.", "ques_id": "6306092e73426c38ae68ad09", "code": ["def validate_length_args(self, args):\n    if len(args) > self.length:\n        raise exceptions.ArgumentTooLongException\n", "def validate_length_args(self, args):\n    if len(args) > self.args_limit:\n        raise ValidationError(\n            'Argument count is longer than limit: {}'.format(len(args)))\n", "def validate_length_args(self, args):\n    if len(args) > self.length:\n        raise LengthRequiredException\n", "def validate_length_args(self, args):\n    length = len(args)\n    if length > self.length:\n        raise ArgumentLengthError(\n            message='The length of the argument must be less than '\n                    '{}. Found {}.'.format(self.length, length),\n            args=args)\n", "def validate_length_args(self, args):\n    if len(args) > self.length:\n        raise InvalidLengthError(\"The length argument must be less than {}.\".format(self.length))\n", "def validate_length_args(self, args):\n    arg_length = len(args)\n    if arg_length > self.length:\n        raise BadRequest('Not enough arguments.')\n", "def validate_length_args(self, args):\n    if args is None or args == []:\n        return\n    if len(args) > self.length:\n        raise exceptions.ArgumentTooLongException\n", "def validate_length_args(self, args):\n    if args['amount'] is not None and args['amount'] < 0:\n        raise InvalidAmountException('amount')\n", "def validate_length_args(self, args):\n    length = len(args)\n    if length > self.args_count:\n        raise InvalidArgumentsError('Not enough arguments specified.')\n", "def validate_length_args(self, args):\n    if len(args) > self.length:\n        raise ArgumentTooLongException\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_length_args(self, args):\n    if len(args) > self.length:\n        raise exceptions.ArgumentTooLongException\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n    if len(args) > self.args_limit:\n        raise ValidationError(\n            'Argument count is longer than limit: {}'.format(len(args)))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n    if len(args) > self.length:\n        raise LengthRequiredException\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n    length = len(args)\n    if length > self.length:\n        raise ArgumentLengthError(\n            message='The length of the argument must be less than '\n                    '{}. Found {}.'.format(self.length, length),\n            args=args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n    if len(args) > self.length:\n        raise InvalidLengthError(\"The length argument must be less than {}.\".format(self.length))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n    arg_length = len(args)\n    if arg_length > self.length:\n        raise BadRequest('Not enough arguments.')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n    if args is None or args == []:\n        return\n    if len(args) > self.length:\n        raise exceptions.ArgumentTooLongException\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n    if args['amount'] is not None and args['amount'] < 0:\n        raise InvalidAmountException('amount')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n    length = len(args)\n    if length > self.args_count:\n        raise InvalidArgumentsError('Not enough arguments specified.')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_length_args(self, args):\n    if len(args) > self.length:\n        raise ArgumentTooLongException\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "validate_choices_args", "docstring": "Check if value of choice arguments is one of the available choices.\n\n:param args: The received arguments.", "ques_id": "6306092e73426c38ae68ad0a", "code": ["def validate_choices_args(self, args):\n    choices = args.get('choices', [])\n    for choice in choices:\n        if choice not in CHOICES:\n            raise UsageError(\n                \"'{}' is an invalid choice (must be one of {})\".format(\n                    choice, CHOICES\n                )\n            )\n", "def validate_choices_args(self, args):\n    choices = args.get('choices', [])\n    if isinstance(choices, list):\n        for choice in choices:\n            if choice not in CHOICES_AVAILABLE_VALUES:\n                raise GraphQLError(\n                    'Missing choice argument \"{}\". Choices are {}.'.format(\n                        choice, ', '.join(CHOICES_AVAILABLE_VALUES)\n                    )\n                )\n    elif choices not in CHOICES_AVAILABLE_VALUES:\n        raise GraphQLError(\n            'Missing choice argument \"{}\". Choices are {}.'.format(\n                choices, ', '.join(CHOICES_AVAILABLE_VALUES)\n            )\n        )\n", "def validate_choices_args(self, args):\n    return all([args['--%s' % key] for key in self.choices])\n", "def validate_choices_args(self, args):\n    if args is None or args not in self.CHOICES:\n        raise ValueError('{} is not a valid choice.'.format(args))\n", "def validate_choices_args(self, args):\n    if args['--choices'] not in self.choices:\n        raise SampleException(\n            'Must be one of {}'.format(self.choices)\n        )\n", "def validate_choices_args(self, args):\n    choices = args.get('choices', '')\n    choices_list = choices.split(',')\n    if len(choices_list) == 1 and not choices_list[0].isdigit():\n        return False\n    return True\n", "def validate_choices_args(self, args):\n    for choice in args:\n        if choice not in self.CHOICES:\n            return False\n    return True\n", "def validate_choices_args(self, args):\n    for choice in args:\n        if choice not in self.CHOICES:\n            raise ValueError(\"Invalid choice '{}'. Choices are {}\"\n                            .format(choice, self.CHOICES))\n", "def validate_choices_args(self, args):\n    choices = args.pop('choices', None)\n    if choices and not isinstance(choices, list):\n        raise InvalidArgument(\"'choices' must be a list\")\n", "def validate_choices_args(self, args):\n    choices = args.pop('choices')\n\n    if not isinstance(choices, list):\n        raise AttributeError(\"'choices' must be a list\")\n\n    for choice in choices:\n        if choice not in self.CHOICES:\n            raise AttributeError(\"'choices' must be one of {}\".format(self.CHOICES))\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_choices_args(self, args):\n    choices = args.get('choices', [])\n    for choice in choices:\n        if choice not in CHOICES:\n            raise UsageError(\n                \"'{}' is an invalid choice (must be one of {})\".format(\n                    choice, CHOICES\n                )\n            )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    choices = args.get('choices', [])\n    if isinstance(choices, list):\n        for choice in choices:\n            if choice not in CHOICES_AVAILABLE_VALUES:\n                raise GraphQLError(\n                    'Missing choice argument \"{}\". Choices are {}.'.format(\n                        choice, ', '.join(CHOICES_AVAILABLE_VALUES)\n                    )\n                )\n    elif choices not in CHOICES_AVAILABLE_VALUES:\n        raise GraphQLError(\n            'Missing choice argument \"{}\". Choices are {}.'.format(\n                choices, ', '.join(CHOICES_AVAILABLE_VALUES)\n            )\n        )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    return all([args['--%s' % key] for key in self.choices])\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    if args is None or args not in self.CHOICES:\n        raise ValueError('{} is not a valid choice.'.format(args))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    if args['--choices'] not in self.choices:\n        raise SampleException(\n            'Must be one of {}'.format(self.choices)\n        )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    choices = args.get('choices', '')\n    choices_list = choices.split(',')\n    if len(choices_list) == 1 and not choices_list[0].isdigit():\n        return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    for choice in args:\n        if choice not in self.CHOICES:\n            return False\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    for choice in args:\n        if choice not in self.CHOICES:\n            raise ValueError(\"Invalid choice '{}'. Choices are {}\"\n                            .format(choice, self.CHOICES))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    choices = args.pop('choices', None)\n    if choices and not isinstance(choices, list):\n        raise InvalidArgument(\"'choices' must be a list\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_choices_args(self, args):\n    choices = args.pop('choices')\n\n    if not isinstance(choices, list):\n        raise AttributeError(\"'choices' must be a list\")\n\n    for choice in choices:\n        if choice not in self.CHOICES:\n            raise AttributeError(\"'choices' must be one of {}\".format(self.CHOICES))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "validate_min_max_args", "docstring": "Check if value of arguments is between minimum and maximum values.\n\n:param args: The received arguments.", "ques_id": "6306092e73426c38ae68ad0b", "code": ["def validate_min_max_args(self, args):\n    if args is None or args is False:\n        return\n\n    if isinstance(args, list) and not isinstance(args, tuple):\n        args = list(args)\n\n    for i in range(len(args)):\n        if not isinstance(args[i], (int, float)):\n            return False\n\n        if args[i] < self.min_value or args[i] > self.max_value:\n            return False\n\n    return True\n", "def validate_min_max_args(self, args):\n    args = list(args)\n\n    if len(args) < 2:\n        raise ValueError(\"Must receive at least two values for min and max\")\n\n    min_val = args[0]\n    max_val = args[1]\n\n    if min_val is not None and min_val < 0:\n        raise ValueError(\"Minimum value for min is a negative number\")\n\n    if max_val is not None and max_val > 0:\n        if len(args) > 2:\n            raise ValueError(\"Cannot receive more than two values for min and max\")\n        if min_val is None:\n            min_val = max_val\n\n    return min_val, max_val\n", "def validate_min_max_args(self, args):\n    if args is None or args == '':\n        return\n\n    min_arg = args.get('min')\n    max_arg = args.get('max')\n    if min_arg is not None and max_arg is not None:\n        if min_arg > max_arg:\n            raise argparse.ArgumentTypeError(\n                'Minimum value for option {} is greater than maximum value '\n                'for option {}.'.format(args.get('name'), args.get('name'))\n            )\n", "def validate_min_max_args(self, args):\n    try:\n        args[0]\n        args[1]\n    except IndexError:\n        raise ValueError(\"Must provide two arguments.\")\n\n    if not self.__validate_range(args[0], args[1]):\n        raise ValueError(\"Argument 0 and 1 must be within the range of the function.\")\n", "def validate_min_max_args(self, args):\n    try:\n        if args[0] < args[1]:\n            raise ValueError\n    except IndexError:\n        raise ValueError(\"Minimum value of arguments must be greater \"\n                         \"than maximum value.\")\n", "def validate_min_max_args(self, args):\n    if args is None:\n        return\n    for arg in args:\n        if not arg >= self._args.min and arg <= self._args.max:\n            raise ValueError(\"Argument '%s' is not between %s and %s\" %\n                             (arg, self._args.min, self._args.max))\n", "def validate_min_max_args(self, args):\n    if args is not None and len(args) > 0:\n        try:\n            for i in args:\n                if not isinstance(i, (int, float)):\n                    raise TypeError\n            for i in args:\n                if i < self.min:\n                    raise ValueError\n                if i > self.max:\n                    raise ValueError\n        except (TypeError, ValueError):\n            raise InvalidArgument(\"Arguments of function must be between {0} and {1}\".format(self.min, self.max))\n", "def validate_min_max_args(self, args):\n    if not args:\n        raise ValueError(\"No arguments provided\")\n\n    if len(args) < 2:\n        raise ValueError(\"Too few arguments provided\")\n\n    min_arg = args[0]\n    max_arg = args[1]\n\n    if min_arg is not None and min_arg > max_arg:\n        raise ValueError(\"Minimum value for argument '{}' is larger than maximum value for argument '{}'\".format(min_arg, max_arg))\n", "def validate_min_max_args(self, args):\n    if args is None:\n        raise exceptions.ArgumentError(\"Missing argument\")\n\n    if isinstance(args, (str, bytes)):\n        raise exceptions.ArgumentError(\"Must be a string\")\n\n    if isinstance(args, list):\n        for item in args:\n            if isinstance(item, (str, bytes)):\n                raise exceptions.ArgumentError(\"Must be a string\")\n\n        return True\n", "def validate_min_max_args(self, args):\n    try:\n        min_val = float(args.get('--min'))\n        max_val = float(args.get('--max'))\n    except ValueError:\n        return False\n    if min_val < min(args.keys()):\n        return False\n    if max_val > max(args.keys()):\n        return False\n    return True\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def validate_min_max_args(self, args):\n    if args is None or args is False:\n        return\n\n    if isinstance(args, list) and not isinstance(args, tuple):\n        args = list(args)\n\n    for i in range(len(args)):\n        if not isinstance(args[i], (int, float)):\n            return False\n\n        if args[i] < self.min_value or args[i] > self.max_value:\n            return False\n\n    return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n    args = list(args)\n\n    if len(args) < 2:\n        raise ValueError(\"Must receive at least two values for min and max\")\n\n    min_val = args[0]\n    max_val = args[1]\n\n    if min_val is not None and min_val < 0:\n        raise ValueError(\"Minimum value for min is a negative number\")\n\n    if max_val is not None and max_val > 0:\n        if len(args) > 2:\n            raise ValueError(\"Cannot receive more than two values for min and max\")\n        if min_val is None:\n            min_val = max_val\n\n    return min_val, max_val\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n    if args is None or args == '':\n        return\n\n    min_arg = args.get('min')\n    max_arg = args.get('max')\n    if min_arg is not None and max_arg is not None:\n        if min_arg > max_arg:\n            raise argparse.ArgumentTypeError(\n                'Minimum value for option {} is greater than maximum value '\n                'for option {}.'.format(args.get('name'), args.get('name'))\n            )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n    try:\n        args[0]\n        args[1]\n    except IndexError:\n        raise ValueError(\"Must provide two arguments.\")\n\n    if not self.__validate_range(args[0], args[1]):\n        raise ValueError(\"Argument 0 and 1 must be within the range of the function.\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n    try:\n        if args[0] < args[1]:\n            raise ValueError\n    except IndexError:\n        raise ValueError(\"Minimum value of arguments must be greater \"\n                         \"than maximum value.\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n    if args is None:\n        return\n    for arg in args:\n        if not arg >= self._args.min and arg <= self._args.max:\n            raise ValueError(\"Argument '%s' is not between %s and %s\" %\n                             (arg, self._args.min, self._args.max))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n    if args is not None and len(args) > 0:\n        try:\n            for i in args:\n                if not isinstance(i, (int, float)):\n                    raise TypeError\n            for i in args:\n                if i < self.min:\n                    raise ValueError\n                if i > self.max:\n                    raise ValueError\n        except (TypeError, ValueError):\n            raise InvalidArgument(\"Arguments of function must be between {0} and {1}\".format(self.min, self.max))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n    if not args:\n        raise ValueError(\"No arguments provided\")\n\n    if len(args) < 2:\n        raise ValueError(\"Too few arguments provided\")\n\n    min_arg = args[0]\n    max_arg = args[1]\n\n    if min_arg is not None and min_arg > max_arg:\n        raise ValueError(\"Minimum value for argument '{}' is larger than maximum value for argument '{}'\".format(min_arg, max_arg))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n    if args is None:\n        raise exceptions.ArgumentError(\"Missing argument\")\n\n    if isinstance(args, (str, bytes)):\n        raise exceptions.ArgumentError(\"Must be a string\")\n\n    if isinstance(args, list):\n        for item in args:\n            if isinstance(item, (str, bytes)):\n                raise exceptions.ArgumentError(\"Must be a string\")\n\n        return True\n", "is_pass": false, "return_code": 1}, {"generate_code": "def validate_min_max_args(self, args):\n    try:\n        min_val = float(args.get('--min'))\n        max_val = float(args.get('--max'))\n    except ValueError:\n        return False\n    if min_val < min(args.keys()):\n        return False\n    if max_val > max(args.keys()):\n        return False\n    return True\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "create_complex_argumet_type", "docstring": "Build the complex argument type\n\n:param subcommand: the command name\n:param type_name: the complex type name\n:param option_name: the option name\n:param spec_option: option's specifications\n:return: the complex type instance", "ques_id": "6306092e73426c38ae68ad0d", "code": ["def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    raise NotImplementedError('Complex argument type build not implemented')\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    raise NotImplementedError('You should not be here.')\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    raise NotImplementedError(self.__class__.__name__ + \": create_complex_argument_type not implemented.\")\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    raise NotImplementedError(\"create_complex_argument_type not implemented\")\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    if'' in option_name:\n        raise InvalidArgumentTypeError(\n            'option_name cannot contain spaces')\n    return ComplexType(subcommand, type_name, option_name, spec_option)\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    raise NotImplementedError(\"create_complex_argument_type not implemented!\")\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    raise NotImplementedError()\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    return ComplexType(subcommand, type_name, option_name, spec_option)\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"Build the complex argument type\n\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    raise NotImplementedError('Must be implemented by subclasses')\n", "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    raise NotImplementedError(\"create_complex_argument_type not implemented\")\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    raise NotImplementedError('Complex argument type build not implemented')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    raise NotImplementedError('You should not be here.')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    raise NotImplementedError(self.__class__.__name__ + \": create_complex_argument_type not implemented.\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    raise NotImplementedError(\"create_complex_argument_type not implemented\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    if'' in option_name:\n        raise InvalidArgumentTypeError(\n            'option_name cannot contain spaces')\n    return ComplexType(subcommand, type_name, option_name, spec_option)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    raise NotImplementedError(\"create_complex_argument_type not implemented!\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    raise NotImplementedError()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    return ComplexType(subcommand, type_name, option_name, spec_option)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"Build the complex argument type\n\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    raise NotImplementedError('Must be implemented by subclasses')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def create_complex_argumet_type(self, subcommand, type_name, option_name,\n                                    spec_option):\n    \"\"\"\n    Build the complex argument type\n    :param subcommand: the command name\n    :param type_name: the complex type name\n    :param option_name: the option name\n    :param spec_option: option's specifications\n    :return: the complex type instance\n    \"\"\"\n    raise NotImplementedError(\"create_complex_argument_type not implemented\")\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "get_nested_custom_and_control_args", "docstring": "Split input arguments to control nested and custom.\n\nControls arguments: control the IR behavior. These arguments\n    will not be put into the spec yml file\nNested arguments: are used by the Ansible playbooks and will be put\n    into the spec yml file.\nCustom arguments: Custom ansible variables to be used instead of the\n    normal nested usage.\n\n:param args: the collected list of args.\n:return: (dict, dict): flat dicts (control_args, nested_args)", "ques_id": "6306092e73426c38ae68ad0f", "code": ["def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for arg in args:\n        if arg.startswith('--') and arg.endswith('='):\n            control_args.update(args[arg])\n        else:\n            nested_args.update({arg: args[arg]})\n\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    custom = {}\n    nested_args = {}\n    for arg in args:\n        if arg.startswith('--') and arg.endswith('='):\n            if '=' in arg:\n                key, value = arg.split('=', 1)\n                nested_args[key] = value\n            else:\n                control = arg\n            nested_args[control] = {}\n        else:\n            custom[arg] = args[arg]\n\n    return (custom, nested_args)\n", "def get_nested_custom_and_control_args(self, args):\n    if 'control' in args:\n        return args['control'], args\n    elif 'nested_args' in args:\n        return args['nested_args'], args\n    else:\n        return None, None\n", "def get_nested_custom_and_control_args(self, args):\n    flat_control_args = {}\n    nested_args = {}\n    for arg in args:\n        if arg.startswith('--') and arg.endswith('='):\n            if arg.split('=', 1)[0] == 'control':\n                nested_args = {arg[2:-1]: arg}\n            else:\n                flat_control_args = {arg[2:-1]: arg}\n        else:\n            nested_args[arg] = args[arg]\n\n    return (flat_control_args, nested_args)\n", "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n\n    for arg in args:\n        if arg[0] == '-':\n            nested_args[arg[1:]] = {}\n        elif arg.startswith('--'):\n            control_args[arg[2:]] = arg[4:]\n        else:\n            return control_args, nested_args\n\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for item in args:\n        if 'control' in item and '{{' not in item['control']:\n            control_args[item['name']] = item['default']\n        if 'nested_args' in item and '{{' not in item['nested_args']:\n            nested_args[item['name']] = item['default']\n    return (control_args, nested_args)\n", "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for arg in args:\n        if arg[0] == '--':\n            control_args.update(arg)\n        elif arg[0] == '-':\n            nested_args.update(arg)\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    if 'custom' in args:\n        custom_args = args['custom']\n        return custom_args, {}\n    return {}, {}\n", "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for arg in args:\n        if arg[0] == '--':\n            nested_args[arg[1:]] = args[arg]\n        else:\n            control_args[arg[1:]] = args[arg]\n\n    return control_args, nested_args\n", "def get_nested_custom_and_control_args(self, args):\n    control_args = dict()\n    nested_args = dict()\n\n    if args is not None:\n        for arg in args:\n            if arg['name'] == '--control':\n                control_args = arg\n            elif arg['name'] == '--nested':\n                nested_args = arg\n    return control_args, nested_args\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for arg in args:\n        if arg.startswith('--') and arg.endswith('='):\n            control_args.update(args[arg])\n        else:\n            nested_args.update({arg: args[arg]})\n\n    return control_args, nested_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    custom = {}\n    nested_args = {}\n    for arg in args:\n        if arg.startswith('--') and arg.endswith('='):\n            if '=' in arg:\n                key, value = arg.split('=', 1)\n                nested_args[key] = value\n            else:\n                control = arg\n            nested_args[control] = {}\n        else:\n            custom[arg] = args[arg]\n\n    return (custom, nested_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    if 'control' in args:\n        return args['control'], args\n    elif 'nested_args' in args:\n        return args['nested_args'], args\n    else:\n        return None, None\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    flat_control_args = {}\n    nested_args = {}\n    for arg in args:\n        if arg.startswith('--') and arg.endswith('='):\n            if arg.split('=', 1)[0] == 'control':\n                nested_args = {arg[2:-1]: arg}\n            else:\n                flat_control_args = {arg[2:-1]: arg}\n        else:\n            nested_args[arg] = args[arg]\n\n    return (flat_control_args, nested_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n\n    for arg in args:\n        if arg[0] == '-':\n            nested_args[arg[1:]] = {}\n        elif arg.startswith('--'):\n            control_args[arg[2:]] = arg[4:]\n        else:\n            return control_args, nested_args\n\n    return control_args, nested_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for item in args:\n        if 'control' in item and '{{' not in item['control']:\n            control_args[item['name']] = item['default']\n        if 'nested_args' in item and '{{' not in item['nested_args']:\n            nested_args[item['name']] = item['default']\n    return (control_args, nested_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for arg in args:\n        if arg[0] == '--':\n            control_args.update(arg)\n        elif arg[0] == '-':\n            nested_args.update(arg)\n    return control_args, nested_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    if 'custom' in args:\n        custom_args = args['custom']\n        return custom_args, {}\n    return {}, {}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    control_args = {}\n    nested_args = {}\n    for arg in args:\n        if arg[0] == '--':\n            nested_args[arg[1:]] = args[arg]\n        else:\n            control_args[arg[1:]] = args[arg]\n\n    return control_args, nested_args\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_nested_custom_and_control_args(self, args):\n    control_args = dict()\n    nested_args = dict()\n\n    if args is not None:\n        for arg in args:\n            if arg['name'] == '--control':\n                control_args = arg\n            elif arg['name'] == '--nested':\n                nested_args = arg\n    return control_args, nested_args\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/settings.py", "project": "redhat-openstack/infrared", "name": "merge_extra_vars", "docstring": "Extend ``vars_dict`` with ``extra-vars``\n\n:param vars_dict: Dictionary to merge extra-vars into\n:param extra_vars: List of extra-vars", "ques_id": "6306092e73426c38ae68ad11", "code": ["def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(vars_dict, dict):\n        for key, val in vars_dict.items():\n            if key not in extra_vars:\n                extra_vars.append(key)\n                vars_dict[key] = val\n    elif isinstance(vars_dict, list):\n        for i, var in enumerate(vars_dict):\n            if i < len(extra_vars):\n                vars_dict[i] = vars_dict[i] + extra_vars[i]\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if vars_dict is None:\n        return extra_vars\n\n    result = vars_dict.copy()\n    for extra_var in extra_vars:\n        result.update(extra_var)\n\n    return result\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    for extra_var in extra_vars:\n        if extra_var not in vars_dict:\n            vars_dict[extra_var] = dict()\n\n        vars_dict = vars_dict[extra_var]\n\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    vars_dict.update(dict(extra_vars))\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if 'all' in vars_dict:\n        return vars_dict\n\n    return dict(vars_dict.items() + extra_vars)\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(vars_dict, dict):\n        for key in vars_dict:\n            if key not in extra_vars:\n                extra_vars.append(key)\n                vars_dict[key] = vars_dict[key]\n\n    return vars_dict, extra_vars\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if '_extra-vars' not in vars_dict:\n        vars_dict['_extra-vars'] = extra_vars\n    elif vars_dict['_extra-vars']!= extra_vars:\n        raise AnsibleParserError(\n            'extra-vars in variables dict does not match existing extra-vars',\n            obj=vars_dict,\n            extra_vars=extra_vars,\n        )\n\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if 'ansible_ssh_connection_string' not in vars_dict:\n        return vars_dict\n\n    vars_dict.update(dict(\n        ansible_ssh_connection_string=vars_dict['ansible_ssh_connection_string'],\n        ansible_ssh_user=vars_dict.get('ansible_ssh_user', None),\n        ansible_ssh_private_key_file=vars_dict.get('ansible_ssh_private_key_file', None),\n        ansible_ssh_extra_vars=extra_vars,\n    ))\n\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    for extra_var in extra_vars:\n        if extra_var not in vars_dict:\n            vars_dict.update(extra_var)\n\n    return vars_dict\n", "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(vars_dict, dict):\n        for key, value in vars_dict.items():\n            if key not in extra_vars:\n                vars_dict[key] = value\n            else:\n                vars_dict[key] = vars_dict[key] + extra_vars[key]\n\n    return vars_dict\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(vars_dict, dict):\n        for key, val in vars_dict.items():\n            if key not in extra_vars:\n                extra_vars.append(key)\n                vars_dict[key] = val\n    elif isinstance(vars_dict, list):\n        for i, var in enumerate(vars_dict):\n            if i < len(extra_vars):\n                vars_dict[i] = vars_dict[i] + extra_vars[i]\n    return vars_dict\n", "is_pass": true, "return_code": 0}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if vars_dict is None:\n        return extra_vars\n\n    result = vars_dict.copy()\n    for extra_var in extra_vars:\n        result.update(extra_var)\n\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    for extra_var in extra_vars:\n        if extra_var not in vars_dict:\n            vars_dict[extra_var] = dict()\n\n        vars_dict = vars_dict[extra_var]\n\n    return vars_dict\n", "is_pass": true, "return_code": 0}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    vars_dict.update(dict(extra_vars))\n    return vars_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if 'all' in vars_dict:\n        return vars_dict\n\n    return dict(vars_dict.items() + extra_vars)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(vars_dict, dict):\n        for key in vars_dict:\n            if key not in extra_vars:\n                extra_vars.append(key)\n                vars_dict[key] = vars_dict[key]\n\n    return vars_dict, extra_vars\n", "is_pass": false, "return_code": 1}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if '_extra-vars' not in vars_dict:\n        vars_dict['_extra-vars'] = extra_vars\n    elif vars_dict['_extra-vars']!= extra_vars:\n        raise AnsibleParserError(\n            'extra-vars in variables dict does not match existing extra-vars',\n            obj=vars_dict,\n            extra_vars=extra_vars,\n        )\n\n    return vars_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if 'ansible_ssh_connection_string' not in vars_dict:\n        return vars_dict\n\n    vars_dict.update(dict(\n        ansible_ssh_connection_string=vars_dict['ansible_ssh_connection_string'],\n        ansible_ssh_user=vars_dict.get('ansible_ssh_user', None),\n        ansible_ssh_private_key_file=vars_dict.get('ansible_ssh_private_key_file', None),\n        ansible_ssh_extra_vars=extra_vars,\n    ))\n\n    return vars_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    for extra_var in extra_vars:\n        if extra_var not in vars_dict:\n            vars_dict.update(extra_var)\n\n    return vars_dict\n", "is_pass": true, "return_code": 0}, {"generate_code": "def merge_extra_vars(vars_dict, extra_vars=None):\n    if extra_vars is None:\n        extra_vars = []\n\n    if isinstance(vars_dict, dict):\n        for key, value in vars_dict.items():\n            if key not in extra_vars:\n                vars_dict[key] = value\n            else:\n                vars_dict[key] = vars_dict[key] + extra_vars[key]\n\n    return vars_dict\n", "is_pass": true, "return_code": 0}]}
{"file_path": "infrared/core/execute.py", "project": "redhat-openstack/infrared", "name": "ansible_playbook", "docstring": "Wraps the 'ansible-playbook' CLI.\n\n:param ir_workspace: An Infrared Workspace object represents the active\nworkspace\n:param ir_plugin: An InfraredPlugin object of the current plugin\n:param playbook_path: the playbook to invoke\n:param verbose: Ansible verbosity level\n:param extra_vars: dict. Passed to Ansible as extra-vars\n:param ansible_args: dict of ansible-playbook arguments to plumb down\n    directly to Ansible.", "ques_id": "6306092f73426c38ae68ad13", "code": ["def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    # Get the playbook path to execute\n    playbook_path = os.path.expanduser(playbook_path)\n\n    # Get the command to execute\n    command = [\n        'ansible-playbook',\n        '-vvvv', '-i', playbook_path,\n        '--inventory-file', ir_workspace.inventory_file,\n        '--verbosity', str(verbose),\n        '--extra-vars', extra_vars or {},\n    ]\n\n    # Pass the extra_vars dictionary to the caller\n    comman", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    workspace_path = ir_workspace.get_absolute_path(ir_plugin)\n    ansible_path = os.path.join(workspace_path, playbook_path)\n    return ansible.playbook.Runner(ir_workspace, ansible_path,\n                                  extra_vars=extra_vars,\n                                  ansible_args=ansible_args,\n                                  verbose=verbose)\n", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    playbook = ir_workspace.get_plugin(ir_plugin).get_playbook(\n        playbook_path, extra_vars=extra_vars, ansible_args=ansible_args)\n\n    # We need to pass the playbook object to the ansible runner to run\n    # it, so we can use the 'eval' decorator to import the plugin and pass it\n    # to the ansible runner.\n    exit_status, output = call_ansible_runner(\n        playbook, verbose=verbose, extra_vars=extra_vars, ansible_args=ansible_args)\n\n    return output", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    playbook_path = os.path.abspath(playbook_path)\n    ir_workspace = ir_workspace.get_path()\n    verbose = verbose or ir_plugin.verbose\n    extra_vars = extra_vars or ir_plugin.extra_vars\n    ansible_args = ansible_args or ir_plugin.ansible_args\n\n    command = [\n        'ansible-playbook',\n        '-w', ir_workspace,\n        '-p', ir_plugin.playbook_dir,\n        '--inventory', ir_workspace,\n        playbook_path,\n    ", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    # pylint: disable=too-many-arguments\n    return _ansible_runner(ir_workspace, ir_plugin, playbook_path, verbose,\n                          extra_vars=extra_vars, ansible_args=ansible_args)\n", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down directly\n        to Ansible.\n    \"\"\"\n    # pylint: disable=no-member\n    runner = Runner(ir_workspace, ir_plugin, ansible_args, verbose=verbose)\n    runner.run(playbook_path, extra_vars=extra_vars)\n", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down directly\n        to Ansible.\n    \"\"\"\n    # Create the playbook\n    playbook = ir_workspace.get_plugin(ir_plugin).get_ansible_playbook(\n        playbook_path=playbook_path, ansible_args=ansible_args,\n        extra_vars=extra_vars)\n\n    # Run the playbook\n    ir_workspace.run_playbook(playbook, verbose=verbose, extra_vars=extra_vars)\n", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    # Make sure the plugin is loaded and working directory exists\n    ir_workspace.get_plugin(ir_plugin).ensure_workdir()\n\n    # Run the playbook\n    playbook_instance = ir_workspace.get_plugin(ir_plugin).get_playbook_instance(\n        playbook_path, verbose=verbose, extra_vars=extra_vars,\n        ansible_args=ansible_args)\n\n    if playbook_instance is None:\n        return 1\n\n    # Run the playbook\n    try:\n        playbook_instance.run()\n    except KeyboardInterrupt:\n", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down directly\n        to Ansible.\n    \"\"\"\n    # Get the path to the playbook\n    playbook_file_path = os.path.join(\n        ir_workspace.ir_plugin_dirs.playbook_dir, playbook_path)\n\n    # Run the playbook\n    with utils.chdir(ir_workspace.ir_plugin_dirs.ansible_cwd):\n        cmd = utils.get_ansible_command(\n            playbook_file_path,\n            ir_plugin=ir_plugin,\n            extra_vars=extra_vars,\n            ansible_args=ansible_args,\n   ", "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    # Run the playbook\n    result = ir_workspace.run_playbook(\n        playbook_path=playbook_path,\n        extra_vars=extra_vars,\n        ansible_args=ansible_args,\n        verbose=verbose,\n        extra_vars_dict=extra_vars,\n        )\n\n    # Check for failure and return the results\n    if result.return_code!= 0:\n        raise AnsibleRunnerError(\"Failed to execute playbook: {}\".format(result.stdout))\n"], "level": "file_runnable", "generate_results": [{"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    # Get the playbook path to execute\n    playbook_path = os.path.expanduser(playbook_path)\n\n    # Get the command to execute\n    command = [\n        'ansible-playbook',\n        '-vvvv', '-i', playbook_path,\n        '--inventory-file', ir_workspace.inventory_file,\n        '--verbosity', str(verbose),\n        '--extra-vars', extra_vars or {},\n    ]\n\n    # Pass the extra_vars dictionary to the caller\n    comman", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    workspace_path = ir_workspace.get_absolute_path(ir_plugin)\n    ansible_path = os.path.join(workspace_path, playbook_path)\n    return ansible.playbook.Runner(ir_workspace, ansible_path,\n                                  extra_vars=extra_vars,\n                                  ansible_args=ansible_args,\n                                  verbose=verbose)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    playbook = ir_workspace.get_plugin(ir_plugin).get_playbook(\n        playbook_path, extra_vars=extra_vars, ansible_args=ansible_args)\n\n    # We need to pass the playbook object to the ansible runner to run\n    # it, so we can use the 'eval' decorator to import the plugin and pass it\n    # to the ansible runner.\n    exit_status, output = call_ansible_runner(\n        playbook, verbose=verbose, extra_vars=extra_vars, ansible_args=ansible_args)\n\n    return output", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    playbook_path = os.path.abspath(playbook_path)\n    ir_workspace = ir_workspace.get_path()\n    verbose = verbose or ir_plugin.verbose\n    extra_vars = extra_vars or ir_plugin.extra_vars\n    ansible_args = ansible_args or ir_plugin.ansible_args\n\n    command = [\n        'ansible-playbook',\n        '-w', ir_workspace,\n        '-p', ir_plugin.playbook_dir,\n        '--inventory', ir_workspace,\n        playbook_path,\n    ", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    # pylint: disable=too-many-arguments\n    return _ansible_runner(ir_workspace, ir_plugin, playbook_path, verbose,\n                          extra_vars=extra_vars, ansible_args=ansible_args)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down directly\n        to Ansible.\n    \"\"\"\n    # pylint: disable=no-member\n    runner = Runner(ir_workspace, ir_plugin, ansible_args, verbose=verbose)\n    runner.run(playbook_path, extra_vars=extra_vars)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down directly\n        to Ansible.\n    \"\"\"\n    # Create the playbook\n    playbook = ir_workspace.get_plugin(ir_plugin).get_ansible_playbook(\n        playbook_path=playbook_path, ansible_args=ansible_args,\n        extra_vars=extra_vars)\n\n    # Run the playbook\n    ir_workspace.run_playbook(playbook, verbose=verbose, extra_vars=extra_vars)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    # Make sure the plugin is loaded and working directory exists\n    ir_workspace.get_plugin(ir_plugin).ensure_workdir()\n\n    # Run the playbook\n    playbook_instance = ir_workspace.get_plugin(ir_plugin).get_playbook_instance(\n        playbook_path, verbose=verbose, extra_vars=extra_vars,\n        ansible_args=ansible_args)\n\n    if playbook_instance is None:\n        return 1\n\n    # Run the playbook\n    try:\n        playbook_instance.run()\n    except KeyboardInterrupt:\n", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down directly\n        to Ansible.\n    \"\"\"\n    # Get the path to the playbook\n    playbook_file_path = os.path.join(\n        ir_workspace.ir_plugin_dirs.playbook_dir, playbook_path)\n\n    # Run the playbook\n    with utils.chdir(ir_workspace.ir_plugin_dirs.ansible_cwd):\n        cmd = utils.get_ansible_command(\n            playbook_file_path,\n            ir_plugin=ir_plugin,\n            extra_vars=extra_vars,\n            ansible_args=ansible_args,\n   ", "is_pass": false, "return_code": 1}, {"generate_code": "def ansible_playbook(ir_workspace, ir_plugin, playbook_path, verbose=None,\n                     extra_vars=None, ansible_args=None):\n    \"\"\"\n    Wraps the 'ansible-playbook' CLI.\n\n    :param ir_workspace: An InfraredWorkspace object represents the active\n        workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :param playbook_path: the playbook to invoke\n    :param verbose: Ansible verbosity\n    :param extra_vars: dict. Passed to Ansible as extra-vars\n    :param ansible_args: dict of ansible-playbook arguments to plumb down\n        directly to Ansible.\n    \"\"\"\n    # Run the playbook\n    result = ir_workspace.run_playbook(\n        playbook_path=playbook_path,\n        extra_vars=extra_vars,\n        ansible_args=ansible_args,\n        verbose=verbose,\n        extra_vars_dict=extra_vars,\n        )\n\n    # Check for failure and return the results\n    if result.return_code!= 0:\n        raise AnsibleRunnerError(\"Failed to execute playbook: {}\".format(result.stdout))\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/execute.py", "project": "redhat-openstack/infrared", "name": "_run_playbook", "docstring": "Runs ansible cli with vars dict\n\n:param vars_dict: dict, Will be passed as Ansible extra-vars\n:param cli_args: the list  of command line arguments\n:param ir_workspace: An Infrared Workspace object represents the active\n workspace\n:param ir_plugin: An InfraredPlugin object of the current plugin\n:return: ansible results", "ques_id": "6306093273426c38ae68ad15", "code": ["def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    ansible_results = AnsibleResults()\n\n    # Check if we are being run from local or from a remote host\n    if ir_workspace.is_remote:\n        # Run the playbook locally\n        ansible_results.playbook = ir_plugin.playbook_local\n        ansible_results.stdout = ir_plugin.playbook_output\n        ansible_results.stderr = ir_plugin.playbook_error\n        ansible_results.return_code = 1\n    else:\n        # Run the playbook remotely\n        ansible_results.playbook = ir_plugin.playbook_remote\n        ansible_results.hosts = ir_workspace.hosts\n        ansible_results.ir_plugin = ir_plugin\n        ansible_results.ir_workspace = ir_workspace\n        ansible_results.ir_plugin._vars_dict = vars_dict\n        ansible_results.stdout = ir_plugin.playbook_output\n        ansible_results.stderr = ir_plugin.playbook_error\n        ansible_results.r", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    if ir_workspace.check_running():\n        return ir_workspace.run_playbook(cli_args, vars_dict, ir_plugin)\n    else:\n        raise exceptions.InfrastructureError('The infrared workspace is not running.')\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    ansible_vars = dict()\n    ansible_vars.update(vars_dict)\n    ansible_vars['ansible_extra_vars'] = cli_args\n    ansible_vars['ir_workspace'] = ir_workspace\n    ansible_vars['ir_plugin'] = ir_plugin\n    result = ir_plugin.ansible.run(playbook_path=cli_args['playbook_path'], inventory=ir_workspace.inventory,\n                                   extra_vars=ansible_vars)\n    return result\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    # Initialize the ansible plugin instance\n    ir_plugin_inst = ir_plugin(cli_args, ir_workspace, ir_plugin.playbook_name)\n\n    # Initialize the variables dict\n    ansible_vars = vars_dict.copy()\n\n    # If the plugin is configured, initialize the variables dict for the plugin\n    if ir_plugin_inst.config:\n        ir_plugin_inst.config.update_vars(ansible_vars)\n\n    # Run the ansible plugin with the variables dict and the initialized plugin\n    return ir_plugin_inst.ansible_playbook(cli_args, ir_workspace, ir_plugin.playbook_name, vars_dict, ir_workspace)\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    # type: (dict, dict, InfraredWorkspace, InfraredPlugin) -> dict\n    \"\"\"\n    Runs an ansible cli with vars dict\n\n    :param vars_dict: dict, Will be passed as Ansible extra-vars\n    :param cli_args: the list of command line arguments\n    :param ir_workspace: An InfraredWorkspace object representing the active workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :return: ansible results\n    \"\"\"\n    ansible_vars = dict(vars_dict)\n    ansible_vars.update(ir_workspace.ansible_vars)\n    ansible_vars.update(ir_plugin.ansible_vars)\n    ansible_vars.update({\n        'ansible_extra_vars': ansible_vars,\n    })\n\n    return cli_args, run_ansible_playbook(cli_args, vars_dict, ir_workspace, ir_plugin)\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    ansible_vars = vars_dict.copy()\n    ansible_vars.update(ir_workspace=ir_workspace, ir_plugin=ir_plugin)\n\n    return AnsibleRunner(cli_args=cli_args, ansible_vars=ansible_vars)\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    # type: (dict, dict, InfraredWorkspace, InfraredPlugin) -> dict\n    \"\"\"\n    Runs ansible cli with vars dict\n    :param vars_dict: dict, Will be passed as Ansible extra-vars\n    :param cli_args: the list of command line arguments\n    :param ir_workspace: An InfraredWorkspace object represnents the active workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :return: an ansible result\n    \"\"\"\n    result = {}\n    result['result'] = None\n    result['changed'] = False\n    result['rc'] = 0\n\n    result = ansible_runner.run(\n        ansible_runner.AnsibleRunner(\n            vars_dict,\n            ir_workspace=ir_workspace,\n            ir_plugin=ir_plugin,\n            cli_args=cli_args,\n        ),\n        workers=ir_workspace.num_cores\n    )\n\n    return result\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    ansible_args = []\n    for arg in cli_args:\n        ansible_args.extend(shlex.split(arg))\n\n    results = {}\n    try:\n        results = ir_plugin.run(ansible_args, vars_dict)\n    except AnsibleRunnerException as exc:\n        results = exc.results\n    return results\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    ansible_runner = Runner(ir_workspace, ir_plugin)\n    results = ansible_runner.run_playbook(cli_args=cli_args)\n    return results\n", "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    # type: (dict, dict, InfraredWorkspace, InfraredPlugin) -> dict\n    \"\"\"\n    Runs an ansible cli with vars dict\n\n    :param vars_dict: dict, Will be passed as Ansible extra-vars\n    :param cli_args: the list of command line arguments\n    :param ir_workspace: An InfraredWorkspace object represents the active workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :return: ansible results\n    \"\"\"\n    ansible_result = cli_args.copy()\n    ansible_result.update(vars_dict)\n    ansible_result['ir_workspace'] = ir_workspace\n    ansible_result['ir_plugin'] = ir_plugin\n    ansible_result['ansible_plugin'] = ir_plugin.__class__.__name__\n    ansible_result['ir_executor'] = ir_workspace.ir_executor.name\n    ansible_result['ir_replay_log_path'] = ir_workspace.ir_replay_log_path\n    ansible_result['ir_exec_results_dir'] = ir_workspace.ir_exec_results_dir\n    ansible"], "level": "project_runnable", "generate_results": [{"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    ansible_results = AnsibleResults()\n\n    # Check if we are being run from local or from a remote host\n    if ir_workspace.is_remote:\n        # Run the playbook locally\n        ansible_results.playbook = ir_plugin.playbook_local\n        ansible_results.stdout = ir_plugin.playbook_output\n        ansible_results.stderr = ir_plugin.playbook_error\n        ansible_results.return_code = 1\n    else:\n        # Run the playbook remotely\n        ansible_results.playbook = ir_plugin.playbook_remote\n        ansible_results.hosts = ir_workspace.hosts\n        ansible_results.ir_plugin = ir_plugin\n        ansible_results.ir_workspace = ir_workspace\n        ansible_results.ir_plugin._vars_dict = vars_dict\n        ansible_results.stdout = ir_plugin.playbook_output\n        ansible_results.stderr = ir_plugin.playbook_error\n        ansible_results.r", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    if ir_workspace.check_running():\n        return ir_workspace.run_playbook(cli_args, vars_dict, ir_plugin)\n    else:\n        raise exceptions.InfrastructureError('The infrared workspace is not running.')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    ansible_vars = dict()\n    ansible_vars.update(vars_dict)\n    ansible_vars['ansible_extra_vars'] = cli_args\n    ansible_vars['ir_workspace'] = ir_workspace\n    ansible_vars['ir_plugin'] = ir_plugin\n    result = ir_plugin.ansible.run(playbook_path=cli_args['playbook_path'], inventory=ir_workspace.inventory,\n                                   extra_vars=ansible_vars)\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    # Initialize the ansible plugin instance\n    ir_plugin_inst = ir_plugin(cli_args, ir_workspace, ir_plugin.playbook_name)\n\n    # Initialize the variables dict\n    ansible_vars = vars_dict.copy()\n\n    # If the plugin is configured, initialize the variables dict for the plugin\n    if ir_plugin_inst.config:\n        ir_plugin_inst.config.update_vars(ansible_vars)\n\n    # Run the ansible plugin with the variables dict and the initialized plugin\n    return ir_plugin_inst.ansible_playbook(cli_args, ir_workspace, ir_plugin.playbook_name, vars_dict, ir_workspace)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    # type: (dict, dict, InfraredWorkspace, InfraredPlugin) -> dict\n    \"\"\"\n    Runs an ansible cli with vars dict\n\n    :param vars_dict: dict, Will be passed as Ansible extra-vars\n    :param cli_args: the list of command line arguments\n    :param ir_workspace: An InfraredWorkspace object representing the active workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :return: ansible results\n    \"\"\"\n    ansible_vars = dict(vars_dict)\n    ansible_vars.update(ir_workspace.ansible_vars)\n    ansible_vars.update(ir_plugin.ansible_vars)\n    ansible_vars.update({\n        'ansible_extra_vars': ansible_vars,\n    })\n\n    return cli_args, run_ansible_playbook(cli_args, vars_dict, ir_workspace, ir_plugin)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    ansible_vars = vars_dict.copy()\n    ansible_vars.update(ir_workspace=ir_workspace, ir_plugin=ir_plugin)\n\n    return AnsibleRunner(cli_args=cli_args, ansible_vars=ansible_vars)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    # type: (dict, dict, InfraredWorkspace, InfraredPlugin) -> dict\n    \"\"\"\n    Runs ansible cli with vars dict\n    :param vars_dict: dict, Will be passed as Ansible extra-vars\n    :param cli_args: the list of command line arguments\n    :param ir_workspace: An InfraredWorkspace object represnents the active workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :return: an ansible result\n    \"\"\"\n    result = {}\n    result['result'] = None\n    result['changed'] = False\n    result['rc'] = 0\n\n    result = ansible_runner.run(\n        ansible_runner.AnsibleRunner(\n            vars_dict,\n            ir_workspace=ir_workspace,\n            ir_plugin=ir_plugin,\n            cli_args=cli_args,\n        ),\n        workers=ir_workspace.num_cores\n    )\n\n    return result\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    ansible_args = []\n    for arg in cli_args:\n        ansible_args.extend(shlex.split(arg))\n\n    results = {}\n    try:\n        results = ir_plugin.run(ansible_args, vars_dict)\n    except AnsibleRunnerException as exc:\n        results = exc.results\n    return results\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    ansible_runner = Runner(ir_workspace, ir_plugin)\n    results = ansible_runner.run_playbook(cli_args=cli_args)\n    return results\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _run_playbook(cli_args, vars_dict, ir_workspace, ir_plugin):\n    # type: (dict, dict, InfraredWorkspace, InfraredPlugin) -> dict\n    \"\"\"\n    Runs an ansible cli with vars dict\n\n    :param vars_dict: dict, Will be passed as Ansible extra-vars\n    :param cli_args: the list of command line arguments\n    :param ir_workspace: An InfraredWorkspace object represents the active workspace\n    :param ir_plugin: An InfraredPlugin object of the current plugin\n    :return: ansible results\n    \"\"\"\n    ansible_result = cli_args.copy()\n    ansible_result.update(vars_dict)\n    ansible_result['ir_workspace'] = ir_workspace\n    ansible_result['ir_plugin'] = ir_plugin\n    ansible_result['ansible_plugin'] = ir_plugin.__class__.__name__\n    ansible_result['ir_executor'] = ir_workspace.ir_executor.name\n    ansible_result['ir_replay_log_path'] = ir_workspace.ir_replay_log_path\n    ansible_result['ir_exec_results_dir'] = ir_workspace.ir_exec_results_dir\n    ansible", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/inspector/inspector.py", "project": "redhat-openstack/infrared", "name": "_convert_non_cli_args", "docstring": "Casts arguments to correct types by modifying values_dict param.\n\nBy default all the values are strings.\n\n:param parser_name: The command name, e.g. main, virsh, ospd, etc\n:param values_dict: The dict of with arguments", "ques_id": "63060ada73426c38ae68ad31", "code": ["def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if type(value) == type([]):\n            values_dict[key] = [str(i) for i in value]\n        elif type(value) == type({}):\n            values_dict[key] = {\n                key: str(value[key]) if key in value else \"\"\n            }\n        elif type(value) == type(None):\n            values_dict[key] = \"\"\n        elif type(value) == int:\n            values_dict[key] = \"%d\" % value\n        elif type(value) == float:\n            values_dict[key] = \"%f\" % value\n        elif type(value) == bool:\n            values_dict[key] = \"%s\" % value\n        elif type(value) == list:\n            values_dict[key] = \",\".join([str(i) for i in value])\n        elif type(value) == dict:\n ", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for k, v in values_dict.items():\n        if isinstance(v, str):\n            values_dict[k] = {'value': v}\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if key.startswith(parser_name + '_'):\n            if isinstance(value, str):\n                values_dict[key] = value.strip()\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in iteritems(values_dict):\n        if key.startswith(parser_name + '_'):\n            if isinstance(value, (list, tuple)):\n                values_dict[key] = [str(item) for item in value]\n            else:\n                values_dict[key] = str(value)\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if key in ['--help']:\n            values_dict[key] = \"[all]\"\n        elif key in ['--key']:\n            values_dict[key] = value\n        elif isinstance(value, str):\n            values_dict[key] = \"'{}'\".format(value)\n        elif isinstance(value, list):\n            values_dict[key] = \"[{}]\".format(\", \".join(value))\n        elif isinstance(value, dict):\n            values_dict[key] = \"{}\".format(\", \".join([\"'{}': '{}'\".format(key, value) for value in value.items()]))\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if isinstance(value, str):\n            values_dict[key] = value.replace('\\n','')\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if key in [\"--tag\", \"--only-show-keys\", \"--no-keys\"]:\n            values_dict[key] = value.replace(\" \", \"\").lower()\n        elif key == \"--key\":\n            if value == \"all\":\n                values_dict[key] = None\n            else:\n                values_dict[key] = value\n        elif key == \"--values\":\n            if value == \"all\":\n                values_dict[key] = None\n            else:\n                values_dict[key] = value\n        elif key in [\"--filter\", \"--show-values\"]:\n            values_dict[key] = value.split(\",\")\n        elif key == \"--select\":\n            values_dict[key] = value\n        elif key == \"--no-select\":\n     ", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if isinstance(value, str):\n            values_dict[key] = [value]\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for k, v in values_dict.items():\n        if type(v) is not str:\n            values_dict[k] = str(v)\n", "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key in values_dict:\n        if key in ('boot_device', 'force', 'no_reboot'):\n            values_dict[key] = str(values_dict[key])\n        elif key in ('timeout','retries'):\n            values_dict[key] = int(values_dict[key])\n        elif key in ('mount_path', 'fs_type','readonly', 'no_wait'):\n            values_dict[key] = values_dict[key] == 'on'\n        elif key in ('remote_host','remote_user'):\n            values_dict[key] = values_dict[key] == 'root'\n        elif key in ('wait', 'wait_timeout'):\n            values_dict[key] = values_dict[key] == '5'\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if type(value) == type([]):\n            values_dict[key] = [str(i) for i in value]\n        elif type(value) == type({}):\n            values_dict[key] = {\n                key: str(value[key]) if key in value else \"\"\n            }\n        elif type(value) == type(None):\n            values_dict[key] = \"\"\n        elif type(value) == int:\n            values_dict[key] = \"%d\" % value\n        elif type(value) == float:\n            values_dict[key] = \"%f\" % value\n        elif type(value) == bool:\n            values_dict[key] = \"%s\" % value\n        elif type(value) == list:\n            values_dict[key] = \",\".join([str(i) for i in value])\n        elif type(value) == dict:\n ", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for k, v in values_dict.items():\n        if isinstance(v, str):\n            values_dict[k] = {'value': v}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if key.startswith(parser_name + '_'):\n            if isinstance(value, str):\n                values_dict[key] = value.strip()\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in iteritems(values_dict):\n        if key.startswith(parser_name + '_'):\n            if isinstance(value, (list, tuple)):\n                values_dict[key] = [str(item) for item in value]\n            else:\n                values_dict[key] = str(value)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if key in ['--help']:\n            values_dict[key] = \"[all]\"\n        elif key in ['--key']:\n            values_dict[key] = value\n        elif isinstance(value, str):\n            values_dict[key] = \"'{}'\".format(value)\n        elif isinstance(value, list):\n            values_dict[key] = \"[{}]\".format(\", \".join(value))\n        elif isinstance(value, dict):\n            values_dict[key] = \"{}\".format(\", \".join([\"'{}': '{}'\".format(key, value) for value in value.items()]))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if isinstance(value, str):\n            values_dict[key] = value.replace('\\n','')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if key in [\"--tag\", \"--only-show-keys\", \"--no-keys\"]:\n            values_dict[key] = value.replace(\" \", \"\").lower()\n        elif key == \"--key\":\n            if value == \"all\":\n                values_dict[key] = None\n            else:\n                values_dict[key] = value\n        elif key == \"--values\":\n            if value == \"all\":\n                values_dict[key] = None\n            else:\n                values_dict[key] = value\n        elif key in [\"--filter\", \"--show-values\"]:\n            values_dict[key] = value.split(\",\")\n        elif key == \"--select\":\n            values_dict[key] = value\n        elif key == \"--no-select\":\n     ", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key, value in values_dict.items():\n        if isinstance(value, str):\n            values_dict[key] = [value]\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for k, v in values_dict.items():\n        if type(v) is not str:\n            values_dict[k] = str(v)\n", "is_pass": false, "return_code": 1}, {"generate_code": "def _convert_non_cli_args(self, parser_name, values_dict):\n    for key in values_dict:\n        if key in ('boot_device', 'force', 'no_reboot'):\n            values_dict[key] = str(values_dict[key])\n        elif key in ('timeout','retries'):\n            values_dict[key] = int(values_dict[key])\n        elif key in ('mount_path', 'fs_type','readonly', 'no_wait'):\n            values_dict[key] = values_dict[key] == 'on'\n        elif key in ('remote_host','remote_user'):\n            values_dict[key] = values_dict[key] == 'root'\n        elif key in ('wait', 'wait_timeout'):\n            values_dict[key] = values_dict[key] == '5'\n", "is_pass": false, "return_code": 1}]}
{"file_path": "tests/test_plugins.py", "project": "redhat-openstack/infrared", "name": "get_plugin_spec_flatten_dict", "docstring": "Creates a flat dict from the plugin spec\n\n:param plugin_dir: A path to the plugin's dir\n:return: A flatten dictionary contains the plugin's properties", "ques_id": "63060b1a73426c38ae68ad3e", "code": ["def get_plugin_spec_flatten_dict(plugin_dir):\n    return {key: value for sub_dict in [get_plugin_spec_flatten_dict(os.path.join(plugin_dir, x)) for x in os.listdir(plugin_dir) if os.path.isdir(os.path.join(plugin_dir, x))] for key, value in sub_dict.items()}\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    return {key: value for sub_dict in [get_plugin_spec_flatten_dict(os.path.join(plugin_dir, key)) for key in os.listdir(plugin_dir)] for value in sub_dict.values()}\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    return {\n        \"name\": None,\n        \"version\": None,\n        \"description\": None,\n        \"author\": None,\n        \"author_email\": None,\n        \"url\": None,\n        \"dependencies\": [],\n        \"install_requires\": [],\n        \"tests\": [],\n        \"install_modules\": [],\n        \"optional\": False,\n        \"tags\": []\n    }\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    return dict((key, value) for key, value in get_plugin_spec_flatten_items(plugin_dir))\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    return {\n        \"plugin_type\": get_plugin_type(plugin_dir),\n        \"plugin_dir\": plugin_dir,\n        \"plugin_name\": get_plugin_name(plugin_dir),\n        \"plugin_version\": get_plugin_version(plugin_dir),\n        \"plugin_author\": get_plugin_author(plugin_dir),\n        \"plugin_author_email\": get_plugin_author_email(plugin_dir),\n        \"author\": get_plugin_author(plugin_dir),\n        \"author_email\": get_plugin_author_email(plugin_dir),\n        \"description\": get_plugin_description(plugin_dir),\n        \"dependencies\": get_plugin_dependencies(plugin_dir),\n        \"dependencies_links\": get_plugin_dependencies_links(plugin_dir),\n        \"install_command\": get_plugin_install_command(plugin_dir),\n        \"install_command_email\": get_plugin_install_command_email(plugin_dir),\n        \"install_command_name\": get_plugin_install_command_name(plugin_dir),\n        \"install_command_version\": get_plugin_install_command_version(plugin_dir),\n        \"install_command_author\": get_plugin_install_command_author(plugin_dir),\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    flat_dict = {}\n    for (dirpath, dirnames, filenames) in os.walk(plugin_dir):\n        for filename in filenames:\n            if filename.endswith('.py'):\n                file_path = os.path.join(dirpath, filename)\n                try:\n                    spec_dict = utils.load_py_file(file_path)\n                    flat_dict.update(spec_dict)\n                except Exception as e:\n                    log.debug('Unable to load plugin specification file %s: %s', file_path, e)\n    return flat_dict\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    return flatten_dict({\n        key: value for key, value in get_plugin_spec_flatten_dict(plugin_dir).items()\n        if not key.startswith(\"_\")\n    })\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    return flatten_dict({\n        PLUGIN_NAME: plugin_dir,\n        PLUGIN_TYPE: PLUGIN_NAME,\n        PLUGIN_NAMESPACE: PLUGIN_NAMESPACE,\n        PLUGIN_CLASS: PLUGIN_NAME,\n        PLUGIN_VERSION: '',\n        PLUGIN_URL: '',\n        PLUGIN_AUTHOR: '',\n        PLUGIN_AUTHOR_EMAIL: '',\n        PLUGIN_AUTHOR_EMAIL_EMAIL: '',\n        PLUGIN_AUTHOR_EMAIL_EMAIL: '',\n        PLUGIN_DESCRIPTION: '',\n        PLUGIN_DESCRIPTION_EMAIL: '',\n        PLUGIN_LONG_DESCRIPTION: '',\n        PLUGIN_LONG_DESCRIPTION_EMAIL: '',\n        PLUGIN_RELEASE: '',\n        PLUGIN_RELEASE_EMAIL: '',\n        PLUGIN_RELEASE_EMAIL_EMAIL: '',\n        PLUGIN_RELEASE_EMAIL_EMAIL: '',\n        PLUGIN_RELEASE_EMAIL_EMAIL_EMAIL: '',\n        PLUGIN_AUTHOR_EMAIL: ", "def get_plugin_spec_flatten_dict(plugin_dir):\n    return {\n        'type': 'flat_dict',\n        'value': {\n            'path': plugin_dir,\n            'template_path': os.path.join(plugin_dir, 'templates'),\n            'variables': {}\n        }\n    }\n", "def get_plugin_spec_flatten_dict(plugin_dir):\n    return {key: value for sublist in [glob.glob(os.path.join(plugin_dir, \"{}.*\".format(key))) for key in PLUGINS_KEYS] for value in sublist}\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    return {key: value for sub_dict in [get_plugin_spec_flatten_dict(os.path.join(plugin_dir, x)) for x in os.listdir(plugin_dir) if os.path.isdir(os.path.join(plugin_dir, x))] for key, value in sub_dict.items()}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    return {key: value for sub_dict in [get_plugin_spec_flatten_dict(os.path.join(plugin_dir, key)) for key in os.listdir(plugin_dir)] for value in sub_dict.values()}\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    return {\n        \"name\": None,\n        \"version\": None,\n        \"description\": None,\n        \"author\": None,\n        \"author_email\": None,\n        \"url\": None,\n        \"dependencies\": [],\n        \"install_requires\": [],\n        \"tests\": [],\n        \"install_modules\": [],\n        \"optional\": False,\n        \"tags\": []\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    return dict((key, value) for key, value in get_plugin_spec_flatten_items(plugin_dir))\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    return {\n        \"plugin_type\": get_plugin_type(plugin_dir),\n        \"plugin_dir\": plugin_dir,\n        \"plugin_name\": get_plugin_name(plugin_dir),\n        \"plugin_version\": get_plugin_version(plugin_dir),\n        \"plugin_author\": get_plugin_author(plugin_dir),\n        \"plugin_author_email\": get_plugin_author_email(plugin_dir),\n        \"author\": get_plugin_author(plugin_dir),\n        \"author_email\": get_plugin_author_email(plugin_dir),\n        \"description\": get_plugin_description(plugin_dir),\n        \"dependencies\": get_plugin_dependencies(plugin_dir),\n        \"dependencies_links\": get_plugin_dependencies_links(plugin_dir),\n        \"install_command\": get_plugin_install_command(plugin_dir),\n        \"install_command_email\": get_plugin_install_command_email(plugin_dir),\n        \"install_command_name\": get_plugin_install_command_name(plugin_dir),\n        \"install_command_version\": get_plugin_install_command_version(plugin_dir),\n        \"install_command_author\": get_plugin_install_command_author(plugin_dir),\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    flat_dict = {}\n    for (dirpath, dirnames, filenames) in os.walk(plugin_dir):\n        for filename in filenames:\n            if filename.endswith('.py'):\n                file_path = os.path.join(dirpath, filename)\n                try:\n                    spec_dict = utils.load_py_file(file_path)\n                    flat_dict.update(spec_dict)\n                except Exception as e:\n                    log.debug('Unable to load plugin specification file %s: %s', file_path, e)\n    return flat_dict\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    return flatten_dict({\n        key: value for key, value in get_plugin_spec_flatten_dict(plugin_dir).items()\n        if not key.startswith(\"_\")\n    })\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    return flatten_dict({\n        PLUGIN_NAME: plugin_dir,\n        PLUGIN_TYPE: PLUGIN_NAME,\n        PLUGIN_NAMESPACE: PLUGIN_NAMESPACE,\n        PLUGIN_CLASS: PLUGIN_NAME,\n        PLUGIN_VERSION: '',\n        PLUGIN_URL: '',\n        PLUGIN_AUTHOR: '',\n        PLUGIN_AUTHOR_EMAIL: '',\n        PLUGIN_AUTHOR_EMAIL_EMAIL: '',\n        PLUGIN_AUTHOR_EMAIL_EMAIL: '',\n        PLUGIN_DESCRIPTION: '',\n        PLUGIN_DESCRIPTION_EMAIL: '',\n        PLUGIN_LONG_DESCRIPTION: '',\n        PLUGIN_LONG_DESCRIPTION_EMAIL: '',\n        PLUGIN_RELEASE: '',\n        PLUGIN_RELEASE_EMAIL: '',\n        PLUGIN_RELEASE_EMAIL_EMAIL: '',\n        PLUGIN_RELEASE_EMAIL_EMAIL: '',\n        PLUGIN_RELEASE_EMAIL_EMAIL_EMAIL: '',\n        PLUGIN_AUTHOR_EMAIL: ", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    return {\n        'type': 'flat_dict',\n        'value': {\n            'path': plugin_dir,\n            'template_path': os.path.join(plugin_dir, 'templates'),\n            'variables': {}\n        }\n    }\n", "is_pass": false, "return_code": 1}, {"generate_code": "def get_plugin_spec_flatten_dict(plugin_dir):\n    return {key: value for sublist in [glob.glob(os.path.join(plugin_dir, \"{}.*\".format(key))) for key in PLUGINS_KEYS] for value in sublist}\n", "is_pass": false, "return_code": 1}]}
{"file_path": "infrared/core/services/ansible_config.py", "project": "redhat-openstack/infrared", "name": "inject_config", "docstring": "Set the environment variable for config path, if it is undefined.", "ques_id": "63060b1b73426c38ae68ad42", "code": ["def inject_config(self):\n    if 'CONFIG_PATH' not in os.environ:\n        os.environ['CONFIG_PATH'] = ''\n", "def inject_config(self):\n    env = {}\n    if 'PYOXIDIZER_CONFIG' in os.environ:\n        env['PYOXIDIZER_CONFIG'] = os.environ['PYOXIDIZER_CONFIG']\n    return env\n", "def inject_config(self):\n    if 'CONFIG_PATH' not in os.environ:\n        os.environ['CONFIG_PATH'] = ''\n", "def inject_config(self):\n    env_config_path = os.environ.get('MYPROGRAM_CONFIG', None)\n\n    if env_config_path is None:\n        env_config_path = os.path.join(os.path.expanduser('~'), '.myprog', 'config.yml')\n\n    if not os.path.isfile(env_config_path):\n        env_config_path = os.path.join(os.path.expanduser('~'), '.myprog', 'config.yml')\n\n    os.environ['MYPROGRAM_CONFIG'] = env_config_path\n", "def inject_config(self):\n    if 'CONFIG_PATH' not in os.environ:\n        os.environ['CONFIG_PATH'] = ''\n", "def inject_config(self):\n    if not self.cfg_path:\n        return\n\n    os.environ['CONFIG_PATH'] = self.cfg_path\n", "def inject_config(self):\n    env_vars = dict(os.environ)\n\n    try:\n        del env_vars['CONFIG']\n    except KeyError:\n        pass\n\n    os.environ = env_vars\n", "def inject_config(self):\n    if not os.getenv(\"CONFIG_PATH\"):\n        os.environ[\"CONFIG_PATH\"] = \"\"\n", "def inject_config(self):\n    env = {}\n    config_path = os.environ.get('MYPROGRAM_CONFIG', '.')\n    if config_path:\n        env['MYPROGRAM_CONFIG'] = config_path\n    return env\n", "def inject_config(self):\n    if not os.environ.get('CONFIG'):\n        os.environ['CONFIG'] = '/etc/hal/hal.conf'\n"], "level": "class_runnable", "generate_results": [{"generate_code": "def inject_config(self):\n    if 'CONFIG_PATH' not in os.environ:\n        os.environ['CONFIG_PATH'] = ''\n", "is_pass": true, "return_code": 0}, {"generate_code": "def inject_config(self):\n    env = {}\n    if 'PYOXIDIZER_CONFIG' in os.environ:\n        env['PYOXIDIZER_CONFIG'] = os.environ['PYOXIDIZER_CONFIG']\n    return env\n", "is_pass": false, "return_code": 1}, {"generate_code": "def inject_config(self):\n    if 'CONFIG_PATH' not in os.environ:\n        os.environ['CONFIG_PATH'] = ''\n", "is_pass": true, "return_code": 0}, {"generate_code": "def inject_config(self):\n    env_config_path = os.environ.get('MYPROGRAM_CONFIG', None)\n\n    if env_config_path is None:\n        env_config_path = os.path.join(os.path.expanduser('~'), '.myprog', 'config.yml')\n\n    if not os.path.isfile(env_config_path):\n        env_config_path = os.path.join(os.path.expanduser('~'), '.myprog', 'config.yml')\n\n    os.environ['MYPROGRAM_CONFIG'] = env_config_path\n", "is_pass": true, "return_code": 0}, {"generate_code": "def inject_config(self):\n    if 'CONFIG_PATH' not in os.environ:\n        os.environ['CONFIG_PATH'] = ''\n", "is_pass": true, "return_code": 0}, {"generate_code": "def inject_config(self):\n    if not self.cfg_path:\n        return\n\n    os.environ['CONFIG_PATH'] = self.cfg_path\n", "is_pass": false, "return_code": 1}, {"generate_code": "def inject_config(self):\n    env_vars = dict(os.environ)\n\n    try:\n        del env_vars['CONFIG']\n    except KeyError:\n        pass\n\n    os.environ = env_vars\n", "is_pass": true, "return_code": 0}, {"generate_code": "def inject_config(self):\n    if not os.getenv(\"CONFIG_PATH\"):\n        os.environ[\"CONFIG_PATH\"] = \"\"\n", "is_pass": true, "return_code": 0}, {"generate_code": "def inject_config(self):\n    env = {}\n    config_path = os.environ.get('MYPROGRAM_CONFIG', '.')\n    if config_path:\n        env['MYPROGRAM_CONFIG'] = config_path\n    return env\n", "is_pass": false, "return_code": 1}, {"generate_code": "def inject_config(self):\n    if not os.environ.get('CONFIG'):\n        os.environ['CONFIG'] = '/etc/hal/hal.conf'\n", "is_pass": true, "return_code": 0}]}
{"file_path": "infrared/main.py", "project": "redhat-openstack/infrared", "name": "extend_cli", "docstring": "Adds the spec cli options to to the main entry point.\n\n:param subparser: the subparser object to extend.", "ques_id": "63060b1b73426c38ae68ad43", "code": ["def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('spec', help='display spec information')\n    parser.add_argument('--all', action='store_true',\n                        help='display all package information')\n    parser.add_argument('package', nargs='?', default=None,\n                        help='package to display information for')\n    parser.add_argument('--filter', nargs='?', default=None,\n                        help='filter query results by package')\n", "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser(\n        \"deploy\",\n        help=\"Deploy a new codereview to GitHub\")\n    parser.add_argument(\n        \"--scm\", default=\"git\", help=\"The git repo to deploy to\")\n    parser.add_argument(\n        \"--branch\", default=\"master\", help=\"The name of the git branch\")\n    parser.add_argument(\n        \"--commit\", default=\"master\", help=\"The name of the git commit\")\n    parser.add_argument(\n        \"--token\", default=\"\", help=\"The GitHub API token to use\")\n", "def extend_cli(self, root_subparsers):\n    pass\n", "def extend_cli(self, root_subparsers):\n    pass\n", "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('config', help='configure the API keys')\n    parser.add_argument('--api-key', default=None, required=False,\n                        help='The API key to use.')\n    parser.add_argument('--user', default=None, required=False,\n                        help='The username to use.')\n    parser.add_argument('--password', default=None, required=False,\n                        help='The password to use.')\n    parser.add_argument('--sandbox', default=False, action='store_true',\n                        help='Whether to use Sandbox mode.')\n", "def extend_cli(self, root_subparsers):\n    pass\n", "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('config', help='configure the project')\n    parser.add_argument('--license', required=False, help='the license name')\n    parser.add_argument('--clean', action='store_true', help='run cleanup steps')\n    parser.add_argument('--remote', action='store_true', help='run remote steps')\n    parser.add_argument('--dry-run', action='store_true', help='do not make changes')\n    parser.add_argument('--no-color', action='store_true', help='do not colorize output')\n    parser.add_argument('--verbose', action='store_true', help='be more verbose')\n    parser.add_argument('--version', action='store_true', help='show the version number')\n    parser.add_argument('--src', action='store', help='source code')\n    parser.add_argument('--external', action='store_true', help='run an external build step')\n", "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser(\n        'update',\n        help='update a spec file based on a schema',\n        )\n\n    parser.add_argument(\n        'file',\n        nargs='?',\n        metavar='FILE',\n        help='the file to be updated',\n        )\n\n    parser.add_argument(\n        '--schema',\n        action='store',\n        dest='schema',\n        metavar='SCHEMA',\n        default='spec.yaml',\n        help='the YAML schema file to use for the spec file',\n        )\n\n    parser.set_defaults(\n        func=update,\n        )\n", "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('cloud-init',\n                                       help='Manage Cloud-init configuration',\n                                       description=self.__doc__)\n\n    parser.add_argument('--update-cfg',\n                        action='store_true',\n                        help='Update the Cloud-init configuration files',\n                        dest='update_cfg')\n\n    parser.add_argument('--update-ssh',\n                        action='store_true',\n                        help='Update the Cloud-init ssh key pair files',\n                        dest='update_ssh')\n\n    parser.add_argument('--update-key',\n                        action='store_true',\n            ", "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('install', help='install a new package')\n    parser.add_argument('package_name', help='the package to be installed')\n    parser.add_argument('--upgrade', action='store_true', help='upgrade the package')\n    parser.add_argument('--remove', action='store_true', help='remove the package from the package list')\n"], "level": "project_runnable", "generate_results": [{"generate_code": "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('spec', help='display spec information')\n    parser.add_argument('--all', action='store_true',\n                        help='display all package information')\n    parser.add_argument('package', nargs='?', default=None,\n                        help='package to display information for')\n    parser.add_argument('--filter', nargs='?', default=None,\n                        help='filter query results by package')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser(\n        \"deploy\",\n        help=\"Deploy a new codereview to GitHub\")\n    parser.add_argument(\n        \"--scm\", default=\"git\", help=\"The git repo to deploy to\")\n    parser.add_argument(\n        \"--branch\", default=\"master\", help=\"The name of the git branch\")\n    parser.add_argument(\n        \"--commit\", default=\"master\", help=\"The name of the git commit\")\n    parser.add_argument(\n        \"--token\", default=\"\", help=\"The GitHub API token to use\")\n", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('config', help='configure the API keys')\n    parser.add_argument('--api-key', default=None, required=False,\n                        help='The API key to use.')\n    parser.add_argument('--user', default=None, required=False,\n                        help='The username to use.')\n    parser.add_argument('--password', default=None, required=False,\n                        help='The password to use.')\n    parser.add_argument('--sandbox', default=False, action='store_true',\n                        help='Whether to use Sandbox mode.')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    pass\n", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('config', help='configure the project')\n    parser.add_argument('--license', required=False, help='the license name')\n    parser.add_argument('--clean', action='store_true', help='run cleanup steps')\n    parser.add_argument('--remote', action='store_true', help='run remote steps')\n    parser.add_argument('--dry-run', action='store_true', help='do not make changes')\n    parser.add_argument('--no-color', action='store_true', help='do not colorize output')\n    parser.add_argument('--verbose', action='store_true', help='be more verbose')\n    parser.add_argument('--version', action='store_true', help='show the version number')\n    parser.add_argument('--src', action='store', help='source code')\n    parser.add_argument('--external', action='store_true', help='run an external build step')\n", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser(\n        'update',\n        help='update a spec file based on a schema',\n        )\n\n    parser.add_argument(\n        'file',\n        nargs='?',\n        metavar='FILE',\n        help='the file to be updated',\n        )\n\n    parser.add_argument(\n        '--schema',\n        action='store',\n        dest='schema',\n        metavar='SCHEMA',\n        default='spec.yaml',\n        help='the YAML schema file to use for the spec file',\n        )\n\n    parser.set_defaults(\n        func=update,\n        )\n", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('cloud-init',\n                                       help='Manage Cloud-init configuration',\n                                       description=self.__doc__)\n\n    parser.add_argument('--update-cfg',\n                        action='store_true',\n                        help='Update the Cloud-init configuration files',\n                        dest='update_cfg')\n\n    parser.add_argument('--update-ssh',\n                        action='store_true',\n                        help='Update the Cloud-init ssh key pair files',\n                        dest='update_ssh')\n\n    parser.add_argument('--update-key',\n                        action='store_true',\n            ", "is_pass": false, "return_code": 1}, {"generate_code": "def extend_cli(self, root_subparsers):\n    parser = root_subparsers.add_parser('install', help='install a new package')\n    parser.add_argument('package_name', help='the package to be installed')\n    parser.add_argument('--upgrade', action='store_true', help='upgrade the package')\n    parser.add_argument('--remove', action='store_true', help='remove the package from the package list')\n", "is_pass": false, "return_code": 1}]}
